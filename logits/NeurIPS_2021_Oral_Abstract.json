{"notes": [{"id": "IVV1putQ90", "original": "CeybBEQmDWX", "number": 11644, "cdate": 1621630300124, "mdate": null, "ddate": null, "tcdate": 1623678891201, "tmdate": 1683307769470, "tddate": null, "forum": "IVV1putQ90", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Latent Equilibrium: A unified learning theory for arbitrarily fast computation with arbitrarily slow neurons", "authorids": ["~Paul_Haider1", "~Benjamin_Ellenberger1", "~Laura_Kriener1", "~Jakob_Jordan1", "~Walter_Senn1", "~Mihai_A._Petrovici1"], "authors": ["Paul Haider", "Benjamin Ellenberger", "Laura Kriener", "Jakob Jordan", "Walter Senn", "Mihai A. Petrovici"], "keywords": ["dynamical systems", "cortical microcircuits", "deep learning", "prospective coding", "noise robustness", "synaptic plasticity"], "TL;DR": "A unified theory of neuronal dynamics and synaptic plasticity that solves the relaxation problem in networks with slow components.", "abstract": "The response time of physical computational elements is finite, and neurons are no exception. In hierarchical models of cortical networks each layer thus introduces a response lag. This inherent property of physical dynamical systems results in delayed processing of stimuli and causes a timing mismatch between network output and instructive signals, thus afflicting not only inference, but also learning. We introduce Latent Equilibrium, a new framework for inference and learning in networks of slow components which avoids these issues by harnessing the ability of biological neurons to phase-advance their output with respect to their membrane potential. This principle enables quasi-instantaneous inference independent of network depth and avoids the need for phased plasticity or computationally expensive network relaxation phases. We jointly derive disentangled neuron and synapse dynamics from a prospective energy function that depends on a network's generalized position and momentum. The resulting model can be interpreted as a biologically plausible approximation of error backpropagation in deep cortical networks with continuous-time, leaky neuronal dynamics and continuously active, local plasticity. We demonstrate successful learning of standard benchmark datasets, achieving competitive performance using both fully-connected and convolutional architectures, and show how our principle can be applied to detailed models of cortical microcircuitry. Furthermore, we study the robustness of our model to spatio-temporal substrate imperfections to demonstrate its feasibility for physical realization, be it in vivo or in silico.", "pdf": "/pdf/c82f75335413f843eead877e1adba102440b1697.pdf", "supplementary_material": "/attachment/f657d77c2358b7a02292d5d8622a3a4c671d9296.pdf", "submission_history": "", "checklist": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "haider|latent_equilibrium_a_unified_learning_theory_for_arbitrarily_fast_computation_with_arbitrarily_slow_neurons", "code": "https://github.com/unibe-cns/le_NeurIPS_code", "thumbnail": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nhaider2021latent,\ntitle={Latent Equilibrium: A unified learning theory for arbitrarily fast computation with arbitrarily slow neurons},\nauthor={Paul Haider and Benjamin Ellenberger and Laura Kriener and Jakob Jordan and Walter Senn and Mihai A. Petrovici},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=IVV1putQ90}\n}", "venue": "NeurIPS 2021 Oral", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "pdate": 1636492688258, "odate": 1636492688213, "details": {"replyCount": 11}}, {"id": "Kvb0482Ysaf", "original": "gkOrajBMkl7", "number": 5209, "cdate": 1621630157707, "mdate": null, "ddate": null, "tcdate": 1623678675685, "tmdate": 1683307718162, "tddate": null, "forum": "Kvb0482Ysaf", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Sequential Causal Imitation Learning with Unobserved Confounders", "authorids": ["~Daniel_Kumor1", "~Junzhe_Zhang3", "~Elias_Bareinboim2"], "authors": ["Daniel Kumor", "Junzhe Zhang", "Elias Bareinboim"], "keywords": ["causality", "reinforcement learning", "imitation"], "TL;DR": "We provide a complete graphical condition for determining feasibility of sequential imitation in the presence of latent confounding", "abstract": "\"Monkey see monkey do\" is an age-old adage, referring to naive imitation without a deep understanding of a system's underlying mechanics. Indeed, if a demonstrator has access to information unavailable to the imitator (monkey), such as a different set of sensors, then no matter how perfectly the imitator models its perceived environment (See), attempting to directly reproduce the demonstrator's behavior (Do) can lead to poor outcomes. Imitation learning in the presence of a mismatch between demonstrator and imitator has been studied in the literature under the rubric of causal imitation learning  (Zhang et. al. 2020), but existing solutions are limited to single-stage decision-making. This paper investigates the problem of causal imitation learning in sequential settings, where the imitator must make multiple decisions per episode. We develop a graphical criterion that is both necessary and sufficient for determining the feasibility of causal imitation, providing conditions when an imitator can match a demonstrator's performance despite differing capabilities. Finally, we provide an efficient algorithm for determining imitability, and corroborate our theory with simulations.", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "kumor|sequential_causal_imitation_learning_with_unobserved_confounders", "pdf": "/pdf/21b08dd1baaebd5e95e14749e617abdc0b6eb30b.pdf", "checklist": "", "supplementary_material": "", "thumbnail": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nkumor2021sequential,\ntitle={Sequential Causal Imitation Learning with Unobserved Confounders},\nauthor={Daniel Kumor and Junzhe Zhang and Elias Bareinboim},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=Kvb0482Ysaf}\n}", "venue": "NeurIPS 2021 Oral", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "pdate": 1636492702564, "odate": 1636492702522, "details": {"replyCount": 11}}, {"id": "kt_s_ZbYvtP", "original": "YRvHkod9Toq", "number": 770, "cdate": 1621630010383, "mdate": null, "ddate": null, "tcdate": 1623678436745, "tmdate": 1683307654877, "tddate": null, "forum": "kt_s_ZbYvtP", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Causal Identification with Matrix Equations", "authorids": ["~Sanghack_Lee1", "~Elias_Bareinboim2"], "authors": ["Sanghack Lee", "Elias Bareinboim"], "keywords": ["Causal Inference", "Causal Effect Identifiability", "Causal Effect", "Causality"], "abstract": "Causal effect identification is concerned with determining whether a causal effect is computable from a combination of qualitative assumptions about the underlying system (e.g., a causal graph) and distributions collected from this system. Many identification algorithms exclusively rely on graphical criteria made of a non-trivial combination of probability axioms, do-calculus, and refined c-factorization (e.g., Lee & Bareinboim, 2020). In a sequence of increasingly sophisticated results, it has been shown how proxy variables can be used to identify certain effects that would not be otherwise recoverable in challenging scenarios through solving matrix equations (e.g., Kuroki & Pearl, 2014; Miao et al., 2018). In this paper, we develop a new causal identification algorithm which utilizes both graphical criteria and matrix equations. Specifically, we first characterize the relationships between certain graphically-driven formulae and matrix multiplications. With such characterizations, we broaden the spectrum of proxy variable based identification conditions and further propose novel intermediary criteria based on the pseudoinverse of a matrix. Finally, we devise a causal effect identification algorithm, which accepts as input a collection of marginal, conditional, and interventional distributions, integrating enriched matrix-based criteria into a graphical identification approach.", "submission_history": "", "submission_history_-_venue_and_year": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "lee|causal_identification_with_matrix_equations", "pdf": "/pdf/189f8958bbfbba71e46f2676147685619d2918e2.pdf", "submission_history_-_improvements_made": "", "checklist": "", "supplementary_material": "", "thumbnail": "", "_bibtex": "@inproceedings{\nlee2021causal,\ntitle={Causal Identification with Matrix Equations},\nauthor={Sanghack Lee and Elias Bareinboim},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=kt_s_ZbYvtP}\n}", "venue": "NeurIPS 2021 Oral", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "pdate": 1636492736183, "odate": 1636492736141, "details": {"replyCount": 9}}, {"id": "UVQNdLIELSU", "original": "NInLOoOG4SOA", "number": 4670, "cdate": 1621629930633, "mdate": null, "ddate": null, "tcdate": 1623678294010, "tmdate": 1697937575938, "tddate": null, "forum": "UVQNdLIELSU", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Replacing Rewards with Examples: Example-Based Policy Search via Recursive Classification", "authorids": ["~Benjamin_Eysenbach1", "~Sergey_Levine1", "~Ruslan_Salakhutdinov1"], "authors": ["Benjamin Eysenbach", "Sergey Levine", "Ruslan Salakhutdinov"], "keywords": ["reinforcement learning", "example-based control"], "TL;DR": "A method for solving RL tasks using examples of desired outcomes, rather than reward functions, that significantly outperforms prior methods.", "abstract": "Reinforcement learning (RL) algorithms assume that users specify tasks by manually writing down a reward function. However, this process can be laborious and demands considerable technical expertise. Can we devise RL algorithms that instead enable users to specify tasks simply by providing examples of successful outcomes? In this paper, we derive a control algorithm that maximizes the future probability of these successful outcome examples. Prior work has approached similar problems with a two-stage process, first learning a reward function and then optimizing this reward function using another reinforcement learning algorithm. In contrast, our method directly learns a value function from transitions and successful outcomes, without learning this intermediate reward function. Our method therefore requires fewer hyperparameters to tune and lines of code to debug. We show that our method satisfies a new data-driven Bellman equation, where examples take the place of the typical reward function term. Experiments show that our approach outperforms prior methods that learn explicit reward functions.", "submission_history": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "checklist": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "eysenbach|replacing_rewards_with_examples_examplebased_policy_search_via_recursive_classification", "pdf": "/pdf/37163f48314b5ccf57ec2a1bb100b3202e3e8da7.pdf", "supplementary_material": "/attachment/a3ba0581ee0ebd65b5628e1a59e0fd58a29b9680.pdf", "code": "https://github.com/google-research/google-research/tree/master/rce", "thumbnail": "", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2103.12656/code)", "_bibtex": "@inproceedings{\neysenbach2021replacing,\ntitle={Replacing Rewards with Examples: Example-Based Policy Search via Recursive Classification},\nauthor={Benjamin Eysenbach and Sergey Levine and Ruslan Salakhutdinov},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=UVQNdLIELSU}\n}", "venue": "NeurIPS 2021 Oral", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "pdate": 1636492716577, "odate": 1636492716521, "details": {"replyCount": 9}}, {"id": "kwN2xvZ2XZ9", "original": "kMmS01qdtz", "number": 40, "cdate": 1621629676567, "mdate": null, "ddate": null, "tcdate": 1623677877009, "tmdate": 1683307516987, "tddate": null, "forum": "kwN2xvZ2XZ9", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Learning Frequency Domain Approximation for Binary Neural Networks", "authorids": ["~Yixing_Xu2", "~Kai_Han2", "~Chang_Xu4", "~Yehui_Tang1", "~Chunjing_Xu1", "~Yunhe_Wang1"], "authors": ["Yixing Xu", "Kai Han", "Chang Xu", "Yehui Tang", "Chunjing Xu", "Yunhe Wang"], "keywords": ["binary neural network", "frequency domain approximation", "fourier series", "noise"], "TL;DR": "Using sine module and noise adaptation module to approximate sign function in BNN.", "abstract": "Binary neural networks (BNNs) represent original full-precision weights and activations into 1-bit with sign function. Since the gradient of the conventional sign function is almost zero everywhere which cannot be used for back-propagation, several attempts have been proposed to alleviate the optimization difficulty by using approximate gradient. However, those approximations corrupt the main direction of factual gradient. To this end, we propose to estimate the gradient of sign function in the Fourier frequency domain using the combination of sine functions for training BNNs, namely frequency domain approximation (FDA). The proposed approach does not affect the low-frequency information of the original sign function which occupies most of the overall energy, and high-frequency coefficients will be ignored to avoid the huge computational overhead. In addition, we embed a noise adaptation module into the training phase to compensate the approximation error. The experiments on several benchmark datasets and neural architectures illustrate that the binary network learned using our method achieves the state-of-the-art accuracy. Code will be available at https://gitee.com/mindspore/models/tree/master/research/cv/FDA-BNN.", "pdf": "/pdf/f5135d3e420519d972d3b45e686042b4e02d82f9.pdf", "submission_history": "", "checklist": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "xu|learning_frequency_domain_approximation_for_binary_neural_networks", "thumbnail": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nxu2021learning,\ntitle={Learning Frequency Domain Approximation for Binary Neural Networks},\nauthor={Yixing Xu and Kai Han and Chang Xu and Yehui Tang and Chunjing Xu and Yunhe Wang},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=kwN2xvZ2XZ9}\n}", "venue": "NeurIPS 2021 Oral", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "pdate": 1636492682108, "odate": 1636492682060, "details": {"replyCount": 7}}, {"id": "bYi_2708mKK", "original": "bQICaU1tTFSy", "number": 10778, "cdate": 1621630300182, "ddate": null, "tcdate": 1621630300182, "tmdate": 1697937341592, "tddate": null, "forum": "bYi_2708mKK", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Retiring Adult: New Datasets for Fair Machine Learning", "authorids": ["~Frances_Ding1", "~Moritz_Hardt1", "~John_Miller1", "~Ludwig_Schmidt1"], "authors": ["Frances Ding", "Moritz Hardt", "John Miller", "Ludwig Schmidt"], "keywords": ["UCI Adult", "datasets", "benchmarks", "Census data", "fairness", "archaeology", "fair machine learning"], "abstract": "Although the fairness community has recognized the importance of data, researchers in the area primarily rely on UCI Adult when it comes to tabular data. Derived from a 1994 US Census survey, this dataset has appeared in hundreds of research papers where it served as the basis for the development and comparison of many algorithmic fairness interventions. We reconstruct a superset of the UCI Adult data from available US Census sources and reveal idiosyncrasies of the UCI Adult dataset that limit its external validity. Our primary contribution is a suite of new datasets derived from US Census surveys that extend the existing data ecosystem for research on fair machine learning. We create prediction tasks relating to income, employment, health, transportation, and housing. The data span multiple years and all states of the United States, allowing researchers to study temporal shift and geographic variation. We highlight a broad initial sweep of new empirical insights relating to trade-offs between fairness criteria, performance of algorithmic interventions, and the role of distribution shift based on our new datasets. Our findings inform ongoing debates, challenge some existing narratives, and point to future research directions.", "pdf": "/pdf/7e36cfca29cbc967d99f1facac7506bc28e6829c.pdf", "supplementary_material": "/attachment/c7d5fa722b967425bc866d861ef9d3ffd95e6bcd.pdf", "submission_history": "", "checklist": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "ding|retiring_adult_new_datasets_for_fair_machine_learning", "code": "https://github.com/zykls/folktables", "thumbnail": "", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 2 code implementations](https://www.catalyzex.com/paper/arxiv:2108.04884/code)", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nding2021retiring,\ntitle={Retiring Adult: New Datasets for Fair Machine Learning},\nauthor={Frances Ding and Moritz Hardt and John Miller and Ludwig Schmidt},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=bYi_2708mKK}\n}", "venue": "NeurIPS 2021 Oral", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492783712, "odate": 1636492783712, "details": {"replyCount": 11}}, {"id": "an8FSGbuCw", "original": "CeybBEQmDWX", "number": 10777, "cdate": 1621630300124, "ddate": null, "tcdate": 1621630300124, "tmdate": 1683307769470, "tddate": null, "forum": "an8FSGbuCw", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Latent Equilibrium: A unified learning theory for arbitrarily fast computation with arbitrarily slow neurons", "authorids": ["~Paul_Haider1", "~Benjamin_Ellenberger1", "~Laura_Kriener1", "~Jakob_Jordan1", "~Walter_Senn1", "~Mihai_A._Petrovici1"], "authors": ["Paul Haider", "Benjamin Ellenberger", "Laura Kriener", "Jakob Jordan", "Walter Senn", "Mihai A. Petrovici"], "keywords": ["dynamical systems", "cortical microcircuits", "deep learning", "prospective coding", "noise robustness", "synaptic plasticity"], "TL;DR": "A unified theory of neuronal dynamics and synaptic plasticity that solves the relaxation problem in networks with slow components.", "abstract": "The response time of physical computational elements is finite, and neurons are no exception. In hierarchical models of cortical networks each layer thus introduces a response lag. This inherent property of physical dynamical systems results in delayed processing of stimuli and causes a timing mismatch between network output and instructive signals, thus afflicting not only inference, but also learning. We introduce Latent Equilibrium, a new framework for inference and learning in networks of slow components which avoids these issues by harnessing the ability of biological neurons to phase-advance their output with respect to their membrane potential. This principle enables quasi-instantaneous inference independent of network depth and avoids the need for phased plasticity or computationally expensive network relaxation phases. We jointly derive disentangled neuron and synapse dynamics from a prospective energy function that depends on a network's generalized position and momentum. The resulting model can be interpreted as a biologically plausible approximation of error backpropagation in deep cortical networks with continuous-time, leaky neuronal dynamics and continuously active, local plasticity. We demonstrate successful learning of standard benchmark datasets, achieving competitive performance using both fully-connected and convolutional architectures, and show how our principle can be applied to detailed models of cortical microcircuitry. Furthermore, we study the robustness of our model to spatio-temporal substrate imperfections to demonstrate its feasibility for physical realization, be it in vivo or in silico.", "pdf": "/pdf/c82f75335413f843eead877e1adba102440b1697.pdf", "supplementary_material": "/attachment/f657d77c2358b7a02292d5d8622a3a4c671d9296.pdf", "submission_history": "", "checklist": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "haider|latent_equilibrium_a_unified_learning_theory_for_arbitrarily_fast_computation_with_arbitrarily_slow_neurons", "code": "https://github.com/unibe-cns/le_NeurIPS_code", "thumbnail": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nhaider2021latent,\ntitle={Latent Equilibrium: A unified learning theory for arbitrarily fast computation with arbitrarily slow neurons},\nauthor={Paul Haider and Benjamin Ellenberger and Laura Kriener and Jakob Jordan and Walter Senn and Mihai A. Petrovici},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=an8FSGbuCw}\n}", "venue": "NeurIPS 2021 Oral", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492688258, "odate": 1636492688213, "details": {"replyCount": 14}}, {"id": "AzmEMstdf3o", "original": "9s06WPjtaca", "number": 10708, "cdate": 1621630296096, "ddate": null, "tcdate": 1621630296096, "tmdate": 1683307768297, "tddate": null, "forum": "AzmEMstdf3o", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Passive attention in artificial neural networks predicts human visual selectivity", "authorids": ["~Thomas_A_Langlois1", "~Haicheng_Charles_Zhao2", "~Erin_Grant1", "~Ishita_Dasgupta1", "~Thomas_L._Griffiths1", "~Nori_Jacoby1"], "authors": ["Thomas A Langlois", "Haicheng Charles Zhao", "Erin Grant", "Ishita Dasgupta", "Thomas L. Griffiths", "Nori Jacoby"], "keywords": ["Cognition", "Attention", "Interpretable AI", "Computer Vision", "Human Visual Perception"], "TL;DR": "We compare ANNs to humans using attention visualization techniques. We find that gradient-based attention visualizations obtained from a select class of networks predict human attention and saliency estimates derived from 6 distinct behavioral tasks.", "abstract": "Developments in machine learning interpretability techniques over the past decade have provided new tools to observe the image regions that are most informative for classification and localization in artificial neural networks (ANNs). Are the same regions similarly informative to human observers? Using data from 79 new experiments and 7,810 participants, we show that passive attention techniques reveal a significant overlap with human visual selectivity estimates derived from 6 distinct behavioral tasks including visual discrimination, spatial localization, recognizability, free-viewing, cued-object search, and saliency search fixations. We find that input visualizations derived from relatively simple ANN architectures probed using guided backpropagation methods are the best predictors of a shared component in the joint variability of the human measures. We validate these correlational results with causal manipulations using recognition experiments. We show that images masked with ANN attention maps were easier for humans to classify than control masks in a speeded recognition experiment. Similarly, we find that recognition performance in the same ANN models was likewise influenced by masking input images using human visual selectivity maps. This work contributes a new approach to evaluating the biological and psychological validity of leading ANNs as models of human vision: by examining their similarities and differences in terms of their visual selectivity to the information contained in images.", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "langlois|passive_attention_in_artificial_neural_networks_predicts_human_visual_selectivity", "pdf": "/pdf/219379184533d639a61682c69c38ab129899fbc7.pdf", "checklist": "", "supplementary_material": "/attachment/750af5f9b765eb1273dbece32f5797b18391e991.pdf", "code": "https://github.com/czhao39/neurips-attention", "thumbnail": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nlanglois2021passive,\ntitle={Passive attention in artificial neural networks predicts human visual selectivity},\nauthor={Thomas A Langlois and Haicheng Charles Zhao and Erin Grant and Ishita Dasgupta and Thomas L. Griffiths and Nori Jacoby},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=AzmEMstdf3o}\n}", "venue": "NeurIPS 2021 Oral", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492667054, "odate": 1636492667054, "details": {"replyCount": 11}}, {"id": "qGvMv3undNJ", "original": "JgualIjMeM", "number": 10022, "cdate": 1621630255063, "ddate": null, "tcdate": 1621630255063, "tmdate": 1683307753530, "tddate": null, "forum": "qGvMv3undNJ", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Moser Flow: Divergence-based Generative Modeling on Manifolds", "authorids": ["~Noam_Rozen1", "~Aditya_Grover1", "~Maximilian_Nickel1", "~Yaron_Lipman1"], "authors": ["Noam Rozen", "Aditya Grover", "Maximilian Nickel", "Yaron Lipman"], "keywords": ["generative models", "manifolds", "normalizing flows"], "abstract": "We are interested in learning generative models for complex geometries described via manifolds, such as spheres, tori, and other implicit surfaces. \nCurrent extensions of existing (Euclidean) generative models are restricted to specific geometries and typically suffer from high computational costs. We introduce Moser Flow (MF), a new class of generative models within the family of continuous normalizing flows (CNF). MF also produces a CNF via a solution to the change-of-variable formula, however differently from other CNF methods, its model (learned) density is parameterized as the source (prior) density minus the divergence of a neural network (NN). The divergence is a local, linear differential operator, easy to approximate and calculate on manifolds. Therefore, \nunlike other CNFs, MF does not require invoking or backpropagating through an ODE solver during training. Furthermore, representing the model density explicitly as the divergence of a NN rather than as a solution of an ODE facilitates learning high fidelity densities. Theoretically, we prove that MF constitutes a universal density approximator under suitable assumptions. Empirically, we demonstrate for the first time the use of flow models for sampling from general curved surfaces and achieve significant improvements in density estimation, sample quality, and training complexity over existing CNFs on challenging synthetic geometries and real-world benchmarks from the earth and climate sciences. ", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "rozen|moser_flow_divergencebased_generative_modeling_on_manifolds", "TL;DR": "Introducing a novel generative model on manifolds based on a classical flow by Moser.", "pdf": "/pdf/cc3baa7b326606195a20c0ed85a5d9b80a533dcb.pdf", "checklist": "", "supplementary_material": "/attachment/e9ad35e02895fb5596f46a1bc5b08b0649d00b4b.pdf", "thumbnail": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nrozen2021moser,\ntitle={Moser Flow: Divergence-based Generative Modeling on Manifolds},\nauthor={Noam Rozen and Aditya Grover and Maximilian Nickel and Yaron Lipman},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=qGvMv3undNJ}\n}", "venue": "NeurIPS 2021 Oral", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492721401, "odate": 1636492721401, "details": {"replyCount": 15}}, {"id": "kB8eks2Edt8", "original": "vrK54In1VgY", "number": 9776, "cdate": 1621630240292, "ddate": null, "tcdate": 1621630240292, "tmdate": 1683307748877, "tddate": null, "forum": "kB8eks2Edt8", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Faster Matchings via Learned Duals", "authorids": ["~Michael_Dinitz1", "~Sungjin_Im1", "~Thomas_Lavastida1", "~Benjamin_Moseley1", "~Sergei_Vassilvitskii2"], "authors": ["Michael Dinitz", "Sungjin Im", "Thomas Lavastida", "Benjamin Moseley", "Sergei Vassilvitskii"], "keywords": ["Bipartite matching", "run time", "learning"], "abstract": "A recent line of research investigates how algorithms can be augmented with machine-learned predictions to overcome worst case lower bounds.  This area has revealed interesting algorithmic insights into problems, with particular success in the design of competitive online algorithms.  However, the question of improving algorithm running times with predictions has largely been unexplored.\n  \nWe take a first step in this direction by combining the idea of machine-learned predictions with the idea of ``warm-starting\" primal-dual algorithms. We consider one of the most important primitives in combinatorial optimization: weighted bipartite matching and its generalization to $b$-matching. We identify three key challenges when using learned dual variables in a primal-dual algorithm.  First, predicted duals may be infeasible, so we give an algorithm that efficiently maps predicted infeasible duals to nearby feasible solutions.  Second, once the duals are feasible, they may not be optimal, so we show that they can be used to quickly find an optimal solution. Finally, such predictions are useful only if they can be learned, so we show that the problem of learning duals for matching has low sample complexity.  We validate our theoretical findings through experiments on both real and synthetic data.  As a result we give a rigorous, practical, and empirically effective method to compute bipartite matchings.", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "dinitz|faster_matchings_via_learned_duals", "pdf": "/pdf/abc294f59a5ac1eb3bc021c41c5f98cb20a11c5a.pdf", "checklist": "", "supplementary_material": "/attachment/17cd5aa312b2ed940fe086275caa87e0d3172291.pdf", "thumbnail": "", "code": "https://github.com/tlavastida/LearnedDuals", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\ndinitz2021faster,\ntitle={Faster Matchings via Learned Duals},\nauthor={Michael Dinitz and Sungjin Im and Thomas Lavastida and Benjamin Moseley and Sergei Vassilvitskii},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=kB8eks2Edt8}\n}", "venue": "NeurIPS 2021 Oral", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492719824, "odate": 1636492719824, "details": {"replyCount": 9}}, {"id": "z5-chidgZU3", "original": "_oCn54gcrnN", "number": 9442, "cdate": 1621630220524, "ddate": null, "tcdate": 1621630220524, "tmdate": 1683307742724, "tddate": null, "forum": "z5-chidgZU3", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Risk Monotonicity in Statistical Learning", "authorids": ["~Zakaria_Mhammedi1"], "authors": ["Zakaria Mhammedi"], "keywords": ["Statistical Learning", "Risk Monotonicity", "Concentration Inequalities", "PAC-Bayesian Bounds"], "abstract": "Acquisition of data is a difficult task in many applications of machine learning, and it is only natural that one hopes and expects the population risk to decrease (better performance) monotonically with increasing data points. It turns out, somewhat surprisingly, that this is not the case even for the most standard algorithms that minimize the empirical risk. Non-monotonic behavior of the risk and instability in training have manifested and appeared in the popular deep learning paradigm under the description of double descent. These problems highlight the current lack of understanding of learning algorithms and generalization. It is, therefore, crucial to pursue this concern and provide a characterization of such behavior. In this paper, we derive the first consistent and risk-monotonic (in high probability) algorithms for a general statistical learning setting under weak assumptions, consequently answering some questions posed by Viering et. al. 2019 on how to avoid non-monotonic behavior of risk curves. We further show that risk monotonicity need not necessarily come at the price of worse excess risk rates. To achieve this, we derive new empirical Bernstein-like concentration inequalities of independent interest that hold for certain non-i.i.d.~processes such as Martingale Difference Sequences. ", "pdf": "/pdf/7c16d25b132346d62595b6df9eb0240e57c3f2c9.pdf", "supplementary_material": "/attachment/eef89081c97878f52aff6d367b525bf775a902c0.pdf", "submission_history": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "checklist": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "mhammedi|risk_monotonicity_in_statistical_learning", "thumbnail": "", "_bibtex": "@inproceedings{\nmhammedi2021risk,\ntitle={Risk Monotonicity in Statistical Learning},\nauthor={Zakaria Mhammedi},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=z5-chidgZU3}\n}", "venue": "NeurIPS 2021 Oral", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492693110, "odate": 1636492693110, "details": {"replyCount": 17}}, {"id": "knKJgksd7kA", "original": "wm7v-8EPNMp", "number": 9407, "cdate": 1621630218385, "ddate": null, "tcdate": 1621630218385, "tmdate": 1697937384527, "tddate": null, "forum": "knKJgksd7kA", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Interesting Object, Curious Agent: Learning Task-Agnostic Exploration", "authorids": ["~Simone_Parisi1", "~Victoria_Dean1", "~Deepak_Pathak1", "~Abhinav_Gupta1"], "authors": ["Simone Parisi", "Victoria Dean", "Deepak Pathak", "Abhinav Gupta"], "keywords": ["reinforcement learning", "exploration", "intrinsic motivation", "continual learning"], "TL;DR": "We propose a framework for combining agent-centric and environment-centric exploration. Key points: definition of a new intrinsic reward; exploration policy learning based on these rewards; transfer of the exploration policy to solve new tasks.", "abstract": "Common approaches for task-agnostic exploration learn tabula-rasa --the agent assumes isolated environments and no prior knowledge or experience. However, in the real world, agents learn in many environments and always come with prior experiences as they explore new ones. Exploration is a lifelong process. In this paper, we propose a paradigm change in the formulation and evaluation of task-agnostic exploration. In this setup, the agent first learns to explore across many environments without any extrinsic goal in a task-agnostic manner.\nLater on, the agent effectively transfers the learned exploration policy to better explore new environments when solving tasks. In this context, we evaluate several baseline exploration strategies and present a simple yet effective approach to learning task-agnostic exploration policies. Our key idea is that there are two components of exploration: (1) an agent-centric component encouraging exploration of unseen parts of the environment based on an agent\u2019s belief; (2) an environment-centric component encouraging exploration of inherently interesting objects. We show that our formulation is effective and provides the most consistent exploration across several training-testing environment pairs. We also introduce benchmarks and metrics for evaluating task-agnostic exploration strategies. The source code is available at https://github.com/sparisi/cbet/.", "submission_history": "", "submission_history_-_venue_and_year": "", "checklist": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "parisi|interesting_object_curious_agent_learning_taskagnostic_exploration", "pdf": "/pdf/68135340c4c5fc2c3699387a8cbce6b38396b5f8.pdf", "submission_history_-_improvements_made": "", "supplementary_material": "/attachment/46bf21f9ff70e73ee4f3a5f6d3ccf608694fd13e.pdf", "code": "https://github.com/sparisi/cbet", "thumbnail": "", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 2 code implementations](https://www.catalyzex.com/paper/arxiv:2111.13119/code)", "_bibtex": "@inproceedings{\nparisi2021interesting,\ntitle={Interesting Object, Curious Agent: Learning Task-Agnostic Exploration},\nauthor={Simone Parisi and Victoria Dean and Deepak Pathak and Abhinav Gupta},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=knKJgksd7kA}\n}", "venue": "NeurIPS 2021 Oral", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492710385, "odate": 1636492710385, "details": {"replyCount": 12}}, {"id": "QkljT4mrfs", "original": "rgVVuDiI_Ri", "number": 9196, "cdate": 1621630205803, "ddate": null, "tcdate": 1621630205803, "tmdate": 1697937390687, "tddate": null, "forum": "QkljT4mrfs", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Partial success in closing the gap between human and machine vision", "authorids": ["~Robert_Geirhos1", "~Kantharaju_Narayanappa1", "~Benjamin_Mitzkus1", "~Tizian_Thieringer1", "~Matthias_Bethge1", "~Felix_A._Wichmann1", "~Wieland_Brendel1"], "authors": ["Robert Geirhos", "Kantharaju Narayanappa", "Benjamin Mitzkus", "Tizian Thieringer", "Matthias Bethge", "Felix A. Wichmann", "Wieland Brendel"], "keywords": ["psychophysics", "machine vision", "human vision", "out-of-distribution generalisation", "visual perception", "robustness", "human behaviour"], "TL;DR": "Data-rich models are closing the gap to human OOD distortion robustness and improve image-level consistency with human psychophysical data.", "abstract": "A few years ago, the first CNN surpassed human performance on ImageNet. However, it soon became clear that machines lack robustness on more challenging test cases, a major obstacle towards deploying machines \"in the wild\" and towards obtaining better computational models of human visual perception. Here we ask: Are we making progress in closing the gap between human and machine vision? To answer this question, we tested human observers on a broad range of out-of-distribution (OOD) datasets, recording 85,120 psychophysical trials across 90 participants. We then investigated a range of promising machine learning developments that crucially deviate from standard supervised CNNs along three axes: objective function (self-supervised, adversarially trained, CLIP language-image training), architecture (e.g. vision transformers), and dataset size (ranging from 1M to 1B).\n\nOur findings are threefold. (1.) The longstanding distortion robustness gap between humans and CNNs is closing, with the best models now exceeding human feedforward performance on most of the investigated OOD datasets. (2.) There is still a substantial image-level consistency gap, meaning that humans make different errors than models. In contrast, most models systematically agree in their categorisation errors, even substantially different ones like contrastive self-supervised vs. standard supervised models. (3.) In many cases, human-to-model consistency improves when training dataset size is increased by one to three orders of magnitude. Our results give reason for cautious optimism: While there is still much room for improvement, the behavioural difference between human and machine vision is narrowing. In order to measure future progress, 17 OOD datasets with image-level human behavioural data and evaluation code are provided as a toolbox and benchmark at: https://github.com/bethgelab/model-vs-human/", "submission_history": "", "submission_history_-_venue_and_year": "", "checklist": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "geirhos|partial_success_in_closing_the_gap_between_human_and_machine_vision", "pdf": "/pdf/3ff20bf21f877221beb03dab05a61187d10d00d9.pdf", "submission_history_-_improvements_made": "", "supplementary_material": "/attachment/1b6b156818d49ca7540dd288a46344576ee0d6ae.pdf", "code": "https://github.com/bethgelab/model-vs-human", "thumbnail": "", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 11 code implementations](https://www.catalyzex.com/paper/arxiv:2106.07411/code)", "_bibtex": "@inproceedings{\ngeirhos2021partial,\ntitle={Partial success in closing the gap between human and machine vision},\nauthor={Robert Geirhos and Kantharaju Narayanappa and Benjamin Mitzkus and Tizian Thieringer and Matthias Bethge and Felix A. Wichmann and Wieland Brendel},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=QkljT4mrfs}\n}", "venue": "NeurIPS 2021 Oral", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492771338, "odate": 1636492771338, "details": {"replyCount": 21}}, {"id": "YIyYkoJX2eA", "original": "0y8l5LtpqkW", "number": 8863, "cdate": 1621630186083, "ddate": null, "tcdate": 1621630186083, "tmdate": 1697937400832, "tddate": null, "forum": "YIyYkoJX2eA", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Learning to Draw: Emergent Communication through Sketching", "authorids": ["~Daniela_Mihai1", "~Jonathon_Hare1"], "authors": ["Daniela Mihai", "Jonathon Hare"], "keywords": ["Emergent Communication", "Sketching", "Drawing", "Perceptual Loss", "Interpretability", "Visual Communication"], "abstract": "Evidence that visual communication preceded written language and provided a basis for it goes back to prehistory, in forms such as cave and rock paintings depicting traces of our distant ancestors. Emergent communication research has sought to explore how agents can learn to communicate in order to collaboratively solve tasks. Existing research has focused on language, with a learned communication channel transmitting sequences of discrete tokens between the agents. In this work, we explore a visual communication channel between agents that are allowed to draw with simple strokes. Our agents are parameterised by deep neural networks, and the drawing procedure is differentiable, allowing for end-to-end training. In the framework of a referential communication game, we demonstrate that agents can not only successfully learn to communicate by drawing, but with appropriate inductive biases, can do so in a fashion that humans can interpret. We hope to encourage future research to consider visual communication as a more flexible and directly interpretable alternative of training collaborative agents.", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "mihai|learning_to_draw_emergent_communication_through_sketching", "pdf": "/pdf/7d58e6415a4bed0aaa386d2e39b1df99e3a707a0.pdf", "checklist": "", "supplementary_material": "/attachment/6d91a0ce84ce389fb29d61b1c29d00176fc1859b.pdf", "thumbnail": "", "TL;DR": "We use self-supervised play to train artificial agents to communicate by drawing and then show that with the appropriate inductive bias a human can successfully play the same games with the pretrained drawing agent.", "code": "https://github.com/Ddaniela13/LearningToDraw", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2106.02067/code)", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nmihai2021learning,\ntitle={Learning to Draw: Emergent Communication through Sketching},\nauthor={Daniela Mihai and Jonathon Hare},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=YIyYkoJX2eA}\n}", "venue": "NeurIPS 2021 Oral", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492710199, "odate": 1636492710199, "details": {"replyCount": 17}}, {"id": "bGfDnD7xo-v", "original": "fBWn-66jjBZ", "number": 8470, "cdate": 1621630162780, "ddate": null, "tcdate": 1621630162780, "tmdate": 1683307720186, "tddate": null, "forum": "bGfDnD7xo-v", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Continuized Accelerations of Deterministic and Stochastic Gradient Descents, and of Gossip Algorithms", "authorids": ["~Mathieu_Even1", "~Rapha\u00ebl_Berthier1", "~Francis_Bach1", "~Nicolas_Flammarion1", "~Hadrien_Hendrikx1", "~Pierre_Gaillard1", "~Laurent_Massouli\u00e91", "~Adrien_Taylor1"], "authors": ["Mathieu Even", "Rapha\u00ebl Berthier", "Francis Bach", "Nicolas Flammarion", "Hadrien Hendrikx", "Pierre Gaillard", "Laurent Massouli\u00e9", "Adrien Taylor"], "keywords": ["Convex optimization", "Nesterov acceleration"], "abstract": "We introduce the ``continuized'' Nesterov acceleration, a close variant of Nesterov acceleration whose variables are indexed by a continuous time parameter. The two variables continuously mix following a linear ordinary differential equation and take gradient steps at random times. This continuized variant benefits from the best of the continuous and the discrete frameworks: as a continuous process, one can use differential calculus to analyze convergence and obtain analytical expressions for the parameters; but a discretization of the continuized process can be computed exactly with convergence rates similar to those of Nesterov original acceleration. We show that the discretization has the same structure as Nesterov acceleration, but with random parameters. \nWe provide continuized Nesterov acceleration under deterministic as well as stochastic gradients, with either additive or multiplicative noise.  Finally, using our continuized framework and expressing the gossip averaging problem as the stochastic minimization of a certain energy function, we provide the first rigorous acceleration of asynchronous gossip algorithms.", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "even|continuized_accelerations_of_deterministic_and_stochastic_gradient_descents_and_of_gossip_algorithms", "pdf": "/pdf/8ee58c3c9395b2f2525cf56fa17d51ffc4273746.pdf", "supplementary_material": "/attachment/a32a14f6ab7a74052b78dc6fbac4de9ff3fcdead.pdf", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "checklist": "", "thumbnail": "", "_bibtex": "@inproceedings{\neven2021continuized,\ntitle={Continuized Accelerations of Deterministic and Stochastic Gradient Descents, and of Gossip Algorithms},\nauthor={Mathieu Even and Rapha{\\\"e}l Berthier and Francis Bach and Nicolas Flammarion and Hadrien Hendrikx and Pierre Gaillard and Laurent Massouli{\\'e} and Adrien Taylor},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=bGfDnD7xo-v}\n}", "venue": "NeurIPS 2021 Oral", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492778192, "odate": 1636492778192, "details": {"replyCount": 10}}, {"id": "o6-k168bBD8", "original": "gkOrajBMkl7", "number": 8385, "cdate": 1621630157707, "ddate": null, "tcdate": 1621630157707, "tmdate": 1683307718162, "tddate": null, "forum": "o6-k168bBD8", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Sequential Causal Imitation Learning with Unobserved Confounders", "authorids": ["~Daniel_Kumor1", "~Junzhe_Zhang3", "~Elias_Bareinboim2"], "authors": ["Daniel Kumor", "Junzhe Zhang", "Elias Bareinboim"], "keywords": ["causality", "reinforcement learning", "imitation"], "TL;DR": "We provide a complete graphical condition for determining feasibility of sequential imitation in the presence of latent confounding", "abstract": "\"Monkey see monkey do\" is an age-old adage, referring to naive imitation without a deep understanding of a system's underlying mechanics. Indeed, if a demonstrator has access to information unavailable to the imitator (monkey), such as a different set of sensors, then no matter how perfectly the imitator models its perceived environment (See), attempting to directly reproduce the demonstrator's behavior (Do) can lead to poor outcomes. Imitation learning in the presence of a mismatch between demonstrator and imitator has been studied in the literature under the rubric of causal imitation learning  (Zhang et. al. 2020), but existing solutions are limited to single-stage decision-making. This paper investigates the problem of causal imitation learning in sequential settings, where the imitator must make multiple decisions per episode. We develop a graphical criterion that is both necessary and sufficient for determining the feasibility of causal imitation, providing conditions when an imitator can match a demonstrator's performance despite differing capabilities. Finally, we provide an efficient algorithm for determining imitability, and corroborate our theory with simulations.", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "kumor|sequential_causal_imitation_learning_with_unobserved_confounders", "pdf": "/pdf/21b08dd1baaebd5e95e14749e617abdc0b6eb30b.pdf", "checklist": "", "supplementary_material": "", "thumbnail": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nkumor2021sequential,\ntitle={Sequential Causal Imitation Learning with Unobserved Confounders},\nauthor={Daniel Kumor and Junzhe Zhang and Elias Bareinboim},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=o6-k168bBD8}\n}", "venue": "NeurIPS 2021 Oral", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492702564, "odate": 1636492702522, "details": {"replyCount": 15}}, {"id": "cVwc7IHWEWi", "original": "41XKTRQvCCt", "number": 8349, "cdate": 1621630155520, "ddate": null, "tcdate": 1621630155520, "tmdate": 1683307717527, "tddate": null, "forum": "cVwc7IHWEWi", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Near-Optimal No-Regret Learning in General Games", "authorids": ["~Constantinos_Costis_Daskalakis1", "~Maxwell_Fishelson1", "~Noah_Golowich1"], "authors": ["Constantinos Costis Daskalakis", "Maxwell Fishelson", "Noah Golowich"], "keywords": ["No-regret learning", "coarse correlated equilibrium", "Optimistic Hedge"], "TL;DR": "We prove a poly-logarithmic regret bound for no-regret learners in general-sum games.", "abstract": "We show that Optimistic Hedge -- a common variant of multiplicative-weights-updates with recency bias -- attains ${\\rm poly}(\\log T)$ regret in multi-player general-sum games. In particular, when every player of the game uses Optimistic Hedge to iteratively update her action in response to the history of play so far, then after $T$ rounds of interaction, each player experiences total regret that is ${\\rm poly}(\\log T)$. Our bound improves, exponentially, the $O(T^{1/2})$ regret attainable  by standard no-regret learners in games, the $O(T^{1/4})$ regret attainable by no-regret learners with recency bias (Syrgkanis et al., NeurIPS 2015), and the $O(T^{1/6})$ bound that was recently shown for Optimistic Hedge in the special case of two-player games (Chen & Peng, NeurIPS 2020). A direct corollary of our bound is that Optimistic Hedge converges to coarse correlated equilibrium in general games at a rate of $\\tilde{O}(1/T)$.", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "daskalakis|nearoptimal_noregret_learning_in_general_games", "pdf": "/pdf/18b08517ad90722c063baf7209c8379b6838dbd6.pdf", "checklist": "", "supplementary_material": "/attachment/36eb9503dc33e8173104eb5394f6d1d925fb7655.pdf", "thumbnail": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\ndaskalakis2021nearoptimal,\ntitle={Near-Optimal No-Regret Learning in General Games},\nauthor={Constantinos Costis Daskalakis and Maxwell Fishelson and Noah Golowich},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=cVwc7IHWEWi}\n}", "venue": "NeurIPS 2021 Oral", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492757542, "odate": 1636492757542, "details": {"replyCount": 10}}, {"id": "FyOhThdDBM", "original": "f0SCrJevkC", "number": 8343, "cdate": 1621630155166, "ddate": null, "tcdate": 1621630155166, "tmdate": 1683307717460, "tddate": null, "forum": "FyOhThdDBM", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Uniform Convergence of Interpolators: Gaussian Width, Norm Bounds and Benign Overfitting", "authorids": ["~Frederic_Koehler1", "~Lijia_Zhou1", "~Danica_J._Sutherland1", "~Nathan_Srebro1"], "authors": ["Frederic Koehler", "Lijia Zhou", "Danica J. Sutherland", "Nathan Srebro"], "keywords": ["interpolation learning", "uniform convergence", "double descent", "statistical learning theory"], "TL;DR": "Uniform convergence of interpolating predictors can explain consistency for high-dimensional linear regression.", "abstract": "We consider interpolation learning in high-dimensional linear regression with Gaussian data, and prove a generic uniform convergence guarantee on the generalization error of interpolators in an arbitrary hypothesis class in terms of the class\u2019s Gaussian width.  Applying the generic bound to Euclidean norm balls recovers the consistency result of Bartlett et al. (2020) for minimum-norm interpolators, and confirms a prediction of Zhou et al. (2020) for near-minimal-norm interpolators in the special case of Gaussian data.  We demonstrate the generality of the bound by applying it to the simplex, obtaining a novel consistency result for minimum $\\ell_1$-norm interpolators (basis pursuit). Our results show how norm-based generalization bounds can explain and be used to analyze benign overfitting, at least in some settings.\n", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "koehler|uniform_convergence_of_interpolators_gaussian_width_norm_bounds_and_benign_overfitting", "pdf": "/pdf/36ed6c922b095efd2a278dff6d723266ab93d1ae.pdf", "checklist": "", "supplementary_material": "/attachment/4f9ec566a08ebdf742d2ce2f1f2e982a1d398f09.zip", "thumbnail": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nkoehler2021uniform,\ntitle={Uniform Convergence of Interpolators: Gaussian Width, Norm Bounds and Benign Overfitting},\nauthor={Frederic Koehler and Lijia Zhou and Danica J. Sutherland and Nathan Srebro},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=FyOhThdDBM}\n}", "venue": "NeurIPS 2021 Oral", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492751384, "odate": 1636492751384, "details": {"replyCount": 8}}, {"id": "Owggnutk6lE", "original": "ClQljZmZOvt", "number": 8331, "cdate": 1621630154456, "ddate": null, "tcdate": 1621630154456, "tmdate": 1697937420008, "tddate": null, "forum": "Owggnutk6lE", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Alias-Free Generative Adversarial Networks", "authorids": ["~Tero_Karras1", "~Miika_Aittala2", "~Samuli_Laine1", "~Erik_H\u00e4rk\u00f6nen1", "~Janne_Hellsten1", "~Jaakko_Lehtinen1", "~Timo_Aila1"], "authors": ["Tero Karras", "Miika Aittala", "Samuli Laine", "Erik H\u00e4rk\u00f6nen", "Janne Hellsten", "Jaakko Lehtinen", "Timo Aila"], "keywords": ["GAN", "CNN", "signal processing", "aliasing", "image synthesis"], "abstract": "We observe that despite their hierarchical convolutional nature, the synthesis process of typical generative adversarial networks depends on absolute pixel coordinates in an unhealthy manner. This manifests itself as, e.g., detail appearing to be glued to image coordinates instead of the surfaces of depicted objects. We trace the root cause to careless signal processing that causes aliasing in the generator network. Interpreting all signals in the network as continuous, we derive generally applicable, small architectural changes that guarantee that unwanted information cannot leak into the hierarchical synthesis process. The resulting networks match the FID of StyleGAN2 but differ dramatically in their internal representations, and they are fully equivariant to translation and rotation even at subpixel scales. Our results pave the way for generative models better suited for video and animation.", "submission_history": "", "checklist": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "karras|aliasfree_generative_adversarial_networks", "pdf": "/pdf/d3783b1361fd4151e06e27ff85a4614821767dce.pdf", "supplementary_material": "/attachment/cb5fc8cd06fa77a2671521e2947c0157e90ebe23.pdf", "TL;DR": "Careless signal processing causes \"texture sticking\" artifacts in GANs; our redesign solves them and dramatically improves visual quality under animation.", "code": "https://github.com/NVlabs/stylegan3", "thumbnail": "", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 7 code implementations](https://www.catalyzex.com/paper/arxiv:2106.12423/code)", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nkarras2021aliasfree,\ntitle={Alias-Free Generative Adversarial Networks},\nauthor={Tero Karras and Miika Aittala and Samuli Laine and Erik H{\\\"a}rk{\\\"o}nen and Janne Hellsten and Jaakko Lehtinen and Timo Aila},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=Owggnutk6lE}\n}", "venue": "NeurIPS 2021 Oral", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492786223, "odate": 1636492786223, "details": {"replyCount": 9}}, {"id": "uJGObgFU0lU", "original": "h3wRzfwxFvE", "number": 8222, "cdate": 1621630147860, "ddate": null, "tcdate": 1621630147860, "tmdate": 1697937424450, "tddate": null, "forum": "uJGObgFU0lU", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Differentiable Quality Diversity", "authorids": ["~Matthew_Christopher_Fontaine1", "~Stefanos_Nikolaidis1"], "authors": ["Matthew Christopher Fontaine", "Stefanos Nikolaidis"], "keywords": ["quality diversity optimization", "generative adversarial network", "latent space exploration"], "TL;DR": "We present the differentiable quality diversity (DQD) problem and the first DQD algorithm.", "abstract": "Quality diversity (QD) is a growing branch of stochastic optimization research that studies the problem of generating an archive of solutions that maximize a given objective function but are also diverse with respect to a set of specified measure functions. However, even when these functions are differentiable, QD algorithms treat them as \"black boxes\", ignoring gradient information. We present the differentiable quality diversity (DQD) problem, a special case of QD, where both the objective and measure functions are first order differentiable. We then present MAP-Elites via a Gradient Arborescence (MEGA), a DQD algorithm that leverages gradient information to efficiently explore the joint range of the objective and measure functions. Results in two QD benchmark domains and in searching the latent space of a StyleGAN show that MEGA significantly outperforms state-of-the-art QD algorithms, highlighting DQD's promise for efficient quality diversity optimization when gradient information is available. Source code is available at https://github.com/icaros-usc/dqd.", "submission_history": "", "checklist": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "fontaine|differentiable_quality_diversity", "pdf": "/pdf/15ef38bc0920bc99a0dba5791d93aa5488cdb1bd.pdf", "supplementary_material": "/attachment/e931b07fc3253c7ca72ec092cb9ddad1c1c203f3.zip", "code": "https://github.com/icaros-usc/dqd", "thumbnail": "", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 2 code implementations](https://www.catalyzex.com/paper/arxiv:2106.03894/code)", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nfontaine2021differentiable,\ntitle={Differentiable Quality Diversity},\nauthor={Matthew Christopher Fontaine and Stefanos Nikolaidis},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=uJGObgFU0lU}\n}", "venue": "NeurIPS 2021 Oral", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492756691, "odate": 1636492756691, "details": {"replyCount": 18}}, {"id": "WnJXcebN7hX", "original": "rZWQ97cspc4", "number": 8007, "cdate": 1621630135167, "ddate": null, "tcdate": 1621630135167, "tmdate": 1683307710270, "tddate": null, "forum": "WnJXcebN7hX", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "An Exponential Lower Bound for Linearly Realizable MDP with Constant Suboptimality Gap", "authorids": ["~Yuanhao_Wang1", "~Ruosong_Wang1", "~Sham_M._Kakade1"], "authors": ["Yuanhao Wang", "Ruosong Wang", "Sham M. Kakade"], "keywords": ["Reinforcement Learning", "Linear Function Approximation", "Lower Bound"], "abstract": "A fundamental question in the theory of reinforcement learning is: suppose the optimal $Q$-function lies in the linear span of a given $d$ dimensional feature mapping, is sample-efficient reinforcement learning (RL) possible? The recent and remarkable result of Weisz et al. (2020) resolves this question in the negative, providing an exponential (in $d$) sample size lower bound, which holds even if the agent has access to a generative model of the environment. One may hope that such a lower can be circumvented with an even stronger assumption that there is a \\emph{constant gap} between the optimal $Q$-value of the best action and that of the second-best action (for all states); indeed, the construction in Weisz et al. (2020) relies on having an exponentially small gap. This work resolves this subsequent question, showing that an exponential sample complexity lower bound still holds even if a constant gap is assumed.  Perhaps surprisingly, this result implies an exponential separation between the online RL setting and the generative model setting, where sample-efficient RL is in fact possible in the latter setting with a constant gap. Complementing our negative hardness result, we give two positive results showing that provably sample-efficient RL is possible either under an additional low-variance assumption or under a novel hypercontractivity assumption.", "pdf": "/pdf/715828e0d27f31124023770d924f73776d1ca465.pdf", "supplementary_material": "/attachment/911c4b218ea3fdb927aaa100048bc417f77947cd.pdf", "submission_history": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "checklist": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "wang|an_exponential_lower_bound_for_linearly_realizable_mdp_with_constant_suboptimality_gap", "thumbnail": "", "_bibtex": "@inproceedings{\nwang2021an,\ntitle={An Exponential Lower Bound for Linearly Realizable {MDP} with Constant Suboptimality Gap},\nauthor={Yuanhao Wang and Ruosong Wang and Sham M. Kakade},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=WnJXcebN7hX}\n}", "venue": "NeurIPS 2021 Oral", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492715380, "odate": 1636492715380, "details": {"replyCount": 10}}, {"id": "Tqx7nJp7PR", "original": "Am9LLgnu3p9", "number": 7853, "cdate": 1621630126261, "ddate": null, "tcdate": 1621630126261, "tmdate": 1683307707327, "tddate": null, "forum": "Tqx7nJp7PR", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "MAUVE: Measuring the Gap Between Neural Text and Human Text using Divergence Frontiers", "authorids": ["~Krishna_Pillutla1", "~Swabha_Swayamdipta1", "~Rowan_Zellers1", "~John_Thickstun1", "~Sean_Welleck1", "~Yejin_Choi1", "~Zaid_Harchaoui1"], "authors": ["Krishna Pillutla", "Swabha Swayamdipta", "Rowan Zellers", "John Thickstun", "Sean Welleck", "Yejin Choi", "Zaid Harchaoui"], "keywords": ["Open-ended generation", "neural text generation", "evaluation", "divergence frontier", "human judgement"], "TL;DR": "A comparison measure for open-ended text generation by directly comparing the distribution of neural machine-generated text to that of human-written text.", "abstract": "As major progress is made in open-ended text generation, measuring how close machine-generated text is to human language remains a critical open problem. We introduce Mauve, a comparison measure for open-ended text generation, which directly compares the learnt distribution from a text generation model to the distribution of human-written text using divergence frontiers. Mauve scales up to modern text generation models by computing information divergences in a quantized embedding space. Through an extensive empirical study on three open-ended generation tasks, we find that Mauve identifies known properties of generated text, scales naturally with model size, and correlates with human judgments, with fewer restrictions than existing distributional evaluation metrics.", "pdf": "/pdf/f76eb3f31a7a8965e8a759010da999b60b1385eb.pdf", "supplementary_material": "/attachment/a335cfc0cf77afd3bc27c5ba4ddcf0df052cde60.pdf", "submission_history": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "checklist": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "pillutla|mauve_measuring_the_gap_between_neural_text_and_human_text_using_divergence_frontiers", "code": "https://github.com/krishnap25/mauve-experiments", "thumbnail": "", "_bibtex": "@inproceedings{\npillutla2021mauve,\ntitle={{MAUVE}: Measuring the Gap Between Neural Text and Human Text using Divergence Frontiers},\nauthor={Krishna Pillutla and Swabha Swayamdipta and Rowan Zellers and John Thickstun and Sean Welleck and Yejin Choi and Zaid Harchaoui},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=Tqx7nJp7PR}\n}", "venue": "NeurIPS 2021 Oral", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492682397, "odate": 1636492682397, "details": {"replyCount": 12}}, {"id": "napaTaDQ0lY", "original": "qOqiKqvsXet", "number": 7820, "cdate": 1621630124254, "ddate": null, "tcdate": 1621630124254, "tmdate": 1683307706196, "tddate": null, "forum": "napaTaDQ0lY", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Lower Bounds on Metropolized Sampling Methods for Well-Conditioned Distributions", "authorids": ["~Yin_Tat_Lee1", "~Ruoqi_Shen1", "~Kevin_Tian1"], "authors": ["Yin Tat Lee", "Ruoqi Shen", "Kevin Tian"], "keywords": ["sampling", "computational statistics", "Bayesian methods", "Langevin dynamics", "Hamiltonian Monte Carlo"], "TL;DR": "We give lower bounds showing the current analyses of MALA for sampling well-conditioned distributions are nearly-tight, and that HMC incurs a polynomial dimension dependence for any number of steps.", "abstract": "We give lower bounds on the performance of two of the most popular sampling methods in practice, the Metropolis-adjusted Langevin algorithm (MALA) and multi-step Hamiltonian Monte Carlo (HMC) with a leapfrog integrator, when applied to well-conditioned distributions. Our main result is a nearly-tight lower bound of $\\widetilde{\\Omega}(\\kappa d)$ on the mixing time of MALA from an exponentially warm start, matching a line of algorithmic results \\cite{DwivediCW018, ChenDWY19, LeeST20a} up to logarithmic factors and answering an open question of \\cite{ChewiLACGR20}. We also show that a polynomial dependence on dimension is necessary for the relaxation time of HMC under any number of leapfrog steps, and bound the gains achievable by changing the step count. Our HMC analysis draws upon a novel connection between leapfrog integration and Chebyshev polynomials, which may be of independent interest.", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "lee|lower_bounds_on_metropolized_sampling_methods_for_wellconditioned_distributions", "pdf": "/pdf/52fa4cf6342418b7dc6aaedbd34552a202d9aaaa.pdf", "supplementary_material": "/attachment/f189d7402e4bcf421844e2055a0b81a5ddbaa9f6.pdf", "checklist": "", "thumbnail": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nlee2021lower,\ntitle={Lower Bounds on Metropolized Sampling Methods for Well-Conditioned Distributions},\nauthor={Yin Tat Lee and Ruoqi Shen and Kevin Tian},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=napaTaDQ0lY}\n}", "venue": "NeurIPS 2021 Oral", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492760373, "odate": 1636492760373, "details": {"replyCount": 11}}, {"id": "e8WWUBeafM", "original": "C4oaf0o59ka", "number": 7718, "cdate": 1621630118121, "ddate": null, "tcdate": 1621630118121, "tmdate": 1683307703631, "tddate": null, "forum": "e8WWUBeafM", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Bellman-consistent Pessimism for Offline Reinforcement Learning", "authorids": ["~Tengyang_Xie1", "~Ching-An_Cheng1", "~Nan_Jiang2", "~Paul_Mineiro1", "~Alekh_Agarwal2"], "authors": ["Tengyang Xie", "Ching-An Cheng", "Nan Jiang", "Paul Mineiro", "Alekh Agarwal"], "keywords": ["offline reinforcement learning", "Bellman-consistent pessimism", "sample complexity bounds", "linear MDP", "function approximation"], "TL;DR": "We introduce the notion of Bellman-consistent pessimism for general function approximation in offline reinforcement learning.", "abstract": "The use of pessimism, when reasoning about datasets lacking exhaustive exploration has recently gained prominence in offline reinforcement learning. Despite the robustness it adds to the algorithm, overly pessimistic reasoning can be equally damaging in precluding the discovery of good policies, which is an issue for the popular bonus-based pessimism. In this paper, we introduce the notion of Bellman-consistent pessimism for general function approximation: instead of calculating a point-wise lower bound for the value function, we implement pessimism at the initial state over the set of functions consistent with the Bellman equations. Our theoretical guarantees only require Bellman closedness as standard in the exploratory setting, in which case bonus-based pessimism fails to provide guarantees.  Even in the special case of linear function approximation where stronger expressivity assumptions hold, our result improves upon a recent bonus-based approach by $\\mathcal O(d)$ in its sample complexity (when the action space is finite). Remarkably, our algorithms automatically adapt to the best bias-variance tradeoff in the hindsight, whereas most prior approaches require tuning extra hyperparameters a priori.", "submission_history": "", "checklist": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "xie|bellmanconsistent_pessimism_for_offline_reinforcement_learning", "pdf": "/pdf/172b82a8a2edef3d7d2d14d6f27e4f9c3818c44b.pdf", "supplementary_material": "/attachment/16ab9255ae9583225ce8d122c706b50d2b98740d.pdf", "thumbnail": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nxie2021bellmanconsistent,\ntitle={Bellman-consistent Pessimism for Offline Reinforcement Learning},\nauthor={Tengyang Xie and Ching-An Cheng and Nan Jiang and Paul Mineiro and Alekh Agarwal},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=e8WWUBeafM}\n}", "venue": "NeurIPS 2021 Oral", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492711723, "odate": 1636492711723, "details": {"replyCount": 12}}, {"id": "CRFSrgYtV7m", "original": "R-Q3lrma7I8", "number": 7477, "cdate": 1621630103787, "ddate": null, "tcdate": 1621630103787, "tmdate": 1683307698170, "tddate": null, "forum": "CRFSrgYtV7m", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "MERLOT: Multimodal Neural Script Knowledge Models", "authorids": ["~Rowan_Zellers1", "~Ximing_Lu1", "~Jack_Hessel1", "~Youngjae_Yu1", "~Jae_Sung_Park2", "~Jize_Cao1", "~Ali_Farhadi1", "~Yejin_Choi1"], "authors": ["Rowan Zellers", "Ximing Lu", "Jack Hessel", "Youngjae Yu", "Jae Sung Park", "Jize Cao", "Ali Farhadi", "Yejin Choi"], "keywords": ["commonsense reasoning", "representation learning", "vision and language"], "TL;DR": "We learn multimodal, temporal representations about \u201chow the world works\u201d through videos.", "abstract": "As humans, we understand events in the visual world contextually, performing multimodal reasoning across time to make inferences about the past, present, and future. We introduce MERLOT, a model that learns multimodal script knowledge by watching millions of YouTube videos with transcribed speech -- in an entirely label-free, self-supervised manner. By pretraining with a mix of both frame-level (spatial) and video-level (temporal) objectives, our model not only learns to match images to temporally corresponding words, but also to contextualize what is happening globally over time. As a result, MERLOT exhibits strong out-of-the-box representations of temporal commonsense, and achieves state-of-the-art performance on 12 different video QA datasets when finetuned. It also transfers well to the world of static images, allowing models to reason about the dynamic context behind visual scenes. On Visual Commonsense Reasoning, MERLOT~answers questions correctly with 80.6\\% accuracy, outperforming state-of-the-art models of similar size by over 3\\%, even those that make heavy use of auxiliary supervised data (like object bounding boxes).\n\nAblation analyses demonstrate the complementary importance of: 1) training on videos versus static images; 2) scaling the magnitude and diversity of the pretraining video corpus; and 3) using diverse objectives that encourage full-stack multimodal reasoning, from the recognition to cognition level.", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "zellers|merlot_multimodal_neural_script_knowledge_models", "pdf": "/pdf/302a68368f21f2fd4b037911ae44f77ed56f3344.pdf", "checklist": "", "supplementary_material": "/attachment/261bce243dbb82e9734866d3f5dbcdd6885bb279.pdf", "code": "https://github.com/rowanz/merlot", "thumbnail": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nzellers2021merlot,\ntitle={{MERLOT}: Multimodal Neural Script Knowledge Models},\nauthor={Rowan Zellers and Ximing Lu and Jack Hessel and Youngjae Yu and Jae Sung Park and Jize Cao and Ali Farhadi and Yejin Choi},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=CRFSrgYtV7m}\n}", "venue": "NeurIPS 2021 Oral", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492779189, "odate": 1636492779189, "details": {"replyCount": 15}}, {"id": "mjyMGFL8N2", "original": "6cLMBnsLQzU", "number": 7303, "cdate": 1621630093722, "ddate": null, "tcdate": 1621630093722, "tmdate": 1683307692034, "tddate": null, "forum": "mjyMGFL8N2", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Provable Guarantees for Self-Supervised Deep Learning with Spectral Contrastive Loss", "authorids": ["~Jeff_Z._HaoChen1", "~Colin_Wei1", "~Adrien_Gaidon1", "~Tengyu_Ma1"], "authors": ["Jeff Z. HaoChen", "Colin Wei", "Adrien Gaidon", "Tengyu Ma"], "keywords": ["theory", "deep learning theory", "unsupervised learning theory", "representation learning theory"], "TL;DR": "We propose a novel theoretical framework for studying self-supervised learning algorithms.", "abstract": "Recent works in self-supervised learning have advanced the state-of-the-art by relying on the contrastive learning paradigm, which learns representations by pushing positive pairs, or similar examples from the same class, closer together while keeping negative pairs far apart. Despite the empirical successes, theoretical foundations are limited -- prior analyses assume conditional independence of the positive pairs given the same class label, but recent empirical applications use heavily correlated positive pairs (i.e., data augmentations of the same image). Our work analyzes contrastive learning without assuming conditional independence of positive pairs using a novel concept of the augmentation graph on data.  Edges in this graph connect augmentations of the same data, and ground-truth classes naturally form connected sub-graphs. We propose a loss that performs spectral decomposition on the population augmentation graph and can be succinctly written as a contrastive learning objective on neural net representations. Minimizing this objective leads to features with provable accuracy guarantees under linear probe evaluation. By standard generalization bounds, these accuracy guarantees also hold when minimizing the training contrastive loss. In all, this work provides the first provable analysis for contrastive learning where the guarantees can apply to realistic empirical settings.", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "haochen|provable_guarantees_for_selfsupervised_deep_learning_with_spectral_contrastive_loss", "pdf": "/pdf/6ddcdbef76f99d91be552137cd0fc15fc6bf7361.pdf", "supplementary_material": "/attachment/9c65d7ea803b22c8eb087769a7d0e7cbd61d5b0b.zip", "checklist": "", "thumbnail": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nhaochen2021provable,\ntitle={Provable Guarantees for Self-Supervised Deep Learning with Spectral Contrastive Loss},\nauthor={Jeff Z. HaoChen and Colin Wei and Adrien Gaidon and Tengyu Ma},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=mjyMGFL8N2}\n}", "venue": "NeurIPS 2021 Oral", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492721970, "odate": 1636492721970, "details": {"replyCount": 12}}, {"id": "9SD2Rb3NiWu", "original": "XkGdSZ3MXZs", "number": 7157, "cdate": 1621630085128, "ddate": null, "tcdate": 1621630085128, "tmdate": 1683307688610, "tddate": null, "forum": "9SD2Rb3NiWu", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "A Compositional Atlas of Tractable Circuit Operations for Probabilistic Inference", "authorids": ["~antonio_vergari1", "~YooJung_Choi1", "~Anji_Liu1", "~Stefano_Teso1", "~Guy_Van_den_Broeck1"], "authors": ["antonio vergari", "YooJung Choi", "Anji Liu", "Stefano Teso", "Guy Van den Broeck"], "keywords": ["probabilistic reasoning", "tractable inference", "probabilistic circuits", "sum-product networks"], "TL;DR": "We systematically characterize a tractable model class for an inference scenario by building a modular pipeline of atomic operations and thus distilling an efficient algorithm for it", "abstract": "Circuit representations are becoming the lingua franca to express and reason about tractable generative and discriminative models. In this paper, we show how complex inference scenarios for these models that commonly arise in machine learning---from  computing the expectations of decision tree ensembles to information-theoretic divergences of sum-product networks---can be represented in terms of tractable modular operations over circuits. Specifically, we characterize the tractability of simple transformations---sums, products, quotients, powers, logarithms, and exponentials---in terms of sufficient structural constraints of the circuits they operate on, and present novel hardness results for the cases in which these properties are not satisfied. Building on these operations, we derive a unified framework for reasoning about tractable models that generalizes several results in the literature and opens up novel tractable inference scenarios.", "submission_history": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "vergari|a_compositional_atlas_of_tractable_circuit_operations_for_probabilistic_inference", "pdf": "/pdf/21df22163d385468bc9cfe223d87042fcbb7c7ce.pdf", "checklist": "", "supplementary_material": "/attachment/96760935c242ef328765762f04aa439ab2a3cd20.pdf", "code": "https://github.com/UCLA-StarAI/circuit-ops-atlas", "thumbnail": "", "_bibtex": "@inproceedings{\nvergari2021a,\ntitle={A Compositional Atlas of Tractable Circuit Operations for Probabilistic Inference},\nauthor={antonio vergari and YooJung Choi and Anji Liu and Stefano Teso and Guy Van den Broeck},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=9SD2Rb3NiWu}\n}", "venue": "NeurIPS 2021 Oral", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492714435, "odate": 1636492714435, "details": {"replyCount": 9}}, {"id": "n11B-1GmTJl", "original": "5gQgnfrylQK", "number": 7041, "cdate": 1621630078933, "ddate": null, "tcdate": 1621630078933, "tmdate": 1683307685147, "tddate": null, "forum": "n11B-1GmTJl", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Data driven semi-supervised learning", "authorids": ["~Nina_Balcan1", "~Dravyansh_Sharma1"], "authors": ["Nina Balcan", "Dravyansh Sharma"], "keywords": ["Semi-supervised learning", "learning theory"], "abstract": "We consider a novel data driven approach for designing semi-supervised learning algorithms that can effectively learn with only a small number of labeled examples. We focus on graph-based techniques, where the unlabeled examples are connected in a graph  under the implicit assumption that similar nodes likely have similar labels. Over the past two decades, several elegant graph-based semi-supervised learning algorithms for inferring the labels of the unlabeled examples given the graph and a few labeled examples have been proposed. However, the problem of how to create the graph (which impacts the practical usefulness of these methods significantly) has been relegated to heuristics and domain-specific art, and no general principles have been proposed. In this work we present a  novel data driven approach for learning the graph and provide strong formal guarantees in both the distributional and online learning formalizations. We show how to leverage problem instances coming from an underlying problem domain to learn the graph hyperparameters for commonly used parametric families of graphs that provably perform well on new instances from the same domain. We obtain low regret and efficient algorithms in the online setting, and generalization guarantees in the distributional setting. We also show how to combine several very different similarity metrics and learn multiple  hyperparameters, our results hold for large classes of problems. We expect some of the tools and techniques we develop along the way to be of independent interest, for data driven algorithms more generally.", "submission_history": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "balcan|data_driven_semisupervised_learning", "TL;DR": "We present a novel data driven approach for learning the graph with strong formal guarantees in both the distributional and online learning formalizations - this overcomes the major drawback of classic graph-based semi-supervised learning techniques.", "pdf": "/pdf/5136940dbb02ec676f34d5618dd48893c96accd0.pdf", "supplementary_material": "/attachment/423d06169e35d3c02196bb5cb7e26d02f209da0e.pdf", "checklist": "", "thumbnail": "", "_bibtex": "@inproceedings{\nbalcan2021data,\ntitle={Data driven semi-supervised learning},\nauthor={Nina Balcan and Dravyansh Sharma},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=n11B-1GmTJl}\n}", "venue": "NeurIPS 2021 Oral", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492701550, "odate": 1636492701550, "details": {"replyCount": 11}}, {"id": "uqv8-U4lKBe", "original": "RC7UcJ-pmq", "number": 7005, "cdate": 1621630076699, "ddate": null, "tcdate": 1621630076699, "tmdate": 1697937476712, "tddate": null, "forum": "uqv8-U4lKBe", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Deep Reinforcement Learning at the Edge of the Statistical Precipice", "authorids": ["~Rishabh_Agarwal2", "~Max_Schwarzer1", "~Pablo_Samuel_Castro1", "~Aaron_Courville3", "~Marc_G_Bellemare1"], "authors": ["Rishabh Agarwal", "Max Schwarzer", "Pablo Samuel Castro", "Aaron Courville", "Marc G Bellemare"], "keywords": ["Reinforcement Learning", "Evaluation", "Benchmarking", "Scientific Progress", "Reliability"], "abstract": "Deep reinforcement learning (RL) algorithms are predominantly evaluated by comparing their relative performance on a large suite of tasks. Most published results on deep RL benchmarks compare point estimates of aggregate performance such as mean and median scores across tasks, ignoring the statistical uncertainty implied by the use of a finite number of training runs. Beginning with the Arcade Learning Environment (ALE), the shift towards computationally-demanding benchmarks has led to the practice of evaluating only a small number of runs per task, exacerbating the statistical uncertainty in point estimates. In this paper, we argue that reliable evaluation in the few run deep RL regime cannot ignore the uncertainty in results without running the risk of slowing down progress in the field. We illustrate this point using a case study on the Atari 100k benchmark, where we find substantial discrepancies between conclusions drawn from point estimates alone versus a more thorough statistical analysis. With the aim of increasing the field's confidence in reported results with a handful of runs, we advocate for reporting interval estimates of aggregate performance and propose performance profiles to account for the variability in results, as well as present more robust and efficient aggregate metrics, such as interquartile mean scores, to achieve small uncertainty in results. Using such statistical tools, we scrutinize performance evaluations of existing algorithms on other widely used RL benchmarks including the ALE, Procgen, and the DeepMind Control Suite, again revealing discrepancies in prior comparisons. Our findings call for a change in how we evaluate performance in deep RL, for which we present a more rigorous evaluation methodology, accompanied with an open-source library rliable, to prevent unreliable results from stagnating the field. This work received an outstanding paper award at NeurIPS 2021.", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "agarwal|deep_reinforcement_learning_at_the_edge_of_the_statistical_precipice", "pdf": "/pdf/52d2fb2f1304b1dd70d9373da566bdbb8e43fcfe.pdf", "checklist": "", "supplementary_material": "/attachment/5c7dfe8447a9aa47ebc9ada15332850d1e42a545.pdf", "TL;DR": "Our findings call for a change in how we report performance on benchmarks when using only a few runs, for which we present more reliable protocols accompanied with an open-source library.", "code": "https://github.com/google-research/rliable", "thumbnail": "", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 4 code implementations](https://www.catalyzex.com/paper/arxiv:2108.13264/code)", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nagarwal2021deep,\ntitle={Deep Reinforcement Learning at the Edge of the Statistical Precipice},\nauthor={Rishabh Agarwal and Max Schwarzer and Pablo Samuel Castro and Aaron Courville and Marc G Bellemare},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=uqv8-U4lKBe}\n}", "venue": "NeurIPS 2021 Oral", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492685104, "odate": 1636492685104, "details": {"replyCount": 14}}, {"id": "XeeTWJvAQl", "original": "q5orBE3EJ1", "number": 6970, "cdate": 1621630074577, "ddate": null, "tcdate": 1621630074577, "tmdate": 1683307682894, "tddate": null, "forum": "XeeTWJvAQl", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "High-probability Bounds for Non-Convex Stochastic Optimization with Heavy Tails", "authorids": ["~Ashok_Cutkosky1", "~Harsh_Mehta1"], "authors": ["Ashok Cutkosky", "Harsh Mehta"], "keywords": ["stochastic optimization", "heavy tails", "non-convex optimization", "optimization for deep learning"], "TL;DR": "We show that combining momentum, normalization, and gradient clipping allows for high-probability convergence guarantees in non-convex stochastic optimization even in the presence of heavy-tailed gradient noise.", "abstract": "We consider non-convex stochastic optimization using first-order algorithms for which the gradient estimates may have heavy tails. We show that a combination of gradient clipping, momentum, and normalized gradient descent yields convergence to critical points in high-probability with best-known rates for smooth losses when the gradients only have bounded $\\mathfrak{p}$th moments for some $\\mathfrak{p}\\in(1,2]$. We then consider the case of second-order smooth losses, which to our knowledge have not been studied in this setting, and again obtain high-probability bounds for any $\\mathfrak{p}$. Moreover, our results hold for arbitrary smooth norms, in contrast to the typical SGD analysis which requires a Hilbert space norm. Further, we show that after a suitable \"burn-in\" period, the objective value will monotonically decrease for every iteration until a critical point is identified, which provides intuition behind the popular practice of learning rate \"warm-up'' and also yields a last-iterate guarantee.", "submission_history": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "checklist": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "cutkosky|highprobability_bounds_for_nonconvex_stochastic_optimization_with_heavy_tails", "pdf": "/pdf/7b3d3e145a0419645712721640d1a7f65cdd6b8f.pdf", "supplementary_material": "/attachment/5cb595173a25215d23c9d20e853556a6ba37f2fa.pdf", "thumbnail": "", "_bibtex": "@inproceedings{\ncutkosky2021highprobability,\ntitle={High-probability Bounds for Non-Convex Stochastic Optimization with Heavy Tails},\nauthor={Ashok Cutkosky and Harsh Mehta},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=XeeTWJvAQl}\n}", "venue": "NeurIPS 2021 Oral", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492718764, "odate": 1636492718764, "details": {"replyCount": 9}}, {"id": "ZRPRjfAF3yd", "original": "-4ZKZkQr2_C", "number": 6077, "cdate": 1621630020326, "ddate": null, "tcdate": 1621630020326, "tmdate": 1683307659506, "tddate": null, "forum": "ZRPRjfAF3yd", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Drop, Swap, and Generate: A Self-Supervised Approach for Generating Neural Activity", "authorids": ["~Ran_Liu2", "~Mehdi_Azabou2", "~Max_Dabagia1", "~Chi-Heng_Lin1", "~Mohammad_Gheshlaghi_Azar1", "~Keith_B_Hengen1", "~Michal_Valko1", "~Eva_L_Dyer1"], "authors": ["Ran Liu", "Mehdi Azabou", "Max Dabagia", "Chi-Heng Lin", "Mohammad Gheshlaghi Azar", "Keith B Hengen", "Michal Valko", "Eva L Dyer"], "keywords": ["Generative modeling", "Self-supervised learning", "Neural decoding", "Neural population activity", "Representation learning"], "TL;DR": "We propose Swap-VAE, a generative approach with an instance-specific alignment loss to disentangle neural activities.", "abstract": "Meaningful and simplified representations of neural activity can yield insights into how and what information is being processed within a neural circuit. However, without labels, finding representations that reveal the link between the brain and behavior can be challenging. Here, we introduce a novel unsupervised approach for learning disentangled representations of neural activity called Swap-VAE. Our approach combines a generative modeling framework with an instance-specific alignment loss that tries to maximize the representational similarity between transformed views of the input (brain state). These transformed (or augmented) views are created by dropping out neurons and jittering samples in time, which intuitively should lead the network to a representation that maintains both temporal consistency and invariance to the specific neurons used to represent the neural state. Through evaluations on both synthetic data and neural recordings from hundreds of neurons in different primate brains, we show that it is possible to build representations that disentangle neural datasets along relevant latent dimensions linked to behavior.", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "liu|drop_swap_and_generate_a_selfsupervised_approach_for_generating_neural_activity", "pdf": "/pdf/044cf9bcd955efa27858483633cd8ca4cc00d1d8.pdf", "checklist": "", "supplementary_material": "/attachment/3035d997dd3c01b80eb22c922b2d4922497f28e9.pdf", "code": "https://github.com/nerdslab/SwapVAE/tree/main", "thumbnail": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nliu2021drop,\ntitle={Drop, Swap, and Generate: A Self-Supervised Approach for Generating Neural Activity},\nauthor={Ran Liu and Mehdi Azabou and Max Dabagia and Chi-Heng Lin and Mohammad Gheshlaghi Azar and Keith B Hengen and Michal Valko and Eva L Dyer},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=ZRPRjfAF3yd}\n}", "venue": "NeurIPS 2021 Oral", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492738233, "odate": 1636492738233, "details": {"replyCount": 10}}, {"id": "-zALR_-372y", "original": "SKOokcl6Xav", "number": 5981, "cdate": 1621630014606, "ddate": null, "tcdate": 1621630014606, "tmdate": 1683307656999, "tddate": null, "forum": "-zALR_-372y", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "The best of both worlds: stochastic and adversarial episodic MDPs with unknown transition", "authorids": ["~Tiancheng_Jin2", "~Longbo_Huang2", "~Haipeng_Luo1"], "authors": ["Tiancheng Jin", "Longbo Huang", "Haipeng Luo"], "keywords": ["reinforcement learning", "online learning", "best of both worlds"], "TL;DR": "We propose algorithms to achieve best-of-both-worlds results of learning episodic MDPs. ", "abstract": "We consider the best-of-both-worlds problem for learning an episodic Markov Decision Process through $T$ episodes, with the goal of achieving $\\widetilde{\\mathcal{O}}(\\sqrt{T})$ regret when the losses are adversarial and simultaneously $\\mathcal{O}(\\log T)$ regret when the losses are (almost) stochastic. Recent work by [Jin and Luo, 2020]  achieves this goal when the fixed transition is known, and leaves the case of unknown transition as a major open question. In this work, we resolve this open problem by using the same Follow-the-Regularized-Leader (FTRL) framework together with a set of new techniques. Specifically, we first propose a loss-shifting trick in the FTRL analysis, which greatly simplifies the approach of [Jin and Luo, 2020] and already improves their results for the known transition case. Then, we extend this idea to the unknown transition case and develop a novel analysis which upper bounds the transition estimation error by the regret itself in the stochastic setting, a key property to ensure $\\mathcal{O}(\\log T)$ regret.", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "jin|the_best_of_both_worlds_stochastic_and_adversarial_episodic_mdps_with_unknown_transition", "pdf": "/pdf/facd73f28c698895da6a21b31a8af6240617e315.pdf", "checklist": "", "supplementary_material": "/attachment/d112d5b8952ef72e8dabf64d880fa3fc7c151d54.pdf", "thumbnail": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\njin2021the,\ntitle={The best of both worlds: stochastic and adversarial episodic {MDP}s with unknown transition},\nauthor={Tiancheng Jin and Longbo Huang and Haipeng Luo},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=-zALR_-372y}\n}", "venue": "NeurIPS 2021 Oral", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492785515, "odate": 1636492785515, "details": {"replyCount": 10}}, {"id": "wfJCeMS-jH", "original": "YRvHkod9Toq", "number": 5910, "cdate": 1621630010383, "ddate": null, "tcdate": 1621630010383, "tmdate": 1683307654877, "tddate": null, "forum": "wfJCeMS-jH", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Causal Identification with Matrix Equations", "authorids": ["~Sanghack_Lee1", "~Elias_Bareinboim2"], "authors": ["Sanghack Lee", "Elias Bareinboim"], "keywords": ["Causal Inference", "Causal Effect Identifiability", "Causal Effect", "Causality"], "abstract": "Causal effect identification is concerned with determining whether a causal effect is computable from a combination of qualitative assumptions about the underlying system (e.g., a causal graph) and distributions collected from this system. Many identification algorithms exclusively rely on graphical criteria made of a non-trivial combination of probability axioms, do-calculus, and refined c-factorization (e.g., Lee & Bareinboim, 2020). In a sequence of increasingly sophisticated results, it has been shown how proxy variables can be used to identify certain effects that would not be otherwise recoverable in challenging scenarios through solving matrix equations (e.g., Kuroki & Pearl, 2014; Miao et al., 2018). In this paper, we develop a new causal identification algorithm which utilizes both graphical criteria and matrix equations. Specifically, we first characterize the relationships between certain graphically-driven formulae and matrix multiplications. With such characterizations, we broaden the spectrum of proxy variable based identification conditions and further propose novel intermediary criteria based on the pseudoinverse of a matrix. Finally, we devise a causal effect identification algorithm, which accepts as input a collection of marginal, conditional, and interventional distributions, integrating enriched matrix-based criteria into a graphical identification approach.", "submission_history": "", "submission_history_-_venue_and_year": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "lee|causal_identification_with_matrix_equations", "pdf": "/pdf/189f8958bbfbba71e46f2676147685619d2918e2.pdf", "submission_history_-_improvements_made": "", "checklist": "", "supplementary_material": "", "thumbnail": "", "_bibtex": "@inproceedings{\nlee2021causal,\ntitle={Causal Identification with Matrix Equations},\nauthor={Sanghack Lee and Elias Bareinboim},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=wfJCeMS-jH}\n}", "venue": "NeurIPS 2021 Oral", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492736183, "odate": 1636492736141, "details": {"replyCount": 10}}, {"id": "lHmhW2zmVN", "original": "EtxZyAZt4yZ", "number": 5869, "cdate": 1621630007948, "ddate": null, "tcdate": 1621630007948, "tmdate": 1683307652803, "tddate": null, "forum": "lHmhW2zmVN", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Attention over Learned Object Embeddings Enables Complex Visual Reasoning", "authorids": ["~David_Ding2", "~Felix_Hill1", "~Adam_Santoro1", "~Malcolm_Reynolds1", "~Matthew_Botvinick1"], "authors": ["David Ding", "Felix Hill", "Adam Santoro", "Malcolm Reynolds", "Matthew Botvinick"], "keywords": ["Spatio-temporal reasoning", "self-attention", "transformers", "object attention", "visual question answering"], "TL;DR": "A general framework of attention over learned object embeddings outperforms task-specific models on complex visual reasoning tasks thought to be too challenging for general models.", "abstract": "Neural networks have achieved success in a wide array of perceptual tasks but often fail at tasks involving both perception and higher-level reasoning. On these more challenging tasks, bespoke approaches (such as modular symbolic components, independent dynamics models or semantic parsers) targeted towards that specific type of task have typically performed better. The downside to these targeted approaches, however, is that they can be more brittle than general-purpose neural networks, requiring significant modification or even redesign according to the particular task at hand. Here, we propose a more general neural-network-based approach to dynamic visual reasoning problems that obtains state-of-the-art performance on three different domains, in each case outperforming bespoke modular approaches tailored specifically to the task. Our method relies on learned object-centric representations, self-attention and self-supervised dynamics learning, and all three elements together are required for strong performance to emerge. The success of this combination suggests that there may be no need to trade off flexibility for performance on problems involving spatio-temporal or causal-style reasoning. With the right soft biases and learning objectives in a neural network we may be able to attain the best of both worlds.    \n", "submission_history": "", "submission_history_-_venue_and_year": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "ding|attention_over_learned_object_embeddings_enables_complex_visual_reasoning", "pdf": "/pdf/49bf3fa700fe4d6a3eafd6f48ba103bd140c95f4.pdf", "submission_history_-_improvements_made": "", "checklist": "", "supplementary_material": "/attachment/52696f15b72fe163e3e32bf0ec9ecb63a5c4483a.pdf", "code": "https://github.com/deepmind/deepmind-research/tree/master/object_attention_for_reasoning", "thumbnail": "", "_bibtex": "@inproceedings{\nding2021attention,\ntitle={Attention over Learned Object Embeddings Enables Complex Visual Reasoning},\nauthor={David Ding and Felix Hill and Adam Santoro and Malcolm Reynolds and Matthew Botvinick},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=lHmhW2zmVN}\n}", "venue": "NeurIPS 2021 Oral", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492737803, "odate": 1636492737803, "details": {"replyCount": 13}}, {"id": "WKxmP7bcFvt", "original": "hs2gg4pa0gj", "number": 5498, "cdate": 1621629982414, "ddate": null, "tcdate": 1621629982414, "tmdate": 1683307645243, "tddate": null, "forum": "WKxmP7bcFvt", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Separation Results between Fixed-Kernel and Feature-Learning Probability Metrics", "authorids": ["~Carles_Domingo-Enrich1", "~Youssef_Mroueh1"], "authors": ["Carles Domingo-Enrich", "Youssef Mroueh"], "keywords": ["integral probability metric", "kernel", "feature", "separation", "distribution", "harmonics", "Legendre"], "TL;DR": "We provide separation results between probability metrics with fixed-kernel and feature-learning discriminators.", "abstract": "Several works in implicit and explicit generative modeling empirically observed that feature-learning discriminators  outperform  fixed-kernel discriminators in terms of the sample quality of the models. We provide separation results between probability metrics with fixed-kernel and feature-learning discriminators using the function classes $\\mathcal{F}_2$  and $\\mathcal{F}_1$ respectively, which were developed to study overparametrized two-layer neural networks. In particular, we construct pairs of distributions over hyper-spheres that can not be discriminated by  fixed kernel $(\\mathcal{F}_2)$ integral probability metric (IPM) and Stein discrepancy (SD) in high dimensions, but that can be discriminated by their feature learning ($\\mathcal{F}_1$) counterparts. To further study the separation we provide links between the $\\mathcal{F}_1$ and $\\mathcal{F}_2$ IPMs with sliced Wasserstein distances. Our work suggests that fixed-kernel discriminators perform worse than their feature learning counterparts because their corresponding metrics are weaker.", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "domingoenrich|separation_results_between_fixedkernel_and_featurelearning_probability_metrics", "pdf": "/pdf/f1810461ace25edaad7e1fa7de6346022c7fd707.pdf", "supplementary_material": "/attachment/f64b65f5c1344eb298ce3b7f7d0e960cfc425591.zip", "checklist": "", "code": "https://github.com/CDEnrich/separation_ipms", "thumbnail": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\ndomingo-enrich2021separation,\ntitle={Separation Results between Fixed-Kernel and Feature-Learning Probability Metrics},\nauthor={Carles Domingo-Enrich and Youssef Mroueh},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=WKxmP7bcFvt}\n}", "venue": "NeurIPS 2021 Oral", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492738150, "odate": 1636492738150, "details": {"replyCount": 15}}, {"id": "dfyjet3BMKA", "original": "AyszjIH_Fqi", "number": 5454, "cdate": 1621629979145, "ddate": null, "tcdate": 1621629979145, "tmdate": 1683307643592, "tddate": null, "forum": "dfyjet3BMKA", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Optimal Rates for Random Order Online Optimization", "authorids": ["~Uri_Sherman1", "~Tomer_Koren1", "~Yishay_Mansour2"], "authors": ["Uri Sherman", "Tomer Koren", "Yishay Mansour"], "keywords": ["Online Learning", "Convex Optimization", "Algorithmic Stability", "Stochastic Gradient Descent"], "abstract": "We study online convex optimization in the random order model, recently proposed by Garber et al. (2020), where the loss functions may be chosen by an adversary, but are then presented to the online algorithm in a uniformly random order. Focusing on the scenario where the cumulative loss function is (strongly) convex, yet individual loss functions are smooth but might be non-convex, we give algorithms that achieve the optimal bounds and significantly outperform the results of Garber et al. (2020), completely removing the dimension dependence and improve their scaling with respect to the strong convexity parameter. Our analysis relies on novel connections between algorithmic stability and generalization for sampling without-replacement analogous to those studied in the with-replacement i.i.d. setting, as well as on a refined average stability analysis of stochastic gradient descent.", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "sherman|optimal_rates_for_random_order_online_optimization", "TL;DR": "Average stability of SGD under without-replacement sampling leads to optimal regret upper bounds for random order online optimization.", "pdf": "/pdf/2afeb552cb828e83a8774799cb25afb780c5b0f0.pdf", "checklist": "", "supplementary_material": "", "thumbnail": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nsherman2021optimal,\ntitle={Optimal Rates for Random Order Online Optimization},\nauthor={Uri Sherman and Tomer Koren and Yishay Mansour},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=dfyjet3BMKA}\n}", "venue": "NeurIPS 2021 Oral", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492705198, "odate": 1636492705198, "details": {"replyCount": 11}}, {"id": "et2st4Jqhc", "original": "rGgKVEzSlqB", "number": 5450, "cdate": 1621629978941, "ddate": null, "tcdate": 1621629978941, "tmdate": 1697937544935, "tddate": null, "forum": "et2st4Jqhc", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Online Variational Filtering and Parameter Learning", "authorids": ["~Andrew_Campbell4", "~Yuyang_Shi2", "~Tom_Rainforth1", "~Arnaud_Doucet2"], "authors": ["Andrew Campbell", "Yuyang Shi", "Tom Rainforth", "Arnaud Doucet"], "keywords": ["Approximate Inference", "Variational inference", "State-space models", "Filtering", "Time series", "Online learning"], "TL;DR": "Novel online variational inference to perform joint state estimation and parameter learning", "abstract": "We present a variational method for online state estimation and parameter learning in state-space models (SSMs), a ubiquitous class of latent variable models for sequential data. As per standard batch variational techniques, we use stochastic gradients to simultaneously optimize a lower bound on the log evidence with respect to both model parameters and a variational approximation of the states' posterior distribution. However, unlike existing approaches, our method is able to operate in an entirely online manner, such that historic observations do not require revisitation after being incorporated and the cost of updates at each time step remains constant, despite the growing dimensionality of the joint posterior distribution of the states. This is achieved by utilizing backward decompositions of this joint posterior distribution and of its variational approximation, combined with Bellman-type recursions for the evidence lower bound and its gradients. We demonstrate the performance of this methodology across several examples, including high-dimensional SSMs and sequential Variational Auto-Encoders.", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "campbell|online_variational_filtering_and_parameter_learning", "pdf": "/pdf/3b0ccb90e312223e18e4cca441f262b0a191956c.pdf", "checklist": "", "supplementary_material": "/attachment/26157242d87590179920dd3a5b25217fc0862d0c.pdf", "code": "https://github.com/andrew-cr/online_var_fil", "thumbnail": "", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 3 code implementations](https://www.catalyzex.com/paper/arxiv:2110.13549/code)", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\ncampbell2021online,\ntitle={Online Variational Filtering and Parameter Learning},\nauthor={Andrew Campbell and Yuyang Shi and Tom Rainforth and Arnaud Doucet},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=et2st4Jqhc}\n}", "venue": "NeurIPS 2021 Oral", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492750815, "odate": 1636492750815, "details": {"replyCount": 16}}, {"id": "S9ZyhWC17wJ", "original": "ia22zIICSC0", "number": 4916, "cdate": 1621629947272, "ddate": null, "tcdate": 1621629947272, "tmdate": 1683307630696, "tddate": null, "forum": "S9ZyhWC17wJ", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Learning with Noisy Correspondence for Cross-modal Matching", "authorids": ["~Zhenyu_Huang1", "~Guocheng_Niu1", "~Xiao_Liu20", "~Wenbiao_Ding1", "~Xinyan_Xiao1", "~hua_wu1", "~Xi_Peng3"], "authors": ["Zhenyu Huang", "Guocheng Niu", "Xiao Liu", "Wenbiao Ding", "Xinyan Xiao", "hua wu", "Xi Peng"], "keywords": ["multimodal learning", "noisy labels", "cross-modal matching", "mismatching"], "abstract": "Cross-modal matching, which aims to establish the correspondence between two different modalities, is fundamental to a variety of tasks such as cross-modal retrieval and vision-and-language understanding. Although a huge number of cross-modal matching methods have been proposed and achieved remarkable progress in recent years, almost all of these methods implicitly assume that the multimodal training data are correctly aligned. In practice, however, such an assumption is extremely expensive even impossible to satisfy. Based on this observation, we reveal and study a latent and challenging direction in cross-modal matching, named noisy correspondence, which could be regarded as a new paradigm of noisy labels. Different from the traditional noisy labels which mainly refer to the errors in category labels, our noisy correspondence refers to the mismatch paired samples. To solve this new problem, we propose a novel method for learning with noisy correspondence, named Noisy Correspondence Rectifier (NCR). In brief, NCR divides the data into clean and noisy partitions based on the memorization effect of neural networks and then rectifies the correspondence via an adaptive prediction model in a co-teaching manner. To verify the effectiveness of our method, we conduct experiments by using the image-text matching as a showcase. Extensive experiments on Flickr30K, MS-COCO, and Conceptual Captions verify the effectiveness of our method. The code could be accessed from www.pengxi.me .", "pdf": "/pdf/bea8fb9aa88c88bc0f403110d9403bbacc61a783.pdf", "supplementary_material": "/attachment/3856ad405fe8904fab3a57f063a8b47936999b7d.pdf", "submission_history": "", "checklist": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "huang|learning_with_noisy_correspondence_for_crossmodal_matching", "code": "http://pengxi.me", "thumbnail": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nhuang2021learning,\ntitle={Learning with Noisy Correspondence for Cross-modal Matching},\nauthor={Zhenyu Huang and Guocheng Niu and Xiao Liu and Wenbiao Ding and Xinyan Xiao and hua wu and Xi Peng},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=S9ZyhWC17wJ}\n}", "venue": "NeurIPS 2021 Oral", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492686786, "odate": 1636492686786, "details": {"replyCount": 17}}, {"id": "VXeoK3fJZhW", "original": "NInLOoOG4SOA", "number": 4641, "cdate": 1621629930633, "ddate": null, "tcdate": 1621629930633, "tmdate": 1697937575938, "tddate": null, "forum": "VXeoK3fJZhW", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Replacing Rewards with Examples: Example-Based Policy Search via Recursive Classification", "authorids": ["~Benjamin_Eysenbach1", "~Sergey_Levine1", "~Ruslan_Salakhutdinov1"], "authors": ["Benjamin Eysenbach", "Sergey Levine", "Ruslan Salakhutdinov"], "keywords": ["reinforcement learning", "example-based control"], "TL;DR": "A method for solving RL tasks using examples of desired outcomes, rather than reward functions, that significantly outperforms prior methods.", "abstract": "Reinforcement learning (RL) algorithms assume that users specify tasks by manually writing down a reward function. However, this process can be laborious and demands considerable technical expertise. Can we devise RL algorithms that instead enable users to specify tasks simply by providing examples of successful outcomes? In this paper, we derive a control algorithm that maximizes the future probability of these successful outcome examples. Prior work has approached similar problems with a two-stage process, first learning a reward function and then optimizing this reward function using another reinforcement learning algorithm. In contrast, our method directly learns a value function from transitions and successful outcomes, without learning this intermediate reward function. Our method therefore requires fewer hyperparameters to tune and lines of code to debug. We show that our method satisfies a new data-driven Bellman equation, where examples take the place of the typical reward function term. Experiments show that our approach outperforms prior methods that learn explicit reward functions.", "submission_history": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "checklist": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "eysenbach|replacing_rewards_with_examples_examplebased_policy_search_via_recursive_classification", "pdf": "/pdf/37163f48314b5ccf57ec2a1bb100b3202e3e8da7.pdf", "supplementary_material": "/attachment/a3ba0581ee0ebd65b5628e1a59e0fd58a29b9680.pdf", "code": "https://github.com/google-research/google-research/tree/master/rce", "thumbnail": "", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2103.12656/code)", "_bibtex": "@inproceedings{\neysenbach2021replacing,\ntitle={Replacing Rewards with Examples: Example-Based Policy Search via Recursive Classification},\nauthor={Benjamin Eysenbach and Sergey Levine and Ruslan Salakhutdinov},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=VXeoK3fJZhW}\n}", "venue": "NeurIPS 2021 Oral", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492716577, "odate": 1636492716521, "details": {"replyCount": 7}}, {"id": "0CDKgyYaxC8", "original": "UCPg8mSkfeJ", "number": 4631, "cdate": 1621629930002, "ddate": null, "tcdate": 1621629930002, "tmdate": 1697937576167, "tddate": null, "forum": "0CDKgyYaxC8", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Evaluating Gradient Inversion Attacks and Defenses in Federated Learning", "authorids": ["~Yangsibo_Huang2", "~Samyak_Gupta1", "~Zhao_Song5", "~Kai_Li8", "~Sanjeev_Arora1"], "authors": ["Yangsibo Huang", "Samyak Gupta", "Zhao Song", "Kai Li", "Sanjeev Arora"], "keywords": ["Federated learning", "gradient inversion", "deep leakage from gradients"], "abstract": "Gradient inversion attack (or input recovery from gradient) is an emerging threat to the security and privacy preservation of Federated learning, whereby malicious eavesdroppers or participants in the protocol can recover (partially) the clients' private data. This paper evaluates existing attacks and defenses. We find that some attacks make strong assumptions about the setup. Relaxing such assumptions can substantially weaken these attacks. We then evaluate the benefits of three proposed defense mechanisms against gradient inversion attacks. We show the trade-offs of privacy leakage and data utility of these defense methods, and find that combining them in an appropriate manner makes the attack less effective, even under the original strong assumptions. We also estimate the computation cost of end-to-end recovery of a single image under each evaluated defense. Our findings suggest that the state-of-the-art attacks can currently be defended against with minor data utility loss, as summarized in a list of potential strategies.", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "huang|evaluating_gradient_inversion_attacks_and_defenses_in_federated_learning", "pdf": "/pdf/73ed67f462a136d9a8071ac89807ec23875213dc.pdf", "checklist": "", "supplementary_material": "/attachment/484c50ac4de31b28c8f0309cc32d7a386d1e76d9.pdf", "thumbnail": "", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 2 code implementations](https://www.catalyzex.com/paper/arxiv:2112.00059/code)", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nhuang2021evaluating,\ntitle={Evaluating Gradient Inversion Attacks and Defenses in Federated Learning},\nauthor={Yangsibo Huang and Samyak Gupta and Zhao Song and Kai Li and Sanjeev Arora},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=0CDKgyYaxC8}\n}", "venue": "NeurIPS 2021 Oral", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492762501, "odate": 1636492762501, "details": {"replyCount": 12}}, {"id": "QT9ulkiN-LX", "original": "yc2IlK-Jshr", "number": 4155, "cdate": 1621629901006, "ddate": null, "tcdate": 1621629901006, "tmdate": 1697937600883, "tddate": null, "forum": "QT9ulkiN-LX", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Framing RNN as a kernel method: A neural ODE approach", "authorids": ["~Adeline_Fermanian1", "~Pierre_Marion1", "~Jean-Philippe_Vert1", "~G\u00e9rard_Biau1"], "authors": ["Adeline Fermanian", "Pierre Marion", "Jean-Philippe Vert", "G\u00e9rard Biau"], "keywords": ["recurrent neural networks", "neural ODE", "kernel method", "theory of deep learning", "generalization bounds"], "abstract": "Building on the interpretation of a recurrent neural network (RNN) as a continuous-time neural differential equation, we show, under appropriate conditions, that the solution of a RNN can be viewed as a linear function of a specific feature set of the input sequence, known as the signature. This connection allows us to frame a RNN as a kernel method in a suitable reproducing kernel Hilbert space. As a consequence, we obtain theoretical guarantees on generalization and stability for a large class of recurrent networks. Our results are illustrated on simulated datasets.", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "fermanian|framing_rnn_as_a_kernel_method_a_neural_ode_approach", "TL;DR": "Via a neural ODE approach, we frame RNN as a kernel method and derive theoretical guarantees on generalization and stability.", "pdf": "/pdf/a396172fe20676803c53ba0b717bf3085c815b02.pdf", "supplementary_material": "/attachment/a104c7c1657a64bf3e3412bc0f1ad1de83c6f55f.pdf", "checklist": "", "code": "https://github.com/afermanian/rnn-kernel", "thumbnail": "", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 5 code implementations](https://www.catalyzex.com/paper/arxiv:2106.01202/code)", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nfermanian2021framing,\ntitle={Framing {RNN} as a kernel method: A neural {ODE} approach},\nauthor={Adeline Fermanian and Pierre Marion and Jean-Philippe Vert and G{\\'e}rard Biau},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=QT9ulkiN-LX}\n}", "venue": "NeurIPS 2021 Oral", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492776083, "odate": 1636492776083, "details": {"replyCount": 10}}, {"id": "-oUhJJILWHb", "original": "uc1QEf15J0", "number": 4037, "cdate": 1621629894113, "ddate": null, "tcdate": 1621629894113, "tmdate": 1683307607195, "tddate": null, "forum": "-oUhJJILWHb", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Learning Debiased Representation via Disentangled Feature Augmentation", "authorids": ["~Jungsoo_Lee1", "~Eungyeup_Kim1", "~Juyoung_Lee2", "~Jihyeon_Lee1", "~Jaegul_Choo1"], "authors": ["Jungsoo Lee", "Eungyeup Kim", "Juyoung Lee", "Jihyeon Lee", "Jaegul Choo"], "keywords": ["Debiasing", "Disentangled representation", "Feature-level augmentation", "Image classification"], "TL;DR": "This paper proposes a novel feature-level data augmentation for debiasing via learning disentangled representation. ", "abstract": "Image classification models tend to make decisions based on peripheral attributes of data items that have strong correlation with a target variable (i.e., dataset bias). These biased models suffer from the poor generalization capability when evaluated on unbiased datasets. Existing approaches for debiasing often identify and emphasize those samples with no such correlation (i.e., bias-conflicting) without defining the bias type in advance. However, such bias-conflicting samples are significantly scarce in biased datasets, limiting the debiasing capability of these approaches. This paper first presents an empirical analysis revealing that training with \"diverse\" bias-conflicting samples beyond a given training set is crucial for debiasing as well as the generalization capability. Based on this observation, we propose a novel feature-level data augmentation technique in order to synthesize diverse bias-conflicting samples.  To this end, our method learns the disentangled representation of (1) the intrinsic attributes (i.e., those inherently defining a certain class) and (2) bias attributes (i.e., peripheral attributes causing the bias), from a large number of bias-aligned samples, the bias attributes of which have strong correlation with the target variable.  Using the disentangled representation, we synthesize bias-conflicting samples that contain the diverse intrinsic attributes of bias-aligned samples by swapping their latent features. By utilizing these diversified bias-conflicting features during the training, our approach achieves superior classification accuracy and debiasing results against the existing baselines on both synthetic and real-world datasets.", "submission_history": "", "checklist": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "lee|learning_debiased_representation_via_disentangled_feature_augmentation", "pdf": "/pdf/cf404f31c4c4796d921c1e0cb287f8ae0bdcbe73.pdf", "supplementary_material": "/attachment/6d1eb6132e983e94c254a6896bfb9b74c3479353.pdf", "code": "https://github.com/kakaoenterprise/Learning-Debiased-Disentangled", "thumbnail": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nlee2021learning,\ntitle={Learning Debiased Representation via Disentangled Feature Augmentation},\nauthor={Jungsoo Lee and Eungyeup Kim and Juyoung Lee and Jihyeon Lee and Jaegul Choo},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=-oUhJJILWHb}\n}", "venue": "NeurIPS 2021 Oral", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492691955, "odate": 1636492691955, "details": {"replyCount": 14}}, {"id": "N5hQI_RowVA", "original": "vei9DKsxUW", "number": 4008, "cdate": 1621629892344, "ddate": null, "tcdate": 1621629892344, "tmdate": 1683307606653, "tddate": null, "forum": "N5hQI_RowVA", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "E(n) Equivariant Normalizing Flows", "authorids": ["~Victor_Garcia_Satorras2", "~Emiel_Hoogeboom1", "~Fabian_Bernd_Fuchs1", "~Ingmar_Posner1", "~Max_Welling1"], "authors": ["Victor Garcia Satorras", "Emiel Hoogeboom", "Fabian Bernd Fuchs", "Ingmar Posner", "Max Welling"], "keywords": ["equivariance", "normalizing flows", "molecule generation", "generative models", "graph neural networks"], "abstract": "This paper introduces a generative model equivariant to Euclidean symmetries: E(n) Equivariant Normalizing Flows (E-NFs). To construct E-NFs, we take the discriminative E(n) graph neural networks and integrate them as a differential equation to obtain an invertible equivariant function: a continuous-time normalizing flow. We demonstrate that E-NFs considerably outperform baselines and existing methods from the literature on particle systems such as DW4 and LJ13, and on molecules from QM9 in terms of log-likelihood. To the best of our knowledge, this is the first flow that jointly generates molecule features and positions in 3D.", "submission_history": "", "checklist": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "satorras|en_equivariant_normalizing_flows", "pdf": "/pdf/387e4d748ad81d22db42fb4bdf048b8fef213e93.pdf", "supplementary_material": "/attachment/b0e974b087d7be645afe34810a2773b48e1e6978.pdf", "code": "https://github.com/vgsatorras/en_flows", "thumbnail": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nsatorras2021en,\ntitle={E(n) Equivariant Normalizing Flows},\nauthor={Victor Garcia Satorras and Emiel Hoogeboom and Fabian Bernd Fuchs and Ingmar Posner and Max Welling},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=N5hQI_RowVA}\n}", "venue": "NeurIPS 2021 Oral", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492747216, "odate": 1636492747216, "details": {"replyCount": 9}}, {"id": "3qYgdGj9Svt", "original": "1yFsSr_c-P", "number": 3582, "cdate": 1621629866729, "ddate": null, "tcdate": 1621629866729, "tmdate": 1683307595422, "tddate": null, "forum": "3qYgdGj9Svt", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Efficient First-Order Contextual Bandits: Prediction, Allocation, and Triangular Discrimination", "authorids": ["~Dylan_J_Foster1", "~Akshay_Krishnamurthy1"], "authors": ["Dylan J Foster", "Akshay Krishnamurthy"], "keywords": ["contextual bandits", "reinforcement learning", "statistical learning", "learning theory", "fast rates", "adaptivity", "sequential probability assignment", "conditional density estimation", "logarithmic loss"], "TL;DR": "We resolve a COLT 2017 open problem (under an additional realizability assumption) with a simple and practical contextual bandit algorithm with an optimal first-order regret guarantee.", "abstract": "A recurring theme in statistical learning, online learning, and beyond is that faster convergence rates are possible for problems with low noise, often quantified by the performance of the best hypothesis; such results are known as first-order or small-loss guarantees. While first-order guarantees are relatively well understood in statistical and online learning, adapting to low noise in contextual bandits (and more broadly, decision making) presents major algorithmic challenges. In a COLT 2017 open problem, Agarwal, Krishnamurthy, Langford, Luo, and Schapire asked whether first-order guarantees are even possible for contextual bandits and---if so---whether they can be attained by efficient algorithms. We give a resolution to this question by providing an optimal and efficient reduction from contextual bandits to online regression with the logarithmic (or, cross-entropy) loss. Our algorithm is simple and practical, readily accommodates rich function classes, and requires no distributional assumptions beyond realizability. In a large-scale empirical evaluation, we find that our approach typically outperforms  comparable non-first-order methods.\n\nOn the technical side, we show that the logarithmic loss and an information-theoretic quantity called the triangular discrimination play a fundamental role in obtaining first-order guarantees, and we combine this observation with new refinements to the regression oracle reduction framework of Foster and Rakhlin (2020). The use of triangular discrimination yields novel results even for the classical statistical learning model, and we anticipate that it will find broader use.", "submission_history": "", "checklist": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "foster|efficient_firstorder_contextual_bandits_prediction_allocation_and_triangular_discrimination", "pdf": "/pdf/e65b3c32f13f89e25580d446fa41ae7f13fbbdd8.pdf", "supplementary_material": "/attachment/fc79e9839839bad18a3f09d3f17d1b61b2124579.pdf", "code": "/attachment/66556e25d1238d428b13abad78faa33283843a39.zip", "thumbnail": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nfoster2021efficient,\ntitle={Efficient First-Order Contextual Bandits: Prediction, Allocation, and Triangular Discrimination},\nauthor={Dylan J Foster and Akshay Krishnamurthy},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=3qYgdGj9Svt}\n}", "venue": "NeurIPS 2021 Oral", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492719873, "odate": 1636492719873, "details": {"replyCount": 11}}, {"id": "6vaActvpcp3", "original": "FgCXCXi-rid", "number": 3579, "cdate": 1621629866536, "ddate": null, "tcdate": 1621629866536, "tmdate": 1683307595266, "tddate": null, "forum": "6vaActvpcp3", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Adaptive Conformal Inference Under Distribution Shift", "authorids": ["~Isaac_Gibbs1", "~Emmanuel_Candes1"], "authors": ["Isaac Gibbs", "Emmanuel Candes"], "keywords": ["Online Learning", "(Other) Statistics"], "abstract": "We develop methods for forming prediction sets in an online setting where the data generating distribution is allowed to vary over time in an unknown fashion. Our framework builds on ideas from conformal inference to provide a general wrapper that can be combined with any black box method that produces point predictions of the unseen label or estimated quantiles of its distribution. While previous conformal inference methods rely on the assumption that the data are exchangeable, our adaptive approach provably achieves the desired coverage frequency over long-time intervals irrespective of the true data generating process. We accomplish this by modelling the distribution shift as a learning problem in a single parameter whose optimal value is varying over time and must be continuously re-estimated. We test our method, adaptive conformal inference, on two real world datasets and find that its predictions are robust to visible and significant distribution shifts.", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "gibbs|adaptive_conformal_inference_under_distribution_shift", "TL;DR": "We develop methods for forming prediction intervals in an online environment that are robust to distribution shift.", "pdf": "/pdf/d1f578009b07b3327c7e28b33a3fb4fa655bf345.pdf", "supplementary_material": "/attachment/ed24b2b4bd009ee4e3465b291bdb58c6797eaca5.pdf", "checklist": "", "code": "https://github.com/isgibbs/AdaptiveConformal", "thumbnail": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\ngibbs2021adaptive,\ntitle={Adaptive Conformal Inference Under Distribution Shift},\nauthor={Isaac Gibbs and Emmanuel Candes},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=6vaActvpcp3}\n}", "venue": "NeurIPS 2021 Oral", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492730790, "odate": 1636492730790, "details": {"replyCount": 18}}, {"id": "026hEw26i3-", "original": "2AjZ3RcKBEB", "number": 3572, "cdate": 1621629866106, "ddate": null, "tcdate": 1621629866106, "tmdate": 1683307594967, "tddate": null, "forum": "026hEw26i3-", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "The decomposition of the higher-order homology embedding constructed from the $k$-Laplacian", "authorids": ["~Yu-Chia_Chen1", "~Marina_Meila1"], "authors": ["Yu-Chia Chen", "Marina Meila"], "keywords": ["homology embedding", "Hodge Laplacian", "unsupervised learning", "spectral method", "topological data analysis"], "abstract": "The null space of the $k$-th order Laplacian $\\mathbf{\\mathcal L}_k$, known as the {\\em $k$-th homology vector space}, encodes the non-trivial topology of a manifold or a network. Understanding the structure of the homology embedding can thus disclose geometric or topological information from the data. The study of the null space embedding of the graph Laplacian $\\mathbf{\\mathcal L}_0$ has spurred new research and applications, such as spectral clustering algorithms with theoretical guarantees and estimators of the Stochastic Block Model. In this work, we investigate the geometry of the $k$-th homology embedding and focus on cases reminiscent of spectral clustering. Namely, we analyze the {\\em connected sum} of manifolds as a perturbation to the direct sum of their homology embeddings. We propose an algorithm to factorize the homology embedding into subspaces corresponding to a manifold's simplest topological components. The proposed framework is applied to the {\\em shortest homologous loop detection} problem, a problem known to be NP-hard in general. Our spectral loop detection algorithm scales better than existing methods and is effective on diverse data such as point clouds and images. ", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "chen|the_decomposition_of_the_higherorder_homology_embedding_constructed_from_the_klaplacian", "pdf": "/pdf/eb088d79e0a9022b728c73866a67647bcff57c6b.pdf", "checklist": "", "supplementary_material": "/attachment/a79b8594381e665170745ec4050e174eed5c57d6.zip", "code": "https://github.com/yuchaz/homology_emb", "thumbnail": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nchen2021the,\ntitle={The decomposition of the higher-order homology embedding constructed from the \\$k\\$-Laplacian},\nauthor={Yu-Chia Chen and Marina Meila},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=026hEw26i3-}\n}", "venue": "NeurIPS 2021 Oral", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492755892, "odate": 1636492755892, "details": {"replyCount": 16}}, {"id": "vY2HsMWG2b_", "original": "S-PL2gzmUN_", "number": 3228, "cdate": 1621629845515, "ddate": null, "tcdate": 1621629845515, "tmdate": 1683307585459, "tddate": null, "forum": "vY2HsMWG2b_", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "The Complexity of Bayesian Network Learning: Revisiting the Superstructure", "authorids": ["~Robert_Ganian1", "~Viktoriia_Korchemna1"], "authors": ["Robert Ganian", "Viktoriia Korchemna"], "keywords": ["Bayesian Network Structure Learning", "parameterized complexity", "fixed-parameter tractability", "Polytree Learning"], "TL;DR": "We circumvent previously established complexity lower bounds and identify conditions under which Bayesian Network Structure Learning becomes fixed-parameter tractable.", "abstract": "We investigate the parameterized complexity of Bayesian Network Structure Learning (BNSL), a classical problem that has received significant attention in empirical but also purely theoretical studies. We follow up on previous works that have analyzed the complexity of BNSL w.r.t. the so-called superstructure of the input. While known results imply that BNSL is unlikely to be fixed-parameter tractable even when parameterized by the size of a vertex cover in the superstructure, here we show that a different kind of parameterization - notably by the size of a feedback edge set - yields fixed-parameter tractability. We proceed by showing that this result can be strengthened to a localized version of the feedback edge set, and provide corresponding lower bounds that complement previous results to provide a complexity classification of BNSL w.r.t. virtually all well-studied graph parameters.\n\nWe then analyze how the complexity of BNSL depends on the representation of the input. In particular, while the bulk of past theoretical work on the topic assumed the use of the so-called non-zero representation, here we prove that if an additive representation can be used instead then BNSL becomes fixed-parameter tractable even under significantly milder restrictions to the superstructure, notably when parameterized by the treewidth alone. Last but not least, we show how our results can be extended to the closely related problem of Polytree Learning.", "submission_history": "", "checklist": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "ganian|the_complexity_of_bayesian_network_learning_revisiting_the_superstructure", "pdf": "/pdf/e027b37a01b62fa3b402fadb6a16ddd7c9ee9f07.pdf", "supplementary_material": "/attachment/b0e3ce1ddc403caf8be80df0028a2a7cfb160d9b.pdf", "thumbnail": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nganian2021the,\ntitle={The Complexity of Bayesian Network Learning: Revisiting the Superstructure},\nauthor={Robert Ganian and Viktoriia Korchemna},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=vY2HsMWG2b_}\n}", "venue": "NeurIPS 2021 Oral", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492782789, "odate": 1636492782789, "details": {"replyCount": 10}}, {"id": "aMZJBOiOOPg", "original": "9u4_8j68Itk", "number": 2751, "cdate": 1621629818360, "ddate": null, "tcdate": 1621629818360, "tmdate": 1683307575277, "tddate": null, "forum": "aMZJBOiOOPg", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Oracle Complexity in Nonsmooth Nonconvex Optimization", "authorids": ["~Guy_Kornowski1", "~Ohad_Shamir1"], "authors": ["Guy Kornowski", "Ohad Shamir"], "keywords": ["nonconvex nonsmooth optimization", "optimization theory", "oracle complexity", "smoothing"], "TL;DR": "We theoretically study nonsmooth nonconvex optimization from an oracle complexity viewpoint, proving both hardness results and tradeoffs between computational efficiency and performance", "abstract": "It is well-known that given a smooth, bounded-from-below, and possibly nonconvex function, standard gradient-based methods can find $\\epsilon$-stationary points (with gradient norm less than $\\epsilon$) in $\\mathcal{O}(1/\\epsilon^2)$ iterations. However, many important nonconvex optimization problems, such as those associated with training modern neural networks, are inherently not smooth, making these results inapplicable. In this paper, we study nonsmooth nonconvex optimization from an oracle complexity viewpoint, where the algorithm is assumed to be given access only to local information about the function at various points. We provide two main results (under mild assumptions): First, we consider the problem of getting \\emph{near} $\\epsilon$-stationary points. This is perhaps the most natural relaxation of \\emph{finding} $\\epsilon$-stationary points, which is impossible in the nonsmooth nonconvex case. We prove that this relaxed goal cannot be achieved efficiently, for any distance and $\\epsilon$ smaller than some constants. Our second result deals with the possibility of tackling nonsmooth nonconvex optimization by reduction to smooth optimization: Namely, applying smooth optimization methods on a smooth approximation of the objective function. For this approach, we prove an inherent trade-off between oracle complexity and smoothness: On the one hand, smoothing a nonsmooth nonconvex function can be done very efficiently (e.g., by randomized smoothing), but with dimension-dependent factors in the smoothness parameter, which can strongly affect iteration complexity when plugging into standard smooth optimization methods. On the other hand, these dimension factors can be  eliminated with suitable smoothing methods, but only by making the oracle complexity of the smoothing process exponentially large.", "pdf": "/pdf/871dde316ca51ed24b86d92cbab904ca02a6cf91.pdf", "supplementary_material": "/attachment/58f0f71812d0bc9ab8856a4e507f4ecde28d5ce9.pdf", "submission_history": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "checklist": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "kornowski|oracle_complexity_in_nonsmooth_nonconvex_optimization", "thumbnail": "", "_bibtex": "@inproceedings{\nkornowski2021oracle,\ntitle={Oracle Complexity in Nonsmooth Nonconvex Optimization},\nauthor={Guy Kornowski and Ohad Shamir},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=aMZJBOiOOPg}\n}", "venue": "NeurIPS 2021 Oral", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492752105, "odate": 1636492752105, "details": {"replyCount": 13}}, {"id": "QmxFsofRvW9", "original": "QoqCFrySvpS", "number": 2384, "cdate": 1621629797289, "ddate": null, "tcdate": 1621629797289, "tmdate": 1697937673770, "tddate": null, "forum": "QmxFsofRvW9", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Unsupervised Speech Recognition", "authorids": ["~Alexei_Baevski1", "~Wei-Ning_Hsu2", "~Alexis_Conneau1", "~Michael_Auli1"], "authors": ["Alexei Baevski", "Wei-Ning Hsu", "Alexis Conneau", "Michael Auli"], "keywords": ["Deep learning", "speech processing", "unsupervised learning", "self-supervised learning", "adversarial learning", "GAN"], "TL;DR": "Unsupervised learning of speech recognition models using self-supervised representations.", "abstract": "Despite rapid progress in the recent past, current speech recognition systems still require labeled training data which limits this technology to a small fraction of the languages spoken around the globe. This paper describes wav2vec-U, short for wav2vec Unsupervised, a method to train speech recognition models without any labeled data. We leverage self-supervised speech representations to segment unlabeled audio and learn a mapping from these representations to phonemes via adversarial training. The right representations are key to the success of our method. Compared to the best previous unsupervised work, wav2vec-U reduces the phone error rate on the TIMIT benchmark from 26.1 to 11.3. On the larger English Librispeech benchmark, wav2vec-U achieves a word error rate of 5.9 on test-other, rivaling some of the best published systems trained on 960 hours of labeled data from only two years ago. We also experiment on nine other languages, including low-resource languages such as Kyrgyz, Swahili and Tatar.", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "baevski|unsupervised_speech_recognition", "pdf": "/pdf/522a0094e7c91a087a2a84dd1649090773ad523b.pdf", "supplementary_material": "/attachment/dac83ff21412eb7b719536e696daad564a3ae42a.pdf", "checklist": "", "code": "https://github.com/pytorch/fairseq/tree/main/examples/wav2vec/unsupervised", "thumbnail": "", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 3 code implementations](https://www.catalyzex.com/paper/arxiv:2105.11084/code)", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nbaevski2021unsupervised,\ntitle={Unsupervised Speech Recognition},\nauthor={Alexei Baevski and Wei-Ning Hsu and Alexis Conneau and Michael Auli},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=QmxFsofRvW9}\n}", "venue": "NeurIPS 2021 Oral", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492788602, "odate": 1636492788602, "details": {"replyCount": 8}}, {"id": "Ecuu521mPpG", "original": "Pr0Y_p_XgTk", "number": 2229, "cdate": 1621629788282, "ddate": null, "tcdate": 1621629788282, "tmdate": 1697937678133, "tddate": null, "forum": "Ecuu521mPpG", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Shape As Points: A Differentiable Poisson Solver", "authorids": ["~Songyou_Peng1", "~Chiyu_Max_Jiang1", "~Yiyi_Liao2", "~Michael_Niemeyer1", "~Marc_Pollefeys2", "~Andreas_Geiger3"], "authors": ["Songyou Peng", "Chiyu Max Jiang", "Yiyi Liao", "Michael Niemeyer", "Marc Pollefeys", "Andreas Geiger"], "keywords": ["Point Clouds", "Shape Representation", "3D Reconstruction", "Poisson Equation", "Implicit Representations", "Differentiable"], "abstract": "In recent years, neural implicit representations gained popularity in 3D reconstruction due to their expressiveness and flexibility. However, the implicit nature of neural implicit representations results in slow inference times and requires careful initialization. In this paper, we revisit the classic yet ubiquitous point cloud representation and introduce a differentiable point-to-mesh layer using a differentiable formulation of Poisson Surface Reconstruction (PSR) which allows for a GPU-accelerated fast solution of the indicator function given an oriented point cloud. The differentiable PSR layer allows us to efficiently and differentiably bridge the explicit 3D point representation with the 3D mesh via the implicit indicator field, enabling end-to-end optimization of surface reconstruction metrics such as Chamfer distance. This duality between points and meshes hence allows us to represent shapes as oriented point clouds, which are explicit, lightweight and expressive. Compared to neural implicit representations, our Shape-As-Points (SAP) model is more interpretable, lightweight, and accelerates inference time by one order of magnitude. Compared to other explicit representations such as points, patches, and meshes, SAP produces topology-agnostic, watertight manifold surfaces. We demonstrate the effectiveness of SAP on the task of surface reconstruction from unoriented point clouds and learning-based reconstruction.", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "peng|shape_as_points_a_differentiable_poisson_solver", "pdf": "/pdf/e157c4f3d739f7dec039317bdc6aca4cc46cc085.pdf", "checklist": "", "supplementary_material": "/attachment/1535d98c54d68416b687d6100dfe8b9fbec28ca9.pdf", "TL;DR": "SAP is a differentiable version of classic Poisson surface reconstruction, and an interpretable shape representation that efficiently connects points with HQ watertight meshes", "code": "https://github.com/autonomousvision/shape_as_points", "thumbnail": "", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 7 code implementations](https://www.catalyzex.com/paper/arxiv:2106.03452/code)", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\npeng2021shape,\ntitle={Shape As Points: A Differentiable Poisson Solver},\nauthor={Songyou Peng and Chiyu Max Jiang and Yiyi Liao and Michael Niemeyer and Marc Pollefeys and Andreas Geiger},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=Ecuu521mPpG}\n}", "venue": "NeurIPS 2021 Oral", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492776598, "odate": 1636492776598, "details": {"replyCount": 11}}, {"id": "8ygF02Zm51q", "original": "CHgFRT3Jbu0", "number": 1754, "cdate": 1621629762448, "ddate": null, "tcdate": 1621629762448, "tmdate": 1683307552126, "tddate": null, "forum": "8ygF02Zm51q", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "EF21: A New, Simpler, Theoretically Better, and Practically Faster Error Feedback", "authorids": ["~Peter_Richt\u00e1rik1", "~Igor_Sokolov3", "~Ilyas_Fatkhullin1"], "authors": ["Peter Richt\u00e1rik", "Igor Sokolov", "Ilyas Fatkhullin"], "keywords": ["error feedback", "distributed learning", "communication compression", "TopK", "contractive compressor", "distributed training", "distributed optimization"], "TL;DR": "We develop and analyze a new, simpler, theoretically better, and practically faster error feedback mechanism for distributed training with contractive compression operators.", "abstract": "Error feedback (EF), also known as error compensation, is an immensely popular convergence stabilization mechanism in the context of distributed training of supervised machine learning models enhanced by the use of contractive communication compression mechanisms, such as Top-$k$. First proposed by Seide et al [2014] as a heuristic, EF resisted any theoretical understanding until recently [Stich et al., 2018, Alistarh et al., 2018]. While these early breakthroughs were followed by a steady stream of works offering various improvements and generalizations, the current theoretical understanding of EF is still very limited. Indeed, to the best of our knowledge, all existing analyses either i) apply to the single node setting only, ii) rely on very strong and often unreasonable assumptions, such as global boundedness of the gradients, or iterate-dependent assumptions that cannot be checked a-priori and may not hold in practice, or iii) circumvent these issues via the introduction of additional unbiased compressors, which increase the communication cost. In this work we fix all these deficiencies by proposing and analyzing a new EF mechanism, which we call EF21, which consistently and substantially outperforms EF in practice. Moreover, our theoretical analysis relies on standard assumptions only, works in the distributed heterogeneous data setting, and leads to better and more meaningful rates. In particular, we prove that EF21 enjoys a fast $\\mathcal{O}(1/T)$  convergence rate for smooth nonconvex problems, beating the previous bound of $\\mathcal{O}(1/T^{2/3})$, which was shown under a strong bounded gradients assumption. We further improve this to a fast linear rate for Polyak-Lojasiewicz functions, which is the first linear convergence result for an error feedback method not relying on unbiased compressors. Since EF has a large number of applications where it reigns supreme, we believe that our 2021 variant, EF21, will have a large impact on the practice of communication efficient distributed learning.\t", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "richt\u00e1rik|ef21_a_new_simpler_theoretically_better_and_practically_faster_error_feedback", "pdf": "/pdf/3f9cf4f69938f800502edf4002f53c10de46be89.pdf", "checklist": "", "supplementary_material": "/attachment/31f0e38911a39d01ec149eb4a52a6d0d26be77ee.pdf", "thumbnail": "", "code": "https://github.com/IgorSokoloff/ef21_experiments_source_code", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nricht{\\'a}rik2021ef,\ntitle={{EF}21: A New, Simpler, Theoretically Better, and Practically Faster Error Feedback},\nauthor={Peter Richt{\\'a}rik and Igor Sokolov and Ilyas Fatkhullin},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=8ygF02Zm51q}\n}", "venue": "NeurIPS 2021 Oral", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492702898, "odate": 1636492702898, "details": {"replyCount": 34}}, {"id": "GlEWs-V9boR", "original": "Hk9qYelXzhS", "number": 1729, "cdate": 1621629760978, "ddate": null, "tcdate": 1621629760978, "tmdate": 1697937696453, "tddate": null, "forum": "GlEWs-V9boR", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Volume Rendering of Neural Implicit Surfaces", "authorids": ["~Lior_Yariv1", "~Jiatao_Gu1", "~Yoni_Kasten1", "~Yaron_Lipman1"], "authors": ["Lior Yariv", "Jiatao Gu", "Yoni Kasten", "Yaron Lipman"], "keywords": ["neural volume rendering", "implicit neural representations"], "abstract": "Neural volume rendering became increasingly popular recently due to its success in synthesizing novel views of a scene from a sparse set of input images. \nSo far, the geometry learned by neural volume rendering techniques was modeled using a generic density function. Furthermore, the geometry itself was extracted using an arbitrary level set of the density function leading to a noisy, often low fidelity reconstruction.\nThe goal of this paper is to improve geometry representation and reconstruction in neural volume rendering. We achieve that by modeling the volume density as a function of the geometry. This is in contrast to previous work modeling the geometry as a function of the volume density. \nIn more detail, we define the volume density function as Laplace's cumulative distribution function (CDF) applied to a signed distance function (SDF) representation. This simple density representation has three benefits: (i) it provides a useful inductive bias to the geometry learned in the neural volume rendering process; (ii) it facilitates a bound on the opacity approximation error, leading to an accurate sampling of the viewing ray. Accurate sampling is important to provide a precise coupling of geometry and radiance; and (iii) it allows efficient unsupervised disentanglement of shape and appearance in volume rendering.\nApplying this new density representation to challenging scene multiview datasets produced high quality geometry reconstructions, outperforming relevant baselines. Furthermore, switching shape and appearance between scenes is possible due to the disentanglement of the two. ", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "yariv|volume_rendering_of_neural_implicit_surfaces", "TL;DR": "Introducing volume rendering for neural implicit surfaces, allowing to learn high fidelity geometry from images.", "pdf": "/pdf/4c58b5c9800607211fa9e9322cf55ed27ebb4763.pdf", "checklist": "", "supplementary_material": "/attachment/9b07168b7d67b49705c7b8eca22e8e455e38e831.zip", "thumbnail": "", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 2 code implementations](https://www.catalyzex.com/paper/arxiv:2106.12052/code)", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nyariv2021volume,\ntitle={Volume Rendering of Neural Implicit Surfaces},\nauthor={Lior Yariv and Jiatao Gu and Yoni Kasten and Yaron Lipman},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=GlEWs-V9boR}\n}", "venue": "NeurIPS 2021 Oral", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492679919, "odate": 1636492679919, "details": {"replyCount": 15}}, {"id": "yaxePRTOhqk", "original": "ia2Bg50RV4T", "number": 1297, "cdate": 1621629736959, "ddate": null, "tcdate": 1621629736959, "tmdate": 1683307540669, "tddate": null, "forum": "yaxePRTOhqk", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Stability and Deviation Optimal Risk Bounds with Convergence Rate $O(1/n)$", "authorids": ["~Yegor_Klochkov3", "~Nikita_Zhivotovskiy2"], "authors": ["Yegor Klochkov", "Nikita Zhivotovskiy"], "keywords": ["algorithmic stability", "generalization bounds", "concentration inequalities", "stochastic convex optimization"], "TL;DR": "The first high-probability deviation risk bounds for uniformly stable algorithms with nearly optimal rate $O(\\log n/ n)$", "abstract": "The sharpest known high probability generalization bounds for uniformly stable algorithms (Feldman, Vondrak, NeurIPS 2018, COLT, 2019), (Bousquet, Klochkov, Zhivotovskiy, COLT, 2020) contain a generally inevitable sampling error term of order $\\Theta(1/\\sqrt{n})$. When applied to excess risk bounds, this leads to suboptimal results in several standard stochastic convex optimization problems. We show that if the so-called Bernstein condition is satisfied, the term $\\Theta(1/\\sqrt{n})$ can be avoided, and high probability excess risk bounds of order up to $O(1/n)$ are possible via uniform stability. Using this result, we show a high probability excess risk bound with the rate $O(\\log n/n)$ for strongly convex and Lipschitz losses valid for \\emph{any} empirical risk minimization method. This resolves a question of Shalev-Shwartz, Shamir, Srebro, and Sridharan (COLT, 2009). We discuss how $O(\\log n/n)$ high probability excess risk bounds are possible for projected gradient descent in the case of strongly convex and Lipschitz losses without the usual smoothness assumption.", "pdf": "/pdf/4bfb0b2d40503eb1f86bc6fbddb303b0f035fff7.pdf", "supplementary_material": "", "submission_history": "", "checklist": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "klochkov|stability_and_deviation_optimal_risk_bounds_with_convergence_rate_o1n", "thumbnail": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nklochkov2021stability,\ntitle={Stability and Deviation Optimal Risk Bounds with Convergence Rate \\$O(1/n)\\$},\nauthor={Yegor Klochkov and Nikita Zhivotovskiy},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=yaxePRTOhqk}\n}", "venue": "NeurIPS 2021 Oral", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492744417, "odate": 1636492744417, "details": {"replyCount": 13}}, {"id": "9DlCh34E1bN", "original": "GXv8lscogF3", "number": 1287, "cdate": 1621629736348, "ddate": null, "tcdate": 1621629736348, "tmdate": 1683307540351, "tddate": null, "forum": "9DlCh34E1bN", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "On the Expressivity of Markov Reward", "authorids": ["~David_Abel1", "~Will_Dabney1", "~Anna_Harutyunyan1", "~Mark_K_Ho1", "~Michael_Littman1", "~Doina_Precup1", "~Satinder_Singh2"], "authors": ["David Abel", "Will Dabney", "Anna Harutyunyan", "Mark K Ho", "Michael Littman", "Doina Precup", "Satinder Singh"], "keywords": ["Reinforcement Learning", "Reward Functions", "Reward", "Reward Hypothesis", "Markov Decision Process"], "abstract": "Reward is the driving force for reinforcement-learning agents. This paper is dedicated to understanding the expressivity of reward as a way to capture tasks that we would want an agent to perform. We frame this study around three new abstract notions of \u201ctask\u201d that might be desirable: (1) a set of acceptable behaviors, (2) a partial ordering over behaviors, or (3) a partial ordering over trajectories. Our main results prove that while reward can express many of these tasks, there exist instances of each task type that no Markov reward function can capture. We then provide a set of polynomial-time algorithms that construct a Markov reward function that allows an agent to optimize tasks of each of these three types, and correctly determine when no such reward function exists. We conclude with an empirical study that corroborates and illustrates our theoretical findings.", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "abel|on_the_expressivity_of_markov_reward", "TL;DR": "We study the expressivity of Markov reward functions in finite environments by inspecting what kinds of tasks such functions can express.", "pdf": "/pdf/f38ec47becfb7e6c3c6be1f07458f010ab06c3da.pdf", "supplementary_material": "/attachment/29976e4305458447aba45e57d5f690441a2a047a.pdf", "checklist": "", "thumbnail": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nabel2021on,\ntitle={On the Expressivity of Markov Reward},\nauthor={David Abel and Will Dabney and Anna Harutyunyan and Mark K Ho and Michael Littman and Doina Precup and Satinder Singh},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=9DlCh34E1bN}\n}", "venue": "NeurIPS 2021 Oral", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492684637, "odate": 1636492684637, "details": {"replyCount": 11}}, {"id": "o-RYNVOlxA8", "original": "EfrAHGpMXPa", "number": 1176, "cdate": 1621629730182, "ddate": null, "tcdate": 1621629730182, "tmdate": 1683307537053, "tddate": null, "forum": "o-RYNVOlxA8", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Hessian Eigenspectra of More Realistic Nonlinear Models", "authorids": ["~Zhenyu_Liao1", "~Michael_W._Mahoney1"], "authors": ["Zhenyu Liao", "Michael W. Mahoney"], "keywords": ["Generalized Linear Model", "Hessian", "Spectral Analysis", "Random Matrix Theory."], "TL;DR": "Precise asymptotic characterization of a family of (convex and non-convex) generalized GLMs, including the (limiting) eigenvalue distribution, the behavior of isolated eigenvalues and eigenvectors.", "abstract": "Given an optimization problem, the Hessian matrix and its eigenspectrum can be used in many ways, ranging from designing more efficient second-order algorithms to performing model analysis and regression diagnostics. \nWhen nonlinear models and non-convex problems are considered, strong simplifying assumptions are often made to make Hessian spectral analysis more tractable.\nThis leads to the question of how relevant the conclusions of such analyses are for realistic nonlinear models. \nIn this paper, we exploit tools from random matrix theory to make a *precise* characterization of the Hessian eigenspectra for a broad family of nonlinear models that extends the classical generalized linear models, without relying on strong simplifying assumptions used previously. \nWe show that, depending on the data properties, the nonlinear response model, and the loss function, the Hessian can have *qualitatively* different spectral behaviors: of bounded or unbounded support, with single- or multi-bulk, and with isolated eigenvalues on the left- or right-hand side of the main eigenvalue bulk. \nBy focusing on such a simple but nontrivial model, our analysis takes a step forward to unveil the theoretical origin of many visually striking features observed in more realistic machine learning models.", "submission_history": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "liao|hessian_eigenspectra_of_more_realistic_nonlinear_models", "pdf": "/pdf/d4e07f4f7951b8379b09e567003538329c3204b4.pdf", "supplementary_material": "", "checklist": "", "thumbnail": "", "_bibtex": "@inproceedings{\nliao2021hessian,\ntitle={Hessian Eigenspectra of More Realistic Nonlinear Models},\nauthor={Zhenyu Liao and Michael W. Mahoney},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=o-RYNVOlxA8}\n}", "venue": "NeurIPS 2021 Oral", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492689468, "odate": 1636492689468, "details": {"replyCount": 12}}, {"id": "z71OSKqTFh7", "original": "bxbQjwk6AxP", "number": 1151, "cdate": 1621629728798, "ddate": null, "tcdate": 1621629728798, "tmdate": 1683307536403, "tddate": null, "forum": "z71OSKqTFh7", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "A Universal Law of Robustness via Isoperimetry", "authorids": ["~Sebastien_Bubeck1", "~Mark_Sellke1"], "authors": ["Sebastien Bubeck", "Mark Sellke"], "keywords": ["adversarial robustness", "over-parametrization", "isoperimetry"], "abstract": "Classically, data interpolation with a parametrized model class is possible as long as the number of parameters is larger than the number of equations to be satisfied. A puzzling phenomenon in the current practice of deep learning is that models are trained with many more parameters than what this classical theory would suggest. We propose a theoretical explanation for this phenomenon. We prove that for a broad class of data distributions and model classes, overparametrization is {\\em necessary} if one wants to interpolate the data {\\em smoothly}. Namely we show that {\\em smooth} interpolation requires $d$ times more parameters than mere interpolation, where $d$ is the ambient data dimension. We prove this universal law of robustness for any smoothly parametrized function class with polynomial size weights, and any covariate distribution verifying isoperimetry. In the case of two-layers neural networks and Gaussian covariates, this law was conjectured in prior work by Bubeck, Li and Nagaraj. We also give an interpretation of our result as an improved generalization bound for model classes consisting of smooth functions.", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "bubeck|a_universal_law_of_robustness_via_isoperimetry", "pdf": "/pdf/5466f137e78f7954598c4048d6980cc0768c2f35.pdf", "supplementary_material": "/attachment/cb033774966ea6c27387140056a09864d6fd3106.pdf", "checklist": "", "thumbnail": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nbubeck2021a,\ntitle={A Universal Law of Robustness via Isoperimetry},\nauthor={Sebastien Bubeck and Mark Sellke},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=z71OSKqTFh7}\n}", "venue": "NeurIPS 2021 Oral", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492687882, "odate": 1636492687882, "details": {"replyCount": 13}}, {"id": "ZBfUo_dr4H", "original": "oNLXN2oupBf", "number": 970, "cdate": 1621629718733, "ddate": null, "tcdate": 1621629718733, "tmdate": 1697937735023, "tddate": null, "forum": "ZBfUo_dr4H", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "DROID-SLAM: Deep Visual SLAM for Monocular, Stereo, and RGB-D Cameras", "authorids": ["~Zachary_Teed1", "~Jia_Deng1"], "authors": ["Zachary Teed", "Jia Deng"], "keywords": ["SLAM", "Simultaneous Localization and Mapping", "3D"], "abstract": "We introduce DROID-SLAM, a new deep learning based SLAM system. DROID-SLAM consists of recurrent iterative updates of camera pose and pixelwise depth through a Dense Bundle Adjustment layer. DROID-SLAM is accurate, achieving large improvements over prior work, and robust, suffering from substantially fewer catastrophic failures. Despite training on monocular video, it can leverage stereo or RGB-D video to achieve improved performance at test time. The URL to our open source code is https://github.com/princeton-vl/DROID-SLAM.", "pdf": "/pdf/1d52f7d194b024aba6aea8835154dbbefe6ce9a6.pdf", "supplementary_material": "/attachment/2f875efc7c9e3982b0e9993212504db5b78f3751.pdf", "submission_history": "", "checklist": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "teed|droidslam_deep_visual_slam_for_monocular_stereo_and_rgbd_cameras", "code": "https://github.com/princeton-vl/DROID-SLAM", "thumbnail": "", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2108.10869/code)", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nteed2021droidslam,\ntitle={{DROID}-{SLAM}: Deep Visual {SLAM} for Monocular, Stereo, and {RGB}-D Cameras},\nauthor={Zachary Teed and Jia Deng},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=ZBfUo_dr4H}\n}", "venue": "NeurIPS 2021 Oral", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492719959, "odate": 1636492719959, "details": {"replyCount": 9}}, {"id": "gEXbJVhVK5_", "original": "1FsTfe8DhK", "number": 881, "cdate": 1621629713684, "ddate": null, "tcdate": 1621629713684, "tmdate": 1697937738670, "tddate": null, "forum": "gEXbJVhVK5_", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Learning Treatment Effects in Panels with General Intervention Patterns", "authorids": ["~Vivek_Farias1", "~Andrew_A_Li1", "~Tianyi_Peng1"], "authors": ["Vivek Farias", "Andrew A Li", "Tianyi Peng"], "keywords": ["Causal Inference", "Treatment Effect", "Low-Rank Matrix Estimation", "Panel Data", "Synthetic Control"], "abstract": "The problem of causal inference with panel data is a central econometric question. The following is a fundamental version of this problem: Let $M^*$ be a low rank matrix and $E$ be a zero-mean noise matrix. For a `treatment' matrix $Z$ with entries in $\\{0,1\\}$ we observe the matrix $O$ with entries $O_{ij} := M^*_{ij} + E_{ij} + \\mathcal{T}_{ij} Z_{ij}$ where $\\mathcal{T}_{ij} $ are unknown, heterogenous treatment effects. The problem requires we estimate the average treatment effect $\\tau^* := \\sum_{ij} \\mathcal{T}_{ij} Z_{ij} / \\sum_{ij} Z_{ij}$. The synthetic control paradigm provides an approach to estimating $\\tau^*$ when $Z$ places support on a single row. This paper extends that framework to allow rate-optimal recovery of $\\tau^*$ for general $Z$, thus broadly expanding its applicability. Our guarantees are the first of their type in this general setting. Computational experiments on synthetic and real-world data show a substantial advantage over competing estimators. ", "submission_history": "", "submission_history_-_venue_and_year": "", "checklist": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "farias|learning_treatment_effects_in_panels_with_general_intervention_patterns", "pdf": "/pdf/6d1c40000d7e9ba91447071f501d3ee8afb129c1.pdf", "submission_history_-_improvements_made": "", "supplementary_material": "", "TL;DR": "An optimal estimator for causal inference on panel data with general treatment patterns. ", "thumbnail": "", "code": "https://github.com/TianyiPeng/Causal-Inference-Code", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2106.02780/code)", "_bibtex": "@inproceedings{\nfarias2021learning,\ntitle={Learning Treatment Effects in Panels with General Intervention Patterns},\nauthor={Vivek Farias and Andrew A Li and Tianyi Peng},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=gEXbJVhVK5_}\n}", "venue": "NeurIPS 2021 Oral", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492757257, "odate": 1636492757257, "details": {"replyCount": 9}}, {"id": "mfQxdSMWOF", "original": "2Y8z2Y5fk1T", "number": 445, "cdate": 1621629689663, "ddate": null, "tcdate": 1621629689663, "tmdate": 1697937753570, "tddate": null, "forum": "mfQxdSMWOF", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Keeping Your Eye on the Ball: Trajectory Attention in Video Transformers", "authorids": ["~Mandela_Patrick1", "~Dylan_Campbell1", "~Yuki_Asano1", "~Ishan_Misra2", "~Florian_Metze1", "~Christoph_Feichtenhofer4", "~Andrea_Vedaldi1", "~Joao_F._Henriques1"], "authors": ["Mandela Patrick", "Dylan Campbell", "Yuki Asano", "Ishan Misra", "Florian Metze", "Christoph Feichtenhofer", "Andrea Vedaldi", "Joao F. Henriques"], "keywords": ["xformers", "video action recognition", "transformers", "attention", "efficient attention"], "TL;DR": "A new attention block for video transformers that implicitly models motion paths", "abstract": "In video transformers, the time dimension is often treated in the same way as the two spatial dimensions. However, in a scene where objects or the camera may move, a physical point imaged at one location in frame $t$ may be entirely unrelated to what is found at that location in frame $t+k$. These temporal correspondences should be modeled to facilitate learning about dynamic scenes. To this end, we propose a new drop-in block for video transformers - trajectory attention - that aggregates information along implicitly determined motion paths. We additionally propose a new method to address the quadratic dependence of computation and memory on the input size, which is particularly important for high resolution or long videos. While these ideas are useful in a range of settings, we apply them to the specific task of video action recognition with a transformer model and obtain state-of-the-art results on the Kinetics, Something-Something V2, and Epic-Kitchens datasets.", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "patrick|keeping_your_eye_on_the_ball_trajectory_attention_in_video_transformers", "pdf": "/pdf/7f2bdc1f1d7f0097cb84419389100008c671e58d.pdf", "checklist": "", "supplementary_material": "/attachment/baf6c000c11c9f0167c13f96caada06302b27d66.pdf", "code": "https://github.com/facebookresearch/Motionformer", "thumbnail": "", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 4 code implementations](https://www.catalyzex.com/paper/arxiv:2106.05392/code)", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\npatrick2021keeping,\ntitle={Keeping Your Eye on the Ball: Trajectory Attention in Video Transformers},\nauthor={Mandela Patrick and Dylan Campbell and Yuki Asano and Ishan Misra and Florian Metze and Christoph Feichtenhofer and Andrea Vedaldi and Joao F. Henriques},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=mfQxdSMWOF}\n}", "venue": "NeurIPS 2021 Oral", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492775908, "odate": 1636492775908, "details": {"replyCount": 11}}, {"id": "5JvnsAdf6Vz", "original": "kMmS01qdtz", "number": 205, "cdate": 1621629676567, "ddate": null, "tcdate": 1621629676567, "tmdate": 1683307516987, "tddate": null, "forum": "5JvnsAdf6Vz", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Learning Frequency Domain Approximation for Binary Neural Networks", "authorids": ["~Yixing_Xu2", "~Kai_Han2", "~Chang_Xu4", "~Yehui_Tang1", "~Chunjing_Xu1", "~Yunhe_Wang1"], "authors": ["Yixing Xu", "Kai Han", "Chang Xu", "Yehui Tang", "Chunjing Xu", "Yunhe Wang"], "keywords": ["binary neural network", "frequency domain approximation", "fourier series", "noise"], "TL;DR": "Using sine module and noise adaptation module to approximate sign function in BNN.", "abstract": "Binary neural networks (BNNs) represent original full-precision weights and activations into 1-bit with sign function. Since the gradient of the conventional sign function is almost zero everywhere which cannot be used for back-propagation, several attempts have been proposed to alleviate the optimization difficulty by using approximate gradient. However, those approximations corrupt the main direction of factual gradient. To this end, we propose to estimate the gradient of sign function in the Fourier frequency domain using the combination of sine functions for training BNNs, namely frequency domain approximation (FDA). The proposed approach does not affect the low-frequency information of the original sign function which occupies most of the overall energy, and high-frequency coefficients will be ignored to avoid the huge computational overhead. In addition, we embed a noise adaptation module into the training phase to compensate the approximation error. The experiments on several benchmark datasets and neural architectures illustrate that the binary network learned using our method achieves the state-of-the-art accuracy. Code will be available at https://gitee.com/mindspore/models/tree/master/research/cv/FDA-BNN.", "pdf": "/pdf/f5135d3e420519d972d3b45e686042b4e02d82f9.pdf", "submission_history": "", "checklist": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "xu|learning_frequency_domain_approximation_for_binary_neural_networks", "thumbnail": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nxu2021learning,\ntitle={Learning Frequency Domain Approximation for Binary Neural Networks},\nauthor={Yixing Xu and Kai Han and Chang Xu and Yehui Tang and Chunjing Xu and Yunhe Wang},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=5JvnsAdf6Vz}\n}", "venue": "NeurIPS 2021 Oral", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492682108, "odate": 1636492682060, "details": {"replyCount": 10}}], "count": 60}