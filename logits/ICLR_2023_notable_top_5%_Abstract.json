{"notes": [{"id": "7YfHla7IxBJ", "original": "DOkGpF_kG4v", "number": 6550, "cdate": 1663850582669, "mdate": null, "ddate": null, "tcdate": 1663850582669, "tmdate": 1677548283063, "tddate": null, "forum": "7YfHla7IxBJ", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Encoding Recurrence into Transformers", "authorids": ["~Feiqing_Huang1", "~Kexin_Lu1", "~Yuxi_CAI1", "~Zhen_Qin7", "~Yanwen_Fang1", "~Guangjian_Tian1", "~Guodong_Li1"], "authors": ["Feiqing Huang", "Kexin Lu", "Yuxi CAI", "Zhen Qin", "Yanwen Fang", "Guangjian Tian", "Guodong Li"], "keywords": ["Recurrent models", "Transformers", "sample efficiency", "gated mechanism"], "TL;DR": "We propose a new module to encode the recurrent dynamics of an RNN layer into Transformers and higher sample efficiency can be achieved.", "abstract": "This paper novelly breaks down with ignorable loss an RNN layer into a sequence of simple RNNs, each of which can be further rewritten into a lightweight positional encoding matrix of a self-attention, named the Recurrence Encoding Matrix (REM). Thus, recurrent dynamics introduced by the RNN layer can be encapsulated into the positional encodings of a multihead self-attention, and this makes it possible to seamlessly incorporate these recurrent dynamics into a Transformer, leading to a new module, Self-Attention with Recurrence (RSA). The proposed module can leverage the recurrent inductive bias of REMs to achieve a better sample efficiency than its corresponding baseline Transformer, while the self-attention is used to model the remaining non-recurrent signals. The relative proportions of these two components are controlled by a data-driven gated mechanism, and the effectiveness of RSA modules are demonstrated by four sequential learning tasks.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Deep Learning and representational learning", "paperhash": "huang|encoding_recurrence_into_transformers", "pdf": "/pdf/70636775789b51f219cb29634cc7c794cc86577b.pdf", "_bibtex": "@inproceedings{\nhuang2023encoding,\ntitle={Encoding Recurrence into Transformers},\nauthor={Feiqing Huang and Kexin Lu and Yuxi CAI and Zhen Qin and Yanwen Fang and Guangjian Tian and Guodong Li},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=7YfHla7IxBJ}\n}", "venue": "ICLR 2023 notable top 5%", "venueid": "ICLR.cc/2023/Conference", "supplementary_material": "/attachment/7bd80d8f46af4f56d77c37d2d709049d79431c11.zip"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279440652, "odate": 1664468100000, "details": {"replyCount": 28}}, {"id": "l6CpxixmUg", "original": "H7hqBTJSYF", "number": 6317, "cdate": 1663850554390, "mdate": null, "ddate": null, "tcdate": 1663850554390, "tmdate": 1677757787112, "tddate": null, "forum": "l6CpxixmUg", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Modeling content creator incentives on algorithm-curated platforms", "authorids": ["~Jiri_Hron1", "~Karl_Krauth1", "~Michael_Jordan1", "~Niki_Kilbertus1", "~Sarah_Dean2"], "authors": ["Jiri Hron", "Karl Krauth", "Michael Jordan", "Niki Kilbertus", "Sarah Dean"], "keywords": ["Nash equilibria", "producer incentives", "attention monetizing platforms", "recommenders", "differentiable games", "exposure game"], "TL;DR": "Algorithmic choices in modern recommenders may have significant and unexpected effects on content creator incentives.", "abstract": "Content creators compete for user attention. Their reach crucially depends on algorithmic choices made by developers on online platforms. To maximize exposure, many creators adapt strategically, as evidenced by examples like the sprawling search engine optimization industry. This begets competition for the finite user attention pool. We formalize these dynamics in what we call an exposure game, a model of incentives induced by modern algorithms including factorization and (deep) two-tower architectures. We prove that seemingly innocuous algorithmic choices\u2014e.g., non-negative vs. unconstrained factorization\u2014significantly affect the existence and character of (Nash) equilibria in exposure games. We proffer use of creator behavior models like ours for an (ex-ante) pre-deployment audit. Such an audit can identify misalignment between desirable and incentivized content, and thus complement post-hoc measures like content filtering and moderation. To this end, we propose tools for numerically finding equilibria in exposure games, and illustrate results of an audit on the MovieLens and LastFM datasets. Among else, we find that the strategically produced content exhibits strong dependence between algorithmic exploration and content diversity, and between model expressivity and bias towards gender-based user and creator groups.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Theory (eg, control theory, learning theory, algorithmic game theory)", "paperhash": "hron|modeling_content_creator_incentives_on_algorithmcurated_platforms", "pdf": "/pdf/12c4dfbbd1516c36a132fe1e8e1205b88da0540b.pdf", "supplementary_material": "/attachment/753a1db88de10a48162497699a14ff2453192c00.zip", "_bibtex": "@inproceedings{\nhron2023modeling,\ntitle={Modeling content creator incentives on algorithm-curated platforms},\nauthor={Jiri Hron and Karl Krauth and Michael Jordan and Niki Kilbertus and Sarah Dean},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=l6CpxixmUg}\n}", "venue": "ICLR 2023 notable top 5%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279431605, "odate": 1664468100000, "details": {"replyCount": 10}}, {"id": "paGvsrl4Ntr", "original": "DJDL_twURTK", "number": 6182, "cdate": 1663850537973, "mdate": null, "ddate": null, "tcdate": 1663850537973, "tmdate": 1677606721093, "tddate": null, "forum": "paGvsrl4Ntr", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Transfer NAS with Meta-learned Bayesian Surrogates", "authorids": ["~Gresa_Shala1", "~Thomas_Elsken1", "~Frank_Hutter1", "~Josif_Grabocka1"], "authors": ["Gresa Shala", "Thomas Elsken", "Frank Hutter", "Josif Grabocka"], "keywords": [], "abstract": "While neural architecture search (NAS) is an intensely-researched area, approaches typically still suffer from either (i) high computational costs or (ii) lack of robustness across datasets and experiments. Furthermore, most methods start searching for an optimal architecture from scratch, ignoring prior knowledge. This is in contrast to the manual design process by researchers and engineers that leverage previous deep learning experiences by, e.g., transferring architectures from previously solved, related problems.\nWe propose to adopt this human design strategy and introduce a novel surrogate for NAS, that is meta-learned across prior architecture evaluations across different datasets. We utilizes Bayesian Optimization (BO) with deep-kernel Gaussian Processes,  graph neural networks for the architecture embeddings and a transformer-based set encoder of datasets. As a result, our method consistently achieves state-of-the-art results on six computer vision datasets, while being as fast as one-shot NAS methods.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Deep Learning and representational learning", "paperhash": "shala|transfer_nas_with_metalearned_bayesian_surrogates", "pdf": "/pdf/1d6bd2efad6066b8250a1ed96932db04f31c080f.pdf", "_bibtex": "@inproceedings{\nshala2023transfer,\ntitle={Transfer {NAS} with Meta-learned Bayesian Surrogates},\nauthor={Gresa Shala and Thomas Elsken and Frank Hutter and Josif Grabocka},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=paGvsrl4Ntr}\n}", "venue": "ICLR 2023 notable top 5%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279425731, "odate": 1664468100000, "details": {"replyCount": 17}}, {"id": "067CGykiZTS", "original": "07jHSOT6YU", "number": 6160, "cdate": 1663850535176, "mdate": null, "ddate": null, "tcdate": 1663850535176, "tmdate": 1697935220865, "tddate": null, "forum": "067CGykiZTS", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Scaling Up Probabilistic Circuits by Latent Variable Distillation", "authorids": ["~Anji_Liu1", "~Honghua_Zhang1", "~Guy_Van_den_Broeck1"], "authors": ["Anji Liu", "Honghua Zhang", "Guy Van den Broeck"], "keywords": [], "abstract": "Probabilistic Circuits (PCs) are a unified framework for tractable probabilistic models that support efficient computation of various probabilistic queries (e.g., marginal probabilities). One key challenge is to scale PCs to model large and high-dimensional real-world datasets: we observe that as the number of parameters in PCs increases, their performance immediately plateaus. This phenomenon suggests that the existing optimizers fail to exploit the full expressive power of large PCs. We propose to overcome such bottleneck by latent variable distillation: we leverage the less tractable but more expressive deep generative models to provide extra supervision over the latent variables of PCs. Specifically, we extract information from Transformer-based generative models to assign values to latent variables of PCs, providing guidance to PC optimizers. Experiments on both image and language modeling benchmarks (e.g., ImageNet and WikiText-2) show that latent variable distillation substantially boosts the performance of large PCs compared to their counterparts without latent variable distillation. In particular, on the image modeling benchmarks, PCs achieve competitive performance against some of the widely-used deep generative models, including variational autoencoders and flow-based models, opening up new avenues for tractable generative modeling. Our code can be found at https://github.com/UCLA-StarAI/LVD.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Probabilistic Methods (eg, variational inference, causal inference, Gaussian processes)", "paperhash": "liu|scaling_up_probabilistic_circuits_by_latent_variable_distillation", "pdf": "/pdf/03a72f57ccbfd43e91ba786ca0f782f4065669e5.pdf", "_bibtex": "@inproceedings{\nliu2023scaling,\ntitle={Scaling Up Probabilistic Circuits by Latent Variable Distillation},\nauthor={Anji Liu and Honghua Zhang and Guy Van den Broeck},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=067CGykiZTS}\n}", "venue": "ICLR 2023 notable top 5%", "venueid": "ICLR.cc/2023/Conference", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 3 code implementations](https://www.catalyzex.com/paper/arxiv:2210.04398/code)"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279425084, "odate": 1664468100000, "details": {"replyCount": 9}}, {"id": "6H_uOfcwiVh", "original": "7QAaMjfGrU4", "number": 6089, "cdate": 1663850526430, "mdate": null, "ddate": null, "tcdate": 1663850526430, "tmdate": 1677491334484, "tddate": null, "forum": "6H_uOfcwiVh", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "A Kernel Perspective of Skip Connections in Convolutional Networks", "authorids": ["~Daniel_Barzilai1", "~Amnon_Geifman1", "~Meirav_Galun1", "~Ronen_Basri1"], "authors": ["Daniel Barzilai", "Amnon Geifman", "Meirav Galun", "Ronen Basri"], "keywords": [], "abstract": "Over-parameterized residual networks (ResNets) are amongst the most successful convolutional neural\u00a0architectures for image processing. Here we study their\u00a0properties through\u00a0their Gaussian Process and Neural Tangent kernels. We derive explicit\u00a0formulas for these kernels, analyze their spectra, and provide bounds on their implied condition numbers. Our results indicate that (1) with ReLU activation, the eigenvalues\u00a0of these residual kernels\u00a0decay polynomially at a similar rate compared to the same kernels when skip connections are not used, thus maintaining a similar frequency bias; (2) however, residual kernels are more locally biased. Our\u00a0analysis further shows that the matrices obtained by these residual kernels yield favorable condition numbers at finite depths than those obtained without the skip connections, enabling therefore faster convergence of training with gradient descent.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Theory (eg, control theory, learning theory, algorithmic game theory)", "paperhash": "barzilai|a_kernel_perspective_of_skip_connections_in_convolutional_networks", "pdf": "/pdf/d02ce0a1fbf33b0f5c0f942e925ba67c6bcfaab5.pdf", "_bibtex": "@inproceedings{\nbarzilai2023a,\ntitle={A Kernel Perspective of Skip Connections in Convolutional Networks},\nauthor={Daniel Barzilai and Amnon Geifman and Meirav Galun and Ronen Basri},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=6H_uOfcwiVh}\n}", "venue": "ICLR 2023 notable top 5%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279422081, "odate": 1664468100000, "details": {"replyCount": 10}}, {"id": "vaxnu-Utr4l", "original": "Q6ZOwifJ9Ai", "number": 5905, "cdate": 1663850504451, "mdate": null, "ddate": null, "tcdate": 1663850504451, "tmdate": 1677713931673, "tddate": null, "forum": "vaxnu-Utr4l", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "WikiWhy: Answering and Explaining Cause-and-Effect Questions", "authorids": ["~Matthew_Ho1", "~Aditya_Sharma3", "~Justin_Chang1", "~Michael_Saxon1", "~Sharon_Levy1", "~Yujie_Lu1", "~William_Yang_Wang2"], "authors": ["Matthew Ho", "Aditya Sharma", "Justin Chang", "Michael Saxon", "Sharon Levy", "Yujie Lu", "William Yang Wang"], "keywords": ["NLP", "Question Answering", "LLM", "Dataset", "Explanation"], "TL;DR": "We propose WikiWhy, a dataset containing 9000+ \"why\" question-answer-rationale triplets to assess Large Language Models' cause-effect reasoning capability.", "abstract": "As large language models (LLMs) grow larger and more sophisticated, assessing their \"reasoning\" capabilities in natural language grows more challenging. Recent question answering (QA) benchmarks that attempt to assess reasoning are often limited by a narrow scope of covered situations and subject matters. We introduce WikiWhy, a QA dataset built around a novel auxiliary task: explaining why an answer is true in natural language. WikiWhy contains over 9,000 \"why\" question-answer-rationale triples, grounded on Wikipedia facts across a diverse set of topics. Each rationale is a set of supporting statements connecting the question to the answer. WikiWhy serves as a benchmark for the reasoning capabilities of LLMs because it demands rigorous explicit rationales for each answer to demonstrate the acquisition of implicit commonsense knowledge, which is unlikely to be easily memorized. GPT-3 baselines achieve only 38.7% human-evaluated correctness in the end-to-end answer & explain condition, leaving significant room for future improvements.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Infrastructure (eg, datasets, competitions, implementations, libraries)", "paperhash": "ho|wikiwhy_answering_and_explaining_causeandeffect_questions", "pdf": "/pdf/dd230e9938db73b0fff7ee629cb682af034688fc.pdf", "supplementary_material": "/attachment/08b7c2412276ab1a13c0aa1626a4b7c65c6ad37a.zip", "_bibtex": "@inproceedings{\nho2023wikiwhy,\ntitle={WikiWhy: Answering and Explaining Cause-and-Effect Questions},\nauthor={Matthew Ho and Aditya Sharma and Justin Chang and Michael Saxon and Sharon Levy and Yujie Lu and William Yang Wang},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=vaxnu-Utr4l}\n}", "venue": "ICLR 2023 notable top 5%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279415467, "odate": 1664468100000, "details": {"replyCount": 11}}, {"id": "CQsmMYmlP5T", "original": "aT4Hu99nC5G", "number": 5836, "cdate": 1663850496277, "mdate": null, "ddate": null, "tcdate": 1663850496277, "tmdate": 1697935246144, "tddate": null, "forum": "CQsmMYmlP5T", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Git Re-Basin: Merging Models modulo Permutation Symmetries", "authorids": ["~Samuel_Ainsworth1", "~Jonathan_Hayase2", "~Siddhartha_Srinivasa1"], "authors": ["Samuel Ainsworth", "Jonathan Hayase", "Siddhartha Srinivasa"], "keywords": [], "abstract": "The success of deep learning is due in large part to our ability to solve certain massive non-convex optimization problems with relative ease. Though non-convex optimization is NP-hard, simple algorithms -- often variants of stochastic gradient descent -- exhibit surprising effectiveness in fitting large neural networks in practice. We argue that neural network loss landscapes often contain (nearly) a single basin after accounting for all possible permutation symmetries of hidden units a la Entezari et al. 2021. We introduce three algorithms to permute the units of one model to bring them into alignment with a reference model in order to merge the two models in weight space. This transformation produces a functionally equivalent set of weights that lie in an approximately convex basin near the reference model. Experimentally, we demonstrate the single basin phenomenon across a variety of model architectures and datasets, including the first (to our knowledge) demonstration of zero-barrier linear mode connectivity between independently trained ResNet models on CIFAR-10. Additionally, we identify intriguing phenomena relating model width and training time to mode connectivity. Finally, we discuss shortcomings of the linear mode connectivity hypothesis, including a counterexample to the single basin theory.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Deep Learning and representational learning", "paperhash": "ainsworth|git_rebasin_merging_models_modulo_permutation_symmetries", "pdf": "/pdf/b212b96bd3f13e202965581f6173495898534b76.pdf", "_bibtex": "@inproceedings{\nainsworth2023git,\ntitle={Git Re-Basin: Merging Models modulo Permutation Symmetries},\nauthor={Samuel Ainsworth and Jonathan Hayase and Siddhartha Srinivasa},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=CQsmMYmlP5T}\n}", "venue": "ICLR 2023 notable top 5%", "venueid": "ICLR.cc/2023/Conference", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 2 code implementations](https://www.catalyzex.com/paper/arxiv:2209.04836/code)"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279412852, "odate": 1664468100000, "details": {"replyCount": 29}}, {"id": "LQIjzPdDt3q", "original": "yvMnSLUcy84", "number": 5834, "cdate": 1663850495796, "mdate": null, "ddate": null, "tcdate": 1663850495796, "tmdate": 1677398491662, "tddate": null, "forum": "LQIjzPdDt3q", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "The Role of Coverage in Online Reinforcement Learning", "authorids": ["~Tengyang_Xie1", "~Dylan_J_Foster1", "~Yu_Bai1", "~Nan_Jiang2", "~Sham_M._Kakade1"], "authors": ["Tengyang Xie", "Dylan J Foster", "Yu Bai", "Nan Jiang", "Sham M. Kakade"], "keywords": ["reinforcement learning theory", "online RL", "offline RL", "learnability", "general function approximation"], "abstract": "Coverage conditions---which assert that the data logging distribution adequately covers the state space---play a fundamental role in determining the sample complexity of offline reinforcement learning. While such conditions might seem irrelevant to online reinforcement learning at first glance, we establish a new connection by showing---somewhat surprisingly---that the mere existence of a data distribution with good coverage can enable sample-efficient online RL. Concretely, we show that coverability---that is, existence of a data distribution that satisfies a ubiquitous coverage condition called concentrability---can be viewed as a structural property of the underlying MDP, and can be exploited by standard algorithms for sample-efficient exploration, even when the agent does not know said distribution. We complement this result by proving that several weaker notions of coverage, despite being sufficient for offline RL, are insufficient for online RL. We also show that existing complexity measures for online RL, including Bellman rank and Bellman-Eluder dimension, fail to optimally capture coverability, and propose a new complexity measure, the self-normalized coefficient, to provide a unification.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Theory (eg, control theory, learning theory, algorithmic game theory)", "paperhash": "xie|the_role_of_coverage_in_online_reinforcement_learning", "TL;DR": "This paper shows surprising connections between online and offline learnability, in particular, how coverage in offline RL enables exploration in online RL.", "pdf": "/pdf/a2c365918c8b9f3e5b7cd871606f05d90118525a.pdf", "_bibtex": "@inproceedings{\nxie2023the,\ntitle={The Role of Coverage in Online Reinforcement Learning},\nauthor={Tengyang Xie and Dylan J Foster and Yu Bai and Nan Jiang and Sham M. Kakade},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=LQIjzPdDt3q}\n}", "venue": "ICLR 2023 notable top 5%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279412442, "odate": 1664468100000, "details": {"replyCount": 7}}, {"id": "FZdJQgy05rz", "original": "0Zsrm6RQE-b", "number": 5741, "cdate": 1663850484725, "mdate": null, "ddate": null, "tcdate": 1663850484725, "tmdate": 1677758046557, "tddate": null, "forum": "FZdJQgy05rz", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Is the Performance of My Deep Network Too Good to Be True? A Direct Approach to Estimating the Bayes Error in Binary Classification", "authorids": ["~Takashi_Ishida1", "~Ikko_Yamane1", "~Nontawat_Charoenphakdee1", "~Gang_Niu1", "~Masashi_Sugiyama1"], "authors": ["Takashi Ishida", "Ikko Yamane", "Nontawat Charoenphakdee", "Gang Niu", "Masashi Sugiyama"], "keywords": ["Bayes error", "best achievable error", "irreducible error"], "TL;DR": "A simple and direct Bayes error estimator that just takes the mean of the labels that show uncertainty of the classes.", "abstract": "There is a fundamental limitation in the prediction performance that a machine learning model can achieve due to the inevitable uncertainty of the prediction target. In classification problems, this can be characterized by the Bayes error, which is the best achievable error with any classifier. The Bayes error can be used as a criterion to evaluate classifiers with state-of-the-art performance and can be used to detect test set overfitting. We propose a simple and direct Bayes error estimator, where we just take the mean of the labels that show \\emph{uncertainty} of the class assignments. Our flexible approach enables us to perform Bayes error estimation even for weakly supervised data. In contrast to others, our method is model-free and even instance-free. Moreover, it has no hyperparameters and gives a more accurate estimate of the Bayes error than several baselines empirically. Experiments using our method suggest that recently proposed deep networks such as the Vision Transformer may have reached, or is about to reach, the Bayes error for benchmark datasets. Finally, we discuss how we can study the inherent difficulty of the acceptance/rejection decision for scientific articles, by estimating the Bayes error of the ICLR papers from 2017 to 2023.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)", "paperhash": "ishida|is_the_performance_of_my_deep_network_too_good_to_be_true_a_direct_approach_to_estimating_the_bayes_error_in_binary_classification", "pdf": "/pdf/adf5cd1db7eb1218ea6e605d13c786cdf71eab45.pdf", "_bibtex": "@inproceedings{\nishida2023is,\ntitle={Is the Performance of My Deep Network Too Good to Be True? A Direct Approach to Estimating the Bayes Error in Binary Classification},\nauthor={Takashi Ishida and Ikko Yamane and Nontawat Charoenphakdee and Gang Niu and Masashi Sugiyama},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=FZdJQgy05rz}\n}", "venue": "ICLR 2023 notable top 5%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279409113, "odate": 1664468100000, "details": {"replyCount": 13}}, {"id": "4-k7kUavAj", "original": "VfI56yuvhmo", "number": 5653, "cdate": 1663850474153, "mdate": null, "ddate": null, "tcdate": 1663850474153, "tmdate": 1677688033279, "tddate": null, "forum": "4-k7kUavAj", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Offline Q-learning on Diverse Multi-Task Data Both Scales And Generalizes", "authorids": ["~Aviral_Kumar2", "~Rishabh_Agarwal2", "~Xinyang_Geng1", "~George_Tucker1", "~Sergey_Levine1"], "authors": ["Aviral Kumar", "Rishabh Agarwal", "Xinyang Geng", "George Tucker", "Sergey Levine"], "keywords": ["offline RL", "multi-task Atari", "large models"], "abstract": "The potential of offline reinforcement learning (RL) is that high-capacity models trained on large, heterogeneous datasets can lead to agents that generalize broadly, analogously to similar advances in vision and NLP. However, recent works argue that offline RL methods encounter unique challenges to scaling up model capacity. Drawing on the learnings from these works, we re-examine previous design choices and find that with appropriate choices: ResNets, cross-entropy based distributional backups, and feature normalization, offline Q-learning algorithms exhibit strong performance that scales with model capacity. Using multi-task Atari as a testbed for scaling and generalization, we train a single policy on 40 games with near-human performance using up-to 80 million parameter networks, finding that model performance scales favorably with capacity. In contrast to prior work, we extrapolate beyond dataset performance even when trained entirely on a large (400M transitions) but highly suboptimal dataset (51% human-level performance). Compared to return-conditioned supervised approaches, offline Q-learning scales similarly with model capacity and has better performance, especially when the dataset is suboptimal. Finally, we show that offline Q-learning with a diverse dataset is sufficient to learn powerful representations that facilitate rapid transfer to novel games and fast online learning on new variations of a training game, improving over existing state-of-the-art representation learning approaches.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)", "paperhash": "kumar|offline_qlearning_on_diverse_multitask_data_both_scales_and_generalizes", "pdf": "/pdf/c4fe1442235b5f185dc41908f09f0b65f8faa938.pdf", "_bibtex": "@inproceedings{\nkumar2023offline,\ntitle={Offline Q-learning on Diverse Multi-Task Data Both Scales And Generalizes},\nauthor={Aviral Kumar and Rishabh Agarwal and Xinyang Geng and George Tucker and Sergey Levine},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=4-k7kUavAj}\n}", "supplementary_material": "/attachment/99d459af38db89b1441b838ab9ef01f3bb8bea5c.zip", "venue": "ICLR 2023 notable top 5%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279404537, "odate": 1664468100000, "details": {"replyCount": 15}}, {"id": "0g0X4H8yN4I", "original": "yF9s3I5Ynj", "number": 5613, "cdate": 1663850469074, "mdate": null, "ddate": null, "tcdate": 1663850469074, "tmdate": 1697935265772, "tddate": null, "forum": "0g0X4H8yN4I", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "\u200b\u200bWhat learning algorithm is in-context learning? Investigations with linear models", "authorids": ["~Ekin_Aky\u00fcrek1", "~Dale_Schuurmans1", "~Jacob_Andreas1", "~Tengyu_Ma1", "~Denny_Zhou1"], "authors": ["Ekin Aky\u00fcrek", "Dale Schuurmans", "Jacob Andreas", "Tengyu Ma", "Denny Zhou"], "keywords": ["in-context learning", "transformers", "sequence models", "deep learning", "meta learning"], "abstract": "Neural sequence models, especially transformers, exhibit a remarkable capacity for in-context learning. They can construct new predictors from sequences of labeled examples $(x, f(x))$ presented in the input without further parameter updates. We investigate the hypothesis that transformer-based in-context learners implement standard learning algorithms implicitly, by encoding context-specific parametric models in their hidden representations, and updating these implicit models as new examples appear in the context. Using linear regression as a model problem, we offer three sources of evidence for this hypothesis. First, we prove by construction that transformers can implement learning algorithms for linear models based on gradient descent and closed-form computation of regression parameters. Second, we show that trained in-context learners closely match the predictors computed by gradient descent, ridge regression, and exact least-squares regression, transitioning between different predictors as transformer depth and dataset noise vary. Third, we present preliminary evidence that in-context learners share algorithmic features with these predictors: learners' late layers encode weight vectors and moment matrices.  These results suggest that in-context learning is understandable in algorithmic terms, and that (at least in the linear case) learners may work by rediscovering standard estimation algorithms.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Deep Learning and representational learning", "paperhash": "aky\u00fcrek|what_learning_algorithm_is_incontext_learning_investigations_with_linear_models", "TL;DR": "We prove that the transformers can implement learning algorithms for linear models based e.g gradient descent, then observe they closely match the predictors of known algorithms, transitioning between different predictors as transformer depth vary.", "pdf": "/pdf/7295479b5085774245ad66c73c5176e41b868b67.pdf", "_bibtex": "@inproceedings{\naky{\\\"u}rek2023what,\ntitle={\u200b\u200bWhat learning algorithm is in-context learning? Investigations with linear models},\nauthor={Ekin Aky{\\\"u}rek and Dale Schuurmans and Jacob Andreas and Tengyu Ma and Denny Zhou},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=0g0X4H8yN4I}\n}", "venue": "ICLR 2023 notable top 5%", "venueid": "ICLR.cc/2023/Conference", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2211.15661/code)"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279402905, "odate": 1664468100000, "details": {"replyCount": 13}}, {"id": "Uuf2q9TfXGA", "original": "we9IWx3teh0", "number": 5565, "cdate": 1663850463270, "mdate": null, "ddate": null, "tcdate": 1663850463270, "tmdate": 1677732949419, "tddate": null, "forum": "Uuf2q9TfXGA", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Towards Understanding Ensemble, Knowledge Distillation and Self-Distillation in Deep Learning", "authorids": ["~Zeyuan_Allen-Zhu1", "~Yuanzhi_Li1"], "authors": ["Zeyuan Allen-Zhu", "Yuanzhi Li"], "keywords": [], "TL;DR": "We provide a theory to explain why ensemble and knowledge distillation work for Deep Learning. It matches practice well, while traditional theory such as boosting, random feature mappings or NTKs, cannot explain the same phenomena for DL.", "abstract": "We formally study how \\emph{ensemble} of deep learning models can improve test accuracy, and how the superior performance of ensemble can be distilled into a single model using \\emph{knowledge distillation}. We consider the challenging case where the ensemble is simply an average of the outputs of a few independently trained neural networks with the \\emph{same} architecture, trained using the \\emph{same} algorithm on the \\emph{same} data set, and they only differ by the random seeds used in the initialization.\n\nWe show that ensemble/knowledge distillation in \\emph{deep learning} works very differently from traditional learning theory (such as boosting or NTKs). We develop a theory showing that when data has a structure we refer to as ``multi-view'', then ensemble of independently trained neural networks can provably improve test accuracy, and such superior test accuracy can also be provably distilled into a single model. Our result sheds light on how ensemble works in deep learning in a way that is completely different from traditional theorems, and how the ``dark knowledge'' is hidden in the outputs of the ensemble and can be used in distillation.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Theory (eg, control theory, learning theory, algorithmic game theory)", "paperhash": "allenzhu|towards_understanding_ensemble_knowledge_distillation_and_selfdistillation_in_deep_learning", "pdf": "/pdf/fbebb24f15ad18f41fae9b87ca59c93d0a7de7f2.pdf", "supplementary_material": "/attachment/720abe811fd66617b293a439bf9a1fdb5fed0d7f.zip", "_bibtex": "@inproceedings{\nallen-zhu2023towards,\ntitle={Towards Understanding Ensemble, Knowledge Distillation and Self-Distillation in Deep Learning},\nauthor={Zeyuan Allen-Zhu and Yuanzhi Li},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=Uuf2q9TfXGA}\n}", "venue": "ICLR 2023 notable top 5%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279400794, "odate": 1664468100000, "details": {"replyCount": 13}}, {"id": "KRLUvxh8uaX", "original": "uZ0vEQwDvCh", "number": 5507, "cdate": 1663850456125, "mdate": null, "ddate": null, "tcdate": 1663850456125, "tmdate": 1677693330493, "tddate": null, "forum": "KRLUvxh8uaX", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "When and Why Vision-Language Models Behave like Bags-Of-Words, and What to Do About It?", "authorids": ["~Mert_Yuksekgonul1", "~Federico_Bianchi1", "~Pratyusha_Kalluri1", "~Dan_Jurafsky1", "~James_Zou1"], "authors": ["Mert Yuksekgonul", "Federico Bianchi", "Pratyusha Kalluri", "Dan Jurafsky", "James Zou"], "keywords": ["vision-language models", "clip", "contrastive learning", "retrieval", "vision-language pretraining", "multimodal representation learning"], "abstract": "Despite the success of large vision and language models (VLMs) in many downstream applications, it is unclear how well they encode the compositional relationships between objects and attributes. Here, we create the Attribution, Relation, and Order (ARO) benchmark to systematically evaluate the ability of VLMs to understand different types of relationships, attributes, and order information. ARO consists of \\emph{Visual Genome Attribution}, to test the understanding of objects' properties; \\emph{Visual Genome Relation}, to test for relational understanding; and \\emph{COCO-Order \\& Flickr30k-Order}, to test for order sensitivity in VLMs. ARO is orders of magnitude larger than previous benchmarks of compositionality, with more than 50,000 test cases. We present the settings where  state-of-the-art VLMs behave like bags-of-words---i.e. when they have poor relational understanding, can blunder when linking objects to their attributes, and demonstrate a severe lack of order sensitivity. VLMs are predominantly trained and evaluated on large scale datasets with rich compositional structure in the images and captions. Yet, training on these datasets has not been enough to address the lack of compositional understanding, and evaluating on these datasets has failed to surface this deficiency. To understand why these limitations emerge and are not represented in the standard tests, we zoom into the evaluation and training procedures. We demonstrate that it is possible to perform well on image-text retrieval over existing datasets without using the composition and order information. This further motivates the value of using ARO to benchmark VLMs. Given that contrastive pretraining optimizes for retrieval on large datasets with similar shortcuts, we hypothesize that this can explain why the models do not need to learn to represent compositional information. This finding suggests a natural solution: composition-aware hard negative mining. We show that a simple-to-implement modification of contrastive learning significantly improves the performance on tasks requiring understanding of order and compositionality. ", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Deep Learning and representational learning", "paperhash": "yuksekgonul|when_and_why_visionlanguage_models_behave_like_bagsofwords_and_what_to_do_about_it", "pdf": "/pdf/ced77554985af011f5544a8798a3035d4b6ab52b.pdf", "_bibtex": "@inproceedings{\nyuksekgonul2023when,\ntitle={When and Why Vision-Language Models Behave like Bags-Of-Words, and What to Do About It?},\nauthor={Mert Yuksekgonul and Federico Bianchi and Pratyusha Kalluri and Dan Jurafsky and James Zou},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=KRLUvxh8uaX}\n}", "venue": "ICLR 2023 notable top 5%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279397718, "odate": 1664468100000, "details": {"replyCount": 11}}, {"id": "Zeb5mTuqT5", "original": "lvJw97B8wkT", "number": 5450, "cdate": 1663850447981, "mdate": null, "ddate": null, "tcdate": 1663850447981, "tmdate": 1677715927287, "tddate": null, "forum": "Zeb5mTuqT5", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Confidence-Conditioned Value Functions for Offline Reinforcement Learning", "authorids": ["~Joey_Hong2", "~Aviral_Kumar2", "~Sergey_Levine1"], "authors": ["Joey Hong", "Aviral Kumar", "Sergey Levine"], "keywords": ["reinforcement learning", "offline reinforcement learning", "ensembles", "adaptation"], "abstract": "Offline reinforcement learning (RL) promises the ability to learn effective policies solely using existing, static datasets, without any costly online interaction. To do so, offline RL methods must handle distributional shift between the dataset and the learned policy. The most common approach is to learn conservative, or lower-bound, value functions, which underestimate the return of OOD actions. However, such methods exhibit one notable drawback: policies optimized on such value functions can only behave according to a fixed, possibly suboptimal, degree of conservatism. However, this can be alleviated if we instead are able to learn policies for varying degrees of conservatism at training time and devise a method to dynamically choose one of them during evaluation. To do so, in this work, we propose learning value functions that additionally condition on the degree of conservatism, which we dub confidence-conditioned value functions. We derive a new form of a Bellman backup that simultaneously learns Q-values for any degree of confidence with high probability. By conditioning on confidence, our value functions enable adaptive strategies during online evaluation by controlling for confidence level using the history of observations thus far. This approach can be implemented in practice by conditioning the Q-function from existing conservative algorithms on the confidence. We theoretically show that our learned value functions produce conservative estimates of the true value at any desired confidence. Finally, we empirically show that our algorithm outperforms existing conservative offline RL algorithms on multiple discrete control domains. ", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)", "paperhash": "hong|confidenceconditioned_value_functions_for_offline_reinforcement_learning", "TL;DR": "We propose a new offline reinforcement learning algorithm that adapts how conservative its behavior will be.", "pdf": "/pdf/83d1be96a20a4accfffcc8dd593c0f0a3c5b5776.pdf", "_bibtex": "@inproceedings{\nhong2023confidenceconditioned,\ntitle={Confidence-Conditioned Value Functions for Offline Reinforcement Learning},\nauthor={Joey Hong and Aviral Kumar and Sergey Levine},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=Zeb5mTuqT5}\n}", "venue": "ICLR 2023 notable top 5%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279394734, "odate": 1664468100000, "details": {"replyCount": 14}}, {"id": "hJqGbUpDGV", "original": "_4VJr7JE6A_", "number": 5447, "cdate": 1663850447630, "mdate": null, "ddate": null, "tcdate": 1663850447630, "tmdate": 1677712135315, "tddate": null, "forum": "hJqGbUpDGV", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "On the Sensitivity of Reward Inference to Misspecified Human Models", "authorids": ["~Joey_Hong2", "~Kush_Bhatia3", "~Anca_Dragan1"], "authors": ["Joey Hong", "Kush Bhatia", "Anca Dragan"], "keywords": ["reward learning", "inverse reinforcement learning", "misspecification"], "abstract": "Inferring reward functions from human behavior is at the center of value alignment \u2013 aligning AI objectives with what we, humans, actually want. But doing so relies on models of how humans behave given their objectives. After decades of research in cognitive science, neuroscience, and behavioral economics, obtaining accurate human models remains an open research topic. This begs the question: how accurate do these models need to be in order for the reward inference to be accurate? On the one hand, if small errors in the model can lead to catastrophic error in inference, the entire framework of reward learning seems ill-fated, as we will never have perfect models of human behavior. On the other hand, if as our models improve, we can have a guarantee that reward accuracy also improves, this would show the benefit of more work on the modeling side. We study this question both theoretically and empirically. We do show that it is unfortunately possible to construct small adversarial biases in behavior that lead to arbitrarily large errors in the inferred reward. However, and arguably more importantly, we are also able to identify reasonable assumptions under which the reward inference error can be bounded linearly in the error in the human model. Finally, we verify our theoretical insights in discrete and continuous control tasks with simulated and human data.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)", "paperhash": "hong|on_the_sensitivity_of_reward_inference_to_misspecified_human_models", "TL;DR": "We investigate the impact of assuming wrong human models on reward learning.", "pdf": "/pdf/787489763506d1437ac7b05b15f89ea0beb8c3b1.pdf", "supplementary_material": "/attachment/91601babf85ad11a2f8f434889ee1316a56a995c.zip", "_bibtex": "@inproceedings{\nhong2023on,\ntitle={On the Sensitivity of Reward Inference to Misspecified Human Models},\nauthor={Joey Hong and Kush Bhatia and Anca Dragan},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=hJqGbUpDGV}\n}", "venue": "ICLR 2023 notable top 5%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279394674, "odate": 1664468100000, "details": {"replyCount": 14}}, {"id": "H3HcEJA2Um", "original": "BxP0eQHLZZD", "number": 5440, "cdate": 1663850446653, "mdate": null, "ddate": null, "tcdate": 1663850446653, "tmdate": 1697935284845, "tddate": null, "forum": "H3HcEJA2Um", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Time Will Tell: New Outlooks and A Baseline for Temporal Multi-View 3D Object Detection", "authorids": ["~Jinhyung_Park1", "~Chenfeng_Xu1", "~Shijia_Yang1", "~Kurt_Keutzer1", "~Kris_M._Kitani1", "~Masayoshi_Tomizuka1", "~Wei_Zhan2"], "authors": ["Jinhyung Park", "Chenfeng Xu", "Shijia Yang", "Kurt Keutzer", "Kris M. Kitani", "Masayoshi Tomizuka", "Wei Zhan"], "keywords": ["Computer Vision", "3D Object Detection", "Stereo Matching"], "TL;DR": "We leverage complementary coarse, long-term and fine-grained, short-term multi-view stereo for camera-only 3D object detection.", "abstract": "While recent camera-only 3D detection methods leverage multiple timesteps, the limited history they use significantly hampers the extent to which temporal fusion can improve object perception. Observing that existing works' fusion of multi-frame images are instances of temporal stereo matching, we find that performance is hindered by the interplay between 1) the low granularity of matching resolution and 2) the sub-optimal multi-view setup produced by limited history usage. Our theoretical and empirical analysis demonstrates that the optimal temporal difference between views varies significantly for different pixels and depths, making it necessary to fuse many timesteps over long-term history. Building on our investigation, we propose to generate a cost volume from a long history of image observations, compensating for the coarse but efficient matching resolution with a more optimal multi-view matching setup. Further, we augment the per-frame monocular depth predictions used for long-term, coarse matching with short-term, fine-grained matching and find that long and short term temporal fusion are highly complementary. While maintaining high efficiency, our framework sets new state-of-the-art on nuScenes, achieving first place on the test set and outperforming previous best art by 5.2% mAP and 3.7% NDS on the validation set. Code will be released here: https://github.com/Divadi/SOLOFusion.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Deep Learning and representational learning", "paperhash": "park|time_will_tell_new_outlooks_and_a_baseline_for_temporal_multiview_3d_object_detection", "pdf": "/pdf/1653c1b285d859cb8e3ba8eb36976b1006f2bf1c.pdf", "_bibtex": "@inproceedings{\npark2023time,\ntitle={Time Will Tell: New Outlooks and A Baseline for Temporal Multi-View 3D Object Detection},\nauthor={Jinhyung Park and Chenfeng Xu and Shijia Yang and Kurt Keutzer and Kris M. Kitani and Masayoshi Tomizuka and Wei Zhan},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=H3HcEJA2Um}\n}", "venue": "ICLR 2023 notable top 5%", "venueid": "ICLR.cc/2023/Conference", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2210.02443/code)"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279394095, "odate": 1664468100000, "details": {"replyCount": 11}}, {"id": "DEGjDDV22pI", "original": "LHk0jwKvAZT", "number": 5247, "cdate": 1663850422238, "mdate": null, "ddate": null, "tcdate": 1663850422238, "tmdate": 1677724565867, "tddate": null, "forum": "DEGjDDV22pI", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Dichotomy of Control: Separating What You Can Control from What You Cannot", "authorids": ["~Sherry_Yang1", "~Dale_Schuurmans1", "~Pieter_Abbeel2", "~Ofir_Nachum1"], "authors": ["Sherry Yang", "Dale Schuurmans", "Pieter Abbeel", "Ofir Nachum"], "keywords": ["Offline reinforcement learning", "return-conditioned supervised learning", "stochastic environments", "decision transformer"], "TL;DR": "We propose dichotomy of control (DoC) for supervised learning in stochastic environments by separating things within a policy's control (actions) from those outside of a policy\u2019s control (env stochasticity) through a mutual information constraint.", "abstract": "Future- or return-conditioned supervised learning is an emerging paradigm for offline reinforcement learning (RL), in which the future outcome (i.e., return) associated with a sequence of actions in an offline dataset is used as input to a policy trained to imitate those same actions. While return-conditioning is at the heart of popular algorithms such as decision transformer (DT), these methods tend to perform poorly in highly stochastic environments, where an occasional high return associated with a sequence of actions may be due more to the randomness of the environment than to the actions themselves. Such situations can lead to a learned policy that is inconsistent with its conditioning inputs; i.e., using the policy \u2013 while conditioned on a specific desired return \u2013 to act in the environment can lead to a distribution of real returns that is wildly different than desired. In this work, we propose the dichotomy of control (DoC), a future-conditioned supervised learning framework that separates mechanisms within a policy\u2019s control (actions) from those outside of a policy\u2019s control (environment stochasticity). We achieve this by conditioning the policy on a latent variable representation of the future and designing a mutual information constraint that removes any future information from the latent variable that is only due to randomness of the environment. Theoretically, we show that DoC yields policies that are consistent with their conditioning inputs, ensuring that conditioning a learned policy on a desired high-return future outcome will correctly induce high-return behavior. Empirically, we show that DoC is able to achieve significantly better performance than DT on environments with highly stochastic rewards (e.g., Bandit) and transitions (e.g., FrozenLake).", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)", "paperhash": "yang|dichotomy_of_control_separating_what_you_can_control_from_what_you_cannot", "pdf": "/pdf/6570cf14640b106571e1d2ce08ee384f1f17eeaf.pdf", "supplementary_material": "/attachment/dd819f96090bcc25a2f9ed64b43c745c2dcb27b1.zip", "_bibtex": "@inproceedings{\nyang2023dichotomy,\ntitle={Dichotomy of Control: Separating What You Can Control from What You Cannot},\nauthor={Sherry Yang and Dale Schuurmans and Pieter Abbeel and Ofir Nachum},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=DEGjDDV22pI}\n}", "venue": "ICLR 2023 notable top 5%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279383892, "odate": 1664468100000, "details": {"replyCount": 15}}, {"id": "en9V5F8PR-", "original": "GrD0EMZZ2lB", "number": 5206, "cdate": 1663850417174, "mdate": null, "ddate": null, "tcdate": 1663850417174, "tmdate": 1677242404718, "tddate": null, "forum": "en9V5F8PR-", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Learning where and when to reason in neuro-symbolic inference", "authorids": ["~Cristina_Cornelio2", "~Jan_Stuehmer1", "~Shell_Xu_Hu1", "~Timothy_Hospedales1"], "authors": ["Cristina Cornelio", "Jan Stuehmer", "Shell Xu Hu", "Timothy Hospedales"], "keywords": [], "abstract": "The integration of hard constraints on neural network outputs is a very desirable capability. This allows to instill trust in AI by guaranteeing the sanity of that neural network predictions with respect to domain knowledge. Recently, this topic has received a lot of attention. However, all the existing methods usually either impose the constraints in a \"weak\" form at training time, with no guarantees at inference, or fail to provide a general framework that supports different tasks and constraint types. We tackle this open problem from a neuro-symbolic perspective. Our pipeline enhances a conventional neural predictor with (1) a symbolic reasoning module capable of correcting structured prediction errors and (2) a neural attention module that learns to direct the reasoning effort to focus on potential prediction errors, while keeping other outputs unchanged. This framework provides an appealing trade-off between the efficiency of constraint-free neural inference and the prohibitive cost of exhaustive reasoning at inference time. We show that our method outperforms the state of the art on visual-Sudoku, and can also benefit visual scene graph prediction. Furthermore, it can improve the performance of existing neuro-symbolic systems that lack our explicit reasoning during inference.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "General Machine Learning (ie none of the above)", "paperhash": "cornelio|learning_where_and_when_to_reason_in_neurosymbolic_inference", "pdf": "/pdf/31f018dbf1b4f56acf88d2715ebd70a6d3908c99.pdf", "_bibtex": "@inproceedings{\ncornelio2023learning,\ntitle={Learning where and when to reason in neuro-symbolic inference},\nauthor={Cristina Cornelio and Jan Stuehmer and Shell Xu Hu and Timothy Hospedales},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=en9V5F8PR-}\n}", "venue": "ICLR 2023 notable top 5%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279382177, "odate": 1664468100000, "details": {"replyCount": 16}}, {"id": "kDEL91Dufpa", "original": "ze0uJXSt54C", "number": 5192, "cdate": 1663850415397, "mdate": null, "ddate": null, "tcdate": 1663850415397, "tmdate": 1677675609756, "tddate": null, "forum": "kDEL91Dufpa", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "On the duality between contrastive and non-contrastive self-supervised learning", "authorids": ["~Quentin_Garrido1", "~Yubei_Chen1", "~Adrien_Bardes1", "~Laurent_Najman1", "~Yann_LeCun1"], "authors": ["Quentin Garrido", "Yubei Chen", "Adrien Bardes", "Laurent Najman", "Yann LeCun"], "keywords": ["Self-supervised learning", "contrastive", "non-contrastive"], "TL;DR": "We show that contrastive and non-contrastive self-supervised methods can be shown to be closely related, and then study how implementation details impact performance. We validate empirically our findings and significantly improve known behaviours.", "abstract": "Recent approaches in self-supervised learning of image representations can be categorized into different families of methods and, in particular, can be divided into contrastive and non-contrastive approaches. While differences between the two families have been thoroughly discussed to motivate new approaches, we focus more on the theoretical similarities between them. By designing contrastive and covariance based non-contrastive criteria that can be related algebraically and shown to be equivalent under limited assumptions, we show how close those families can be. We further study popular methods and introduce variations of them, allowing us to relate this theoretical result to current practices and show the influence (or lack thereof) of design choices on downstream performance. Motivated by our equivalence result, we investigate the low performance of SimCLR and show how it can match VICReg's with careful hyperparameter tuning, improving significantly over known baselines. We also challenge the popular assumption that non-contrastive methods need large output dimensions. Our theoretical and quantitative results suggest that the numerical gaps between contrastive and non-contrastive methods in certain regimes can be closed given better network design choices and hyperparameter tuning. The evidence shows that unifying different SOTA methods is an important direction to build a better understanding of self-supervised learning.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Unsupervised and Self-supervised learning", "paperhash": "garrido|on_the_duality_between_contrastive_and_noncontrastive_selfsupervised_learning", "pdf": "/pdf/b65a5392645765469baab2e39bb691bf22a9e6fd.pdf", "_bibtex": "@inproceedings{\ngarrido2023on,\ntitle={On the duality between contrastive and non-contrastive self-supervised learning},\nauthor={Quentin Garrido and Yubei Chen and Adrien Bardes and Laurent Najman and Yann LeCun},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=kDEL91Dufpa}\n}", "venue": "ICLR 2023 notable top 5%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279381187, "odate": 1664468100000, "details": {"replyCount": 16}}, {"id": "FjNys5c7VyY", "original": "J4RQiJ6kkPQ", "number": 5182, "cdate": 1663850414208, "mdate": null, "ddate": null, "tcdate": 1663850414208, "tmdate": 1697935311428, "tddate": null, "forum": "FjNys5c7VyY", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "DreamFusion: Text-to-3D using 2D Diffusion", "authorids": ["~Ben_Poole1", "~Ajay_Jain1", "~Jonathan_T._Barron1", "~Ben_Mildenhall1"], "authors": ["Ben Poole", "Ajay Jain", "Jonathan T. Barron", "Ben Mildenhall"], "keywords": ["diffusion models", "score-based generative models", "NeRF", "neural rendering", "3d synthesis"], "TL;DR": "DeepDream on a pretrained 2D diffusion model enables text-to-3D synthesis", "abstract": "Recent breakthroughs in text-to-image synthesis have been driven by diffusion models trained on billions of image-text pairs. Adapting this approach to 3D synthesis would require large-scale datasets of labeled 3D or multiview data and efficient architectures for denoising 3D data, neither of which currently exist. In this work, we circumvent these limitations by using a pretrained 2D text-to-image diffusion model to perform text-to-3D synthesis. We introduce a loss based on probability density distillation that enables the use of a 2D diffusion model as a prior for optimization of a parametric image generator. Using this loss in a DeepDream-like procedure, we optimize a randomly-initialized 3D model (a Neural Radiance Field, or NeRF) via gradient descent such that its 2D renderings from random angles achieve a low loss. The resulting 3D model of the given text can be viewed from any angle, relit by arbitrary illumination, or composited into any 3D environment. Our approach requires no 3D training data and no modifications to the image diffusion model, demonstrating the effectiveness of pretrained image diffusion models as priors.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Generative models", "paperhash": "poole|dreamfusion_textto3d_using_2d_diffusion", "pdf": "/pdf/fc5d88df1a06d30ae79fb23e87030f0fb2c8bd76.pdf", "supplementary_material": "/attachment/2085ee205d8d430c77198b35a3a47a814259c85e.zip", "_bibtex": "@inproceedings{\npoole2023dreamfusion,\ntitle={DreamFusion: Text-to-3D using 2D Diffusion},\nauthor={Ben Poole and Ajay Jain and Jonathan T. Barron and Ben Mildenhall},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=FjNys5c7VyY}\n}", "venue": "ICLR 2023 notable top 5%", "venueid": "ICLR.cc/2023/Conference", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 2 code implementations](https://www.catalyzex.com/paper/arxiv:2209.14988/code)"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279380229, "odate": 1664468100000, "details": {"replyCount": 12}}, {"id": "zyLVMgsZ0U_", "original": "GUCUWUkjmMV", "number": 5148, "cdate": 1663850410084, "mdate": null, "ddate": null, "tcdate": 1663850410084, "tmdate": 1676330820335, "tddate": null, "forum": "zyLVMgsZ0U_", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Sampling is as easy as learning the score: theory for diffusion models with minimal data assumptions", "authorids": ["~Sitan_Chen1", "~Sinho_Chewi1", "~Jerry_Li1", "~Yuanzhi_Li1", "~Adil_Salim2", "~Anru_Zhang3"], "authors": ["Sitan Chen", "Sinho Chewi", "Jerry Li", "Yuanzhi Li", "Adil Salim", "Anru Zhang"], "keywords": ["diffusion models", "score-based generative models", "sampling", "score estimation", "Langevin", "stochastic differential equations"], "TL;DR": "We prove that given an L2-accurate score estimate, diffusion models can sample from (essentially) any data distribution, even if it is highly non-log-concave and/or supported on a low dimensional manifold.", "abstract": "We provide theoretical convergence guarantees for score-based generative models (SGMs) such as denoising diffusion probabilistic models (DDPMs), which constitute the backbone of large-scale real-world generative models such as DALL$\\cdot$E 2. Our main result is that, assuming accurate score estimates, such SGMs can efficiently sample from essentially any realistic data distribution. In contrast to prior works, our results (1) hold for an $L^2$-accurate score estimate (rather than $L^\\infty$-accurate); (2) do not require restrictive functional inequality conditions that preclude substantial non-log-concavity; (3) scale polynomially in all relevant problem parameters; and (4) match state-of-the-art complexity guarantees for discretization of the Langevin diffusion, provided that the score error is sufficiently small. We view this as strong theoretical justification for the empirical success of SGMs. We also examine SGMs based on the critically damped Langevin diffusion (CLD). Contrary to conventional wisdom, we provide evidence that the use of the CLD does *not* reduce the complexity of SGMs.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Generative models", "paperhash": "chen|sampling_is_as_easy_as_learning_the_score_theory_for_diffusion_models_with_minimal_data_assumptions", "pdf": "/pdf/f0dc173be132440952bd7d8221b096d0a0ecf2c7.pdf", "_bibtex": "@inproceedings{\nchen2023sampling,\ntitle={Sampling is as easy as learning the score: theory for diffusion models with minimal data assumptions},\nauthor={Sitan Chen and Sinho Chewi and Jerry Li and Yuanzhi Li and Adil Salim and Anru Zhang},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=zyLVMgsZ0U_}\n}", "venue": "ICLR 2023 notable top 5%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279378486, "odate": 1664468100000, "details": {"replyCount": 16}}, {"id": "88nT0j5jAn", "original": "TKwuLO2Vcc", "number": 5139, "cdate": 1663850408977, "mdate": null, "ddate": null, "tcdate": 1663850408977, "tmdate": 1697935316373, "tddate": null, "forum": "88nT0j5jAn", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Universal Few-shot Learning of Dense Prediction Tasks with Visual Token Matching", "authorids": ["~Donggyun_Kim1", "~Jinwoo_Kim4", "~Seongwoong_Cho1", "~Chong_Luo1", "~Seunghoon_Hong2"], "authors": ["Donggyun Kim", "Jinwoo Kim", "Seongwoong Cho", "Chong Luo", "Seunghoon Hong"], "keywords": ["few-shot learning", "dense prediction tasks"], "TL;DR": "a universal few-shot learner for general dense prediction tasks", "abstract": "Dense prediction tasks are a fundamental class of problems in computer vision. As supervised methods suffer from high pixel-wise labeling cost, a few-shot learning solution that can learn any dense task from a few labeled images is desired. Yet, current few-shot learning methods target a restricted set of tasks such as semantic segmentation, presumably due to challenges in designing a general and unified model that is able to flexibly and efficiently adapt to arbitrary tasks of unseen semantics. We propose Visual Token Matching (VTM), a universal few-shot learner for arbitrary dense prediction tasks. It employs non-parametric matching on patch-level embedded tokens of images and labels that encapsulates all tasks. Also, VTM flexibly adapts to any task with a tiny amount of task-specific parameters that modulate the matching algorithm. We implement VTM as a powerful hierarchical encoder-decoder architecture involving ViT backbones where token matching is performed at multiple feature hierarchies. We experiment VTM on a challenging variant of Taskonomy dataset and observe that it robustly few-shot learns various unseen dense prediction tasks. Surprisingly, it is competitive with fully supervised baselines using only 10 labeled examples of novel tasks ($0.004\\%$ of full supervision) and sometimes outperforms using $0.1\\%$ of full supervision. Codes are available at https://github.com/GitGyun/visual_token_matching.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Deep Learning and representational learning", "paperhash": "kim|universal_fewshot_learning_of_dense_prediction_tasks_with_visual_token_matching", "pdf": "/pdf/45149e96f3e88087d3e81a1ff08f0d2b5e719921.pdf", "_bibtex": "@inproceedings{\nkim2023universal,\ntitle={Universal Few-shot Learning of Dense Prediction Tasks with Visual Token Matching},\nauthor={Donggyun Kim and Jinwoo Kim and Seongwoong Cho and Chong Luo and Seunghoon Hong},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=88nT0j5jAn}\n}", "venue": "ICLR 2023 notable top 5%", "venueid": "ICLR.cc/2023/Conference", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2303.14969/code)"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279377852, "odate": 1664468100000, "details": {"replyCount": 14}}, {"id": "dLAYGdKTi2", "original": "XlPGtS5Rq-", "number": 5040, "cdate": 1663850397064, "mdate": null, "ddate": null, "tcdate": 1663850397064, "tmdate": 1677652137261, "tddate": null, "forum": "dLAYGdKTi2", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Mitigating Gradient Bias in Multi-objective Learning: A Provably Convergent Approach", "authorids": ["~Heshan_Devaka_Fernando1", "~Han_Shen3", "~Miao_Liu1", "~Subhajit_Chaudhury1", "~Keerthiram_Murugesan1", "~Tianyi_Chen5"], "authors": ["Heshan Devaka Fernando", "Han Shen", "Miao Liu", "Subhajit Chaudhury", "Keerthiram Murugesan", "Tianyi Chen"], "keywords": ["Multi-objective Optimization", "Machine Learning"], "abstract": "Many machine learning problems today have multiple objective functions. They appear either in learning with multiple criteria where learning has to make a trade-off between multiple performance metrics such as fairness, safety and accuracy; or, in multi-task learning where multiple tasks are optimized jointly, sharing inductive bias between them. This problems are often tackled by the multi-objective optimization framework. However, existing stochastic multi-objective gradient methods and its variants (e.g., MGDA, PCGrad, CAGrad, etc.) all adopt a biased noisy gradient direction, which leads to degraded empirical performance. \nTo this end, we develop a stochastic multi-objective gradient correction (MoCo) method for multi-objective optimization. The unique feature of our method is that it can guarantee convergence without increasing the batch size even in the nonconvex setting. Simulations on multi-task supervised and reinforcement learning demonstrate the effectiveness of our method relative to the state-of-the-art methods. ", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Optimization (eg, convex and non-convex optimization)", "paperhash": "fernando|mitigating_gradient_bias_in_multiobjective_learning_a_provably_convergent_approach", "TL;DR": "We propose a gradient based multi-objective optimization algorithm which provably convergence to a Pareto stationary point in stochastic convex and non-convex settings.", "pdf": "/pdf/9e46581e9b775d4b10ffcc00c43e0bdb8d21e1b4.pdf", "supplementary_material": "", "_bibtex": "@inproceedings{\nfernando2023mitigating,\ntitle={Mitigating Gradient Bias in Multi-objective Learning: A Provably Convergent Approach},\nauthor={Heshan Devaka Fernando and Han Shen and Miao Liu and Subhajit Chaudhury and Keerthiram Murugesan and Tianyi Chen},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=dLAYGdKTi2}\n}", "venue": "ICLR 2023 notable top 5%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279372997, "odate": 1664468100000, "details": {"replyCount": 7}}, {"id": "WE_vluYUL-X", "original": "sjekd_VoDTJ", "number": 5016, "cdate": 1663850394097, "mdate": null, "ddate": null, "tcdate": 1663850394097, "tmdate": 1697935329546, "tddate": null, "forum": "WE_vluYUL-X", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "ReAct: Synergizing Reasoning and Acting in Language Models", "authorids": ["~Shunyu_Yao1", "~Jeffrey_Zhao1", "~Dian_Yu2", "~Nan_Du1", "~Izhak_Shafran1", "~Karthik_R_Narasimhan1", "~Yuan_Cao2"], "authors": ["Shunyu Yao", "Jeffrey Zhao", "Dian Yu", "Nan Du", "Izhak Shafran", "Karthik R Narasimhan", "Yuan Cao"], "keywords": ["Language model", "agent", "reasoning", "decision making"], "TL;DR": "We synergize reasoning and action taking in language models and make them more capable, versatile and interpretable.", "abstract": "While large language models (LLMs) have demonstrated impressive capabilities across tasks in language understanding and interactive decision making, their abilities for reasoning (e.g. chain-of-thought prompting) and acting (e.g. action plan generation) have primarily been studied as separate topics. In this paper, we explore the use of LLMs to generate both reasoning traces and task-specific actions in an interleaved manner, allowing for greater synergy between the two: reasoning traces help the model induce, track, and update action plans as well as handle exceptions, while actions allow it to interface with external sources, such as knowledge bases or environments, to gather additional information. We apply our approach, named ReAct, to a diverse set of language and decision making tasks and demonstrate its effectiveness over state-of-the-art baselines, as well as improved human interpretability and trustworthiness over methods without reasoning or acting components. Concretely, on question answering (HotpotQA) and fact verification (Fever), ReAct overcomes issues of hallucination and error propagation prevalent in chain-of-thought reasoning by interacting with a simple Wikipedia API, and generates human-like task-solving trajectories that are more interpretable than baselines without reasoning traces. On two interactive decision making benchmarks (ALFWorld and WebShop), ReAct outperforms imitation and reinforcement learning methods by an absolute success rate of 34% and 10% respectively, while being prompted with only one or two in-context examples.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Applications (eg, speech processing, computer vision, NLP)", "paperhash": "yao|react_synergizing_reasoning_and_acting_in_language_models", "pdf": "/pdf/bc117919562a4ccddbe5c5b24ee364d14289cdee.pdf", "_bibtex": "@inproceedings{\nyao2023react,\ntitle={ReAct: Synergizing Reasoning and Acting in Language Models},\nauthor={Shunyu Yao and Jeffrey Zhao and Dian Yu and Nan Du and Izhak Shafran and Karthik R Narasimhan and Yuan Cao},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=WE_vluYUL-X}\n}", "venue": "ICLR 2023 notable top 5%", "venueid": "ICLR.cc/2023/Conference", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2210.03629/code)"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279371510, "odate": 1664468100000, "details": {"replyCount": 4}}, {"id": "ayPPc0SyLv1", "original": "ZAb8cXNkcWC", "number": 4948, "cdate": 1663850385719, "mdate": null, "ddate": null, "tcdate": 1663850385719, "tmdate": 1697935336980, "tddate": null, "forum": "ayPPc0SyLv1", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Do We Really Need Complicated Model Architectures For Temporal Networks?", "authorids": ["~Weilin_Cong1", "~Si_Zhang1", "~Jian_Kang1", "~Baichuan_Yuan1", "~Hao_Wu16", "~Xin_Zhou8", "~Hanghang_Tong3", "~Mehrdad_Mahdavi2"], "authors": ["Weilin Cong", "Si Zhang", "Jian Kang", "Baichuan Yuan", "Hao Wu", "Xin Zhou", "Hanghang Tong", "Mehrdad Mahdavi"], "keywords": ["temporal graph", "link prediction"], "TL;DR": "This paper propose a conceptually and technically simple method for temporal graph link prediction", "abstract": "Recurrent neural network (RNN) and self-attention mechanism (SAM) are the de facto methods to extract spatial-temporal information for temporal graph learning. Interestingly, we found that although both RNN and SAM could lead to a good performance, in practice neither of them is always necessary. In this paper, we propose GraphMixer, a conceptually and technically simple architecture that consists of three components: (1) a link-encoder that is only based on multi-layer perceptrons (MLP) to summarize the information from temporal links, (2) a node-encoder that is only based on neighbor mean-pooling to summarize node information, and (3) an MLP-based link classifier that performs link prediction based on the outputs of the encoders. Despite its simplicity, GraphMixer attains an outstanding performance on temporal link prediction benchmarks with faster convergence and better generalization performance. These results motivate us to rethink the importance of simpler model architecture.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Applications (eg, speech processing, computer vision, NLP)", "paperhash": "cong|do_we_really_need_complicated_model_architectures_for_temporal_networks", "pdf": "/pdf/4b4fffb0d6f563cba29cdcf32f829b333eb53899.pdf", "_bibtex": "@inproceedings{\ncong2023do,\ntitle={Do We Really Need Complicated Model Architectures For Temporal Networks?},\nauthor={Weilin Cong and Si Zhang and Jian Kang and Baichuan Yuan and Hao Wu and Xin Zhou and Hanghang Tong and Mehrdad Mahdavi},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=ayPPc0SyLv1}\n}", "venue": "ICLR 2023 notable top 5%", "venueid": "ICLR.cc/2023/Conference", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 6 code implementations](https://www.catalyzex.com/paper/arxiv:2302.11636/code)"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279367397, "odate": 1664468100000, "details": {"replyCount": 13}}, {"id": "sP1fo2K9DFG", "original": "WaA9l4L_SKP", "number": 4940, "cdate": 1663850384747, "mdate": null, "ddate": null, "tcdate": 1663850384747, "tmdate": 1677750076829, "tddate": null, "forum": "sP1fo2K9DFG", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Is Conditional Generative Modeling all you need for Decision Making?", "authorids": ["~Anurag_Ajay1", "~Yilun_Du1", "abhig@mit.edu", "~Joshua_B._Tenenbaum1", "~Tommi_S._Jaakkola1", "~Pulkit_Agrawal1"], "authors": ["Anurag Ajay", "Yilun Du", "Abhi Gupta", "Joshua B. Tenenbaum", "Tommi S. Jaakkola", "Pulkit Agrawal"], "keywords": ["Offline Reinforcement Learning", "Conditional Generative Modeling", "Sequential Decision Making", "Diffusion Models"], "TL;DR": "Framing (offline) sequential decision making as conditional diffusion generative modeling", "abstract": "Recent improvements in conditional generative modeling have made it possible to generate high-quality images from language descriptions alone. We investigate whether these methods can directly address the problem of sequential decision-making. We view decision-making not through the lens of reinforcement learning (RL), but rather through conditional generative modeling. To our surprise, we find that our formulation leads to policies that can outperform existing offline RL approaches across standard benchmarks. By modeling a policy as a return-conditional generative model, we avoid the need for dynamic programming and subsequently eliminate many of the complexities that come with traditional offline RL. We further demonstrate the advantages of modeling policies as conditional generative models by considering two other conditioning variables: constraints and skills. Conditioning on a single constraint or skill during training leads to behaviors at test-time that can satisfy several constraints together or demonstrate a composition of skills. Our results illustrate that conditional generative modeling is a powerful tool for decision-making. ", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)", "paperhash": "ajay|is_conditional_generative_modeling_all_you_need_for_decision_making", "pdf": "/pdf/e4e0b6540b8164996a357a85347d96a324cf5647.pdf", "_bibtex": "@inproceedings{\najay2023is,\ntitle={Is Conditional Generative Modeling all you need for Decision Making?},\nauthor={Anurag Ajay and Yilun Du and Abhi Gupta and Joshua B. Tenenbaum and Tommi S. Jaakkola and Pulkit Agrawal},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=sP1fo2K9DFG}\n}", "venue": "ICLR 2023 notable top 5%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279366643, "odate": 1664468100000, "details": {"replyCount": 24}}, {"id": "JL7Va5Vy15J", "original": "D5ofaroArnI", "number": 4877, "cdate": 1663850377165, "mdate": null, "ddate": null, "tcdate": 1663850377165, "tmdate": 1697935344679, "tddate": null, "forum": "JL7Va5Vy15J", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "The Lie Derivative for Measuring Learned Equivariance", "authorids": ["~Nate_Gruver1", "~Marc_Anton_Finzi1", "~Micah_Goldblum1", "~Andrew_Gordon_Wilson1"], "authors": ["Nate Gruver", "Marc Anton Finzi", "Micah Goldblum", "Andrew Gordon Wilson"], "keywords": [], "abstract": "Equivariance guarantees that a model's predictions capture key symmetries in data. When an image is translated or rotated, an equivariant model's representation of that image will translate or rotate accordingly. The success of convolutional neural networks has historically been tied to translation equivariance directly encoded in their architecture. The rising success of vision transformers, which have no explicit architectural bias towards equivariance, challenges this narrative and suggests that augmentations and training data might also play a significant role in their performance. In order to better understand the role of equivariance in recent vision models, we apply the Lie derivative, a method for measuring equivariance with strong mathematical foundations and minimal hyperparameters. Using the Lie derivative, we study the equivariance properties of hundreds of pretrained models, spanning CNNs, transformers, and Mixer architectures. The scale of our analysis allows us to separate the impact of architecture from other factors like model size or training method. Surprisingly, we find that many violations of equivariance can be linked to spatial aliasing in ubiquitous network layers, such as pointwise non-linearities, and that as models get larger and more accurate they tend to display more equivariance, regardless of architecture. For example, transformers can be more equivariant than convolutional neural networks after training.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Deep Learning and representational learning", "paperhash": "gruver|the_lie_derivative_for_measuring_learned_equivariance", "pdf": "/pdf/6d3e8e96475697f1cf6193df36e370ffd12302e8.pdf", "supplementary_material": "/attachment/5261b69b57661a9fd7cb61b3c1445fab10de7754.zip", "_bibtex": "@inproceedings{\ngruver2023the,\ntitle={The Lie Derivative for Measuring Learned Equivariance},\nauthor={Nate Gruver and Marc Anton Finzi and Micah Goldblum and Andrew Gordon Wilson},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=JL7Va5Vy15J}\n}", "venue": "ICLR 2023 notable top 5%", "venueid": "ICLR.cc/2023/Conference", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 3 code implementations](https://www.catalyzex.com/paper/arxiv:2210.02984/code)"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279363181, "odate": 1664468100000, "details": {"replyCount": 10}}, {"id": "K7CbYQbyYhY", "original": "q7cYP-9qPyu", "number": 4873, "cdate": 1663850376681, "mdate": null, "ddate": null, "tcdate": 1663850376681, "tmdate": 1677592770232, "tddate": null, "forum": "K7CbYQbyYhY", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Agree to Disagree: Diversity through Disagreement for Better Transferability", "authorids": ["~Matteo_Pagliardini1", "~Martin_Jaggi1", "~Fran\u00e7ois_Fleuret2", "~Sai_Praneeth_Karimireddy1"], "authors": ["Matteo Pagliardini", "Martin Jaggi", "Fran\u00e7ois Fleuret", "Sai Praneeth Karimireddy"], "keywords": ["OOD generalization", "Diversity", "Ensemble"], "abstract": "Gradient-based learning algorithms have an implicit \\emph{simplicity bias} which in effect can limit the diversity of predictors being sampled by the learning procedure. This behavior can hinder the transferability of trained models by (i) favoring the learning of simpler but spurious features --- present in the training data but absent from the test data --- and (ii) by only leveraging a small subset of predictive features.  Such an effect is especially magnified when the test distribution does not exactly match the train distribution---referred to as the Out of Distribution (OOD) generalization problem. However, given only the training data, it is not always possible to apriori assess if a given feature is spurious or transferable. Instead, we advocate for learning an ensemble of models which capture a diverse set of predictive features. Towards this, we propose a new algorithm D-BAT (Diversity-By-disAgreement Training), which enforces agreement among the models on the training data, but disagreement on the OOD data. We show how D-BAT naturally emerges from the notion of generalized discrepancy, as well as demonstrate in multiple experiments how the proposed method can mitigate shortcut-learning, enhance uncertainty and OOD detection, as well as improve transferability.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Deep Learning and representational learning", "paperhash": "pagliardini|agree_to_disagree_diversity_through_disagreement_for_better_transferability", "pdf": "/pdf/bffcee09d1939996b54123724697afa1a9d4df37.pdf", "_bibtex": "@inproceedings{\npagliardini2023agree,\ntitle={Agree to Disagree: Diversity through Disagreement for Better Transferability},\nauthor={Matteo Pagliardini and Martin Jaggi and Fran{\\c{c}}ois Fleuret and Sai Praneeth Karimireddy},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=K7CbYQbyYhY}\n}", "venue": "ICLR 2023 notable top 5%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279362993, "odate": 1664468100000, "details": {"replyCount": 12}}, {"id": "dJruFeSRym1", "original": "yzWUVtUoD6v", "number": 4723, "cdate": 1663850357698, "mdate": null, "ddate": null, "tcdate": 1663850357698, "tmdate": 1697935362591, "tddate": null, "forum": "dJruFeSRym1", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Efficient Conditionally Invariant Representation Learning", "authorids": ["~Roman_Pogodin1", "~Namrata_Deka1", "~Yazhe_Li2", "~Danica_J._Sutherland1", "~Victor_Veitch1", "~Arthur_Gretton1"], "authors": ["Roman Pogodin", "Namrata Deka", "Yazhe Li", "Danica J. Sutherland", "Victor Veitch", "Arthur Gretton"], "keywords": ["conditional independence", "kernel methods"], "TL;DR": "Batch-efficient conditional independence regularization", "abstract": "We introduce the Conditional Independence Regression CovariancE (CIRCE), a measure of conditional independence for multivariate continuous-valued variables. CIRCE applies as a regularizer in settings where we wish to learn neural features $\\varphi(X)$ of data $X$ to estimate a target $Y$, while being conditionally independent of a distractor $Z$ given $Y$. Both $Z$ and $Y$ are assumed to be continuous-valued but relatively low dimensional, whereas $X$ and its features may be complex and high dimensional. Relevant settings include domain-invariant learning, fairness, and causal learning. The procedure requires just a single ridge regression from $Y$ to kernelized features of $Z$, which can be done in advance. It is then only necessary to enforce independence of $\\varphi(X)$ from residuals of this regression, which is possible with attractive estimation properties and consistency guarantees. By contrast, earlier measures of conditional feature dependence require multiple regressions for each step of feature learning, resulting in more severe bias and variance, and greater computational cost. When sufficiently rich features are used, we establish that CIRCE is zero if and only if $\\varphi(X) \\perp \\!\\!\\! \\perp Z \\mid Y$. In experiments, we show superior performance to previous methods on challenging benchmarks, including learning conditionally invariant image features. Code for image data experiments is available at github.com/namratadeka/circe.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Deep Learning and representational learning", "paperhash": "pogodin|efficient_conditionally_invariant_representation_learning", "pdf": "/pdf/59fb48f35c3ae783e6d4bb6e29843529e56a0305.pdf", "supplementary_material": "/attachment/b37a5138ec9102a149625d08fc31099f4e6c613d.zip", "_bibtex": "@inproceedings{\npogodin2023efficient,\ntitle={Efficient Conditionally Invariant Representation Learning},\nauthor={Roman Pogodin and Namrata Deka and Yazhe Li and Danica J. Sutherland and Victor Veitch and Arthur Gretton},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=dJruFeSRym1}\n}", "venue": "ICLR 2023 notable top 5%", "venueid": "ICLR.cc/2023/Conference", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2212.08645/code)"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279353882, "odate": 1664468100000, "details": {"replyCount": 9}}, {"id": "SMYdcXjJh1q", "original": "rCgXDvlJML", "number": 4692, "cdate": 1663850353919, "mdate": null, "ddate": null, "tcdate": 1663850353919, "tmdate": 1677699248768, "tddate": null, "forum": "SMYdcXjJh1q", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Aligning Model and Macaque Inferior Temporal Cortex Representations Improves Model-to-Human Behavioral Alignment and Adversarial Robustness", "authorids": ["~Joel_Dapello1", "~Kohitij_Kar2", "~Martin_Schrimpf1", "~Robert_Baldwin_Geary1", "~Michael_Ferguson3", "~David_Daniel_Cox1", "~James_J._DiCarlo1"], "authors": ["Joel Dapello", "Kohitij Kar", "Martin Schrimpf", "Robert Baldwin Geary", "Michael Ferguson", "David Daniel Cox", "James J. DiCarlo"], "keywords": ["Computer Vision", "Primate Vision", "Adversarial Robustness", "Behavioral Alignment", "Inferior Temporal Cortex"], "TL;DR": "Aligning late stage model representations with neural recordings from macaque IT broadly improves adversarial robustness and alignment on human behavior.", "abstract": "While some state-of-the-art artificial neural network systems in computer vision are strikingly accurate models of the corresponding primate visual processing, there are still many discrepancies between these models and the behavior of primates on object recognition tasks. Many current models suffer from extreme sensitivity to adversarial attacks and often do not align well with the image-by-image behavioral error patterns observed in humans. Previous research has provided strong evidence that primate object recognition behavior can be very accurately predicted by neural population activity in the inferior temporal (IT) cortex, a brain area in the late stages of the visual processing hierarchy. Therefore, here we directly test whether making the late stage representations of models more similar to that of macaque IT produces new models that exhibit more robust, primate-like behavior. We conducted chronic, large-scale multi-electrode recordings  across the IT cortex in six non-human primates (rhesus macaques). We then use these data to fine-tune (end-to-end) the model \"IT\" representations such that they are more aligned with the biological IT representations, while preserving accuracy on object recognition tasks. We generate a cohort of models with a range of IT similarity scores validated on held-out animals across two image sets with distinct statistics. Across a battery of optimization conditions, we observed a strong correlation between the models' IT-likeness and alignment with human behavior, as well as an increase in its adversarial robustness. We further assessed the limitations of this approach and find that the improvements in behavioral alignment and adversarial robustness generalize across different image statistics, but not to object categories outside of those covered in our IT training set. Taken together, our results demonstrate that building models that are more aligned with the primate brain leads to more robust and human-like behavior, and call for larger neural data-sets to further augment these gains.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Deep Learning and representational learning", "paperhash": "dapello|aligning_model_and_macaque_inferior_temporal_cortex_representations_improves_modeltohuman_behavioral_alignment_and_adversarial_robustness", "pdf": "/pdf/9c4c1940dba43cb5ad6502b7a23339d19d3a9a49.pdf", "supplementary_material": "/attachment/a2ee5ffe47c5d6cdb6863f3fa7c50a2d74d4add3.zip", "_bibtex": "@inproceedings{\ndapello2023aligning,\ntitle={Aligning Model and Macaque Inferior Temporal Cortex Representations Improves Model-to-Human Behavioral Alignment and Adversarial Robustness},\nauthor={Joel Dapello and Kohitij Kar and Martin Schrimpf and Robert Baldwin Geary and Michael Ferguson and David Daniel Cox and James J. DiCarlo},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=SMYdcXjJh1q}\n}", "venue": "ICLR 2023 notable top 5%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279352277, "odate": 1664468100000, "details": {"replyCount": 8}}, {"id": "De4FYqjFueZ", "original": "u16n0SVN2d", "number": 4543, "cdate": 1663850336454, "mdate": null, "ddate": null, "tcdate": 1663850336454, "tmdate": 1697935381879, "tddate": null, "forum": "De4FYqjFueZ", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Transformers Learn Shortcuts to Automata", "authorids": ["~Bingbin_Liu1", "~Jordan_T._Ash1", "~Surbhi_Goel1", "~Akshay_Krishnamurthy1", "~Cyril_Zhang1"], "authors": ["Bingbin Liu", "Jordan T. Ash", "Surbhi Goel", "Akshay Krishnamurthy", "Cyril Zhang"], "keywords": ["Transformer", "self-attention", "group theory", "semigroup theory", "algebraic automata theory", "shortcut learning", "theory of deep learning"], "abstract": "Algorithmic reasoning requires capabilities which are most naturally understood through recurrent models of computation, like the Turing machine. However, Transformer models, while lacking recurrence, are able to perform such reasoning using far fewer layers than the number of reasoning steps. This raises the question: what solutions are these shallow and non-recurrent models finding? We investigate this question in the setting of learning automata, discrete dynamical systems naturally suited to recurrent modeling and expressing algorithmic tasks. Our theoretical results completely characterize shortcut solutions, whereby a shallow Transformer with only $o(T)$ layers can exactly replicate the computation of an automaton on an input sequence of length $T$. By representing automata using the algebraic structure of their underlying transformation semigroups, we obtain $O(\\log T)$-depth simulators for all automata and $O(1)$-depth simulators for all automata whose associated groups are solvable. Empirically, we perform synthetic experiments by training Transformers to simulate a wide variety of automata, and show that shortcut solutions can be learned via standard training. We further investigate the brittleness of these solutions and propose potential mitigations.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Theory (eg, control theory, learning theory, algorithmic game theory)", "paperhash": "liu|transformers_learn_shortcuts_to_automata", "TL;DR": "Shallow, non-recurrent Transformers can simulate the recurrent dynamics of finite-state automata, via counterintuitive shortcuts.", "pdf": "/pdf/6fceba3e100352173ef8f64b4743424fc99f1e8d.pdf", "supplementary_material": "/attachment/a6bb850bd7ce5ce37df76892ec4c3b91474f8d16.zip", "_bibtex": "@inproceedings{\nliu2023transformers,\ntitle={Transformers Learn Shortcuts to Automata},\nauthor={Bingbin Liu and Jordan T. Ash and Surbhi Goel and Akshay Krishnamurthy and Cyril Zhang},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=De4FYqjFueZ}\n}", "venue": "ICLR 2023 notable top 5%", "venueid": "ICLR.cc/2023/Conference", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2210.10749/code)"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279343637, "odate": 1664468100000, "details": {"replyCount": 8}}, {"id": "hy0a5MMPUv", "original": "Nhb94mf_1Ry", "number": 4438, "cdate": 1663850323468, "mdate": null, "ddate": null, "tcdate": 1663850323468, "tmdate": 1677534187034, "tddate": null, "forum": "hy0a5MMPUv", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "In-context Reinforcement Learning with Algorithm Distillation", "authorids": ["~Michael_Laskin1", "~Luyu_Wang2", "~Junhyuk_Oh2", "~Emilio_Parisotto1", "stspencer@google.com", "steigerwald@google.com", "~DJ_Strouse1", "~Steven_Stenberg_Hansen1", "~Angelos_Filos1", "~Ethan_Brooks1", "~maxime_gazeau1", "~Himanshu_Sahni1", "~Satinder_Singh2", "~Volodymyr_Mnih1"], "authors": ["Michael Laskin", "Luyu Wang", "Junhyuk Oh", "Emilio Parisotto", "Stephen Spencer", "Richie Steigerwald", "DJ Strouse", "Steven Stenberg Hansen", "Angelos Filos", "Ethan Brooks", "maxime gazeau", "Himanshu Sahni", "Satinder Singh", "Volodymyr Mnih"], "keywords": ["Reinforcement Learning", "Transformers", "Learning to Learn", "Large Language Models"], "TL;DR": "We present Algorithm Distillation, a method that outputs an in-context RL algorithm by treating learning to reinforcement learn as a sequential prediction problem.", "abstract": "We propose Algorithm Distillation (AD), a method for distilling reinforcement learning (RL) algorithms into neural networks by modeling their training histories with a causal sequence model. Algorithm Distillation treats learning to reinforcement learn as an across-episode sequential prediction problem. A dataset of learning histories is generated by a source RL algorithm, and then a causal transformer is trained by autoregressively predicting actions given their preceding learning histories as context. Unlike sequential policy prediction architectures that distill post-learning or expert sequences, AD is able to improve its policy entirely in-context without updating its network parameters. We demonstrate that AD can reinforcement learn in-context in a variety of environments with sparse rewards, combinatorial task structure, and pixel-based observations, and find that AD learns a more data-efficient RL algorithm than the one that generated the source data.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)", "paperhash": "laskin|incontext_reinforcement_learning_with_algorithm_distillation", "pdf": "/pdf/c985c5523f4d0b869ac3914fad93d499e71fcb5a.pdf", "_bibtex": "@inproceedings{\nlaskin2023incontext,\ntitle={In-context Reinforcement Learning with Algorithm Distillation},\nauthor={Michael Laskin and Luyu Wang and Junhyuk Oh and Emilio Parisotto and Stephen Spencer and Richie Steigerwald and DJ Strouse and Steven Stenberg Hansen and Angelos Filos and Ethan Brooks and maxime gazeau and Himanshu Sahni and Satinder Singh and Volodymyr Mnih},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=hy0a5MMPUv}\n}", "venue": "ICLR 2023 notable top 5%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279337275, "odate": 1664468100000, "details": {"replyCount": 14}}, {"id": "3Pf3Wg6o-A4", "original": "a--f-a6joId", "number": 4350, "cdate": 1663850310732, "mdate": null, "ddate": null, "tcdate": 1663850310732, "tmdate": 1677692393129, "tddate": null, "forum": "3Pf3Wg6o-A4", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Selection-Inference: Exploiting Large Language Models for Interpretable Logical Reasoning", "authorids": ["~Antonia_Creswell2", "~Murray_Shanahan1", "~Irina_Higgins1"], "authors": ["Antonia Creswell", "Murray Shanahan", "Irina Higgins"], "keywords": ["System 2", "Logical reasoning", "Language Models", "Large Language Models", "Reasoning", "Neuro-symbolic", "Neural Symbolic", "Interpretability"], "TL;DR": "Using language models to produce a human interpretable chain of logical reasoning to answer questions.", "abstract": "Large language models (LLMs) have been shown to be capable of impressive few-shot generalisation to new tasks. However, they still tend to perform poorly on multi-step logical reasoning problems. Here we carry out a comprehensive evaluation of LLMs on 46 tasks that probe different aspects of logical reasoning. We show that language models tend to perform fairly well at single step inference or entailment tasks, but struggle to chain together multiple reasoning steps to solve more complex problems. In light of this, we propose a Selection-Inference (SI) framework that exploits pre-trained LLMs as general processing modules, and alternates between selection and inference to generate a series of interpretable, casual reasoning steps leading to the final answer. We show that a 7B parameter LLM used within the SI framework in a 5-shot generalisation setting, with no fine-tuning, yields a performance improvement of over 100% compared to an equivalent vanilla baseline on a suite of 10 logical reasoning tasks. The same model in the same setting even outperforms a significantly larger 280B parameter baseline on the same suite of tasks. Moreover, answers produced by the SI framework are accompanied by a causal natural-language-based reasoning trace, which has important implications for the safety and trustworthiness of the system.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)", "paperhash": "creswell|selectioninference_exploiting_large_language_models_for_interpretable_logical_reasoning", "pdf": "/pdf/4c8f591f9bb58ccd07ed826e0e57885bc4227b12.pdf", "supplementary_material": "/attachment/cb841040a356427e79fb1947b003ee8a3d412822.zip", "_bibtex": "@inproceedings{\ncreswell2023selectioninference,\ntitle={Selection-Inference: Exploiting Large Language Models for Interpretable Logical Reasoning},\nauthor={Antonia Creswell and Murray Shanahan and Irina Higgins},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=3Pf3Wg6o-A4}\n}", "venue": "ICLR 2023 notable top 5%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279333063, "odate": 1664468100000, "details": {"replyCount": 16}}, {"id": "Y5SEe3dfniJ", "original": "9j4KjjE1K14", "number": 4215, "cdate": 1663850294782, "mdate": null, "ddate": null, "tcdate": 1663850294782, "tmdate": 1677756475931, "tddate": null, "forum": "Y5SEe3dfniJ", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Compressing multidimensional weather and climate data into neural networks", "authorids": ["~Langwen_Huang1", "~Torsten_Hoefler1"], "authors": ["Langwen Huang", "Torsten Hoefler"], "keywords": ["Weather and climate data", "Compression"], "TL;DR": "We compress weather and climate data into neural network weights.", "abstract": "Weather and climate simulations produce petabytes of high-resolution data that are later analyzed by researchers in order to understand climate change or severe weather. We propose a new method of compressing this multidimensional weather and climate data: a coordinate-based neural network is trained to overfit the data, and the resulting parameters are taken as a compact representation of the original grid-based data. While compression ratios range from 300x to more than 3,000x, our method outperforms the state-of-the-art compressor SZ3 in terms of weighted RMSE, MAE. It can faithfully preserve important large scale atmosphere structures and does not introduce significant artifacts.\nWhen using the resulting neural network as a 790x compressed dataloader to train the WeatherBench forecasting model, its RMSE increases by less than 2%. The three orders of magnitude compression democratizes access to high-resolution climate data and enables numerous new research directions.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )", "paperhash": "huang|compressing_multidimensional_weather_and_climate_data_into_neural_networks", "pdf": "/pdf/6959d1573e13008d77bafdde3a013ed0767d1185.pdf", "_bibtex": "@inproceedings{\nhuang2023compressing,\ntitle={Compressing multidimensional weather and climate data into neural networks},\nauthor={Langwen Huang and Torsten Hoefler},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=Y5SEe3dfniJ}\n}", "venue": "ICLR 2023 notable top 5%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279324180, "odate": 1664468100000, "details": {"replyCount": 9}}, {"id": "iIfDQVyuFD", "original": "IRgzwHK47Jj", "number": 4102, "cdate": 1663850281434, "mdate": null, "ddate": null, "tcdate": 1663850281434, "tmdate": 1677752824177, "tddate": null, "forum": "iIfDQVyuFD", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Confidential-PROFITT: Confidential PROof of FaIr Training of Trees", "authorids": ["~Ali_Shahin_Shamsabadi1", "~Sierra_Calanda_Wyllie1", "nicholasfranzese2026@u.northwestern.edu", "~Natalie_Dullerud1", "~S\u00e9bastien_Gambs2", "~Nicolas_Papernot1", "~Xiao_Wang11", "~Adrian_Weller1"], "authors": ["Ali Shahin Shamsabadi", "Sierra Calanda Wyllie", "Nicholas Franzese", "Natalie Dullerud", "S\u00e9bastien Gambs", "Nicolas Papernot", "Xiao Wang", "Adrian Weller"], "keywords": ["Fairness", "Audit", "Confidentiality", "Zero-Knowledge Proof"], "TL;DR": "We introduce a method to provide a confidential proof of fair training.", "abstract": "Post hoc auditing of model fairness suffers from potential drawbacks: (1) auditing may be highly sensitive to the test samples chosen; (2) the model and/or its training data may need to be shared with an auditor thereby breaking confidentiality. We address these issues by instead providing a certificate that demonstrates that the learning algorithm itself is fair, and hence, as a consequence, so too is the trained model. We introduce a method to provide a confidential proof of fairness for training, in the context of widely used decision trees, which we term Confidential-PROFITT. We propose novel fair decision tree learning algorithms along with customized zero-knowledge proof protocols to obtain a proof of fairness that can be audited by a third party. Using zero-knowledge proofs enables us to guarantee confidentiality of both the model and its training data. We show empirically that bounding the information gain of each node with respect to the sensitive attributes reduces the unfairness of the final tree. In extensive experiments on the COMPAS, Communities and Crime, Default Credit, and Adult datasets, we demonstrate that a company can use Confidential-PROFITT to certify the fairness of their decision tree to an auditor in less than 2 minutes, thus indicating the applicability of our approach. This is true for both the demographic parity and equalized odds definitions of fairness. Finally, we extend Confidential-PROFITT to apply to ensembles of trees.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)", "paperhash": "shamsabadi|confidentialprofitt_confidential_proof_of_fair_training_of_trees", "pdf": "/pdf/20b12822064b2d7eb054021a0f1209e1dd066515.pdf", "supplementary_material": "/attachment/660c1b939f8af2508947557fb9e64836ee925af2.zip", "_bibtex": "@inproceedings{\nshamsabadi2023confidentialprofitt,\ntitle={Confidential-{PROFITT}: Confidential {PRO}of of FaIr Training of Trees},\nauthor={Ali Shahin Shamsabadi and Sierra Calanda Wyllie and Nicholas Franzese and Natalie Dullerud and S{\\'e}bastien Gambs and Nicolas Papernot and Xiao Wang and Adrian Weller},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=iIfDQVyuFD}\n}", "venue": "ICLR 2023 notable top 5%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279318387, "odate": 1664468100000, "details": {"replyCount": 8}}, {"id": "Nc1ZkRW8Vde", "original": "IliBPSzcUWr", "number": 3911, "cdate": 1663850258756, "mdate": null, "ddate": null, "tcdate": 1663850258756, "tmdate": 1677249126091, "tddate": null, "forum": "Nc1ZkRW8Vde", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Near-optimal Coresets for Robust Clustering", "authorids": ["~Lingxiao_Huang2", "~Shaofeng_H.-C._Jiang1", "~Jianing_Lou1", "~Xuan_Wu2"], "authors": ["Lingxiao Huang", "Shaofeng H.-C. Jiang", "Jianing Lou", "Xuan Wu"], "keywords": ["clustering", "outlier", "robustness", "coreset"], "abstract": "We consider robust clustering problems in $\\mathbb{R}^d$, specifically $k$-clustering problems (e.g., $k$-Median and $k$-Means) with $m$ \\emph{outliers}, where the cost for a given center set $C \\subset \\mathbb{R}^d$ aggregates the distances from $C$ to all but the furthest $m$ data points, instead of all points as in classical clustering. We focus on the $\\epsilon$-coreset for robust clustering, a small proxy of the dataset that preserves the clustering cost within $\\epsilon$-relative error for all center sets. Our main result is an $\\epsilon$-coreset of size $O(m + \\mathrm{poly}(k \\epsilon^{-1}))$ that can be constructed in near-linear time. This significantly improves previous results, which either suffers an exponential dependence on $(m + k)$ [Feldman and Schulman, SODA'12], or has a weaker bi-criteria guarantee [Huang et al., FOCS'18]. Furthermore, we show this dependence in $m$ is nearly-optimal, and the fact that it is isolated from other factors may be crucial for dealing with large number of outliers. We construct our coresets by adapting to the outlier setting a recent framework [Braverman et al., FOCS'22] which was designed for capacity-constrained clustering, overcoming a new challenge that the participating terms in the cost, particularly the excluded $m$ outlier points, are dependent on the center set $C$. We validate our coresets on various datasets, and we observe a superior size-accuracy tradeoff compared with popular baselines including uniform sampling and sensitivity sampling. We also achieve a significant speedup of existing approximation algorithms for robust clustering using our coresets.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Theory (eg, control theory, learning theory, algorithmic game theory)", "paperhash": "huang|nearoptimal_coresets_for_robust_clustering", "TL;DR": "We obtain an \\epsilon-coreset of near-optimal size for (k, z)-clustering (which includes k-median and k-means) with m outliers", "pdf": "/pdf/697bd8e4cac416b91757762ed8f0209073062f6d.pdf", "supplementary_material": "/attachment/bf00513be771e6dd37ac023ada087c068d55b321.zip", "_bibtex": "@inproceedings{\nhuang2023nearoptimal,\ntitle={Near-optimal Coresets for Robust Clustering},\nauthor={Lingxiao Huang and Shaofeng H.-C. Jiang and Jianing Lou and Xuan Wu},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=Nc1ZkRW8Vde}\n}", "venue": "ICLR 2023 notable top 5%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279307745, "odate": 1664468100000, "details": {"replyCount": 12}}, {"id": "0Ij9_q567Ma", "original": "B9QTUw-0gG-", "number": 3717, "cdate": 1663850235564, "mdate": null, "ddate": null, "tcdate": 1663850235564, "tmdate": 1677732407718, "tddate": null, "forum": "0Ij9_q567Ma", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Targeted Hyperparameter Optimization with Lexicographic Preferences Over Multiple Objectives", "authorids": ["~Shaokun_Zhang2", "~Feiran_Jia1", "~Chi_Wang3", "~Qingyun_Wu2"], "authors": ["Shaokun Zhang", "Feiran Jia", "Chi Wang", "Qingyun Wu"], "keywords": ["Automatic Machine learning", "Hyperparameter tuning", "Lexicographic preference"], "TL;DR": "Hyperparameter tuning under lexicographic preference", "abstract": "Motivated by various practical applications, we propose a novel and general formulation of targeted multi-objective hyperparameter optimization. Our formulation allows a clear specification of an automatable optimization goal using lexicographic preference over multiple objectives. We then propose a randomized directed search method named LexiFlow to solve this problem. We demonstrate the strong empirical performance of the proposed algorithm in multiple hyperparameter optimization tasks.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "General Machine Learning (ie none of the above)", "paperhash": "zhang|targeted_hyperparameter_optimization_with_lexicographic_preferences_over_multiple_objectives", "pdf": "/pdf/01544b5bcb68c0bc76fbffa2876dca9d12ec0f24.pdf", "supplementary_material": "/attachment/f6ab1cbadf61d2b6bfb1cd40de5ad4a7812898a0.zip", "_bibtex": "@inproceedings{\nzhang2023targeted,\ntitle={Targeted Hyperparameter Optimization with Lexicographic Preferences Over Multiple Objectives},\nauthor={Shaokun Zhang and Feiran Jia and Chi Wang and Qingyun Wu},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=0Ij9_q567Ma}\n}", "venue": "ICLR 2023 notable top 5%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279296797, "odate": 1664468100000, "details": {"replyCount": 11}}, {"id": "F61FwJTZhb", "original": "eUASo8VMgtl", "number": 3671, "cdate": 1663850230023, "mdate": null, "ddate": null, "tcdate": 1663850230023, "tmdate": 1677726963177, "tddate": null, "forum": "F61FwJTZhb", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Mastering the Game of No-Press Diplomacy via Human-Regularized Reinforcement Learning and Planning", "authorids": ["~Anton_Bakhtin1", "~David_J_Wu1", "~Adam_Lerer1", "~Jonathan_Gray2", "~Athul_Paul_Jacob1", "~Gabriele_Farina1", "~Alexander_H_Miller1", "~Noam_Brown2"], "authors": ["Anton Bakhtin", "David J Wu", "Adam Lerer", "Jonathan Gray", "Athul Paul Jacob", "Gabriele Farina", "Alexander H Miller", "Noam Brown"], "keywords": [], "TL;DR": "We train a bot that places first in a no-press Diplomacy tournament with humans by using human-data-regularized reinforcement learning and planning ", "abstract": "No-press Diplomacy is a complex strategy game involving both cooperation and competition that has served as a benchmark for multi-agent AI research. While self-play reinforcement learning has resulted in numerous successes in purely adversarial games like chess, Go, and poker, self-play alone is insufficient for achieving optimal performance in domains involving cooperation with humans. We address this shortcoming by first introducing a planning algorithm we call DiL-piKL that regularizes a reward-maximizing policy toward a human imitation-learned policy. We prove that this is a no-regret learning algorithm under a modified utility function. We then show that DiL-piKL can be extended into a self-play reinforcement learning algorithm we call RL-DiL-piKL that provides a model of human play while simultaneously training an agent that responds well to this human model. We used RL-DiL-piKL to train an agent we name Diplodocus.\nIn a 200-game no-press Diplomacy tournament involving 62 human participants spanning skill levels from beginner to expert, two Diplodocus agents both achieved a higher average score than all other participants who played more than two games, and ranked first and third according to an Elo ratings model.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)", "paperhash": "bakhtin|mastering_the_game_of_nopress_diplomacy_via_humanregularized_reinforcement_learning_and_planning", "pdf": "/pdf/5355b9a9bc1eabd198a78654d7dbfa4e5f1664b0.pdf", "_bibtex": "@inproceedings{\nbakhtin2023mastering,\ntitle={Mastering the Game of No-Press Diplomacy via Human-Regularized Reinforcement Learning and Planning},\nauthor={Anton Bakhtin and David J Wu and Adam Lerer and Jonathan Gray and Athul Paul Jacob and Gabriele Farina and Alexander H Miller and Noam Brown},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=F61FwJTZhb}\n}", "venue": "ICLR 2023 notable top 5%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279294314, "odate": 1664468100000, "details": {"replyCount": 10}}, {"id": "G-uNfHKrj46", "original": "_ukqU-kJmRx", "number": 3557, "cdate": 1663850216501, "mdate": null, "ddate": null, "tcdate": 1663850216501, "tmdate": 1697935484436, "tddate": null, "forum": "G-uNfHKrj46", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Efficient Attention via Control Variates", "authorids": ["~Lin_Zheng1", "~Jianbo_Yuan1", "~Chong_Wang8", "~Lingpeng_Kong1"], "authors": ["Lin Zheng", "Jianbo Yuan", "Chong Wang", "Lingpeng Kong"], "keywords": ["attention mechanism", "transformers", "random features", "control variates", "importance sampling"], "abstract": "Random-feature-based attention (RFA) is an efficient approximation of softmax attention with linear runtime and space complexity. However, the approximation gap between RFA and conventional softmax attention is not well studied. Built upon previous progress of RFA, we characterize this gap through the lens of control variates and show that RFA can be decomposed into a sum of multiple control variate estimators for each element in the sequence. This new framework reveals that exact softmax attention can be recovered from RFA by manipulating each control variate. Besides, it allows us to develop a more flexible form of control variates, resulting in a novel attention mechanism that significantly reduces the approximation gap while maintaining linear complexity. Extensive experiments demonstrate that our model outperforms state-of-the-art efficient attention mechanisms on both vision and language tasks.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Deep Learning and representational learning", "paperhash": "zheng|efficient_attention_via_control_variates", "TL;DR": "We present a novel analysis of random feature attention based on control variates, which characterizes its gap to full softmax attention and induces a novel efficient variant that significantly improves the approximation while remaining efficient.", "pdf": "/pdf/2d280a38a1ccefd5c4718511ab9b2b2571c6bd05.pdf", "_bibtex": "@inproceedings{\nzheng2023efficient,\ntitle={Efficient Attention via Control Variates},\nauthor={Lin Zheng and Jianbo Yuan and Chong Wang and Lingpeng Kong},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=G-uNfHKrj46}\n}", "venue": "ICLR 2023 notable top 5%", "venueid": "ICLR.cc/2023/Conference", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 2 code implementations](https://www.catalyzex.com/paper/arxiv:2302.04542/code)"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279288299, "odate": 1664468100000, "details": {"replyCount": 14}}, {"id": "k4fevFqSQcX", "original": "9KyPWxGa78", "number": 3475, "cdate": 1663850206526, "mdate": null, "ddate": null, "tcdate": 1663850206526, "tmdate": 1677742633723, "tddate": null, "forum": "k4fevFqSQcX", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "SAM as an Optimal Relaxation of Bayes", "authorids": ["~Thomas_M\u00f6llenhoff1", "~Mohammad_Emtiyaz_Khan1"], "authors": ["Thomas M\u00f6llenhoff", "Mohammad Emtiyaz Khan"], "keywords": ["bayesian deep learning", "sharpness-aware minimization", "variational bayes", "convex duality"], "TL;DR": "We show that SAM can be seen as a relaxation of Bayes, by using Fenchel conjugates.", "abstract": "Sharpness-aware minimization (SAM) and related adversarial deep-learning methods can drastically improve generalization, but their underlying mechanisms are not yet fully understood. Here, we establish SAM as a relaxation of the Bayes objective where the expected negative-loss is replaced by the optimal convex lower bound, obtained by using the so-called Fenchel biconjugate. The connection enables a new Adam-like extension of SAM to automatically obtain reasonable uncertainty estimates, while sometimes also improving its accuracy. By connecting adversarial and Bayesian methods, our work opens a new path to robustness.  ", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Probabilistic Methods (eg, variational inference, causal inference, Gaussian processes)", "paperhash": "m\u00f6llenhoff|sam_as_an_optimal_relaxation_of_bayes", "pdf": "/pdf/9f7784562cd53ab7d908c93bc8ece8b40dcaa922.pdf", "_bibtex": "@inproceedings{\nm{\\\"o}llenhoff2023sam,\ntitle={{SAM} as an Optimal Relaxation of Bayes},\nauthor={Thomas M{\\\"o}llenhoff and Mohammad Emtiyaz Khan},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=k4fevFqSQcX}\n}", "venue": "ICLR 2023 notable top 5%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279284108, "odate": 1664468100000, "details": {"replyCount": 15}}, {"id": "q0nmYciuuZN", "original": "GF5lsK4oXzi", "number": 3472, "cdate": 1663850206166, "mdate": null, "ddate": null, "tcdate": 1663850206166, "tmdate": 1697935493310, "tddate": null, "forum": "q0nmYciuuZN", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Learning on Large-scale Text-attributed Graphs via Variational Inference", "authorids": ["~Jianan_Zhao2", "~Meng_Qu2", "~Chaozhuo_Li1", "~Hao_Yan6", "~Qian_Liu2", "~Rui_Li16", "~Xing_Xie3", "~Jian_Tang1"], "authors": ["Jianan Zhao", "Meng Qu", "Chaozhuo Li", "Hao Yan", "Qian Liu", "Rui Li", "Xing Xie", "Jian Tang"], "keywords": ["Language Model", "Graph Neural Network", "Node Classification"], "TL;DR": "We propose a GLEM framework to effectively fuse GNN and LM with scalability, SOTA results are achieved on OGB datasets.", "abstract": "This paper studies learning on text-attributed graphs (TAGs), where each node is associated with a text description. An ideal solution for such a problem would be integrating both the text and graph structure information with large language models and graph neural networks (GNNs). However, the problem becomes very challenging when graphs are large due to the high computational complexity brought by training large language models and  GNNs together. In this paper, we propose an efficient and effective solution to learning on large text-attributed graphs by fusing graph structure and language learning with a variational Expectation-Maximization (EM) framework, called GLEM. Instead of simultaneously training large language models and GNNs on big graphs, GLEM proposes to alternatively update the two modules in the E-step and M-step. Such a procedure allows training the two modules separately while simultaneously allowing the two modules to interact and mutually enhance each other. Extensive experiments on multiple data sets demonstrate the efficiency and effectiveness of the proposed approach.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Deep Learning and representational learning", "paperhash": "zhao|learning_on_largescale_textattributed_graphs_via_variational_inference", "pdf": "/pdf/d5933681412eb0329ac9f838744d30d98d4f8c3d.pdf", "_bibtex": "@inproceedings{\nzhao2023learning,\ntitle={Learning on Large-scale Text-attributed Graphs via Variational Inference},\nauthor={Jianan Zhao and Meng Qu and Chaozhuo Li and Hao Yan and Qian Liu and Rui Li and Xing Xie and Jian Tang},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=q0nmYciuuZN}\n}", "supplementary_material": "/attachment/4a4210feac742a33ed6c57859e3a8b8ef161046c.zip", "venue": "ICLR 2023 notable top 5%", "venueid": "ICLR.cc/2023/Conference", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2210.14709/code)"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279283491, "odate": 1664468100000, "details": {"replyCount": 9}}, {"id": "SJ0Lde3tRL", "original": "KTIjgPgtjvB", "number": 3449, "cdate": 1663850203664, "mdate": null, "ddate": null, "tcdate": 1663850203664, "tmdate": 1697935495712, "tddate": null, "forum": "SJ0Lde3tRL", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Extreme Q-Learning: MaxEnt RL without Entropy", "authorids": ["~Divyansh_Garg1", "~Joey_Hejna1", "~Matthieu_Geist1", "~Stefano_Ermon1"], "authors": ["Divyansh Garg", "Joey Hejna", "Matthieu Geist", "Stefano Ermon"], "keywords": ["reinforcement learning", "offline reinforcement learning", "statistical learning", "extreme value analysis", "maximum entropy rl", "gumbel"], "TL;DR": "Introduce a novel framework for Q-learning that models the maximal soft-values without needing to sample from a policy and reaches SOTA performance on online and offline RL settings.", "abstract": "Modern Deep Reinforcement Learning (RL) algorithms require estimates of the maximal Q-value, which are difficult to compute in continuous domains with an infinite number of possible actions. In this work, we introduce a new update rule for online and offline RL which directly models the maximal value using Extreme Value Theory (EVT), drawing inspiration from economics. By doing so, we avoid computing Q-values using out-of-distribution actions which is often a substantial source of error. Our key insight is to introduce an objective that directly estimates the optimal soft-value functions (LogSumExp) in the maximum entropy RL setting without needing to sample from a policy. Using EVT, we derive our \\emph{Extreme Q-Learning} framework and consequently online and, for the first time, offline MaxEnt Q-learning algorithms, that do not explicitly require access to a policy or its entropy. Our method obtains consistently strong performance in the D4RL benchmark, outperforming prior works by \\emph{10+ points} on the challenging Franka Kitchen tasks while offering moderate improvements over SAC and TD3 on online DM Control tasks. Visualizations and code can be found on our website.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)", "paperhash": "garg|extreme_qlearning_maxent_rl_without_entropy", "pdf": "/pdf/fe4a8907cc4cf7607754d21d04e1da5914902db2.pdf", "supplementary_material": "/attachment/bc9aeca039fdf42a9f7c0788b657e41130fab7f9.zip", "_bibtex": "@inproceedings{\ngarg2023extreme,\ntitle={Extreme Q-Learning: MaxEnt {RL} without Entropy},\nauthor={Divyansh Garg and Joey Hejna and Matthieu Geist and Stefano Ermon},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=SJ0Lde3tRL}\n}", "venue": "ICLR 2023 notable top 5%", "venueid": "ICLR.cc/2023/Conference", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 3 code implementations](https://www.catalyzex.com/paper/arxiv:2301.02328/code)"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279282465, "odate": 1664468100000, "details": {"replyCount": 20}}, {"id": "mjzm6btqgV", "original": "csztRYz0EE", "number": 3334, "cdate": 1663850190275, "mdate": null, "ddate": null, "tcdate": 1663850190275, "tmdate": 1677725620501, "tddate": null, "forum": "mjzm6btqgV", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Efficiently Computing Nash Equilibria in Adversarial Team Markov Games", "authorids": ["~Fivos_Kalogiannis1", "~Ioannis_Anagnostides1", "~Ioannis_Panageas1", "~Emmanouil-Vasileios_Vlatakis-Gkaragkounis1", "~Vaggos_Chatziafratis1", "~Stelios_Andrew_Stavroulakis1"], "authors": ["Fivos Kalogiannis", "Ioannis Anagnostides", "Ioannis Panageas", "Emmanouil-Vasileios Vlatakis-Gkaragkounis", "Vaggos Chatziafratis", "Stelios Andrew Stavroulakis"], "keywords": ["multiagent-reinforcement-learning.marl", "rl", "reinforcement-learning", "learning-in-games", "optimization", "game-theory", "policy-gradient"], "TL;DR": "Nash equlibrium can be computed effieciently in Markov games where a single player competes against multiple agents who share a common interest.", "abstract": "    Computing Nash equilibrium policies is a central problem in multi-agent reinforcement learning that has received extensive attention both in theory and in practice. However, in light of computational intractability barriers in general-sum games, provable guarantees have been thus far either limited to fully competitive or cooperative scenarios or impose strong assumptions that are difficult to meet in most practical applications.\n    \n    In this work, we depart from those prior results by investigating infinite-horizon \\emph{adversarial team Markov games}, a natural and well-motivated class of games in which a team of identically-interested players---in the absence of any explicit coordination or communication---is competing against an adversarial player. This setting allows for a unifying treatment of zero-sum Markov games and Markov potential games, and serves as a step to model more realistic strategic interactions that feature both competing and cooperative interests. Our main contribution is the first algorithm for computing stationary $\\epsilon$-approximate Nash equilibria in adversarial team Markov games with computational complexity that is polynomial in all the natural parameters of the game, as well as $1/\\epsilon$.\n    \n    The proposed algorithm is based on performing independent policy gradient steps for each player in the team, in tandem with best responses from the side of the adversary; in turn, the policy for the adversary is then obtained by solving a carefully constructed linear program. Our analysis leverages non-standard techniques to establish the KKT optimality conditions for a nonlinear program with nonconvex constraints, thereby leading to a natural interpretation of the induced Lagrange multipliers.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Theory (eg, control theory, learning theory, algorithmic game theory)", "paperhash": "kalogiannis|efficiently_computing_nash_equilibria_in_adversarial_team_markov_games", "pdf": "/pdf/3e531dec92de6b02fcbeef7a63d114423e73b571.pdf", "_bibtex": "@inproceedings{\nkalogiannis2023efficiently,\ntitle={Efficiently Computing Nash Equilibria in Adversarial Team Markov Games},\nauthor={Fivos Kalogiannis and Ioannis Anagnostides and Ioannis Panageas and Emmanouil-Vasileios Vlatakis-Gkaragkounis and Vaggos Chatziafratis and Stelios Andrew Stavroulakis},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=mjzm6btqgV}\n}", "venue": "ICLR 2023 notable top 5%", "venueid": "ICLR.cc/2023/Conference", "supplementary_material": "/attachment/4ec25fe664316def6c09adb264d66d1a621f4c3e.zip"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279275385, "odate": 1664468100000, "details": {"replyCount": 14}}, {"id": "Ai8Hw3AXqks", "original": "NvTHkFjJkI", "number": 3320, "cdate": 1663850188621, "mdate": null, "ddate": null, "tcdate": 1663850188621, "tmdate": 1697935511679, "tddate": null, "forum": "Ai8Hw3AXqks", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Simplified State Space Layers for Sequence Modeling", "authorids": ["~Jimmy_T.H._Smith1", "~Andrew_Warrington2", "~Scott_Linderman1"], "authors": ["Jimmy T.H. Smith", "Andrew Warrington", "Scott Linderman"], "keywords": ["sequence models", "state space", "S4", "RNN", "transformers", "long range arena"], "TL;DR": "We introduce a new state space sequence modeling layer, building on the recent S4 layer, that increases the state of the art on many long-range benchmark tasks.", "abstract": "Models using structured state space sequence (S4) layers have achieved state-of-the-art performance on long-range sequence modeling tasks. An S4 layer combines linear state space models (SSMs), the HiPPO framework, and deep learning to achieve high performance. We build on the design of the S4 layer and introduce a new state space layer, the S5 layer.  Whereas an S4 layer uses many independent single-input, single-output SSMs, the S5 layer uses one multi-input, multi-output SSM.  We establish a connection between S5 and S4, and use this to develop the initialization and parameterization used by the S5 model.  The result is a state space layer that can leverage efficient and widely implemented parallel scans, allowing S5 to match the computational efficiency of S4, while also achieving state-of-the-art performance on several long-range sequence modeling tasks.  S5 averages $87.4\\%$ on the long range arena benchmark, and $98.5\\%$ on the most difficult Path-X task.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Deep Learning and representational learning", "paperhash": "smith|simplified_state_space_layers_for_sequence_modeling", "pdf": "/pdf/57b1a9f476230b4a6e75b745f2c8fe47c5fa8c5a.pdf", "_bibtex": "@inproceedings{\nsmith2023simplified,\ntitle={Simplified State Space Layers for Sequence Modeling},\nauthor={Jimmy T.H. Smith and Andrew Warrington and Scott Linderman},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=Ai8Hw3AXqks}\n}", "supplementary_material": "", "venue": "ICLR 2023 notable top 5%", "venueid": "ICLR.cc/2023/Conference", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2208.04933/code)"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279274408, "odate": 1664468100000, "details": {"replyCount": 12}}, {"id": "vmjctNUSWI", "original": "Nod9yR9UUw4", "number": 3284, "cdate": 1663850184317, "mdate": null, "ddate": null, "tcdate": 1663850184317, "tmdate": 1677795296957, "tddate": null, "forum": "vmjctNUSWI", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Moving Forward by Moving Backward: Embedding Action Impact over Action Semantics", "authorids": ["~Kuo-Hao_Zeng3", "~Luca_Weihs1", "~Roozbeh_Mottaghi1", "~Ali_Farhadi3"], "authors": ["Kuo-Hao Zeng", "Luca Weihs", "Roozbeh Mottaghi", "Ali Farhadi"], "keywords": ["Embodied AI", "Adaptation", "Visual Navigation"], "abstract": "A common assumption when training embodied agents is that the impact of taking an action is stable; for instance, executing the ``move ahead'' action will always move the agent forward by a fixed distance, perhaps with some small amount of actuator-induced noise. This assumption is limiting; an agent may encounter settings that dramatically alter the impact of actions: a move ahead action on a wet floor may send the agent twice as far as it expects and using the same action with a broken wheel might transform the expected translation into a rotation. Instead of relying that the impact of an action stably reflects its pre-defined semantic meaning, we propose to model the impact of actions on-the-fly using latent embeddings. By combining these latent action embeddings with a novel, transformer-based, policy head, we design an Action Adaptive Policy (AAP). We evaluate our AAP on two challenging visual navigation tasks in the AI2-THOR and Habitat environments and show that our AAP is highly performant even when faced, at inference-time, with missing actions and, previously unseen, perturbed action spaces. Moreover, we observe significant improvement in robustness against these actions when evaluating in real-world scenarios.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)", "paperhash": "zeng|moving_forward_by_moving_backward_embedding_action_impact_over_action_semantics", "pdf": "/pdf/5fd307801a722f24990855f8235ae461cabf66fa.pdf", "_bibtex": "@inproceedings{\nzeng2023moving,\ntitle={Moving Forward by Moving Backward: Embedding Action Impact over Action Semantics},\nauthor={Kuo-Hao Zeng and Luca Weihs and Roozbeh Mottaghi and Ali Farhadi},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=vmjctNUSWI}\n}", "venue": "ICLR 2023 notable top 5%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279272116, "odate": 1664468100000, "details": {"replyCount": 16}}, {"id": "EKpMeEV0hOo", "original": "dmRkuRFFzo_", "number": 3273, "cdate": 1663850183021, "mdate": null, "ddate": null, "tcdate": 1663850183021, "tmdate": 1697935517133, "tddate": null, "forum": "EKpMeEV0hOo", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "SimPer: Simple Self-Supervised Learning of Periodic Targets", "authorids": ["~Yuzhe_Yang1", "~Xin_Liu8", "wujiang@google.com", "sborac@google.com", "~Dina_Katabi1", "~Ming-Zher_Poh2", "~Daniel_McDuff1"], "authors": ["Yuzhe Yang", "Xin Liu", "Jiang Wu", "Silviu Borac", "Dina Katabi", "Ming-Zher Poh", "Daniel McDuff"], "keywords": ["Periodic learning", "Self-supervised learning", "Representation learning", "Periodic targets", "Periodicity"], "TL;DR": "A simple contrastive self-supervised framework for learning periodic targets and tasks.", "abstract": "From human physiology to environmental evolution, important processes in nature often exhibit meaningful and strong periodic or quasi-periodic changes. Due to their inherent label scarcity, learning useful representations for periodic tasks with limited or no supervision is of great benefit. Yet, existing self-supervised learning (SSL) methods overlook the intrinsic periodicity in data, and fail to learn representations that capture periodic or frequency attributes. In this paper, we present SimPer, a simple contrastive SSL regime for learning periodic information in data. To exploit the periodic inductive bias, SimPer introduces customized augmentations, feature similarity measures, and a generalized contrastive loss for learning efficient and robust periodic representations. Extensive experiments on common real-world tasks in human behavior analysis, environmental sensing, and healthcare domains verify the superior performance of SimPer compared to state-of-the-art SSL methods, highlighting its intriguing properties including better data efficiency, robustness to spurious correlations, and generalization to distribution shifts.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Unsupervised and Self-supervised learning", "paperhash": "yang|simper_simple_selfsupervised_learning_of_periodic_targets", "pdf": "/pdf/efc783fea3d58e0bcea5f077e7756fc620f0d6c2.pdf", "_bibtex": "@inproceedings{\nyang2023simper,\ntitle={SimPer: Simple Self-Supervised Learning of Periodic Targets},\nauthor={Yuzhe Yang and Xin Liu and Jiang Wu and Silviu Borac and Dina Katabi and Ming-Zher Poh and Daniel McDuff},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=EKpMeEV0hOo}\n}", "venue": "ICLR 2023 notable top 5%", "venueid": "ICLR.cc/2023/Conference", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2210.03115/code)"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279271704, "odate": 1664468100000, "details": {"replyCount": 27}}, {"id": "mWVoBz4W0u", "original": "6NFbc3Q_Ic", "number": 3201, "cdate": 1663850174653, "mdate": null, "ddate": null, "tcdate": 1663850174653, "tmdate": 1697935525911, "tddate": null, "forum": "mWVoBz4W0u", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "PaLI: A Jointly-Scaled Multilingual Language-Image Model", "authorids": ["~Xi_Chen23", "~Xiao_Wang5", "~Soravit_Changpinyo1", "~AJ_Piergiovanni1", "prazek@google.com", "danielsalz@google.com", "~Sebastian_Goodman1", "~Adam_Grycner2", "~Basil_Mustafa1", "~Lucas_Beyer1", "~Alexander_Kolesnikov2", "~Joan_Puigcerver1", "~Nan_Ding3", "keranrong@google.com", "~Hassan_Akbari1", "mishragaurav@google.com", "~Linting_Xue1", "~Ashish_V_Thapliyal1", "~James_Bradbury1", "~Weicheng_Kuo1", "~Mojtaba_Seyedhosseini2", "chaojia@google.com", "~Burcu_Karagol_Ayan1", "~Carlos_Riquelme_Ruiz1", "~Andreas_Peter_Steiner1", "~Anelia_Angelova1", "~Xiaohua_Zhai2", "~Neil_Houlsby1", "~Radu_Soricut2"], "authors": ["Xi Chen", "Xiao Wang", "Soravit Changpinyo", "AJ Piergiovanni", "Piotr Padlewski", "Daniel Salz", "Sebastian Goodman", "Adam Grycner", "Basil Mustafa", "Lucas Beyer", "Alexander Kolesnikov", "Joan Puigcerver", "Nan Ding", "Keran Rong", "Hassan Akbari", "Gaurav Mishra", "Linting Xue", "Ashish V Thapliyal", "James Bradbury", "Weicheng Kuo", "Mojtaba Seyedhosseini", "Chao Jia", "Burcu Karagol Ayan", "Carlos Riquelme Ruiz", "Andreas Peter Steiner", "Anelia Angelova", "Xiaohua Zhai", "Neil Houlsby", "Radu Soricut"], "keywords": [], "abstract": "Effective scaling and a flexible task interface enable large language models to excel at many tasks. We present PaLI, a model that extends this approach to the joint modeling of language and vision. PaLI generates text based on visual and textual inputs, and with this interface performs many vision, language, and multimodal tasks, in many languages. To train PaLI, we make use of large pretrained encoder-decoder language models and Vision Transformers (ViTs). This allows us to capitalize on their existing capabilities and leverage the substantial cost of training them. We find that joint scaling of the vision and language components is important. Since existing Transformers for language are much larger than their vision counterparts, we train a large, 4-billion parameter ViT (ViT-e) to quantify the benefits from even larger-capacity vision models. To train PaLI, we create a large multilingual mix of pretraining tasks, based on a new image-text training set containing 10B images and texts in over 100 languages. PaLI achieves state-of-the-art in multiple vision and language tasks (such as captioning, visual question-answering, scene-text understanding), while retaining a simple, modular, and scalable design.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Deep Learning and representational learning", "paperhash": "chen|pali_a_jointlyscaled_multilingual_languageimage_model", "pdf": "/pdf/1870a0455d0e7a6ed7d8f02e8e156cf63f5d6b6a.pdf", "_bibtex": "@inproceedings{\nchen2023pali,\ntitle={Pa{LI}: A Jointly-Scaled Multilingual Language-Image Model},\nauthor={Xi Chen and Xiao Wang and Soravit Changpinyo and AJ Piergiovanni and Piotr Padlewski and Daniel Salz and Sebastian Goodman and Adam Grycner and Basil Mustafa and Lucas Beyer and Alexander Kolesnikov and Joan Puigcerver and Nan Ding and Keran Rong and Hassan Akbari and Gaurav Mishra and Linting Xue and Ashish V Thapliyal and James Bradbury and Weicheng Kuo and Mojtaba Seyedhosseini and Chao Jia and Burcu Karagol Ayan and Carlos Riquelme Ruiz and Andreas Peter Steiner and Anelia Angelova and Xiaohua Zhai and Neil Houlsby and Radu Soricut},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=mWVoBz4W0u}\n}", "venue": "ICLR 2023 notable top 5%", "venueid": "ICLR.cc/2023/Conference", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2209.06794/code)"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279267028, "odate": 1664468100000, "details": {"replyCount": 13}}, {"id": "OpC-9aBBVJe", "original": "0s7rXLC4aCv", "number": 3149, "cdate": 1663850168440, "mdate": null, "ddate": null, "tcdate": 1663850168440, "tmdate": 1676330886703, "tddate": null, "forum": "OpC-9aBBVJe", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Sample-Efficient Reinforcement Learning by Breaking the Replay Ratio Barrier", "authorids": ["~Pierluca_D'Oro1", "~Max_Schwarzer1", "~Evgenii_Nikishin1", "~Pierre-Luc_Bacon1", "~Marc_G_Bellemare1", "~Aaron_Courville3"], "authors": ["Pierluca D'Oro", "Max Schwarzer", "Evgenii Nikishin", "Pierre-Luc Bacon", "Marc G Bellemare", "Aaron Courville"], "keywords": ["reinforcement learning", "sample efficiency", "resets"], "TL;DR": "The combination of a large number of updates and resets drastically improves the sample efficiency of deep RL algorithms.", "abstract": "Increasing the replay ratio, the number of updates of an agent's parameters per environment interaction, is an appealing strategy for improving the sample efficiency of deep reinforcement learning algorithms. In this work, we show that fully or partially resetting the parameters of deep reinforcement learning agents causes better replay ratio scaling capabilities to emerge. We push the limits of the sample efficiency of carefully-modified algorithms by training them using an order of magnitude more updates than usual, significantly improving their performance in the Atari 100k and DeepMind Control Suite benchmarks. We then provide an analysis of the design choices required for favorable replay ratio scaling to be possible and discuss inherent limits and tradeoffs.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)", "paperhash": "doro|sampleefficient_reinforcement_learning_by_breaking_the_replay_ratio_barrier", "pdf": "/pdf/c891095f8e46b891138ef064f19d6b0e2d84dcb2.pdf", "_bibtex": "@inproceedings{\nd'oro2023sampleefficient,\ntitle={Sample-Efficient Reinforcement Learning by Breaking the Replay Ratio Barrier},\nauthor={Pierluca D'Oro and Max Schwarzer and Evgenii Nikishin and Pierre-Luc Bacon and Marc G Bellemare and Aaron Courville},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=OpC-9aBBVJe}\n}", "venue": "ICLR 2023 notable top 5%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279263191, "odate": 1664468100000, "details": {"replyCount": 14}}, {"id": "Wc5bmZZU9cy", "original": "suYyWiDcs8L", "number": 3121, "cdate": 1663850165066, "mdate": null, "ddate": null, "tcdate": 1663850165066, "tmdate": 1676606365006, "tddate": null, "forum": "Wc5bmZZU9cy", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Dr.Spider: A Diagnostic Evaluation Benchmark towards Text-to-SQL Robustness", "authorids": ["~Shuaichen_Chang1", "~Jun_Wang32", "~Mingwen_Dong1", "~Lin_Pan1", "~Henghui_Zhu1", "~Alexander_Hanbo_Li1", "~Wuwei_Lan1", "~Sheng_Zhang8", "~Jiarong_Jiang1", "~Joseph_Lilien1", "~Steve_Ash1", "~William_Yang_Wang2", "~Zhiguo_Wang4", "~Vittorio_Castelli1", "~Patrick_Ng1", "~Bing_Xiang2"], "authors": ["Shuaichen Chang", "Jun Wang", "Mingwen Dong", "Lin Pan", "Henghui Zhu", "Alexander Hanbo Li", "Wuwei Lan", "Sheng Zhang", "Jiarong Jiang", "Joseph Lilien", "Steve Ash", "William Yang Wang", "Zhiguo Wang", "Vittorio Castelli", "Patrick Ng", "Bing Xiang"], "keywords": [], "abstract": "Neural text-to-SQL models have achieved remarkable performance in translating natural language questions into SQL queries. However, recent studies reveal that text-to-SQL models are vulnerable to task-specific perturbations. Previous curated robustness test sets usually focus on individual phenomena. In this paper, we propose a comprehensive robustness benchmark based on Spider, a cross-domain text-to-SQL benchmark, to diagnose the model robustness. We design 17 perturbations on databases, natural language questions, and SQL queries to measure the robustness from different angles. In order to collect more diversified natural question perturbations, we utilize large pretrained language models (PLMs) to simulate human behaviors in creating natural questions. We conduct a diagnostic study of the state-of-the-art models on the robustness set. Experimental results reveal that even the most robust model suffers from a 14.0% performance drop overall and a 50.7% performance drop on the most challenging perturbation. We also present a breakdown analysis regarding text-to-SQL model designs and provide insights for improving model robustness.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Applications (eg, speech processing, computer vision, NLP)", "paperhash": "chang|drspider_a_diagnostic_evaluation_benchmark_towards_texttosql_robustness", "pdf": "/pdf/28dd8eb27d485f652c4874af1d995452557ae2b3.pdf", "_bibtex": "@inproceedings{\nchang2023drspider,\ntitle={Dr.Spider: A Diagnostic Evaluation Benchmark towards Text-to-{SQL} Robustness},\nauthor={Shuaichen Chang and Jun Wang and Mingwen Dong and Lin Pan and Henghui Zhu and Alexander Hanbo Li and Wuwei Lan and Sheng Zhang and Jiarong Jiang and Joseph Lilien and Steve Ash and William Yang Wang and Zhiguo Wang and Vittorio Castelli and Patrick Ng and Bing Xiang},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=Wc5bmZZU9cy}\n}", "venue": "ICLR 2023 notable top 5%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279261384, "odate": 1664468100000, "details": {"replyCount": 10}}, {"id": "sWOsRj4nT1n", "original": "H_UNgvz0Yk8", "number": 3056, "cdate": 1663850157158, "mdate": null, "ddate": null, "tcdate": 1663850157158, "tmdate": 1677505573592, "tddate": null, "forum": "sWOsRj4nT1n", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Temporal Domain Generalization with Drift-Aware Dynamic Neural Networks", "authorids": ["~Guangji_Bai1", "~Chen_Ling3", "~Liang_Zhao6"], "authors": ["Guangji Bai", "Chen Ling", "Liang Zhao"], "keywords": ["Domain Generalization", "Sequential Learning Model", "Dynamic Neural Network"], "TL;DR": "A novel framework is proposed to dynamically model how neural networks evolve across domains for characterizing the distribution drift across time in temporal domain generalization.", "abstract": "Temporal domain generalization is a promising yet extremely challenging area where the goal is to learn models under temporally changing data distributions and generalize to unseen data distributions following the trends of the change. The advancement of this area is challenged by: 1) characterizing data distribution drift and its impacts on models, 2) expressiveness in tracking the model dynamics, and 3) theoretical guarantee on the performance. To address them, we propose a Temporal Domain Generalization with Drift-Aware Dynamic Neural Network (DRAIN) framework. Specifically, we formulate the problem into a Bayesian framework that jointly models the relation between data and model dynamics. We then build a recurrent graph generation scenario to characterize the dynamic graph-structured neural networks learned across different time points. It captures the temporal drift of model parameters and data distributions and can predict models in the future without the presence of future data. In addition, we explore theoretical guarantees of the model performance under the challenging temporal DG setting and provide theoretical analysis, including uncertainty and generalization error. Finally, extensive experiments on several real-world benchmarks with temporal drift demonstrate the proposed method\u2019s effectiveness and efficiency.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "General Machine Learning (ie none of the above)", "paperhash": "bai|temporal_domain_generalization_with_driftaware_dynamic_neural_networks", "pdf": "/pdf/5951cadc6186425d767a2acdd1f92bd01ab49268.pdf", "supplementary_material": "/attachment/5898b46df2b25f0ad557a551d8690e5a5b2f090c.zip", "_bibtex": "@inproceedings{\nbai2023temporal,\ntitle={Temporal Domain Generalization with Drift-Aware Dynamic Neural Networks},\nauthor={Guangji Bai and Chen Ling and Liang Zhao},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=sWOsRj4nT1n}\n}", "venue": "ICLR 2023 notable top 5%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279257410, "odate": 1664468100000, "details": {"replyCount": 12}}, {"id": "SMa9EAovKMC", "original": "YunfoG5lyy", "number": 2890, "cdate": 1663850137730, "mdate": null, "ddate": null, "tcdate": 1663850137730, "tmdate": 1676906816604, "tddate": null, "forum": "SMa9EAovKMC", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Draft, Sketch, and Prove: Guiding Formal Theorem Provers with Informal Proofs", "authorids": ["~Albert_Qiaochu_Jiang1", "~Sean_Welleck1", "~Jin_Peng_Zhou1", "~Timothee_Lacroix1", "~Jiacheng_Liu2", "~Wenda_Li1", "~Mateja_Jamnik1", "~Guillaume_Lample1", "~Yuhuai_Wu1"], "authors": ["Albert Qiaochu Jiang", "Sean Welleck", "Jin Peng Zhou", "Timothee Lacroix", "Jiacheng Liu", "Wenda Li", "Mateja Jamnik", "Guillaume Lample", "Yuhuai Wu"], "keywords": [], "abstract": "The formalization of existing mathematical proofs is a notoriously difficult process. Despite decades of research on automation and proof assistants, writing formal proofs remains arduous and only accessible to a few experts. While previous studies to automate formalization focused on powerful search algorithms, no attempts were made to take advantage of available informal proofs. In this work, we introduce Draft, Sketch, and Prove (DSP), a method that maps informal proofs to formal proof sketches, and uses the sketches to guide an automated prover by directing its search to easier sub-problems. We investigate two relevant setups where informal proofs are either written by humans or generated by a language model. Our experiments and ablation studies show that large language models are able to produce well-structured formal sketches that follow the same reasoning steps as the informal proofs. Guiding an automated prover with these sketches enhances its performance from $20.9\\%$ to $39.3\\%$ on a collection of mathematical competition problems.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )", "paperhash": "jiang|draft_sketch_and_prove_guiding_formal_theorem_provers_with_informal_proofs", "pdf": "/pdf/cfd03f19d20263d9c1d1cc026a2b3528392fc857.pdf", "supplementary_material": "/attachment/8c607c5975302ad8ab559737ea1172dc947f1f66.zip", "_bibtex": "@inproceedings{\njiang2023draft,\ntitle={Draft, Sketch, and Prove: Guiding Formal Theorem Provers with Informal Proofs},\nauthor={Albert Qiaochu Jiang and Sean Welleck and Jin Peng Zhou and Timothee Lacroix and Jiacheng Liu and Wenda Li and Mateja Jamnik and Guillaume Lample and Yuhuai Wu},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=SMa9EAovKMC}\n}", "venue": "ICLR 2023 notable top 5%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279247209, "odate": 1664468100000, "details": {"replyCount": 18}}, {"id": "uVcDssQff_", "original": "GF8_tWBQpAO", "number": 2880, "cdate": 1663850136541, "mdate": null, "ddate": null, "tcdate": 1663850136541, "tmdate": 1677873484963, "tddate": null, "forum": "uVcDssQff_", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "REVISITING PRUNING AT INITIALIZATION THROUGH THE LENS OF RAMANUJAN GRAPH", "authorids": ["~Duc_N.M_Hoang1", "~Shiwei_Liu2", "~Radu_Marculescu2", "~Zhangyang_Wang1"], "authors": ["Duc N.M Hoang", "Shiwei Liu", "Radu Marculescu", "Zhangyang Wang"], "keywords": ["pruning at initialization", "graph theory", "Ramanujan Graph", "sparse neural networks"], "abstract": "Pruning neural networks at initialization (PaI) has received an upsurge of interest due to its end-to-end saving potential. PaI is able to find sparse subnetworks at initialization that can achieve comparable performance to the full networks. These methods can surpass the trivial baseline of random pruning but suffer from a significant performance gap compared to post-training pruning. Previous approaches firmly rely on weights, gradients, and sanity checks as primary signals when conducting PaI analysis. To better understand the underlying mechanism of PaI, we propose to interpret it through the lens of the Ramanujan Graph - a class of expander graphs that are sparse while being highly connected. It is often believed there should be a strong correlation between the Ramanujan graph and PaI since both are about finding sparse and well-connected neural networks. However, the finer-grained link relating highly sparse and connected networks to their relative performance (i.e., ranking of difference sparse structures at the same specific global sparsity) is still missing. We observe that not only the Ramanujan property for sparse networks shows no significant relationship to PaI\u2019s relative performance, but maximizing it can also lead to the formation of pseudo-random graphs with no structural meanings. We reveal the underlying cause to be Ramanujan Graph\u2019s strong assumption on the upper bound of the largest nontrivial eigenvalue (\u00b5\u02c6) of layers belonging to highly sparse networks. We hence propose Iterative Mean Difference of Bound (IMDB) as a mean to relax the \u00b5\u02c6 upper bound. Likewise, we also show there exists a lower bound for \u00b5\u02c6, which we call the Normalized Random Coefficient (NaRC), that gives us an accurate assessment for when sparse but highly connected structure degenerates into naive randomness. Finally, we systematically analyze the behavior of various PaI methods and demonstrate the utility of our proposed metrics in characterizing PaI performance. We show that subnetworks preserving better the IMDB property correlate higher in performance, while NaRC provides us with a possible mean to locate the region where highly connected, highly sparse, and non-trivial Ramanujan expanders exist. Our code is available at: https://github.com/VITA-Group/ramanujan-on-pai.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Deep Learning and representational learning", "paperhash": "hoang|revisiting_pruning_at_initialization_through_the_lens_of_ramanujan_graph", "pdf": "/pdf/f73064906e38441e21dd0a622065469ef3f5b5bd.pdf", "_bibtex": "@inproceedings{\nhoang2023revisiting,\ntitle={{REVISITING} {PRUNING} {AT} {INITIALIZATION} {THROUGH} {THE} {LENS} {OF} {RAMANUJAN} {GRAPH}},\nauthor={Duc N.M Hoang and Shiwei Liu and Radu Marculescu and Zhangyang Wang},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=uVcDssQff_}\n}", "venue": "ICLR 2023 notable top 5%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279246508, "odate": 1664468100000, "details": {"replyCount": 9}}, {"id": "5N0wtJZ89r9", "original": "C2hINFHENut", "number": 2771, "cdate": 1663850123640, "mdate": null, "ddate": null, "tcdate": 1663850123640, "tmdate": 1697935581751, "tddate": null, "forum": "5N0wtJZ89r9", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Embedding Fourier for Ultra-High-Definition Low-Light Image Enhancement", "authorids": ["~Chongyi_Li1", "~Chun-Le_Guo1", "~man_zhou1", "~Zhexin_Liang1", "~Shangchen_Zhou1", "~Ruicheng_Feng1", "~Chen_Change_Loy2"], "authors": ["Chongyi Li", "Chun-Le Guo", "man zhou", "Zhexin Liang", "Shangchen Zhou", "Ruicheng Feng", "Chen Change Loy"], "keywords": ["low-light image enhancement", "high-resolution image processing", "Fourier transform", "benchmark"], "TL;DR": "In this paper,  we propose a new solution for UHD LLIE based on the characteristics of the Fourier domain.  We also propose the first real UHD LLIE dataset with diverse data.", "abstract": "Ultra-High-Definition (UHD) photo has gradually become the standard configuration in advanced imaging devices. The new standard unveils many issues in existing approaches for low-light image enhancement (LLIE), especially in dealing with the intricate issue of joint luminance enhancement and noise removal while remaining efficient. Unlike existing methods that address the problem in the spatial domain, we propose a new solution, UHDFour, that embeds Fourier transform into a cascaded network. Our approach is motivated by a few unique characteristics in the Fourier domain:  1) most luminance information concentrates on amplitudes while noise is closely related to phases, and 2) a high-resolution image and its low-resolution version share similar amplitude patterns. Through embedding Fourier into our network, the amplitude and phase of a low-light image are separately processed to avoid amplifying noise when enhancing luminance. Besides, UHDFour is scalable to UHD images by implementing amplitude and phase enhancement under the low-resolution regime and then adjusting the high-resolution scale with few computations. We also contribute the first real UHD LLIE dataset, UHD-LL, that contains 2,150 low-noise/normal-clear 4K image pairs with diverse darkness and noise levels captured in different scenarios. With this dataset, we systematically analyze the performance of existing LLIE methods for processing UHD images and demonstrate the advantage of our solution. We believe our new framework, coupled with the dataset, would push the frontier of LLIE towards UHD. The code and dataset are available at https://li-chongyi.github.io/UHDFour/.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Applications (eg, speech processing, computer vision, NLP)", "paperhash": "li|embedding_fourier_for_ultrahighdefinition_lowlight_image_enhancement", "pdf": "/pdf/4e2ab7acffc377a1981d0ed5d1e4310328115c82.pdf", "_bibtex": "@inproceedings{\nli2023embedding,\ntitle={Embedding Fourier for Ultra-High-Definition Low-Light Image Enhancement},\nauthor={Chongyi Li and Chun-Le Guo and man zhou and Zhexin Liang and Shangchen Zhou and Ruicheng Feng and Chen Change Loy},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=5N0wtJZ89r9}\n}", "venue": "ICLR 2023 notable top 5%", "venueid": "ICLR.cc/2023/Conference", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 2 code implementations](https://www.catalyzex.com/paper/arxiv:2302.11831/code)"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279240494, "odate": 1664468100000, "details": {"replyCount": 13}}, {"id": "YnkGMIh0gvX", "original": "zuAdXAsXg1G", "number": 2762, "cdate": 1663850122489, "mdate": null, "ddate": null, "tcdate": 1663850122489, "tmdate": 1697935583339, "tddate": null, "forum": "YnkGMIh0gvX", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "A Call to Reflect on Evaluation Practices for Failure Detection in Image Classification", "authorids": ["~Paul_F_Jaeger1", "~Carsten_Tim_L\u00fcth1", "~Lukas_Klein1", "~Till_J._Bungert1"], "authors": ["Paul F Jaeger", "Carsten Tim L\u00fcth", "Lukas Klein", "Till J. Bungert"], "keywords": ["failure detection", "out-of-distribution detection", "predictive uncertainty quantification", "selective classification", "robustness", "method evaluation"], "TL;DR": "We present a holistic perspective on the task of failure detection including a large-scale empirical study for the first time enabling benchmarking confidence scoring functions w.r.t all relevant methods and distribution shifts. ", "abstract": "Reliable application of machine learning-based decision systems in the wild is one of the major challenges currently investigated by the field. A large portion of established approaches aims to detect erroneous predictions by means of assigning confidence scores. This confidence may be obtained by either quantifying the model's predictive uncertainty, learning explicit scoring functions, or assessing whether the input is in line with the training distribution. Curiously, while these approaches all state to address the same eventual goal of detecting failures of a classifier upon real-world application, they currently constitute largely separated research fields with individual evaluation protocols, which either exclude a substantial part of relevant methods or ignore large parts of relevant failure sources. In this work, we systematically reveal current pitfalls caused by these inconsistencies and derive requirements for a holistic and realistic evaluation of failure detection. To demonstrate the relevance of this unified perspective, we present a large-scale empirical study for the first time enabling benchmarking confidence scoring functions w.r.t all relevant methods and failure sources. The revelation of a simple softmax response baseline as the overall best performing method underlines the drastic shortcomings of current evaluation in the plethora of publicized research on confidence scoring. Code and trained models are at https://github.com/https://github.com/IML-DKFZ/fd-shifts", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Applications (eg, speech processing, computer vision, NLP)", "paperhash": "jaeger|a_call_to_reflect_on_evaluation_practices_for_failure_detection_in_image_classification", "pdf": "/pdf/a5de8999d6fc1e463fee479f14b17ae999f6cbc2.pdf", "_bibtex": "@inproceedings{\njaeger2023a,\ntitle={A Call to Reflect on Evaluation Practices for Failure Detection in Image Classification},\nauthor={Paul F Jaeger and Carsten Tim L{\\\"u}th and Lukas Klein and Till J. Bungert},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=YnkGMIh0gvX}\n}", "venue": "ICLR 2023 notable top 5%", "venueid": "ICLR.cc/2023/Conference", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2211.15259/code)"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279239836, "odate": 1664468100000, "details": {"replyCount": 11}}, {"id": "7JsGYvjE88d", "original": "PyVzSTac3cA", "number": 2716, "cdate": 1663850117145, "mdate": null, "ddate": null, "tcdate": 1663850117145, "tmdate": 1677717417767, "tddate": null, "forum": "7JsGYvjE88d", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Fast and Precise: Adjusting Planning Horizon with Adaptive Subgoal Search", "authorids": ["~Micha\u0142_Zawalski1", "~Micha\u0142_Tyrolski1", "~Konrad_Czechowski1", "~Tomasz_Odrzyg\u00f3\u017ad\u017a1", "~Damian_Stachura1", "~Piotr_Pi\u0119kos2", "~Yuhuai_Wu1", "~\u0141ukasz_Kuci\u0144ski1", "~Piotr_Mi\u0142o\u015b1"], "authors": ["Micha\u0142 Zawalski", "Micha\u0142 Tyrolski", "Konrad Czechowski", "Tomasz Odrzyg\u00f3\u017ad\u017a", "Damian Stachura", "Piotr Pi\u0119kos", "Yuhuai Wu", "\u0141ukasz Kuci\u0144ski", "Piotr Mi\u0142o\u015b"], "keywords": ["search", "adaptive horizon", "verification", "deep learning", "hierarchical planning"], "TL;DR": "We propose Adaptive Subgoal Search (AdaSubS), a search algorithm that adjusts the planning horizon to match the local complexity of the solved problems.", "abstract": "Complex reasoning problems contain states that vary in the computational cost required to determine the right action plan. To take advantage of this property, we propose Adaptive Subgoal Search (AdaSubS), a search method that adaptively adjusts the planning horizon. To this end, AdaSubS generates diverse sets of subgoals at different distances. A verification mechanism is employed to filter out unreachable subgoals swiftly, making it possible to focus on feasible further subgoals. In this way, AdaSubS benefits from the efficiency of planning with longer-term subgoals and the fine control with shorter-term ones, and thus scales well to difficult planning problems. We show that AdaSubS significantly surpasses hierarchical planning algorithms on three complex reasoning tasks: Sokoban, the Rubik\u2019s Cube, and the inequality-proving benchmark INT. ", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)", "paperhash": "zawalski|fast_and_precise_adjusting_planning_horizon_with_adaptive_subgoal_search", "pdf": "/pdf/361fb386c64c303b0467dd1fb8d3946766d58d4c.pdf", "_bibtex": "@inproceedings{\nzawalski2023fast,\ntitle={Fast and Precise: Adjusting Planning Horizon with Adaptive Subgoal Search},\nauthor={Micha{\\l} Zawalski and Micha{\\l} Tyrolski and Konrad Czechowski and Tomasz Odrzyg{\\'o}{\\'z}d{\\'z} and Damian Stachura and Piotr Pi{\\k{e}}kos and Yuhuai Wu and {\\L}ukasz Kuci{\\'n}ski and Piotr Mi{\\l}o{\\'s}},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=7JsGYvjE88d}\n}", "venue": "ICLR 2023 notable top 5%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279237259, "odate": 1664468100000, "details": {"replyCount": 21}}, {"id": "N9Pk5iSCzAn", "original": "-wlQruh49fW", "number": 2701, "cdate": 1663850115362, "mdate": null, "ddate": null, "tcdate": 1663850115362, "tmdate": 1677737212359, "tddate": null, "forum": "N9Pk5iSCzAn", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Towards Open Temporal Graph Neural Networks", "authorids": ["~Kaituo_Feng1", "~Changsheng_Li4", "~Xiaolu_Zhang2", "~JUN_ZHOU6"], "authors": ["Kaituo Feng", "Changsheng Li", "Xiaolu Zhang", "JUN ZHOU"], "keywords": ["Temporal Graph Neural Networks", "Open Temporal Graphs", "Class-Incremental Learning"], "TL;DR": "In this paper, we propose a general and principled learning approach for open temporal graphs where the class set for nodes is open.", "abstract": "Graph neural networks (GNNs) for temporal graphs have recently attracted increasing attentions, where a common assumption is that the class set for nodes is closed. However, in real-world scenarios, it often faces the open set problem with the dynamically increased class set as the time passes by. This will bring two big challenges to the existing dynamic GNN methods: (i) How to dynamically propagate appropriate information in an open temporal graph, where new class nodes are often linked to old class nodes. This case will lead to a sharp contradiction. This is because typical GNNs are prone to make the embeddings of connected nodes become similar, while we expect the embeddings of these two interactive nodes to be distinguishable since they belong to different classes. (ii) How to avoid catastrophic knowledge forgetting over old classes when learning new classes occurred in temporal graphs. In this paper, we propose a general and principled learning approach for open temporal graphs, called OTGNet, with the goal of addressing the above two challenges. We assume the knowledge of a node can be disentangled into class-relevant and class-agnostic one, and thus explore a new message passing mechanism by extending the information bottleneck principle to only propagate class-agnostic knowledge between nodes of different classes, avoiding aggregating conflictive information. Moreover, we devise a strategy to select both important and diverse triad sub-graph structures for effective class-incremental learning. Extensive experiments on three real-world datasets of different domains demonstrate the superiority of our method, compared to the baselines.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Deep Learning and representational learning", "paperhash": "feng|towards_open_temporal_graph_neural_networks", "pdf": "/pdf/50805c42deb9d452f3b80c28edbbd14aa21932f7.pdf", "_bibtex": "@inproceedings{\nfeng2023towards,\ntitle={Towards Open Temporal Graph Neural Networks},\nauthor={Kaituo Feng and Changsheng Li and Xiaolu Zhang and JUN ZHOU},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=N9Pk5iSCzAn}\n}", "venue": "ICLR 2023 notable top 5%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279236362, "odate": 1664468100000, "details": {"replyCount": 16}}, {"id": "SrC-nwieGJ", "original": "FDy8ychkxbj", "number": 2618, "cdate": 1663850105457, "mdate": null, "ddate": null, "tcdate": 1663850105457, "tmdate": 1697935598796, "tddate": null, "forum": "SrC-nwieGJ", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Relative representations enable zero-shot latent space communication", "authorids": ["~Luca_Moschella1", "~Valentino_Maiorca1", "~Marco_Fumero1", "~Antonio_Norelli2", "~Francesco_Locatello1", "~Emanuele_Rodol\u00e01"], "authors": ["Luca Moschella", "Valentino Maiorca", "Marco Fumero", "Antonio Norelli", "Francesco Locatello", "Emanuele Rodol\u00e0"], "keywords": ["relative representation", "zero-shot", "stitching", "invariance", "latent communication", "isometry", "representation learning"], "TL;DR": "Relative representations can be leveraged to enable solving tasks regarding \"latent communication\": from zero-shot model stitching to latent space comparison between diverse settings.", "abstract": "Neural networks embed the geometric structure of a data manifold lying in a high-dimensional space into latent representations. Ideally, the distribution of the data points in the latent space should depend only on the task, the data, the loss, and other architecture-specific constraints. However, factors such as the random weights initialization, training hyperparameters, or other sources of randomness in the training phase may induce incoherent latent spaces that hinder any form of reuse. Nevertheless, we empirically observe that, under the same data and modeling choices, the angles between the encodings within distinct latent spaces do not change. In this work, we propose the latent similarity between each sample and a fixed set of anchors as an alternative data representation, demonstrating that it can enforce the desired invariances without any additional training. We show how neural architectures can leverage these relative representations to guarantee, in practice, invariance to latent isometries and rescalings, effectively enabling latent space communication: from zero-shot model stitching to latent space comparison between diverse settings. We extensively validate the generalization capability of our approach on different datasets, spanning various modalities (images, text, graphs), tasks (e.g., classification, reconstruction) and architectures (e.g., CNNs, GCNs, transformers).", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Deep Learning and representational learning", "paperhash": "moschella|relative_representations_enable_zeroshot_latent_space_communication", "pdf": "/pdf/2d9f62e22019d0d53476f0c4a9d760c6cc7895e2.pdf", "supplementary_material": "/attachment/d5b9db5fe044181bfa21d0f1d2406f69deb91e7f.zip", "_bibtex": "@inproceedings{\nmoschella2023relative,\ntitle={Relative representations enable zero-shot latent space communication},\nauthor={Luca Moschella and Valentino Maiorca and Marco Fumero and Antonio Norelli and Francesco Locatello and Emanuele Rodol{\\`a}},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=SrC-nwieGJ}\n}", "venue": "ICLR 2023 notable top 5%", "venueid": "ICLR.cc/2023/Conference", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 3 code implementations](https://www.catalyzex.com/paper/arxiv:2209.15430/code)"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279232107, "odate": 1664468100000, "details": {"replyCount": 13}}, {"id": "FkSp8VW8RjH", "original": "9XWOsyhsyt8", "number": 2584, "cdate": 1663850101431, "mdate": null, "ddate": null, "tcdate": 1663850101431, "tmdate": 1697935602300, "tddate": null, "forum": "FkSp8VW8RjH", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Language Modelling with Pixels", "authorids": ["~Phillip_Rust1", "~Jonas_F._Lotz1", "~Emanuele_Bugliarello1", "~Elizabeth_Salesky1", "~Miryam_de_Lhoneux1", "~Desmond_Elliott1"], "authors": ["Phillip Rust", "Jonas F. Lotz", "Emanuele Bugliarello", "Elizabeth Salesky", "Miryam de Lhoneux", "Desmond Elliott"], "keywords": ["representation learning", "nlp", "transformers", "language model", "masked autoencoder"], "TL;DR": "We train PIXEL, a language model that operates solely on images of rendered text, and show that it is possible to transfer representations across languages based on orthographic similarity or the co-activation of pixels.", "abstract": "Language models are defined over a finite set of inputs, which creates a vocabulary bottleneck when we attempt to scale the number of supported languages. Tackling this bottleneck results in a trade-off between what can be represented in the embedding matrix and computational issues in the output layer. This paper introduces PIXEL, the Pixel-based Encoder of Language, which suffers from neither of these issues. PIXEL is a pretrained language model that renders text as images, making it possible to transfer representations across languages based on orthographic similarity or the co-activation of pixels. PIXEL is trained to reconstruct the pixels of masked patches instead of predicting a distribution over tokens. We pretrain the 86M parameter PIXEL model on the same English data as BERT and evaluate on syntactic and semantic tasks in typologically diverse languages, including various non-Latin scripts. We find that PIXEL substantially outperforms BERT on syntactic and semantic processing tasks on scripts that are not found in the pretraining data, but PIXEL is slightly weaker than BERT when working with Latin scripts. Furthermore, we find that PIXEL is more robust than BERT to orthographic attacks and linguistic code-switching, further confirming the benefits of modelling language with pixels.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Applications (eg, speech processing, computer vision, NLP)", "paperhash": "rust|language_modelling_with_pixels", "pdf": "/pdf/5ade25a9134d48be86a9acbbebf941357365462c.pdf", "_bibtex": "@inproceedings{\nrust2023language,\ntitle={Language Modelling with Pixels},\nauthor={Phillip Rust and Jonas F. Lotz and Emanuele Bugliarello and Elizabeth Salesky and Miryam de Lhoneux and Desmond Elliott},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=FkSp8VW8RjH}\n}", "venue": "ICLR 2023 notable top 5%", "venueid": "ICLR.cc/2023/Conference", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 4 code implementations](https://www.catalyzex.com/paper/arxiv:2207.06991/code)"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279230148, "odate": 1664468100000, "details": {"replyCount": 13}}, {"id": "M95oDwJXayG", "original": "QXAM_tUkoHH", "number": 2559, "cdate": 1663850098436, "mdate": null, "ddate": null, "tcdate": 1663850098436, "tmdate": 1677577101773, "tddate": null, "forum": "M95oDwJXayG", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Addressing Parameter Choice Issues in Unsupervised Domain Adaptation by Aggregation", "authorids": ["~Marius-Constantin_Dinu1", "~Markus_Holzleitner1", "~Maximilian_Beck1", "~Hoan_Duc_Nguyen1", "~Andrea_Huber1", "~Hamid_Eghbal-zadeh1", "~Bernhard_A._Moser1", "~Sergei_Pereverzyev1", "~Sepp_Hochreiter1", "~Werner_Zellinger1"], "authors": ["Marius-Constantin Dinu", "Markus Holzleitner", "Maximilian Beck", "Hoan Duc Nguyen", "Andrea Huber", "Hamid Eghbal-zadeh", "Bernhard A. Moser", "Sergei Pereverzyev", "Sepp Hochreiter", "Werner Zellinger"], "keywords": ["Domain adaptation", "parameter choice", "model selection", "aggregation", "importance weighting"], "TL;DR": "A method for addressing the issue of hyper-parameter selection in unsupervised domain adaptation.", "abstract": "We study the problem of choosing algorithm hyper-parameters in unsupervised domain adaptation, i.e., with labeled data in a source domain and unlabeled data in a target domain, drawn from a different input distribution. We follow the strategy to compute several models using different hyper-parameters, and, to subsequently compute a linear aggregation of the models. While several heuristics exist that follow this strategy, methods are still missing that rely on thorough theories for bounding the target error. In this turn, we propose a method that extends weighted least squares to vector-valued functions, e.g., deep neural networks. We show that the target error of the proposed algorithm is asymptotically not worse than twice the error of the unknown optimal aggregation. We also perform a large scale empirical comparative study on several datasets, including text, images, electroencephalogram, body sensor signals and signals from mobile phones. Our method outperforms deep embedded validation (DEV) and importance weighted validation (IWV) on all datasets, setting a new state-of-the-art performance for solving parameter choice issues in unsupervised domain adaptation with theoretical error guarantees. We further study several competitive heuristics, all outperforming IWV and DEV on at least five datasets. However, our method outperforms each heuristic on at least five of seven datasets.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Deep Learning and representational learning", "paperhash": "dinu|addressing_parameter_choice_issues_in_unsupervised_domain_adaptation_by_aggregation", "pdf": "/pdf/36c115dd350b35beffcf18cbfd0a6afd2ab5a0e7.pdf", "_bibtex": "@inproceedings{\ndinu2023addressing,\ntitle={Addressing Parameter Choice Issues in Unsupervised Domain Adaptation by Aggregation},\nauthor={Marius-Constantin Dinu and Markus Holzleitner and Maximilian Beck and Hoan Duc Nguyen and Andrea Huber and Hamid Eghbal-zadeh and Bernhard A. Moser and Sergei Pereverzyev and Sepp Hochreiter and Werner Zellinger},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=M95oDwJXayG}\n}", "venue": "ICLR 2023 notable top 5%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279228589, "odate": 1664468100000, "details": {"replyCount": 11}}, {"id": "ZTK3SefE8_Z", "original": "3mc3Uq62oyA", "number": 2488, "cdate": 1663850089729, "mdate": null, "ddate": null, "tcdate": 1663850089729, "tmdate": 1677044188662, "tddate": null, "forum": "ZTK3SefE8_Z", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Symbolic Physics Learner: Discovering governing equations via Monte Carlo tree search", "authorids": ["~Fangzheng_Sun1", "~Yang_Liu52", "~Jian-Xun_Wang1", "~Hao_Sun4"], "authors": ["Fangzheng Sun", "Yang Liu", "Jian-Xun Wang", "Hao Sun"], "keywords": ["symbolic regression", "Monte Carlo tree search", "governing equations", "nonlinear dynamics"], "TL;DR": "Proposed a novel Symbolic Physics Learner (SPL) machine to discover the mathematical structure of nonlinear dynamics based on limited measurement data.", "abstract": "Nonlinear dynamics is ubiquitous in nature and commonly seen in various science and engineering disciplines. Distilling analytical expressions that govern nonlinear dynamics from limited data remains vital but challenging. To tackle this fundamental issue, we propose a novel Symbolic Physics Learner (SPL) machine to discover the mathematical structure of nonlinear dynamics. The key concept is to interpret mathematical operations and system state variables by computational rules and symbols, establish symbolic reasoning of mathematical formulas via expression trees, and employ a Monte Carlo tree search (MCTS) agent to explore optimal expression trees based on measurement data. The MCTS agent obtains an optimistic selection policy through the traversal of expression trees, featuring the one that maps to the arithmetic expression of underlying physics. Salient features of the proposed framework include search flexibility and enforcement of parsimony for discovered equations. The efficacy and superiority of the SPL machine are demonstrated by numerical examples, compared with state-of-the-art baselines.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )", "paperhash": "sun|symbolic_physics_learner_discovering_governing_equations_via_monte_carlo_tree_search", "pdf": "/pdf/0c815f206ac64432f9caf1f36b816f9e368dee15.pdf", "_bibtex": "@inproceedings{\nsun2023symbolic,\ntitle={Symbolic Physics Learner: Discovering governing equations via Monte Carlo tree search},\nauthor={Fangzheng Sun and Yang Liu and Jian-Xun Wang and Hao Sun},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=ZTK3SefE8_Z}\n}", "venue": "ICLR 2023 notable top 5%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279224979, "odate": 1664468100000, "details": {"replyCount": 14}}, {"id": "rFQfjDC9Mt", "original": "C3Vy8gL9xGm", "number": 2431, "cdate": 1663850082625, "mdate": null, "ddate": null, "tcdate": 1663850082625, "tmdate": 1677115177737, "tddate": null, "forum": "rFQfjDC9Mt", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Clean-image Backdoor: Attacking Multi-label Models with Poisoned Labels Only", "authorids": ["~Kangjie_Chen1", "~Xiaoxuan_Lou1", "~Guowen_Xu1", "~Jiwei_Li1", "~Tianwei_Zhang1"], "authors": ["Kangjie Chen", "Xiaoxuan Lou", "Guowen Xu", "Jiwei Li", "Tianwei Zhang"], "keywords": [], "abstract": "Multi-label models have been widely used in various applications including image annotation and object detection. The fly in the ointment is its inherent vulnerability to backdoor attacks due to the adoption of deep learning techniques. However, all existing backdoor attacks exclusively require to modify training inputs (e.g., images), which may be impractical in real-world applications. In this paper, we aim to break this wall and propose the first clean-image backdoor attack, which only poisons the training labels without touching the training samples. Our key insight is that in a multi-label learning task, the adversary can just manipulate the annotations of training samples consisting of a specific set of classes to activate the backdoor. We design a novel trigger exploration method to find convert and effective triggers to enhance the attack performance. We also propose three target label selection strategies to achieve different goals. Experimental results indicate that our clean-image backdoor can achieve a 98% attack success rate while preserving the model's functionality on the benign inputs. Besides, the proposed clean-image backdoor can evade existing state-of-the-art defenses.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Applications (eg, speech processing, computer vision, NLP)", "paperhash": "chen|cleanimage_backdoor_attacking_multilabel_models_with_poisoned_labels_only", "pdf": "/pdf/6021cbdfd717a31730914f92bc2b1e9762135b65.pdf", "_bibtex": "@inproceedings{\nchen2023cleanimage,\ntitle={Clean-image Backdoor: Attacking Multi-label Models with Poisoned Labels Only},\nauthor={Kangjie Chen and Xiaoxuan Lou and Guowen Xu and Jiwei Li and Tianwei Zhang},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=rFQfjDC9Mt}\n}", "venue": "ICLR 2023 notable top 5%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279221854, "odate": 1664468100000, "details": {"replyCount": 13}}, {"id": "m1oqEOAozQU", "original": "M9p5_GqFW6p", "number": 2406, "cdate": 1663850079527, "mdate": null, "ddate": null, "tcdate": 1663850079527, "tmdate": 1697935619261, "tddate": null, "forum": "m1oqEOAozQU", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Graph Neural Networks for Link Prediction with Subgraph Sketching", "authorids": ["~Benjamin_Paul_Chamberlain1", "~Sergey_Shirobokov1", "~Emanuele_Rossi1", "~Fabrizio_Frasca1", "~Thomas_Markovich1", "~Nils_Yannick_Hammerla1", "~Michael_M._Bronstein1", "~Max_Hansmire1"], "authors": ["Benjamin Paul Chamberlain", "Sergey Shirobokov", "Emanuele Rossi", "Fabrizio Frasca", "Thomas Markovich", "Nils Yannick Hammerla", "Michael M. Bronstein", "Max Hansmire"], "keywords": ["Graph Neural Networks", "Link Prediction", "Data Sketching"], "TL;DR": "A method that solves the expressivity issues that plague most MPNNs for link prediction while being as efficient to run as GCN. This is achieved by passing subgraph sketches as messages.", "abstract": "Many Graph Neural Networks (GNNs) perform poorly compared to simple heuristics on Link Prediction (LP) tasks. This is due to limitations in expressive power such as the inability to count triangles (the backbone of most LP heuristics) and because they can not distinguish automorphic nodes (those having identical structural roles). Both expressiveness issues can be alleviated by learning link (rather than node) representations and incorporating structural features such as triangle counts. Since explicit link representations are often prohibitively expensive, recent works resorted to subgraph-based methods, which have achieved state-of-the-art performance for LP, but suffer from poor efficiency due to high levels of redundancy between subgraphs. We analyze the components of subgraph GNN (SGNN) methods for link prediction. Based on our analysis, we propose a novel full-graph GNN called ELPH (Efficient Link Prediction with Hashing) that passes subgraph sketches as messages to approximate the key components of SGNNs without explicit subgraph construction. ELPH is provably more expressive than Message Passing GNNs (MPNNs).  It outperforms existing SGNN models on many standard LP benchmarks while being orders of magnitude faster. However, it shares the common GNN limitation that it is only efficient when the dataset fits in GPU memory. Accordingly, we develop a highly scalable model, called BUDDY, which uses feature precomputation to circumvent this limitation without sacrificing predictive performance. Our experiments show that BUDDY also outperforms SGNNs on standard LP benchmarks while being highly scalable and faster than ELPH.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Deep Learning and representational learning", "paperhash": "chamberlain|graph_neural_networks_for_link_prediction_with_subgraph_sketching", "pdf": "/pdf/c24fea923ffff6f10becdc0da41b8e84eb3412a1.pdf", "_bibtex": "@inproceedings{\nchamberlain2023graph,\ntitle={Graph Neural Networks for Link Prediction with Subgraph Sketching},\nauthor={Benjamin Paul Chamberlain and Sergey Shirobokov and Emanuele Rossi and Fabrizio Frasca and Thomas Markovich and Nils Yannick Hammerla and Michael M. Bronstein and Max Hansmire},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=m1oqEOAozQU}\n}", "venue": "ICLR 2023 notable top 5%", "venueid": "ICLR.cc/2023/Conference", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2209.15486/code)"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279220681, "odate": 1664468100000, "details": {"replyCount": 6}}, {"id": "_2bDpAtr7PI", "original": "RLKnSUjxEn", "number": 2230, "cdate": 1663850057791, "mdate": null, "ddate": null, "tcdate": 1663850057791, "tmdate": 1697935636893, "tddate": null, "forum": "_2bDpAtr7PI", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Image to Sphere: Learning Equivariant Features for Efficient Pose Prediction", "authorids": ["~David_Klee1", "~Ondrej_Biza1", "~Robert_Platt1", "~Robin_Walters1"], "authors": ["David Klee", "Ondrej Biza", "Robert Platt", "Robin Walters"], "keywords": ["equivariance", "sample efficiency", "pose detection", "symmetry", "SO(3)"], "abstract": "Predicting the pose of objects from a single image is an important but difficult computer vision problem. Methods that predict a single point estimate do not predict the pose of objects with symmetries well and cannot represent uncertainty. Alternatively, some works predict a distribution over orientations in $\\mathrm{SO}(3)$. However, training such models can be computation- and sample-inefficient. Instead, we propose a novel mapping of features from the image domain to the 3D rotation manifold. Our method then leverages $\\mathrm{SO}(3)$ equivariant layers, which are more sample efficient, and outputs a distribution over rotations that can be sampled at arbitrary resolution. We demonstrate the effectiveness of our method at object orientation prediction, and achieve state-of-the-art performance on the popular PASCAL3D+ dataset. Moreover, we show that our method can model complex object symmetries, without any modifications to the parameters or loss function.  Code is available at \\url{https://dmklee.github.io/image2sphere}.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Deep Learning and representational learning", "paperhash": "klee|image_to_sphere_learning_equivariant_features_for_efficient_pose_prediction", "TL;DR": "We propose a novel architecture which efficiently describes uncertainty in pose estimation from images by using learned SO(3)-equivariant features to generate complex distributions over SO(3) with the Fourier basis.", "pdf": "/pdf/dc2578c49b3cfc78beece0602f3564947a512c18.pdf", "supplementary_material": "/attachment/c2b9cd1a356d2e8186b8390b4eb4053f32a4b67e.zip", "_bibtex": "@inproceedings{\nklee2023image,\ntitle={Image to Sphere: Learning Equivariant Features for Efficient Pose Prediction},\nauthor={David Klee and Ondrej Biza and Robert Platt and Robin Walters},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=_2bDpAtr7PI}\n}", "venue": "ICLR 2023 notable top 5%", "venueid": "ICLR.cc/2023/Conference", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2302.13926/code)"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279211693, "odate": 1664468100000, "details": {"replyCount": 11}}, {"id": "zt53IDUR1U", "original": "KsYdNN2qaDx", "number": 2222, "cdate": 1663850056827, "mdate": null, "ddate": null, "tcdate": 1663850056827, "tmdate": 1676461099163, "tddate": null, "forum": "zt53IDUR1U", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "MICN: Multi-scale Local and Global Context Modeling for Long-term Series Forecasting", "authorids": ["~Huiqiang_Wang1", "~Jian_Peng5", "~Feihu_Huang2", "~Jince_Wang1", "~Junhui_Chen1", "~Yifei_Xiao1"], "authors": ["Huiqiang Wang", "Jian Peng", "Feihu Huang", "Jince Wang", "Junhui Chen", "Yifei Xiao"], "keywords": ["long-term forecasting", "local and global context", "multi-branch architecture", "different potential patterns."], "TL;DR": "New modeling perspective, new forecasting framework, linear complexity and best performance.", "abstract": "Recently, Transformer-based methods have achieved surprising performance in the field of long-term series forecasting, but the attention mechanism for computing global correlations entails high complexity. And they do not allow for targeted modeling of local features as CNN structures do. To solve the above problems, we propose to combine local features and global correlations to capture the overall view of time series (e.g., fluctuations, trends). To fully exploit the underlying information in the time series, a multi-scale branch structure is adopted to model different potential patterns separately. Each pattern is extracted with down-sampled convolution and isometric convolution for local features and global correlations, respectively. In addition to being more effective, our proposed method, termed as Multi-scale Isometric Convolution Network (MICN), is more efficient with linear complexity about the sequence length with suitable convolution kernels. Our experiments on six benchmark datasets show that compared with state-of-the-art methods, MICN yields 17.2% and 21.6% relative improvements for multivariate and univariate time series, respectively.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Deep Learning and representational learning", "paperhash": "wang|micn_multiscale_local_and_global_context_modeling_for_longterm_series_forecasting", "pdf": "/pdf/6e3044ae6e9494f027b7c011f97efa8f0ed029c0.pdf", "_bibtex": "@inproceedings{\nwang2023micn,\ntitle={{MICN}: Multi-scale Local and Global Context Modeling for Long-term Series Forecasting},\nauthor={Huiqiang Wang and Jian Peng and Feihu Huang and Jince Wang and Junhui Chen and Yifei Xiao},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=zt53IDUR1U}\n}", "venue": "ICLR 2023 notable top 5%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279210149, "odate": 1664468100000, "details": {"replyCount": 9}}, {"id": "SXZr8aDKia", "original": "BJWmmxtve2", "number": 2165, "cdate": 1663850049805, "mdate": null, "ddate": null, "tcdate": 1663850049805, "tmdate": 1697935645055, "tddate": null, "forum": "SXZr8aDKia", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Personalized Federated Learning with Feature Alignment and Classifier Collaboration", "authorids": ["~Jian_Xu7", "~Xinyi_Tong1", "~Shao-Lun_Huang3"], "authors": ["Jian Xu", "Xinyi Tong", "Shao-Lun Huang"], "keywords": ["Federated Learning", "Personalization", "Collaboration"], "abstract": "Data heterogeneity is one of the most challenging issues in federated learning, which motivates a variety of approaches to learn personalized models for participating clients. One such approach in deep neural networks based tasks is employing a shared feature representation and learning a customized classifier head for each client. However, previous works do not utilize the global knowledge during local representation learning and also neglect the fine-grained collaboration between local classifier heads, which limits the model generalization ability. In this work, we conduct explicit local-global feature alignment by leveraging global semantic knowledge for learning a better representation. Moreover, we quantify the benefit of classifier combination for each client as a function of the combining weights and derive an optimization problem for estimating optimal weights. Finally, extensive evaluation results on benchmark datasets with various heterogeneous data scenarios demonstrate the effectiveness of our proposed method.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "General Machine Learning (ie none of the above)", "paperhash": "xu|personalized_federated_learning_with_feature_alignment_and_classifier_collaboration", "pdf": "/pdf/7e45d7414cae758349f97df5277f8897ef7b8c04.pdf", "_bibtex": "@inproceedings{\nxu2023personalized,\ntitle={Personalized Federated Learning with Feature Alignment and Classifier Collaboration},\nauthor={Jian Xu and Xinyi Tong and Shao-Lun Huang},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=SXZr8aDKia}\n}", "venue": "ICLR 2023 notable top 5%", "venueid": "ICLR.cc/2023/Conference", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2306.11867/code)"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279206756, "odate": 1664468100000, "details": {"replyCount": 21}}, {"id": "c7rM7F7jQjN", "original": "JMbkkYtI_Lj", "number": 2136, "cdate": 1663850046403, "mdate": null, "ddate": null, "tcdate": 1663850046403, "tmdate": 1697935648177, "tddate": null, "forum": "c7rM7F7jQjN", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "From Play to Policy: Conditional Behavior Generation from Uncurated Robot Data", "authorids": ["~Zichen_Jeff_Cui1", "~Yibin_Wang1", "~Nur_Muhammad_Mahi_Shafiullah1", "~Lerrel_Pinto1"], "authors": ["Zichen Jeff Cui", "Yibin Wang", "Nur Muhammad Mahi Shafiullah", "Lerrel Pinto"], "keywords": ["behavior generation", "robot manipulation", "learning from play"], "abstract": "While large-scale sequence modelling from offline data has led to impressive performance gains in natural language generation and image generation, directly translating such ideas to robotics has been challenging. One critical reason for this is that uncurated robot demonstration data, i.e. play data, collected from non-expert human demonstrators are often noisy, diverse, and distributionally multi-modal. This makes extracting useful, task-centric behaviors from such data a difficult generative modelling problem. In this work, we present Conditional Behavior Transformers (C-BeT), a method that combines the multi-modal generation ability of Behavior Transformer with future-conditioned goal specification. On a suite of simulated benchmark tasks, we find that C-BeT improves upon prior state-of-the-art work in learning from play data by an average of 45.7%. Further, we demonstrate for the first time that useful task-centric behaviors can be learned on a real-world robot purely from play data without any task labels or reward information. Robot videos are best viewed on our project website: play-to-policy.github.io", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Deep Learning and representational learning", "paperhash": "cui|from_play_to_policy_conditional_behavior_generation_from_uncurated_robot_data", "TL;DR": "We train a transformer-based model on uncurated play data, which can produce targeted real-world robot policies by conditioning on future observations.", "pdf": "/pdf/2ac61e4b87940fa144ced394ae19abce9e89a184.pdf", "_bibtex": "@inproceedings{\ncui2023from,\ntitle={From Play to Policy: Conditional Behavior Generation from Uncurated Robot Data},\nauthor={Zichen Jeff Cui and Yibin Wang and Nur Muhammad Mahi Shafiullah and Lerrel Pinto},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=c7rM7F7jQjN}\n}", "supplementary_material": "/attachment/ce9eabd77d88c50e00312ec86e7712ced84c5877.zip", "venue": "ICLR 2023 notable top 5%", "venueid": "ICLR.cc/2023/Conference", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 2 code implementations](https://www.catalyzex.com/paper/arxiv:2210.10047/code)"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279204988, "odate": 1664468100000, "details": {"replyCount": 15}}, {"id": "jlAjNL8z5cs", "original": "XZnAQJPS-NO", "number": 2128, "cdate": 1663850045425, "mdate": null, "ddate": null, "tcdate": 1663850045425, "tmdate": 1677725428295, "tddate": null, "forum": "jlAjNL8z5cs", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Visual Classification via Description from Large Language Models", "authorids": ["~Sachit_Menon1", "~Carl_Vondrick2"], "authors": ["Sachit Menon", "Carl Vondrick"], "keywords": ["vision-language models", "CLIP", "prompting", "GPT-3", "large language models", "zero-shot recognition", "multimodal"], "TL;DR": "We enhance zero-shot recognition with vision-language models by comparing to category descriptors from GPT-3, enabling better performance in an interpretable setting that also allows for incorporation of new concepts and bias mitigation.", "abstract": "Vision-language models such as CLIP have shown promising performance on a variety of recognition tasks using the standard zero-shot classification procedure -- computing similarity between the query image and the embedded words for each category. By only using the category name, they neglect to make use of the rich context of additional information that language affords. The procedure gives no intermediate understanding of why a category is chosen, and furthermore provides no mechanism for adjusting the criteria used towards this decision. We present an alternative framework for classification with VLMs, which we call classification by description. We ask VLMs to check for descriptive features rather than broad categories: to find a tiger, look for its stripes; its claws; and more. By basing decisions on these descriptors, we can provide additional cues that encourage using the features we want to be used. In the process, we can get a clear idea of what the model ``thinks\" it is seeing to make its decision; it gains some level of inherent explainability. We query large language models (e.g., GPT-3) for these descriptors to obtain them in a scalable way. Extensive experiments show our framework has numerous advantages past interpretability. We show improvements in accuracy on ImageNet across distribution shifts; demonstrate the ability to adapt VLMs to recognize concepts unseen during training; and illustrate how descriptors can be edited to effectively mitigate bias compared to the baseline. ", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Applications (eg, speech processing, computer vision, NLP)", "paperhash": "menon|visual_classification_via_description_from_large_language_models", "pdf": "/pdf/d171255a976821dd4ebfacb7a012082c4b888b7a.pdf", "_bibtex": "@inproceedings{\nmenon2023visual,\ntitle={Visual Classification via Description from Large Language Models},\nauthor={Sachit Menon and Carl Vondrick},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=jlAjNL8z5cs}\n}", "venue": "ICLR 2023 notable top 5%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279204507, "odate": 1664468100000, "details": {"replyCount": 13}}, {"id": "w0QXrZ3N-s", "original": "KfzOVzX9X5", "number": 2113, "cdate": 1663850043743, "mdate": null, "ddate": null, "tcdate": 1663850043743, "tmdate": 1677700432549, "tddate": null, "forum": "w0QXrZ3N-s", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "The Modality Focusing Hypothesis: Towards Understanding Crossmodal Knowledge Distillation", "authorids": ["~Zihui_Xue1", "~Zhengqi_Gao1", "~Sucheng_Ren1", "~Hang_Zhao1"], "authors": ["Zihui Xue", "Zhengqi Gao", "Sucheng Ren", "Hang Zhao"], "keywords": ["multimodal learning", "knowledge distillation"], "TL;DR": "We provide a thorough investigation of crossmodal knowledge transfer", "abstract": "Crossmodal knowledge distillation (KD) extends traditional knowledge distillation to the area of multimodal learning and demonstrates great success in various applications. To achieve knowledge transfer across modalities, a pretrained network from one modality is adopted as the teacher to provide supervision signals to a student network learning from the other modality. In contrast to the empirical success reported in prior works, the working mechanism of crossmodal KD remains a mystery. In this paper, we present a thorough understanding of crossmodal KD. We begin by providing two failure cases and demonstrate that KD is not a universal cure in crossmodal knowledge transfer. We then present the modality Venn diagram to understand modality relationships and the modality focusing hypothesis revealing the decisive factor in the efficacy of crossmodal KD. Experimental results on 6 multimodal datasets help justify our hypothesis, diagnose failure cases, and point directions to improve crossmodal knowledge transfer in the future.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "General Machine Learning (ie none of the above)", "paperhash": "xue|the_modality_focusing_hypothesis_towards_understanding_crossmodal_knowledge_distillation", "pdf": "/pdf/741eead42fe714d67fac001285243a76fd4ad259.pdf", "supplementary_material": "/attachment/271e5fd57260bcebcbec66b087e11fda50687414.zip", "_bibtex": "@inproceedings{\nxue2023the,\ntitle={The Modality Focusing Hypothesis: Towards Understanding Crossmodal Knowledge Distillation},\nauthor={Zihui Xue and Zhengqi Gao and Sucheng Ren and Hang Zhao},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=w0QXrZ3N-s}\n}", "venue": "ICLR 2023 notable top 5%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279203702, "odate": 1664468100000, "details": {"replyCount": 11}}, {"id": "OJ8aSjCaMNK", "original": "o1UhIpLpuTY", "number": 2076, "cdate": 1663850039409, "mdate": null, "ddate": null, "tcdate": 1663850039409, "tmdate": 1697935654543, "tddate": null, "forum": "OJ8aSjCaMNK", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Multi-Rate VAE: Train Once, Get the Full Rate-Distortion Curve", "authorids": ["~Juhan_Bae2", "~Michael_R._Zhang1", "~Michael_Ruan2", "ericdywang@gmail.com", "hasegawa.sou@fujitsu.com", "~Jimmy_Ba1", "~Roger_Baker_Grosse1"], "authors": ["Juhan Bae", "Michael R. Zhang", "Michael Ruan", "Eric Wang", "So Hasegawa", "Jimmy Ba", "Roger Baker Grosse"], "keywords": ["Variational Autoencoders", "VAEs", "Hypernetworks", "Response Functions", "Hyperparameter Tuning"], "abstract": "Variational autoencoders (VAEs) are powerful tools for learning latent representations of data used in a wide range of applications. In practice, VAEs usually require multiple training rounds to choose the amount of information the latent variable should retain. This trade-off between the reconstruction error (distortion) and the KL divergence (rate) is typically parameterized by a hyperparameter $\\beta$. In this paper, we introduce Multi-Rate VAE (MR-VAE), a computationally efficient framework for learning optimal parameters corresponding to various $\\beta$ in a single training run. The key idea is to explicitly formulate a response function using hypernetworks that maps $\\beta$ to the optimal parameters. MR-VAEs construct a compact response hypernetwork where the pre-activations are conditionally gated based on $\\beta$. We justify the proposed architecture by analyzing linear VAEs and showing that it can represent response functions exactly for linear VAEs. With the learned hypernetwork, MR-VAEs can construct the rate-distortion curve without additional training and can be deployed with significantly less hyperparameter tuning. Empirically, our approach is competitive and often exceeds the performance of multiple $\\beta$-VAEs training with minimal computation and memory overheads.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Deep Learning and representational learning", "paperhash": "bae|multirate_vae_train_once_get_the_full_ratedistortion_curve", "TL;DR": "MR-VAEs can construct the rate-distortion curve in a single training run.", "pdf": "/pdf/14a6477c29547f6a0e88be838a4bb2fe39d0bef6.pdf", "supplementary_material": "/attachment/856e9f14f87161c138e8dfb837592c25c1393b90.zip", "_bibtex": "@inproceedings{\nbae2023multirate,\ntitle={Multi-Rate {VAE}: Train Once, Get the Full Rate-Distortion Curve},\nauthor={Juhan Bae and Michael R. Zhang and Michael Ruan and Eric Wang and So Hasegawa and Jimmy Ba and Roger Baker Grosse},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=OJ8aSjCaMNK}\n}", "venue": "ICLR 2023 notable top 5%", "venueid": "ICLR.cc/2023/Conference", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 4 code implementations](https://www.catalyzex.com/paper/arxiv:2212.03905/code)"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279201691, "odate": 1664468100000, "details": {"replyCount": 13}}, {"id": "3OR2tbtnYC-", "original": "MDvneaBxjPQ", "number": 2043, "cdate": 1663850035611, "mdate": null, "ddate": null, "tcdate": 1663850035611, "tmdate": 1697935658998, "tddate": null, "forum": "3OR2tbtnYC-", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Near-optimal Policy Identification in Active Reinforcement Learning", "authorids": ["~Xiang_Li42", "~Viraj_Mehta1", "~Johannes_Kirschner1", "~Ian_Char1", "~Willie_Neiswanger2", "~Jeff_Schneider1", "~Andreas_Krause1", "~Ilija_Bogunovic2"], "authors": ["Xiang Li", "Viraj Mehta", "Johannes Kirschner", "Ian Char", "Willie Neiswanger", "Jeff Schneider", "Andreas Krause", "Ilija Bogunovic"], "keywords": ["reinforcement learning", "contextual bayesian optimization", "kernelized least-squares value iteration"], "abstract": "Many real-world reinforcement learning tasks require control of complex dynamical systems that involve both costly data acquisition processes and large state spaces. In cases where the expensive transition dynamics can be readily evaluated at specified states (e.g., via a simulator), agents can operate in what is often referred to as planning with a \\emph{generative model}. We propose the AE-LSVI algorithm for best policy identification, a novel variant of the kernelized least-squares value iteration (LSVI) algorithm that combines optimism with pessimism for active exploration (AE). AE-LSVI provably identifies a near-optimal policy \\emph{uniformly} over an entire state space and achieves polynomial sample complexity guarantees that are independent of the number of states. When specialized to the recently introduced offline contextual Bayesian optimization setting, our algorithm achieves improved sample complexity bounds. Experimentally, we demonstrate that AE-LSVI outperforms other RL algorithms in a variety of environments when robustness to the initial state is required. ", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)", "paperhash": "li|nearoptimal_policy_identification_in_active_reinforcement_learning", "TL;DR": "We propose a novel kernelized LSVI algorithm for active reinforcement learning which provably identifies a near-optimal policy uniformly over the entire state space.", "pdf": "/pdf/3f2fd20ea112039f10550e677478e83b1f6260a7.pdf", "supplementary_material": "/attachment/7c1bb7a69faa78900abb2e05ba29ad0dfe0ebc1b.zip", "_bibtex": "@inproceedings{\nli2023nearoptimal,\ntitle={Near-optimal Policy Identification in Active Reinforcement Learning},\nauthor={Xiang Li and Viraj Mehta and Johannes Kirschner and Ian Char and Willie Neiswanger and Jeff Schneider and Andreas Krause and Ilija Bogunovic},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=3OR2tbtnYC-}\n}", "venue": "ICLR 2023 notable top 5%", "venueid": "ICLR.cc/2023/Conference", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 2 code implementations](https://www.catalyzex.com/paper/arxiv:2212.09510/code)"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279199558, "odate": 1664468100000, "details": {"replyCount": 14}}, {"id": "LFHFQbjxIiP", "original": "AaUiSI7nhl0", "number": 1842, "cdate": 1663850010357, "mdate": null, "ddate": null, "tcdate": 1663850010357, "tmdate": 1697935685873, "tddate": null, "forum": "LFHFQbjxIiP", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Conditional Antibody Design as 3D Equivariant Graph Translation", "authorids": ["~Xiangzhe_Kong1", "~Wenbing_Huang1", "~Yang_Liu19"], "authors": ["Xiangzhe Kong", "Wenbing Huang", "Yang Liu"], "keywords": ["conditional antibody generation", "equivariant", "multi-channel attention"], "abstract": "Antibody design is valuable for therapeutic usage and biological research. Existing deep-learning-based methods encounter several key issues: 1) incomplete context for Complementarity-Determining Regions (CDRs) generation; 2) incapability of capturing the entire 3D geometry of the input structure; 3) inefficient prediction of the CDR sequences in an autoregressive manner. In this paper, we propose Multi-channel Equivariant Attention Network (MEAN) to co-design 1D sequences and 3D structures of CDRs. To be specific, MEAN formulates antibody design as a conditional graph translation problem by importing extra components including the target antigen and the light chain of the antibody. Then, MEAN resorts to E(3)-equivariant message passing along with a proposed attention mechanism to better capture the geometrical correlation between different components. Finally, it outputs both the 1D sequences and 3D structure via a multi-round progressive full-shot scheme, which enjoys more efficiency and precision against previous autoregressive approaches. Our method significantly surpasses state-of-the-art models in sequence and structure modeling, antigen-binding CDR design, and binding affinity optimization. Specifically, the relative improvement to baselines is about 23\\% in antigen-binding CDR design and 34\\% for affinity optimization.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )", "paperhash": "kong|conditional_antibody_design_as_3d_equivariant_graph_translation", "pdf": "/pdf/3ad0b04b8a9b31f816c7c80ce0cf71fad13fa636.pdf", "_bibtex": "@inproceedings{\nkong2023conditional,\ntitle={Conditional Antibody Design as 3D Equivariant Graph Translation},\nauthor={Xiangzhe Kong and Wenbing Huang and Yang Liu},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=LFHFQbjxIiP}\n}", "venue": "ICLR 2023 notable top 5%", "venueid": "ICLR.cc/2023/Conference", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2208.06073/code)"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279187169, "odate": 1664468100000, "details": {"replyCount": 12}}, {"id": "DeG07_TcZvT", "original": "2lVVtGpAa3d", "number": 1818, "cdate": 1663850007704, "mdate": null, "ddate": null, "tcdate": 1663850007704, "tmdate": 1697935687805, "tddate": null, "forum": "DeG07_TcZvT", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Emergent World Representations: Exploring a Sequence Model Trained on a Synthetic Task", "authorids": ["~Kenneth_Li1", "~Aspen_K_Hopkins1", "~David_Bau1", "~Fernanda_Vi\u00e9gas1", "~Hanspeter_Pfister1", "~Martin_Wattenberg1"], "authors": ["Kenneth Li", "Aspen K Hopkins", "David Bau", "Fernanda Vi\u00e9gas", "Hanspeter Pfister", "Martin Wattenberg"], "keywords": ["world representation", "GPT"], "abstract": "Language models show a surprising range of capabilities, but the source of their apparent competence is unclear. Do these networks just memorize a collection of surface statistics, or do they rely on internal representations of the process that generates the sequences they see? We investigate this question by applying a variant of the GPT model to the task of predicting legal moves in a simple board game, Othello. Although the network has no a priori knowledge of the game or its rules, we uncover evidence of an emergent nonlinear internal representation of the board state. Interventional experiments indicate this representation can be used to control the output of the network and create \"latent saliency maps\" that can help explain predictions in human terms.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Deep Learning and representational learning", "paperhash": "li|emergent_world_representations_exploring_a_sequence_model_trained_on_a_synthetic_task", "pdf": "/pdf/70fb51a26cffdf3304e24f4d2e803b729904fe20.pdf", "supplementary_material": "", "_bibtex": "@inproceedings{\nli2023emergent,\ntitle={Emergent World Representations: Exploring a Sequence Model Trained on a Synthetic Task},\nauthor={Kenneth Li and Aspen K Hopkins and David Bau and Fernanda Vi{\\'e}gas and Hanspeter Pfister and Martin Wattenberg},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=DeG07_TcZvT}\n}", "venue": "ICLR 2023 notable top 5%", "venueid": "ICLR.cc/2023/Conference", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2210.13382/code)"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279186211, "odate": 1664468100000, "details": {"replyCount": 14}}, {"id": "VELL0PlWfc", "original": "OotgzXvP81j", "number": 1774, "cdate": 1663850002458, "mdate": null, "ddate": null, "tcdate": 1663850002458, "tmdate": 1697935691844, "tddate": null, "forum": "VELL0PlWfc", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Tailoring Language Generation Models under Total Variation Distance", "authorids": ["~Haozhe_Ji2", "~Pei_Ke2", "~Zhipeng_Hu1", "~Rongsheng_Zhang1", "~Minlie_Huang1"], "authors": ["Haozhe Ji", "Pei Ke", "Zhipeng Hu", "Rongsheng Zhang", "Minlie Huang"], "keywords": ["language generation", "maximum likelihood estimation", "total variation distance", "text degeneration"], "TL;DR": "We analyze total variation distance (TVD) as a robust metric to outliers and devise a new training objective based on TVD to alleviate text degeneration and improve the generation quality.", "abstract": "The standard paradigm of neural language generation adopts maximum likelihood estimation (MLE) as the optimizing method. From a distributional view, MLE in fact minimizes the Kullback-Leibler divergence (KLD) between the distribution of the real data and that of the model. However, this approach forces the model to distribute non-zero (sometimes large) probability mass to all training samples regardless of their quality. Moreover, in the attempt to cover the low-probability regions in the data distribution, the model systematically overestimates the probability of corrupted text sequences, which we conjecture is one of the main reasons for text degeneration during autoregressive decoding. To remedy this problem, we leverage the total variation distance (TVD) with its robustness to outliers, and develop practical bounds to apply it to language generation. Then, we introduce the TaiLr objective that balances the tradeoff of estimating TVD. Intuitively, TaiLr downweights real data samples that have low model probabilities with tunable penalization intensity. Experimental results show that our method alleviates the overestimation of degenerated sequences without sacrificing diversity and improves generation quality on a wide range of text generation tasks.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Applications (eg, speech processing, computer vision, NLP)", "paperhash": "ji|tailoring_language_generation_models_under_total_variation_distance", "pdf": "/pdf/222b0c66b1d6e4c664fc67e8d5d1348ae37c505e.pdf", "supplementary_material": "/attachment/ef08f4bee8dfab1f96ef459c9101e3e802a1e7fd.zip", "_bibtex": "@inproceedings{\nji2023tailoring,\ntitle={Tailoring Language Generation Models under Total Variation Distance},\nauthor={Haozhe Ji and Pei Ke and Zhipeng Hu and Rongsheng Zhang and Minlie Huang},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=VELL0PlWfc}\n}", "venue": "ICLR 2023 notable top 5%", "venueid": "ICLR.cc/2023/Conference", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 4 code implementations](https://www.catalyzex.com/paper/arxiv:2302.13344/code)"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279183953, "odate": 1664468100000, "details": {"replyCount": 11}}, {"id": "vhFu1Acb0xb", "original": "RxFuN-y-7kJ", "number": 1759, "cdate": 1663850000565, "mdate": null, "ddate": null, "tcdate": 1663850000565, "tmdate": 1677661406926, "tddate": null, "forum": "vhFu1Acb0xb", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Transformers are Sample-Efficient World Models", "authorids": ["~Vincent_Micheli1", "~Eloi_Alonso1", "~Fran\u00e7ois_Fleuret2"], "authors": ["Vincent Micheli", "Eloi Alonso", "Fran\u00e7ois Fleuret"], "keywords": ["deep learning", "reinforcement learning", "model-based reinforcement learning", "world models", "learning in imagination", "transformers", "discrete autoencoders", "generative modeling", "sequence modeling"], "TL;DR": "We introduce a data-efficient agent that learns in a world model composed of a discrete autoencoder and an autoregressive Transformer.", "abstract": "Deep reinforcement learning agents are notoriously sample inefficient, which considerably limits their application to real-world problems. Recently, many model-based methods have been designed to address this issue, with learning in the imagination of a world model being one of the most prominent approaches. However, while virtually unlimited interaction with a simulated environment sounds appealing, the world model has to be accurate over extended periods of time. Motivated by the success of Transformers in sequence modeling tasks, we introduce IRIS, a data-efficient agent that learns in a world model composed of a discrete autoencoder and an autoregressive Transformer. With the equivalent of only two hours of gameplay in the Atari 100k benchmark, IRIS achieves a mean human normalized score of 1.046, and outperforms humans on 10 out of 26 games, setting a new state of the art for methods without lookahead search. To foster future research on Transformers and world models for sample-efficient reinforcement learning, we release our code and models at https://github.com/eloialonso/iris.", "pdf": "/pdf/f23ea2080e754e26ad7f8a9f9a55865dd11f0a73.pdf", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)", "paperhash": "micheli|transformers_are_sampleefficient_world_models", "supplementary_material": "/attachment/b4793bcf47c6682c198e0bc06365b298c27344f9.zip", "_bibtex": "@inproceedings{\nmicheli2023transformers,\ntitle={Transformers are Sample-Efficient World Models},\nauthor={Vincent Micheli and Eloi Alonso and Fran{\\c{c}}ois Fleuret},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=vhFu1Acb0xb}\n}", "venue": "ICLR 2023 notable top 5%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279182978, "odate": 1664468100000, "details": {"replyCount": 12}}, {"id": "TD7AnQjNzR6", "original": "8IyLafgSxf", "number": 1578, "cdate": 1663849977610, "mdate": null, "ddate": null, "tcdate": 1663849977610, "tmdate": 1678055248234, "tddate": null, "forum": "TD7AnQjNzR6", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Statistical Efficiency of Score Matching: The View from Isoperimetry", "authorids": ["~Frederic_Koehler1", "aheckett@andrew.cmu.edu", "~Andrej_Risteski2"], "authors": ["Frederic Koehler", "Alexander Heckett", "Andrej Risteski"], "keywords": ["score matching", "log-Sobolev inequality", "isoperimetry", "relative efficiency", "sample complexity"], "TL;DR": "We show a tight connection between the statistical efficiency of score matching and the isoperimetric properties (e.g. log-Sobolev constant) of the distribution being estimated", "abstract": "  Deep generative models parametrized up to a normalizing constant (e.g. energy-based models) are difficult to train by maximizing the likelihood of the data because the likelihood and/or gradients thereof cannot be explicitly or efficiently written down. Score matching is a training method, whereby instead of fitting the likelihood $\\log p(x)$ for the training data, we instead fit the score function $\\nabla_x \\log p(x)$ --- obviating the need to evaluate the partition function. Though this estimator is known to be consistent, its unclear whether (and when) its statistical efficiency is comparable to that of maximum likelihood --- which is known to be (asymptotically) optimal. We initiate this line of inquiry in this paper, and show a tight connection between statistical efficiency of score matching and the isoperimetric properties of the distribution being estimated --- i.e. the Poincar\\'e, log-Sobolev and isoperimetric constant --- quantities which govern the mixing time of Markov processes like Langevin dynamics. Roughly, we show that the score matching estimator is statistically comparable to the maximum likelihood when the  distribution has a small isoperimetric constant. Conversely, if the distribution has a large isoperimetric constant --- even for simple families of distributions like exponential families with rich enough sufficient statistics --- score matching will be substantially less efficient than maximum likelihood. We suitably formalize these results both in the finite sample regime, and in the asymptotic regime. Finally, we identify a direct parallel in the discrete setting, where we connect the statistical properties of pseudolikelihood estimation with approximate tensorization of entropy and the Glauber dynamics.\n", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Theory (eg, control theory, learning theory, algorithmic game theory)", "paperhash": "koehler|statistical_efficiency_of_score_matching_the_view_from_isoperimetry", "pdf": "/pdf/650e8b5c38872cf721fff2c0b10c3e5fa039579b.pdf", "_bibtex": "@inproceedings{\nkoehler2023statistical,\ntitle={Statistical Efficiency of Score Matching: The View from Isoperimetry},\nauthor={Frederic Koehler and Alexander Heckett and Andrej Risteski},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=TD7AnQjNzR6}\n}", "venue": "ICLR 2023 notable top 5%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279172308, "odate": 1664468100000, "details": {"replyCount": 9}}, {"id": "0ypGZvm0er0", "original": "a2tE7mGVFa", "number": 1283, "cdate": 1663849943246, "mdate": null, "ddate": null, "tcdate": 1663849943246, "tmdate": 1697935744622, "tddate": null, "forum": "0ypGZvm0er0", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "View Synthesis with Sculpted Neural Points", "authorids": ["~Yiming_Zuo2", "~Jia_Deng1"], "authors": ["Yiming Zuo", "Jia Deng"], "keywords": [], "abstract": "We address the task of view synthesis, generating novel views of a scene given a set of images as input. In many recent works such as NeRF (Mildenhall et al., 2020), the scene geometry is parameterized using neural implicit representations (i.e., MLPs). Implicit neural representations have achieved impressive visual quality but have drawbacks in computational efficiency. In this work, we propose a new approach that performs view synthesis using point clouds. It is the first point-based method that achieves better visual quality than NeRF while being 100\u00d7 faster in rendering speed. Our approach builds on existing works on differentiable point-based rendering but introduces a novel technique we call \u201cSculpted Neural Points (SNP)\u201d, which significantly improves the robustness to errors and holes in the reconstructed point cloud. We further propose to use view-dependent point features based on spherical harmonics to capture non-Lambertian surfaces, and new designs in the point-based rendering pipeline that further boost the performance. Finally, we show that our system supports fine-grained scene editing. Code is available at https://github.com/princeton-vl/SNP.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Applications (eg, speech processing, computer vision, NLP)", "paperhash": "zuo|view_synthesis_with_sculpted_neural_points", "pdf": "/pdf/a844600e54c069b827ba8e0013a60b4a1193f97f.pdf", "supplementary_material": "/attachment/48cb4d26c510c2629c1b3743c42bc78bc250c882.zip", "_bibtex": "@inproceedings{\nzuo2023view,\ntitle={View Synthesis with Sculpted Neural Points},\nauthor={Yiming Zuo and Jia Deng},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=0ypGZvm0er0}\n}", "venue": "ICLR 2023 notable top 5%", "venueid": "ICLR.cc/2023/Conference", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2205.05869/code)"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279155763, "odate": 1664468100000, "details": {"replyCount": 7}}, {"id": "GcM7qfl5zY", "original": "f109AF8VQaf", "number": 1210, "cdate": 1663849934659, "mdate": null, "ddate": null, "tcdate": 1663849934659, "tmdate": 1678006207465, "tddate": null, "forum": "GcM7qfl5zY", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "AutoGT: Automated Graph Transformer Architecture Search", "authorids": ["~Zizhao_Zhang4", "~Xin_Wang17", "~Chaoyu_Guan1", "~Ziwei_Zhang1", "~Haoyang_Li1", "~Wenwu_Zhu1"], "authors": ["Zizhao Zhang", "Xin Wang", "Chaoyu Guan", "Ziwei Zhang", "Haoyang Li", "Wenwu Zhu"], "keywords": [], "abstract": "Although Transformer architectures have been successfully applied to graph data with the advent of Graph Transformer, current design of Graph Transformer still heavily relies on human labor and expertise knowledge to decide proper neural architectures and suitable graph encoding strategies at each Transformer layer. In literature, there have been some works on automated design of Transformers focusing on non-graph data such as texts and images without considering graph encoding strategies, which fail to handle the non-euclidean graph data. In this paper, we study the problem of automated graph Transformer, for the first time. However, solving these problems poses the following challenges: i) how can we design a unified search space for graph Transformer, and ii) how to deal with the coupling relations between Transformer architectures and the graph encodings of each Transformer layer. To address these challenges, we propose Automated Graph Transformer (AutoGT), a neural architecture search framework that can automatically discover the optimal graph Transformer architectures by joint optimization of Transformer architecture and graph encoding strategies. Specifically, we first propose a unified graph Transformer formulation that can represent most of state-of-the-art graph Transformer architectures. Based upon the unified formulation, we further design the graph Transformer search space that includes both candidate architectures and various graph encodings. To handle the coupling relations, we propose a novel encoding-aware performance estimation strategy by gradually training and splitting the supernets according to the correlations between graph encodings and architectures. The proposed strategy can provide a more consistent and fine-grained performance prediction when evaluating the jointly optimized graph encodings and architectures. Extensive experiments and ablation studies show that our proposed AutoGT gains sufficient improvement over state-of-the-art hand-crafted baselines on all datasets, demonstrating its effectiveness and wide applicability.\n", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Deep Learning and representational learning", "paperhash": "zhang|autogt_automated_graph_transformer_architecture_search", "pdf": "/pdf/ea1ae3473367dc3011d3f2b84c2b2192c39aee04.pdf", "_bibtex": "@inproceedings{\nzhang2023autogt,\ntitle={Auto{GT}: Automated Graph Transformer Architecture Search},\nauthor={Zizhao Zhang and Xin Wang and Chaoyu Guan and Ziwei Zhang and Haoyang Li and Wenwu Zhu},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=GcM7qfl5zY}\n}", "venue": "ICLR 2023 notable top 5%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279150912, "odate": 1664468100000, "details": {"replyCount": 9}}, {"id": "vSVLM2j9eie", "original": "cqThAxZQ57f", "number": 992, "cdate": 1663849909422, "mdate": null, "ddate": null, "tcdate": 1663849909422, "tmdate": 1677728596066, "tddate": null, "forum": "vSVLM2j9eie", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Crossformer: Transformer Utilizing Cross-Dimension Dependency for Multivariate Time Series Forecasting", "authorids": ["~Yunhao_Zhang1", "~Junchi_Yan2"], "authors": ["Yunhao Zhang", "Junchi Yan"], "keywords": ["Transformer", "multivariate time series forecasting", "deep learning"], "abstract": "Recently many deep models have been proposed for multivariate time series (MTS) forecasting. In particular, Transformer-based models have shown great potential because they can capture long-term dependency. However, existing Transformer-based models mainly focus on modeling the temporal dependency (cross-time dependency) yet often omit the dependency among different variables (cross-dimension dependency), which is critical for MTS forecasting. To fill the gap, we propose Crossformer, a Transformer-based model utilizing cross-dimension dependency for MTS forecasting. In Crossformer, the input MTS is embedded into a 2D vector array through the Dimension-Segment-Wise (DSW) embedding to preserve time and dimension information. Then the Two-Stage Attention (TSA) layer is proposed to efficiently capture the cross-time and cross-dimension dependency. Utilizing DSW embedding and TSA layer, Crossformer establishes a Hierarchical Encoder-Decoder (HED) to use the information at different scales for the final forecasting. Extensive experimental results on six real-world datasets show the effectiveness of Crossformer against previous state-of-the-arts.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Applications (eg, speech processing, computer vision, NLP)", "paperhash": "zhang|crossformer_transformer_utilizing_crossdimension_dependency_for_multivariate_time_series_forecasting", "TL;DR": "We propose Crossformer, a Transformer-based model that explicitly utilizes cross-dimension dependency for multivariate time series forecasting.", "pdf": "/pdf/1d793d6ba7c00ecfe98128614d58e2493255bd89.pdf", "_bibtex": "@inproceedings{\nzhang2023crossformer,\ntitle={Crossformer: Transformer Utilizing Cross-Dimension Dependency for Multivariate Time Series Forecasting},\nauthor={Yunhao Zhang and Junchi Yan},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=vSVLM2j9eie}\n}", "venue": "ICLR 2023 notable top 5%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279138361, "odate": 1664468100000, "details": {"replyCount": 21}}, {"id": "LV_MeMS38Q9", "original": "fu5URJcHPV4", "number": 963, "cdate": 1663849906080, "mdate": null, "ddate": null, "tcdate": 1663849906080, "tmdate": 1697935779030, "tddate": null, "forum": "LV_MeMS38Q9", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Betty: An Automatic Differentiation Library for Multilevel Optimization", "authorids": ["~Sang_Keun_Choe1", "~Willie_Neiswanger2", "~Pengtao_Xie3", "~Eric_Xing1"], "authors": ["Sang Keun Choe", "Willie Neiswanger", "Pengtao Xie", "Eric Xing"], "keywords": ["Multilevel Optimization", "Automatic Differentiation", "Bilevel Optimization", "Meta Learning", "Software Library"], "TL;DR": "We develop a scalable, user-friendly, and modular automatic differentiation library for multilevel optimization based on a novel interpretation of multilevel optimization as a dataflow graph.", "abstract": "Gradient-based multilevel optimization (MLO) has gained attention as a framework for studying numerous problems, ranging from hyperparameter optimization and meta-learning to neural architecture search and reinforcement learning. However, gradients in MLO, which are obtained by composing best-response Jacobians via the chain rule, are notoriously difficult to implement and memory/compute intensive. We take an initial step towards closing this gap by introducing Betty, a software library for large-scale MLO. At its core, we devise a novel dataflow graph for MLO, which allows us to (1) develop efficient automatic differentiation for MLO that reduces the computational complexity from $\\mathcal{O}(d^3)$ to $\\mathcal{O}(d^2)$, (2) incorporate systems support such as mixed-precision and data-parallel training for scalability, and (3) facilitate implementation of MLO programs of arbitrary complexity while allowing a modular interface for diverse algorithmic and systems design choices. We empirically demonstrate that Betty can be used to implement an array of MLO programs, while also observing up to 11% increase in test accuracy, 14% decrease in GPU memory usage, and 20% decrease in training wall time over existing implementations on multiple benchmarks. We also showcase that Betty enables scaling MLO to models with hundreds of millions of parameters. We open-source the code at https://github.com/leopard-ai/betty.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Infrastructure (eg, datasets, competitions, implementations, libraries)", "paperhash": "choe|betty_an_automatic_differentiation_library_for_multilevel_optimization", "pdf": "/pdf/e92379cd67840d63d8a85743600bfe396bcdf7fb.pdf", "supplementary_material": "/attachment/50604f54232b54885bc61c52e0d6de2f1634a8d4.zip", "_bibtex": "@inproceedings{\nchoe2023betty,\ntitle={Betty: An Automatic Differentiation Library for Multilevel Optimization},\nauthor={Sang Keun Choe and Willie Neiswanger and Pengtao Xie and Eric Xing},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=LV_MeMS38Q9}\n}", "venue": "ICLR 2023 notable top 5%", "venueid": "ICLR.cc/2023/Conference", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 2 code implementations](https://www.catalyzex.com/paper/arxiv:2207.02849/code)"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279137102, "odate": 1664468100000, "details": {"replyCount": 12}}, {"id": "ueYYgo2pSSU", "original": "XThy-VPfuER", "number": 657, "cdate": 1663849871946, "mdate": null, "ddate": null, "tcdate": 1663849871946, "tmdate": 1677756528062, "tddate": null, "forum": "ueYYgo2pSSU", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Offline RL with No OOD Actions: In-Sample Learning via Implicit Value Regularization", "authorids": ["~Haoran_Xu4", "~Li_Jiang4", "~Jianxiong_Li1", "~Zhuoran_Yang1", "~Zhaoran_Wang1", "~Victor_Wai_Kin_Chan1", "~Xianyuan_Zhan1"], "authors": ["Haoran Xu", "Li Jiang", "Jianxiong Li", "Zhuoran Yang", "Zhaoran Wang", "Victor Wai Kin Chan", "Xianyuan Zhan"], "keywords": ["Deep Reinforcement Learning", "Offline Reinforcement Learning", "Value Regularization", "Continuous Control"], "TL;DR": "We show that some form of Implicit Value Regularization (IVR) will result in the In-sample Learning paradigm in offline RL. We also propose a practical algorithm based on the IVR framework, which obtains new SOTA results.", "abstract": "Most offline reinforcement learning (RL) methods suffer from the trade-off between improving the policy to surpass the behavior policy and constraining the policy to limit the deviation from the behavior policy as computing $Q$-values using out-of-distribution (OOD) actions will suffer from errors due to distributional shift. The recent proposed \\textit{In-sample Learning} paradigm (i.e., IQL), which improves the policy by quantile regression using only data samples, shows great promise because it learns an optimal policy without querying the value function of any unseen actions. However, it remains unclear how this type of method handles the distributional shift in learning the value function. In this work, we make a key finding that the in-sample learning paradigm arises under the \\textit{Implicit Value Regularization} (IVR) framework. This gives a deeper understanding of why the in-sample learning paradigm works, i.e., it applies implicit value regularization to the policy. Based on the IVR framework, we further propose two practical algorithms, Sparse $Q$-learning (SQL) and Exponential $Q$-learning (EQL), which adopt the same value regularization used in existing works, but in a complete in-sample manner. Compared with IQL, we find that our algorithms introduce sparsity in learning the value function, making them more robust in noisy data regimes. We also verify the effectiveness of SQL and EQL on D4RL benchmark datasets and show the benefits of in-sample learning by comparing them with CQL in small data regimes. Code is available at \\url{https://github.com/ryanxhr/SQL}.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)", "paperhash": "xu|offline_rl_with_no_ood_actions_insample_learning_via_implicit_value_regularization", "pdf": "/pdf/dbd2c001478b511324bdbec3a393c6f1552fbb3d.pdf", "_bibtex": "@inproceedings{\nxu2023offline,\ntitle={Offline {RL} with No {OOD} Actions: In-Sample Learning via Implicit Value Regularization},\nauthor={Haoran Xu and Li Jiang and Jianxiong Li and Zhuoran Yang and Zhaoran Wang and Victor Wai Kin Chan and Xianyuan Zhan},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=ueYYgo2pSSU}\n}", "venue": "ICLR 2023 notable top 5%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279115745, "odate": 1664468100000, "details": {"replyCount": 15}}, {"id": "CPdc77SQfQ5", "original": "6GDvvge9l7", "number": 653, "cdate": 1663849871456, "mdate": null, "ddate": null, "tcdate": 1663849871456, "tmdate": 1677728998208, "tddate": null, "forum": "CPdc77SQfQ5", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Win: Weight-Decay-Integrated Nesterov Acceleration for Adaptive Gradient Algorithms", "authorids": ["~Pan_Zhou3", "~Xingyu_Xie1", "~Shuicheng_YAN3"], "authors": ["Pan Zhou", "Xingyu Xie", "Shuicheng YAN"], "keywords": ["Optimization acceleration in deep learning", "network optimizers", "deep learning optimizer", "deep learning algorithm"], "TL;DR": "We  propose a new and general Weight-decay-Integrated Nesterov acceleration for adaptive  algorithms to enhance their convergence speed, and also analyze their convergence  justify their convergence superiority. ", "abstract": "Training deep  networks on  large-scale datasets is computationally challenging.  In this work, we explore the problem of ``\\textit{how to  accelerate  adaptive gradient algorithms in a general manner}\", and aim to provide practical efficiency-boosting insights.   To this end, we   propose an effective and general   {Weight-decay-Integrated Nesterov acceleration} (Win) to accelerate adaptive  algorithms. Taking AdamW and Adam as examples,  we minimize a dynamical   loss per iteration which combines the vanilla training loss and a dynamic regularizer inspired by proximal point method (PPM) to improve the convexity of the problem. To introduce Nesterov-alike-acceleration into AdamW and Adam,  we respectively  use the  first- and second-order Taylor approximations of vanilla loss  to  update the variable  twice. In this way,  we arrive at  our Win acceleration  for AdamW and Adam that uses  a conservative step  and a  reckless step to update twice and then linearly combines these two updates for acceleration. Next,  we  extend  Win acceleration to LAMB and SGD. Our transparent acceleration derivation  could  provide insights for  other accelerated methods and their integration into  adaptive algorithms.  Besides, we prove the convergence of Win-accelerated adaptive  algorithms and  justify their convergence superiority over their non-accelerated counterparts by taking AdamW and Adam as examples.  Experimental results testify to the faster convergence speed and superior performance of our Win-accelerated AdamW, Adam, LAMB and SGD over their non-accelerated counterparts on vision classification tasks and  language modeling tasks with both CNN and Transformer backbones.  We hope Win  shall be a default acceleration option for  popular optimizers in deep learning community to improve the training efficiency. Code will be released at \\url{https://github.com/sail-sg/win}.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Deep Learning and representational learning", "paperhash": "zhou|win_weightdecayintegrated_nesterov_acceleration_for_adaptive_gradient_algorithms", "pdf": "/pdf/b3453f304fc9650f5fcaa04d42bafe01e1c5bd1a.pdf", "_bibtex": "@inproceedings{\nzhou2023win,\ntitle={Win: Weight-Decay-Integrated Nesterov Acceleration for Adaptive Gradient Algorithms},\nauthor={Pan Zhou and Xingyu Xie and Shuicheng YAN},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=CPdc77SQfQ5}\n}", "supplementary_material": "/attachment/8315eae99791a485116b3ad3b92bd7b664ab30c3.zip", "venue": "ICLR 2023 notable top 5%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279115578, "odate": 1664468100000, "details": {"replyCount": 16}}, {"id": "g2YraF75Tj", "original": "lmbGDK7W4bj", "number": 593, "cdate": 1663849865788, "mdate": null, "ddate": null, "tcdate": 1663849865788, "tmdate": 1697935813009, "tddate": null, "forum": "g2YraF75Tj", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Towards Stable Test-time Adaptation in Dynamic Wild World", "authorids": ["~Shuaicheng_Niu1", "~Jiaxiang_Wu1", "~Yifan_Zhang1", "~Zhiquan_Wen1", "~Yaofo_Chen1", "~Peilin_Zhao2", "~Mingkui_Tan2"], "authors": ["Shuaicheng Niu", "Jiaxiang Wu", "Yifan Zhang", "Zhiquan Wen", "Yaofo Chen", "Peilin Zhao", "Mingkui Tan"], "keywords": ["Test-time adaptation", "Roustness"], "TL;DR": "Propose a Sharpness-aware and Reliable entropy minimization method to make online test-time adaptation stable under wild test scenarios 1) small batch sizes; 2) mixed distribution shifts; 3) imbalanced online label distribution shifts.", "abstract": "Test-time adaptation (TTA) has shown to be effective at tackling distribution shifts between training and testing data by adapting a given model on test samples. However, the online model updating of TTA may be unstable and this is often a key obstacle preventing existing TTA methods from being deployed in the real world. Specifically, TTA may fail to improve or even harm the model performance when test data have: 1) mixed distribution shifts, 2) small batch sizes, and 3) online imbalanced label distribution shifts, which are quite common in practice. In this paper, we investigate the unstable reasons and find that the batch norm layer is a crucial factor hindering TTA stability. Conversely, TTA can perform more stably with batch-agnostic norm layers, i.e., group or layer norm. However, we observe that TTA with group and layer norms does not always succeed and still suffers many failure cases. By digging into the failure cases, we find that certain noisy test samples with large gradients may disturb the model adaption and result in collapsed trivial solutions, i.e., assigning the same class label for all samples. To address the above collapse issue, we propose a sharpness-aware and reliable entropy minimization method, called SAR, for further stabilizing TTA from two aspects: 1) remove partial noisy samples with large gradients, 2) encourage model weights to go to a flat minimum so that the model is robust to the remaining noisy samples. Promising results demonstrate that SAR performs more stably than prior methods and is computationally efficient under the above wild test scenarios. ", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Unsupervised and Self-supervised learning", "paperhash": "niu|towards_stable_testtime_adaptation_in_dynamic_wild_world", "pdf": "/pdf/4bf9a568654ef33fe83fe18f5e34b489be3ca06b.pdf", "_bibtex": "@inproceedings{\nniu2023towards,\ntitle={Towards Stable Test-time Adaptation in Dynamic Wild World},\nauthor={Shuaicheng Niu and Jiaxiang Wu and Yifan Zhang and Zhiquan Wen and Yaofo Chen and Peilin Zhao and Mingkui Tan},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=g2YraF75Tj}\n}", "venue": "ICLR 2023 notable top 5%", "venueid": "ICLR.cc/2023/Conference", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 7 code implementations](https://www.catalyzex.com/paper/arxiv:2302.12400/code)"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279112665, "odate": 1664468100000, "details": {"replyCount": 21}}, {"id": "2QGJXyMNoPz", "original": "sm5dUvZQhqX", "number": 537, "cdate": 1663849860323, "mdate": null, "ddate": null, "tcdate": 1663849860323, "tmdate": 1677783040434, "tddate": null, "forum": "2QGJXyMNoPz", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "MocoSFL: enabling cross-client collaborative self-supervised learning", "authorids": ["~Jingtao_Li1", "~Lingjuan_Lyu1", "daisuke.iso@sony.com", "~Chaitali_Chakrabarti1", "~Michael_Spranger2"], "authors": ["Jingtao Li", "Lingjuan Lyu", "Daisuke Iso", "Chaitali Chakrabarti", "Michael Spranger"], "keywords": ["Self-supervised Learning", "Collaborative Learning", "Split Federated Learning", "Momentum Contrast"], "TL;DR": "Existing collaborative SSL schemes are not suitable for cross-client applications because of their expensive computation and local data requirements. To address these issues, we propose MocoSFL based on Split Federated Learning and MoCo.", "abstract": "Existing collaborative self-supervised learning (SSL) schemes are not suitable for cross-client applications because of their expensive computation and large local data requirements. To address these issues, we propose MocoSFL, a collaborative SSL framework based on Split Federated Learning (SFL) and Momentum Contrast (MoCo). In MocoSFL, the large backbone model is split into a small client-side model and a large server-side model, and only the small client-side model is processed locally on the client's local devices. MocoSFL has three key components: (i) vector concatenation which enables the use of small batch size and reduces computation and memory requirements by orders of magnitude; (ii) feature sharing that helps achieve high accuracy regardless of the quality and volume of local data; (iii) frequent synchronization that helps achieve better non-IID performance because of smaller local model divergence. For a 1,000-client case with non-IID data (each client only has data from 2 random classes of CIFAR-10), MocoSFL can achieve over 84% accuracy with ResNet-18 model. Next we present TAResSFL module that significantly improves the resistance to privacy threats and communication overhead with small sacrifice in accuracy for a MocoSFL system. On a Raspberry Pi 4B device, the MocoSFL-based scheme requires less than 1MB of memory and less than 40MB of communication, and consumes less than 5W power. The code is available at https://github.com/SonyAI/MocoSFL.", "pdf": "/pdf/e7d98a4942f9fa3e0236bec53218b97e0792f3ee.pdf", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Unsupervised and Self-supervised learning", "paperhash": "li|mocosfl_enabling_crossclient_collaborative_selfsupervised_learning", "_bibtex": "@inproceedings{\nli2023mocosfl,\ntitle={Moco{SFL}: enabling cross-client collaborative self-supervised learning},\nauthor={Jingtao Li and Lingjuan Lyu and Daisuke Iso and Chaitali Chakrabarti and Michael Spranger},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=2QGJXyMNoPz}\n}", "venue": "ICLR 2023 notable top 5%", "venueid": "ICLR.cc/2023/Conference", "supplementary_material": "/attachment/ebcf468f684d290bcc742c1331dad3c7f5b890e2.zip"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279109373, "odate": 1664468100000, "details": {"replyCount": 14}}, {"id": "1NAzMofMnWl", "original": "WjG2nLOm37G", "number": 496, "cdate": 1663849856124, "mdate": null, "ddate": null, "tcdate": 1663849856124, "tmdate": 1677678377009, "tddate": null, "forum": "1NAzMofMnWl", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "DaxBench: Benchmarking Deformable Object Manipulation with Differentiable Physics", "authorids": ["~Siwei_Chen3", "~Yiqing_Xu1", "~Cunjun_Yu1", "~Linfeng_Li2", "~Xiao_Ma2", "~Zhongwen_Xu1", "~David_Hsu1"], "authors": ["Siwei Chen", "Yiqing Xu", "Cunjun Yu", "Linfeng Li", "Xiao Ma", "Zhongwen Xu", "David Hsu"], "keywords": ["deformable object manipulation", "differentiable physics", "benchmark"], "abstract": "Deformable object manipulation (DOM) is a long-standing challenge in robotics and has attracted significant interest recently. This paper presents DaXBench, a differentiable simulation framework for DOM. While existing work often focuses on a specific type of deformable objects, DaXBench supports fluid, rope, cloth ...; it provides a general-purpose benchmark to evaluate widely different DOM methods, including planning, imitation learning, and reinforcement learning. DaXBench combines recent advances in deformable object simulation with JAX, a high-performance computational framework. All DOM tasks in DaXBench are wrapped with the OpenAI Gym API for easy integration with DOM algorithms. We hope that DaXBench provides to the research community a comprehensive, standardized benchmark and a valuable tool to support the development and evaluation of new DOM methods. The code and video are available online.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Infrastructure (eg, datasets, competitions, implementations, libraries)", "paperhash": "chen|daxbench_benchmarking_deformable_object_manipulation_with_differentiable_physics", "pdf": "/pdf/3c5184bef72b67b8b06885038e921049f56dc94e.pdf", "supplementary_material": "/attachment/b0144952beb552a91c4702cb44ce0530e1818bc1.zip", "_bibtex": "@inproceedings{\nchen2023daxbench,\ntitle={DaxBench: Benchmarking Deformable Object Manipulation with Differentiable Physics},\nauthor={Siwei Chen and Yiqing Xu and Cunjun Yu and Linfeng Li and Xiao Ma and Zhongwen Xu and David Hsu},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=1NAzMofMnWl}\n}", "venue": "ICLR 2023 notable top 5%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279107248, "odate": 1664468100000, "details": {"replyCount": 9}}, {"id": "U2WjB9xxZ9q", "original": "KuMsq_UbqRu", "number": 463, "cdate": 1663849852599, "mdate": null, "ddate": null, "tcdate": 1663849852599, "tmdate": 1697935824709, "tddate": null, "forum": "U2WjB9xxZ9q", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "3D generation on ImageNet", "authorids": ["~Ivan_Skorokhodov1", "~Aliaksandr_Siarohin1", "~Yinghao_Xu1", "~Jian_Ren2", "~Hsin-Ying_Lee2", "~Peter_Wonka1", "~Sergey_Tulyakov1"], "authors": ["Ivan Skorokhodov", "Aliaksandr Siarohin", "Yinghao Xu", "Jian Ren", "Hsin-Ying Lee", "Peter Wonka", "Sergey Tulyakov"], "keywords": ["3d-generation", "gans", "generative adversarial networks", "knowledge distillation", "nerf", "stylegan", "radiance fields", "volume rendering"], "TL;DR": "3D generation on ImageNet", "abstract": "All existing 3D-from-2D generators are designed for well-curated single-category datasets, where all the objects have (approximately) the same scale, 3D location, and orientation, and the camera always points to the center of the scene. This makes them inapplicable to diverse, in-the-wild datasets of non-alignable scenes rendered from arbitrary camera poses. In this work, we develop a 3D generator with Generic Priors (3DGP): a 3D synthesis framework with more general assumptions about the training data, and show that it scales to very challenging datasets, like ImageNet. Our model is based on three new ideas. First, we incorporate an inaccurate off-the-shelf depth estimator into 3D GAN training via a special depth adaptation module to handle the imprecision. Then, we create a flexible camera model and a regularization strategy for it to learn its distribution parameters during training. Finally, we extend the recent ideas of transferring knowledge from pretrained classifiers into GANs for patch-wise trained models by employing a simple distillation-based technique on top of the discriminator. It achieves more stable training than the existing methods and speeds up the convergence by at least 40%. We explore our model on four datasets: SDIP Dogs $256^2$, SDIP Elephants $256^2$, LSUN Horses $256^2$, and ImageNet $256^2$ and demonstrate that 3DGP outperforms the recent state-of-the-art in terms of both texture and geometry quality. Code and visualizations: https://snap-research.github.io/3dgp.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Generative models", "paperhash": "skorokhodov|3d_generation_on_imagenet", "pdf": "/pdf/303cbc4bcfff52f24148569ddc61d7213ad090eb.pdf", "_bibtex": "@inproceedings{\nskorokhodov2023d,\ntitle={3D generation on ImageNet},\nauthor={Ivan Skorokhodov and Aliaksandr Siarohin and Yinghao Xu and Jian Ren and Hsin-Ying Lee and Peter Wonka and Sergey Tulyakov},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=U2WjB9xxZ9q}\n}", "venue": "ICLR 2023 notable top 5%", "venueid": "ICLR.cc/2023/Conference", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 4 code implementations](https://www.catalyzex.com/paper/arxiv:2303.01416/code)"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279103873, "odate": 1664468100000, "details": {"replyCount": 20}}, {"id": "r9hNv76KoT3", "original": "Rmnbgzx7BO", "number": 453, "cdate": 1663849851345, "mdate": null, "ddate": null, "tcdate": 1663849851345, "tmdate": 1697935825773, "tddate": null, "forum": "r9hNv76KoT3", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Rethinking the Expressive Power of GNNs via Graph Biconnectivity", "authorids": ["~Bohang_Zhang1", "~Shengjie_Luo1", "~Liwei_Wang1", "~Di_He1"], "authors": ["Bohang Zhang", "Shengjie Luo", "Liwei Wang", "Di He"], "keywords": ["Graph Neural Networks", "Expressive Power", "Weisfeiler-Lehman test", "Graph Transformer", "Biconnectivity"], "abstract": "Designing expressive Graph Neural Networks (GNNs) is a central topic in learning graph-structured data. While numerous approaches have been proposed to improve GNNs with respect to the Weisfeiler-Lehman (WL) test, for most of them, there is still a lack of deep understanding of what additional power they can systematically and provably gain. In this paper, we take a fundamentally different perspective to study the expressive power of GNNs beyond the WL test. Specifically, we introduce a novel class of expressivity metrics via graph biconnectivity and highlight their importance in both theory and practice. As biconnectivity can be easily calculated using simple algorithms that have linear computational costs, it is natural to expect that popular GNNs can learn it easily as well. However, after a thorough review of prior GNN architectures, we surprisingly find that most of them are not expressive for any of these metrics. The only exception is the ESAN framework (Bevilacqua et al., 2022), for which we give a theoretical justification of its power. We proceed to introduce a principled and more efficient approach, called the Generalized Distance Weisfeiler-Lehman (GD-WL), which is provably expressive for all biconnectivity metrics. Practically, we show GD-WL can be implemented by a Transformer-like architecture that preserves expressiveness and enjoys full parallelizability. A set of experiments on both synthetic and real datasets demonstrates that our approach can consistently outperform prior GNN architectures.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Deep Learning and representational learning", "paperhash": "zhang|rethinking_the_expressive_power_of_gnns_via_graph_biconnectivity", "pdf": "/pdf/be0ebeff1b3c008481709874f052f374a1d68dec.pdf", "_bibtex": "@inproceedings{\nzhang2023rethinking,\ntitle={Rethinking the Expressive Power of {GNN}s via Graph Biconnectivity},\nauthor={Bohang Zhang and Shengjie Luo and Liwei Wang and Di He},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=r9hNv76KoT3}\n}", "venue": "ICLR 2023 notable top 5%", "venueid": "ICLR.cc/2023/Conference", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2301.09505/code)"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279101311, "odate": 1664468100000, "details": {"replyCount": 13}}, {"id": "RecZ9nB9Q4", "original": "xWBBtH5z8S", "number": 432, "cdate": 1663849849059, "mdate": null, "ddate": null, "tcdate": 1663849849059, "tmdate": 1677766473128, "tddate": null, "forum": "RecZ9nB9Q4", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Sparse Mixture-of-Experts are Domain Generalizable Learners", "authorids": ["~Bo_Li23", "~Yifei_Shen1", "~Jingkang_Yang1", "~Yezhen_Wang1", "~Jiawei_Ren1", "~Tong_Che1", "~Jun_Zhang25", "~Ziwei_Liu1"], "authors": ["Bo Li", "Yifei Shen", "Jingkang Yang", "Yezhen Wang", "Jiawei Ren", "Tong Che", "Jun Zhang", "Ziwei Liu"], "keywords": ["domain generalization", "mixture-of-experts", "algorithmic alignment", "visual attributes"], "TL;DR": "We theoretically investigate the impact of backbone architecture on DG. We propose a novel SOTA model Generalizable Mixture-of-Experts (GMoE) for DG.", "abstract": "Human visual perception can easily generalize to out-of-distributed visual data, which is far beyond the capability of modern machine learning models. Domain generalization (DG) aims to close this gap, with existing DG methods mainly focusing on the loss function design. In this paper, we propose to explore an orthogonal direction, i.e., the design of the backbone architecture. It is motivated by an empirical finding that transformer-based models trained with empirical risk minimization (ERM) outperform CNN-based models employing state-of-the-art (SOTA) DG algorithms on multiple DG datasets. We develop a formal framework to characterize a network's robustness to distribution shifts by studying its architecture's alignment with the correlations in the dataset. This analysis guides us to propose a novel DG model built upon vision transformers, namely \\emph{Generalizable Mixture-of-Experts (GMoE)}. Extensive experiments on DomainBed demonstrate that GMoE trained with ERM outperforms SOTA DG baselines by a large margin. Moreover, GMoE is complementary to existing DG methods and its performance is substantially improved when trained with DG algorithms.", "pdf": "/pdf/7bdb46ea980861f27d1fc50dacde68ac444c5231.pdf", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Deep Learning and representational learning", "paperhash": "li|sparse_mixtureofexperts_are_domain_generalizable_learners", "supplementary_material": "/attachment/78b2842e3cfed8bd0a85fcfe29c68bb81c9e412f.zip", "_bibtex": "@inproceedings{\nli2023sparse,\ntitle={Sparse Mixture-of-Experts are Domain Generalizable Learners},\nauthor={Bo Li and Yifei Shen and Jingkang Yang and Yezhen Wang and Jiawei Ren and Tong Che and Jun Zhang and Ziwei Liu},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=RecZ9nB9Q4}\n}", "venue": "ICLR 2023 notable top 5%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279098412, "odate": 1664468100000, "details": {"replyCount": 15}}, {"id": "JroZRaRw7Eu", "original": "ut6ha7EfMAM", "number": 391, "cdate": 1663849843866, "mdate": null, "ddate": null, "tcdate": 1663849843866, "tmdate": 1697935830748, "tddate": null, "forum": "JroZRaRw7Eu", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Token Merging: Your ViT But Faster", "authorids": ["~Daniel_Bolya1", "~Cheng-Yang_Fu1", "~Xiaoliang_Dai1", "~Peizhao_Zhang1", "~Christoph_Feichtenhofer4", "~Judy_Hoffman1"], "authors": ["Daniel Bolya", "Cheng-Yang Fu", "Xiaoliang Dai", "Peizhao Zhang", "Christoph Feichtenhofer", "Judy Hoffman"], "keywords": ["token merging", "token pruning", "inference speed", "training speed", "throughput", "off-the-shelf", "fine tuning"], "TL;DR": "We merge tokens in a ViT at runtime using a fast custom matching algorithm. Our method, ToMe, can increase training and inference speed, lower training memory, and can be applied with and without training.", "abstract": "We introduce Token Merging (ToMe), a simple method to increase the throughput of existing ViT models without needing to train. ToMe gradually combines similar tokens in a transformer using a general and light-weight matching algorithm that is as fast as pruning while being more accurate. Off-the-shelf, ToMe can 2x the throughput of state-of-the-art ViT-L @ 512 and ViT-H @ 518 models on images and 2.2x the throughput of ViT-L on video with only a 0.2-0.3% accuracy drop in each case. ToMe can also easily be applied during training, improving in practice training speed up to 2x for MAE fine-tuning on video. Training with ToMe further minimizes accuracy drop, leading to 2x the throughput of ViT-B on audio for only a 0.4% mAP drop. Qualitatively, we find that ToMe merges object parts into one token, even over multiple frames of video. Overall, ToMe\u2019s accuracy and speed are competitive with state-of-the-art on images, video, and audio.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Deep Learning and representational learning", "paperhash": "bolya|token_merging_your_vit_but_faster", "pdf": "/pdf/ef10c4387f0309b8f942d720fdb3ed5bc6ec5b30.pdf", "_bibtex": "@inproceedings{\nbolya2023token,\ntitle={Token Merging: Your ViT But Faster},\nauthor={Daniel Bolya and Cheng-Yang Fu and Xiaoliang Dai and Peizhao Zhang and Christoph Feichtenhofer and Judy Hoffman},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=JroZRaRw7Eu}\n}", "venue": "ICLR 2023 notable top 5%", "venueid": "ICLR.cc/2023/Conference", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2210.09461/code)"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279096914, "odate": 1664468100000, "details": {"replyCount": 13}}, {"id": "FeWvD0L_a4", "original": "BcSK4kBHmsQ", "number": 219, "cdate": 1663849825354, "mdate": null, "ddate": null, "tcdate": 1663849825354, "tmdate": 1677744956404, "tddate": null, "forum": "FeWvD0L_a4", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Learnable Behavior Control: Breaking Atari Human World Records via Sample-Efficient Behavior Selection", "authorids": ["~Jiajun_Fan1", "~Yuzheng_Zhuang1", "~Yuecheng_Liu2", "~Jianye_HAO1", "~Bin_Wang12", "~Jiangcheng_Zhu1", "~Hao_Wang25", "~Shu-Tao_Xia1"], "authors": ["Jiajun Fan", "Yuzheng Zhuang", "Yuecheng Liu", "Jianye HAO", "Bin Wang", "Jiangcheng Zhu", "Hao Wang", "Shu-Tao Xia"], "keywords": ["Deep Reinforcement Learning", "The Arcade Learning Environment", "Human World Records", "Behavioral Control"], "TL;DR": "We have constructed a general framework to control the behaviors in RL  and achieved SOTA performance in Atari 1B benchmark.", "abstract": "The exploration problem is one of the main challenges in deep reinforcement learning (RL). Recent promising works tried to handle the problem with population-based methods, which collect samples with diverse behaviors derived from a population of different exploratory policies. Adaptive policy selection has been adopted for behavior control. However, the behavior selection space is largely limited by the predefined policy population, which further limits behavior diversity.  In this paper, we propose a general framework called Learnable Behavioral Control (LBC) to address the limitation, which a) enables a significantly enlarged behavior selection space via formulating a hybrid behavior mapping from all policies; b) constructs a unified learnable process for behavior selection. We introduce LBC into distributed off-policy actor-critic methods and achieve behavior control via optimizing the selection of the behavior mappings with bandit-based meta-controllers. Our agents have achieved 10077.52% mean human normalized score and surpassed 24 human world records within 1B training frames in the Arcade Learning Environment, which demonstrates our significant state-of-the-art (SOTA) performance without degrading the sample efficiency.", "pdf": "/pdf/6576875018fe482d865d62a571a8b8df3278b360.pdf", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "supplementary_material": "/attachment/6746eb48c97dfbd01313f76908b65a38fde4a943.zip", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)", "paperhash": "fan|learnable_behavior_control_breaking_atari_human_world_records_via_sampleefficient_behavior_selection", "_bibtex": "@inproceedings{\nfan2023learnable,\ntitle={Learnable Behavior Control: Breaking Atari Human World Records via Sample-Efficient Behavior Selection},\nauthor={Jiajun Fan and Yuzheng Zhuang and Yuecheng Liu and Jianye HAO and Bin Wang and Jiangcheng Zhu and Hao Wang and Shu-Tao Xia},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=FeWvD0L_a4}\n}", "venue": "ICLR 2023 notable top 5%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279089896, "odate": 1664468100000, "details": {"replyCount": 6}}, {"id": "awnvqZja69", "original": "IC-EA9-GM-j", "number": 210, "cdate": 1663849824286, "mdate": null, "ddate": null, "tcdate": 1663849824286, "tmdate": 1697935847562, "tddate": null, "forum": "awnvqZja69", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Image as Set of Points", "authorids": ["~Xu_Ma2", "~Yuqian_Zhou2", "~Huan_Wang3", "~Can_Qin1", "~Bin_Sun1", "~Chang_Liu13", "~Yun_Fu1"], "authors": ["Xu Ma", "Yuqian Zhou", "Huan Wang", "Can Qin", "Bin Sun", "Chang Liu", "Yun Fu"], "keywords": ["Clustering", "Image Processing", "Context Cluster", "Representation"], "TL;DR": "We introduce Context Cluster, a new paradigm that considers an image as a set of point and employs clustering method for feature extraction.", "abstract": "\nWhat is an image, and how to extract latent features? \nConvolutional Networks (ConvNets) consider an image as organized pixels in a rectangular shape and extract features via convolutional operation in a local region; Vision Transformers (ViTs) treat an image as a sequence of patches and extract features via attention mechanism in a global range. In this work, we introduce a straightforward and promising paradigm for visual representation, which is called Context Clusters. Context clusters (CoCs) view an image as a set of unorganized points and extract features via a simplified clustering algorithm. In detail, each point includes the raw feature (e.g., color) and positional information (e.g., coordinates), and a simplified clustering algorithm is employed to group and extract deep features hierarchically. Our CoCs are convolution- and attention-free, only relying on clustering algorithm for spatial interaction. Owing to the simple design, we show CoCs endow gratifying interpretability via the visualization of the clustering process.  \nOur CoCs aim at providing a new perspective on image and visual representation, which may enjoy broad applications in different domains and exhibit profound insights. Even though we are not targeting SOTA performance, COCs still achieve comparable or even better performance than ConvNets or ViTs on several benchmarks.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Deep Learning and representational learning", "paperhash": "ma|image_as_set_of_points", "pdf": "/pdf/839da9c992ee84a8fa5be183d987fa55966e54ff.pdf", "_bibtex": "@inproceedings{\nma2023image,\ntitle={Image as Set of Points},\nauthor={Xu Ma and Yuqian Zhou and Huan Wang and Can Qin and Bin Sun and Chang Liu and Yun Fu},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=awnvqZja69}\n}", "venue": "ICLR 2023 notable top 5%", "venueid": "ICLR.cc/2023/Conference", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 2 code implementations](https://www.catalyzex.com/paper/arxiv:2303.01494/code)"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279089156, "odate": 1664468100000, "details": {"replyCount": 20}}], "count": 90}