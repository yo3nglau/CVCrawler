{"notes": [{"id": "FPCMqjI0jXN", "original": "DBnJpoqg_XF", "number": 4597, "cdate": 1632875763332, "mdate": null, "ddate": null, "tcdate": 1632875763332, "tmdate": 1697934508408, "tddate": null, "forum": "FPCMqjI0jXN", "replyto": null, "invitation": "ICLR.cc/2022/Conference/-/Blind_Submission", "content": {"title": "Domino: Discovering Systematic Errors with Cross-Modal Embeddings", "authorids": ["~Sabri_Eyuboglu1", "~Maya_Varma1", "~Khaled_Kamal_Saab1", "~Jean-Benoit_Delbrouck1", "~Christopher_Lee-Messer1", "~Jared_Dunnmon1", "~James_Zou1", "~Christopher_Re1"], "authors": ["Sabri Eyuboglu", "Maya Varma", "Khaled Kamal Saab", "Jean-Benoit Delbrouck", "Christopher Lee-Messer", "Jared Dunnmon", "James Zou", "Christopher Re"], "keywords": ["robustness", "subgroup analysis", "error analysis", "multimodal", "slice discovery"], "abstract": "Machine learning models that achieve high overall accuracy often make systematic errors on important subsets (or slices) of data. Identifying underperforming slices is particularly challenging when working with high-dimensional inputs (e.g. images, audio), where important slices are often unlabeled. In order to address this issue, recent studies have proposed automated slice discovery methods (SDMs), which leverage learned model representations to mine input data for slices on which a model performs poorly. To be useful to a practitioner, these methods must identify slices that are both underperforming and coherent (i.e. united by a human-understandable concept). However, no quantitative evaluation framework currently exists for rigorously assessing SDMs with respect to these criteria. Additionally, prior qualitative evaluations have shown that SDMs often identify slices that are incoherent. In this work, we address these challenges by first designing a principled evaluation framework that enables a quantitative comparison of SDMs across 1,235 slice discovery settings in three input domains (natural images, medical images, and time-series data).\nThen, motivated by the recent development of powerful cross-modal representation learning approaches, we present Domino, an SDM that leverages cross-modal embeddings and a novel error-aware mixture model to discover and describe coherent slices. We find that Domino accurately identifies 36% of the 1,235 slices in our framework -- a 12 percentage point improvement over prior methods. Further, Domino is the first SDM that can provide natural language descriptions of identified slices, correctly generating the exact name of the slice in 35% of settings. ", "code_of_ethics": "", "submission_guidelines": "", "resubmission": "", "student_author": "", "serve_as_reviewer": "", "paperhash": "eyuboglu|domino_discovering_systematic_errors_with_crossmodal_embeddings", "pdf": "/pdf/a5ca838a35d810400cfa090453cd85abe02ab6b0.pdf", "data": "", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 5 code implementations](https://www.catalyzex.com/paper/arxiv:2203.14960/code)", "_bibtex": "@inproceedings{\neyuboglu2022domino,\ntitle={Domino: Discovering Systematic Errors with Cross-Modal Embeddings},\nauthor={Sabri Eyuboglu and Maya Varma and Khaled Kamal Saab and Jean-Benoit Delbrouck and Christopher Lee-Messer and Jared Dunnmon and James Zou and Christopher Re},\nbooktitle={International Conference on Learning Representations},\nyear={2022},\nurl={https://openreview.net/forum?id=FPCMqjI0jXN}\n}", "venue": "ICLR 2022 Oral", "venueid": "ICLR.cc/2022/Conference"}, "signatures": ["ICLR.cc/2022/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2022/Conference"], "pdate": 1643407560000, "odate": 1633539600000, "details": {"replyCount": 14}}, {"id": "NudBMY-tzDr", "original": "QlZFYtuzaOmW", "number": 4559, "cdate": 1632875760922, "mdate": null, "ddate": null, "tcdate": 1632875760922, "tmdate": 1697934510686, "tddate": null, "forum": "NudBMY-tzDr", "replyto": null, "invitation": "ICLR.cc/2022/Conference/-/Blind_Submission", "content": {"title": "Natural Language Descriptions of Deep Visual Features", "authorids": ["~Evan_Hernandez1", "~Sarah_Schwettmann2", "~David_Bau1", "~Teona_Bagashvili1", "~Antonio_Torralba1", "~Jacob_Andreas1"], "authors": ["Evan Hernandez", "Sarah Schwettmann", "David Bau", "Teona Bagashvili", "Antonio Torralba", "Jacob Andreas"], "keywords": [], "abstract": "Some neurons in deep networks specialize in recognizing highly specific perceptual, structural, or semantic features of inputs. In computer vision, techniques exist for identifying neurons that respond to individual concept categories like colors, textures, and object classes. But these techniques are limited in scope, labeling only a small subset of neurons and behaviors in any network. Is a richer characterization of neuron-level computation possible? We introduce a procedure (called MILAN, for mutual information-guided linguistic annotation of neurons) that automatically labels neurons with open-ended, compositional, natural language descriptions. Given a neuron, MILAN generates a description by searching for a natural language string that maximizes pointwise mutual information with the image regions in which the neuron is active. MILAN produces fine-grained descriptions that capture categorical, relational, and logical structure in learned features. These descriptions obtain high agreement with human-generated feature descriptions across a diverse set of model architectures and tasks, and can aid in understanding and controlling learned models. We highlight three applications of natural language neuron descriptions. First, we use MILAN for analysis, characterizing the distribution and importance of neurons selective for attribute, category, and relational information in vision models. Second, we use MILAN for auditing, surfacing neurons sensitive to human faces in datasets designed to obscure them. Finally, we use MILAN for editing, improving robustness in an image classifier by deleting neurons sensitive to text features spuriously correlated with class labels.", "pdf": "/pdf/842234024e58a8d5073a88b3c04282011b8e20a7.pdf", "code_of_ethics": "", "submission_guidelines": "", "resubmission": "", "student_author": "", "serve_as_reviewer": "", "paperhash": "hernandez|natural_language_descriptions_of_deep_visual_features", "data": "", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2201.11114/code)", "_bibtex": "@inproceedings{\nhernandez2022natural,\ntitle={Natural Language Descriptions of Deep Features},\nauthor={Evan Hernandez and Sarah Schwettmann and David Bau and Teona Bagashvili and Antonio Torralba and Jacob Andreas},\nbooktitle={International Conference on Learning Representations},\nyear={2022},\nurl={https://openreview.net/forum?id=NudBMY-tzDr}\n}", "venue": "ICLR 2022 Oral", "venueid": "ICLR.cc/2022/Conference"}, "signatures": ["ICLR.cc/2022/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2022/Conference"], "pdate": 1643407560000, "odate": 1633539600000, "details": {"replyCount": 13}}, {"id": "tYRrOdSnVUy", "original": "cZFyD1Edo7e", "number": 4491, "cdate": 1632875756321, "mdate": null, "ddate": null, "tcdate": 1632875756321, "tmdate": 1676330449209, "tddate": null, "forum": "tYRrOdSnVUy", "replyto": null, "invitation": "ICLR.cc/2022/Conference/-/Blind_Submission", "content": {"title": "Non-Transferable Learning: A New Approach for Model Ownership Verification and Applicability Authorization", "authorids": ["~Lixu_Wang1", "~Shichao_Xu1", "~Ruiqi_Xu1", "~Xiao_Wang11", "~Qi_Zhu2"], "authors": ["Lixu Wang", "Shichao Xu", "Ruiqi Xu", "Xiao Wang", "Qi Zhu"], "keywords": ["Domain Adaptation", "Transfer Learning", "Societal Considerations of Representation Learning", "Model Watermark"], "abstract": "As Artificial Intelligence as a Service gains popularity, protecting well-trained models as intellectual property is becoming increasingly important. There are two common types of protection methods: ownership verification and usage authorization. In this paper, we propose Non-Transferable Learning (NTL), a novel approach that captures the exclusive data representation in the learned model and restricts the model generalization ability to certain domains. This approach provides effective solutions to both model verification and authorization. Specifically: 1) For ownership verification, watermarking techniques are commonly used but are often vulnerable to sophisticated watermark removal methods. By comparison, our NTL-based ownership verification provides robust resistance to state-of-the-art watermark removal methods, as shown in extensive experiments with 6 removal approaches over the digits, CIFAR10 & STL10, and VisDA datasets. 2) For usage authorization, prior solutions focus on authorizing specific users to access the model, but authorized users can still apply the model to any data without restriction. Our NTL-based authorization approach instead provides data-centric protection, which we call applicability authorization, by significantly degrading the performance of the model on unauthorized data. Its effectiveness is also shown through experiments on aforementioned datasets. ", "code_of_ethics": "", "submission_guidelines": "", "resubmission": "", "student_author": "", "serve_as_reviewer": "", "paperhash": "wang|nontransferable_learning_a_new_approach_for_model_ownership_verification_and_applicability_authorization", "pdf": "/pdf/cc0b829e495ebd36c4e0dcce6f5d044ad4dce58d.pdf", "one-sentence_summary": "We propose a novel Non-Transferable Learning (NTL) method to restrict the model generalization ability to certain domains for model ownership verification and applicability authorization.", "supplementary_material": "", "data": "", "_bibtex": "@inproceedings{\nwang2022nontransferable,\ntitle={Non-Transferable Learning: A New Approach for Model Ownership Verification and Applicability Authorization},\nauthor={Lixu Wang and Shichao Xu and Ruiqi Xu and Xiao Wang and Qi Zhu},\nbooktitle={International Conference on Learning Representations},\nyear={2022},\nurl={https://openreview.net/forum?id=tYRrOdSnVUy}\n}", "venue": "ICLR 2022 Oral", "venueid": "ICLR.cc/2022/Conference"}, "signatures": ["ICLR.cc/2022/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2022/Conference"], "pdate": 1643407560000, "odate": 1633539600000, "details": {"replyCount": 12}}, {"id": "YWNAX0caEjI", "original": "6oHJkMbmZC", "number": 4412, "cdate": 1632875751208, "mdate": null, "ddate": null, "tcdate": 1632875751208, "tmdate": 1697934521154, "tddate": null, "forum": "YWNAX0caEjI", "replyto": null, "invitation": "ICLR.cc/2022/Conference/-/Blind_Submission", "content": {"title": "Neural Structured Prediction for Inductive Node Classification", "authorids": ["~Meng_Qu2", "~Huiyu_Cai1", "~Jian_Tang1"], "authors": ["Meng Qu", "Huiyu Cai", "Jian Tang"], "keywords": [], "abstract": "This paper studies node classification in the inductive setting, i.e., aiming to learn a model on labeled training graphs and generalize it to infer node labels on unlabeled test graphs. This problem has been extensively studied with graph neural networks (GNNs) by learning effective node representations, as well as traditional structured prediction methods for modeling the structured output of node labels, e.g., conditional random fields (CRFs). In this paper, we present a new approach called the Structured Proxy Network (SPN), which combines the advantages of both worlds. SPN defines flexible potential functions of CRFs with GNNs. However, learning such a model is nontrivial as it involves optimizing a maximin game with high-cost inference. Inspired by the underlying connection between joint and marginal distributions defined by Markov networks, we propose to solve an approximate version of the optimization problem as a proxy, which yields a near-optimal solution, making learning more efficient. Extensive experiments on two settings show that our approach outperforms many competitive baselines.", "code_of_ethics": "", "submission_guidelines": "", "resubmission": "", "student_author": "", "serve_as_reviewer": "", "paperhash": "qu|neural_structured_prediction_for_inductive_node_classification", "pdf": "/pdf/df1b628202430dff01a7eeed5b5e5a2e703d1bad.pdf", "supplementary_material": "", "data": "", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 2 code implementations](https://www.catalyzex.com/paper/arxiv:2204.07524/code)", "_bibtex": "@inproceedings{\nqu2022neural,\ntitle={Neural Structured Prediction for Inductive Node Classification},\nauthor={Meng Qu and Huiyu Cai and Jian Tang},\nbooktitle={International Conference on Learning Representations},\nyear={2022},\nurl={https://openreview.net/forum?id=YWNAX0caEjI}\n}", "venue": "ICLR 2022 Oral", "venueid": "ICLR.cc/2022/Conference"}, "signatures": ["ICLR.cc/2022/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2022/Conference"], "pdate": 1643407560000, "odate": 1633539600000, "details": {"replyCount": 21}}, {"id": "uxgg9o7bI_3", "original": "dTCfEPq3MWu", "number": 4320, "cdate": 1632875745150, "mdate": null, "ddate": null, "tcdate": 1632875745150, "tmdate": 1676330456889, "tddate": null, "forum": "uxgg9o7bI_3", "replyto": null, "invitation": "ICLR.cc/2022/Conference/-/Blind_Submission", "content": {"title": "A New Perspective on \"How Graph Neural Networks Go Beyond Weisfeiler-Lehman?\"", "authorids": ["~Asiri_Wijesinghe1", "~Qing_Wang14"], "authors": ["Asiri Wijesinghe", "Qing Wang"], "keywords": ["Graph Neural Networks", "Graph Isomorphism", "Weisfeiler Lehman"], "abstract": "We propose a new perspective on designing powerful Graph Neural Networks (GNNs). In a nutshell, this enables a general solution to inject structural properties of graphs into a message-passing aggregation scheme of GNNs. As a theoretical basis, we develop a new hierarchy of local isomorphism on neighborhood subgraphs. Then, we theoretically characterize how message-passing GNNs can be designed to be more expressive than the Weisfeiler Lehman test. To elaborate this characterization, we propose a novel neural model, called GraphSNN, and prove that this model is strictly more expressive than the Weisfeiler Lehman test in distinguishing graph structures. We empirically verify the strength of our model on different graph learning tasks. It is shown that our model consistently improves the state-of-the-art methods on the benchmark tasks without sacrificing computational simplicity and efficiency.", "code_of_ethics": "", "submission_guidelines": "", "resubmission": "", "student_author": "", "serve_as_reviewer": "", "paperhash": "wijesinghe|a_new_perspective_on_how_graph_neural_networks_go_beyond_weisfeilerlehman", "pdf": "/pdf/376e7da3d7f86a2bd40cd51fadfc278e94372443.pdf", "supplementary_material": "/attachment/933ba75f12d12c8e12bde0edcad6fc41e3aaf1a4.zip", "data": "", "_bibtex": "@inproceedings{\nwijesinghe2022a,\ntitle={A New Perspective on ''How Graph Neural Networks Go Beyond Weisfeiler-Lehman?''},\nauthor={Asiri Wijesinghe and Qing Wang},\nbooktitle={International Conference on Learning Representations},\nyear={2022},\nurl={https://openreview.net/forum?id=uxgg9o7bI_3}\n}", "venue": "ICLR 2022 Oral", "venueid": "ICLR.cc/2022/Conference"}, "signatures": ["ICLR.cc/2022/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2022/Conference"], "pdate": 1643407560000, "odate": 1633539600000, "details": {"replyCount": 24}}, {"id": "LdlwbBP2mlq", "original": "4xIPiBYolul", "number": 4253, "cdate": 1632875740859, "mdate": null, "ddate": null, "tcdate": 1632875740859, "tmdate": 1676330460125, "tddate": null, "forum": "LdlwbBP2mlq", "replyto": null, "invitation": "ICLR.cc/2022/Conference/-/Blind_Submission", "content": {"title": "Minibatch vs Local SGD with Shuffling: Tight Convergence Bounds and Beyond", "authorids": ["~Chulhee_Yun1", "~Shashank_Rajput1", "~Suvrit_Sra1"], "authors": ["Chulhee Yun", "Shashank Rajput", "Suvrit Sra"], "keywords": ["Local SGD", "Minibatch SGD", "Shuffling", "Without-replacement", "Convex Optimization", "Stochastic Optimization", "Federated Learning", "Large Scale Learning", "Distributed Learning"], "abstract": "In distributed learning, local SGD (also known as federated averaging) and its simple baseline minibatch SGD are widely studied optimization methods. Most existing analyses of these methods assume independent and unbiased gradient estimates obtained via with-replacement sampling. In contrast, we study shuffling-based variants: minibatch and local Random Reshuffling, which draw stochastic gradients without replacement and are thus closer to practice. For smooth functions satisfying the Polyak-\u0141ojasiewicz condition, we obtain convergence bounds (in the large epoch regime) which show that these shuffling-based variants converge faster than their with-replacement counterparts. Moreover, we prove matching lower bounds showing that our convergence analysis is tight. Finally, we propose an algorithmic modification called synchronized shuffling that leads to convergence rates faster than our lower bounds in near-homogeneous settings.", "code_of_ethics": "", "submission_guidelines": "", "resubmission": "", "student_author": "", "serve_as_reviewer": "", "paperhash": "yun|minibatch_vs_local_sgd_with_shuffling_tight_convergence_bounds_and_beyond", "pdf": "/pdf/1669f6cc32c853b0d69068b7ed1a230ce3f321d0.pdf", "one-sentence_summary": "We provide tight upper and lower bounds on convergence rates of shuffling-based minibatch SGD and local SGD, and propose an algorithmic modification that improves convergence rates beyond our lower bounds.", "supplementary_material": "/attachment/214714c214de248a5a59d905312cfe380de10aa4.zip", "_bibtex": "@inproceedings{\nyun2022minibatch,\ntitle={Minibatch vs Local {SGD} with Shuffling: Tight Convergence Bounds and Beyond},\nauthor={Chulhee Yun and Shashank Rajput and Suvrit Sra},\nbooktitle={International Conference on Learning Representations},\nyear={2022},\nurl={https://openreview.net/forum?id=LdlwbBP2mlq}\n}", "venue": "ICLR 2022 Oral", "venueid": "ICLR.cc/2022/Conference"}, "signatures": ["ICLR.cc/2022/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2022/Conference"], "pdate": 1643407560000, "odate": 1633539600000, "details": {"replyCount": 9}}, {"id": "Z7Lk2cQEG8a", "original": "o8gWb5bzyB0r", "number": 4247, "cdate": 1632875740445, "mdate": null, "ddate": null, "tcdate": 1632875740445, "tmdate": 1676330460670, "tddate": null, "forum": "Z7Lk2cQEG8a", "replyto": null, "invitation": "ICLR.cc/2022/Conference/-/Blind_Submission", "content": {"title": "The Hidden Convex Optimization Landscape of Regularized Two-Layer ReLU Networks: an Exact Characterization of Optimal Solutions", "authorids": ["~Yifei_Wang2", "~Jonathan_Lacotte1", "~Mert_Pilanci3"], "authors": ["Yifei Wang", "Jonathan Lacotte", "Mert Pilanci"], "keywords": ["Neural networks", "global optimization", "convex optimization", "convex analysis"], "abstract": "We prove that finding all globally optimal two-layer ReLU neural networks can be performed by solving a convex optimization program with cone constraints. Our analysis is novel, characterizes all optimal solutions, and does not leverage duality-based analysis which was recently used to lift neural network training into convex spaces. Given the set of solutions of our convex optimization program, we show how to construct exactly the entire set of optimal neural networks. We provide a detailed characterization of this optimal set and its invariant transformations. As additional consequences of our convex perspective, (i) we establish that Clarke stationary points found by stochastic gradient descent correspond to the global optimum of a subsampled convex problem (ii) we provide a polynomial-time algorithm for checking if a neural network is a global minimum of the training loss (iii) we provide an explicit construction of a continuous path between any neural network and the global minimum of its sublevel set and (iv) characterize the minimal size of the hidden layer so that the neural network optimization landscape has no spurious valleys.\nOverall, we provide a rich framework for studying the landscape of neural network training loss through convexity.", "code_of_ethics": "", "submission_guidelines": "", "resubmission": "", "student_author": "", "serve_as_reviewer": "", "paperhash": "wang|the_hidden_convex_optimization_landscape_of_regularized_twolayer_relu_networks_an_exact_characterization_of_optimal_solutions", "pdf": "/pdf/9733b1623c23b45535cc2c126e6fb496e55e8049.pdf", "supplementary_material": "/attachment/f17e392702c46d321772e0ae0d51d86683a951a1.zip", "_bibtex": "@inproceedings{\nwang2022the,\ntitle={The Hidden Convex Optimization Landscape of Regularized Two-Layer Re{LU} Networks: an Exact Characterization of Optimal Solutions},\nauthor={Yifei Wang and Jonathan Lacotte and Mert Pilanci},\nbooktitle={International Conference on Learning Representations},\nyear={2022},\nurl={https://openreview.net/forum?id=Z7Lk2cQEG8a}\n}", "venue": "ICLR 2022 Oral", "venueid": "ICLR.cc/2022/Conference"}, "signatures": ["ICLR.cc/2022/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2022/Conference"], "pdate": 1643407560000, "odate": 1633539600000, "details": {"replyCount": 9}}, {"id": "RQLLzMCefQu", "original": "gZEvYQ3y0tEK", "number": 4212, "cdate": 1632875738088, "mdate": null, "ddate": null, "tcdate": 1632875738088, "tmdate": 1676330462808, "tddate": null, "forum": "RQLLzMCefQu", "replyto": null, "invitation": "ICLR.cc/2022/Conference/-/Blind_Submission", "content": {"title": "Provably Filtering Exogenous Distractors using Multistep Inverse Dynamics", "authorids": ["~Yonathan_Efroni2", "~Dipendra_Misra1", "~Akshay_Krishnamurthy1", "~Alekh_Agarwal2", "~John_Langford1"], "authors": ["Yonathan Efroni", "Dipendra Misra", "Akshay Krishnamurthy", "Alekh Agarwal", "John Langford"], "keywords": ["Reinforcement Learning Theory", "Invariant Representation", "Rich Observation Reinforcement Learning", "Exogenous Noise", "Inverse Dynamics"], "abstract": "Many real-world applications of reinforcement learning (RL) require the agent to deal with high-dimensional observations such as those generated from a megapixel camera. Prior work has addressed such problems with representation learning, through which the agent can provably extract endogenous, latent state information from raw observations and subsequently plan efficiently. However, such approaches can fail in the presence of temporally correlated noise in the observations, a phenomenon that is common in practice. We initiate the formal study of latent state discovery in the presence of such exogenous noise sources by proposing a new model, the Exogenous Block MDP (EX-BMDP), for rich observation RL. We start by establishing several negative results, by highlighting failure cases of prior representation learning based approaches. Then, we introduce the Predictive Path Elimination (PPE) algorithm, that learns a generalization of inverse dynamics and is provably sample and computationally efficient in EX-BMDPs when the endogenous state dynamics are near deterministic. The sample complexity of PPE depends polynomially on the size of the latent endogenous state space while not directly depending on the size of the observation space, nor the exogenous state space. We provide experiments on challenging exploration problems which show that our approach works empirically. ", "code_of_ethics": "", "submission_guidelines": "", "resubmission": "", "student_author": "", "serve_as_reviewer": "", "paperhash": "efroni|provably_filtering_exogenous_distractors_using_multistep_inverse_dynamics", "pdf": "/pdf/310151127bcaaee206f6987dfe48a6f9a49ae848.pdf", "supplementary_material": "/attachment/f967ff5acd44c135ebd15ad1bb92a5d01c70c077.zip", "_bibtex": "@inproceedings{\nefroni2022provably,\ntitle={Provably Filtering Exogenous Distractors using Multistep Inverse Dynamics},\nauthor={Yonathan Efroni and Dipendra Misra and Akshay Krishnamurthy and Alekh Agarwal and John Langford},\nbooktitle={International Conference on Learning Representations},\nyear={2022},\nurl={https://openreview.net/forum?id=RQLLzMCefQu}\n}", "venue": "ICLR 2022 Oral", "venueid": "ICLR.cc/2022/Conference"}, "signatures": ["ICLR.cc/2022/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2022/Conference"], "pdate": 1643407560000, "odate": 1633539600000, "details": {"replyCount": 19}}, {"id": "b-ny3x071E5", "original": "SAcbI6nAV-G", "number": 4127, "cdate": 1632875732363, "mdate": null, "ddate": null, "tcdate": 1632875732363, "tmdate": 1676330469248, "tddate": null, "forum": "b-ny3x071E5", "replyto": null, "invitation": "ICLR.cc/2022/Conference/-/Blind_Submission", "content": {"title": "Bootstrapped Meta-Learning", "authorids": ["~Sebastian_Flennerhag1", "~Yannick_Schroecker1", "~Tom_Zahavy2", "~Hado_van_Hasselt1", "~David_Silver1", "~Satinder_Singh2"], "authors": ["Sebastian Flennerhag", "Yannick Schroecker", "Tom Zahavy", "Hado van Hasselt", "David Silver", "Satinder Singh"], "keywords": ["meta-learning", "meta-gradients", "meta-reinforcement learning"], "abstract": "Meta-learning empowers artificial intelligence to increase its efficiency by learning how to learn. Unlocking this potential involves overcoming a challenging meta-optimisation problem. We propose an algorithm that tackles this problem by letting the meta-learner teach itself. The algorithm first bootstraps a target from the meta-learner, then optimises the meta-learner by minimising the distance to that target under a chosen (pseudo-)metric. Focusing on meta-learning with gradients, we establish conditions that guarantee performance improvements and show that metric can be used to control meta-optimisation. Meanwhile, the bootstrapping mechanism can extend the effective meta-learning horizon without requiring backpropagation through all updates. We achieve a new state-of-the art for model-free agents on the Atari ALE benchmark and demonstrate that it yields both performance and efficiency gains in multi-task meta-learning. Finally, we explore how bootstrapping opens up new possibilities and find that it can meta-learn efficient exploration in an epsilon-greedy Q-learning agent - without backpropagating through the update rule.", "one-sentence_summary": "We propose an algorithm for meta-learning with gradients that bootstraps the meta-learner from itself or another update rule. ", "code_of_ethics": "", "submission_guidelines": "", "resubmission": "", "student_author": "", "serve_as_reviewer": "", "paperhash": "flennerhag|bootstrapped_metalearning", "pdf": "/pdf/0eccd48eddcbf9cfc77b50cb0e97fb58937aee70.pdf", "data": "", "_bibtex": "@inproceedings{\nflennerhag2022bootstrapped,\ntitle={Bootstrapped Meta-Learning},\nauthor={Sebastian Flennerhag and Yannick Schroecker and Tom Zahavy and Hado van Hasselt and David Silver and Satinder Singh},\nbooktitle={International Conference on Learning Representations},\nyear={2022},\nurl={https://openreview.net/forum?id=b-ny3x071E5}\n}", "venue": "ICLR 2022 Oral", "venueid": "ICLR.cc/2022/Conference"}, "signatures": ["ICLR.cc/2022/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2022/Conference"], "pdate": 1643407560000, "odate": 1633539600000, "details": {"replyCount": 15}}, {"id": "XzTtHjgPDsT", "original": "qYr_o1LQsWl", "number": 4032, "cdate": 1632875726148, "mdate": null, "ddate": null, "tcdate": 1632875726148, "tmdate": 1697934558280, "tddate": null, "forum": "XzTtHjgPDsT", "replyto": null, "invitation": "ICLR.cc/2022/Conference/-/Blind_Submission", "content": {"title": "Coordination Among Neural Modules Through a Shared Global Workspace", "authorids": ["~Anirudh_Goyal1", "~Aniket_Rajiv_Didolkar1", "~Alex_Lamb1", "~Kartikeya_Badola1", "~Nan_Rosemary_Ke1", "~Nasim_Rahaman1", "~Jonathan_Binas1", "~Charles_Blundell1", "~Michael_Curtis_Mozer1", "~Yoshua_Bengio1"], "authors": ["Anirudh Goyal", "Aniket Rajiv Didolkar", "Alex Lamb", "Kartikeya Badola", "Nan Rosemary Ke", "Nasim Rahaman", "Jonathan Binas", "Charles Blundell", "Michael Curtis Mozer", "Yoshua Bengio"], "keywords": ["slot based recurrent architectures", "attention", "transformers", "latent bottleneck."], "abstract": " Deep learning has seen a movement away from representing examples with a monolithic hidden state towards a richly structured state. For example, Transformers segment by position, and object-centric architectures decompose images into entities. In all these architectures, interactions between different elements are modeled via pairwise interactions: Transformers make use of self-attention to incorporate information from other positions and object-centric architectures make use of graph neural networks to model interactions among entities.  We consider how to improve on pairwise interactions in terms of global coordination and a coherent, integrated representation that can be used for downstream tasks. In cognitive science, a global workspace architecture has been proposed in which functionally  specialized  components share information through a common, bandwidth-limited communication channel. We explore the use of such a communication channel in the context of deep learning for modeling the structure of complex environments. The proposed method includes a shared workspace through which communication among different specialist modules takes place but due to limits on the communication bandwidth, specialist modules must compete for access. We show that capacity limitations have  a rational basis in that (1) they encourage specialization and compositionality and (2) they facilitate the synchronization of otherwise  independent specialists.\n", "one-sentence_summary": "communication among different specialist using a shared workspace allowing higher order interactions ", "code_of_ethics": "", "submission_guidelines": "", "resubmission": "", "student_author": "", "serve_as_reviewer": "", "paperhash": "goyal|coordination_among_neural_modules_through_a_shared_global_workspace", "pdf": "/pdf/19aac83e8824498df7b9d1e6952523f7c068218b.pdf", "supplementary_material": "/attachment/05665d6b26ef6ebbf7a57aa77ddae775cc08aafa.zip", "data": "", "code": "", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2103.01197/code)", "_bibtex": "@inproceedings{\ngoyal2022coordination,\ntitle={Coordination Among Neural Modules Through a Shared Global Workspace},\nauthor={Anirudh Goyal and Aniket Rajiv Didolkar and Alex Lamb and Kartikeya Badola and Nan Rosemary Ke and Nasim Rahaman and Jonathan Binas and Charles Blundell and Michael Curtis Mozer and Yoshua Bengio},\nbooktitle={International Conference on Learning Representations},\nyear={2022},\nurl={https://openreview.net/forum?id=XzTtHjgPDsT}\n}", "venue": "ICLR 2022 Oral", "venueid": "ICLR.cc/2022/Conference"}, "signatures": ["ICLR.cc/2022/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2022/Conference"], "pdate": 1643407560000, "odate": 1633539600000, "details": {"replyCount": 9}}, {"id": "l4IHywGq6a", "original": "rq0AwPCTANp", "number": 3972, "cdate": 1632875722113, "mdate": null, "ddate": null, "tcdate": 1632875722113, "tmdate": 1697934564306, "tddate": null, "forum": "l4IHywGq6a", "replyto": null, "invitation": "ICLR.cc/2022/Conference/-/Blind_Submission", "content": {"title": "Data-Efficient Graph Grammar Learning for Molecular Generation", "authorids": ["~Minghao_Guo1", "~Veronika_Thost1", "~Beichen_Li1", "~Payel_Das1", "~Jie_Chen1", "~Wojciech_Matusik2"], "authors": ["Minghao Guo", "Veronika Thost", "Beichen Li", "Payel Das", "Jie Chen", "Wojciech Matusik"], "keywords": ["molecular generation", "graph grammar", "data efficient generative model"], "abstract": "The problem of molecular generation has received significant attention recently. Existing methods are typically based on deep neural networks and require training on large datasets with tens of thousands of samples. In practice, however, the size of class-specific chemical datasets is usually limited (e.g., dozens of samples) due to labor-intensive experimentation and data collection. Another major challenge is to generate only physically synthesizable molecules. This is a non-trivial task for neural network-based generative models since the relevant chemical knowledge can only be extracted and generalized from the limited training data. In this work, we propose a data-efficient generative model that can be learned from datasets with orders of magnitude smaller sizes than common benchmarks. At the heart of this method is a learnable graph grammar that generates molecules from a sequence of production rules. Without any human assistance, these production rules are automatically constructed from training data. Furthermore, additional chemical knowledge can be incorporated into the model by further grammar optimization. Our learned graph grammar yields state-of-the-art results on generating high-quality molecules for three monomer datasets that contain only ${\\sim}20$ samples each. Our approach also achieves remarkable performance in a challenging polymer generation task with $only$ $117$ training samples and is competitive against existing methods using $81$k data points.\n", "code_of_ethics": "", "submission_guidelines": "", "resubmission": "", "student_author": "", "serve_as_reviewer": "", "paperhash": "guo|dataefficient_graph_grammar_learning_for_molecular_generation", "pdf": "/pdf/c17b0db09f98b3279ad677650f18acbf907883ce.pdf", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 4 code implementations](https://www.catalyzex.com/paper/arxiv:2203.08031/code)", "_bibtex": "@inproceedings{\nguo2022dataefficient,\ntitle={Data-Efficient Graph Grammar Learning for Molecular Generation},\nauthor={Minghao Guo and Veronika Thost and Beichen Li and Payel Das and Jie Chen and Wojciech Matusik},\nbooktitle={International Conference on Learning Representations},\nyear={2022},\nurl={https://openreview.net/forum?id=l4IHywGq6a}\n}", "venue": "ICLR 2022 Oral", "venueid": "ICLR.cc/2022/Conference"}, "signatures": ["ICLR.cc/2022/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2022/Conference"], "pdate": 1643407560000, "odate": 1633539600000, "details": {"replyCount": 14}}, {"id": "iC4UHbQ01Mp", "original": "ZfIOwkS5Xq", "number": 3949, "cdate": 1632875720562, "mdate": null, "ddate": null, "tcdate": 1632875720562, "tmdate": 1676330479605, "tddate": null, "forum": "iC4UHbQ01Mp", "replyto": null, "invitation": "ICLR.cc/2022/Conference/-/Blind_Submission", "content": {"title": "Poisoning and Backdooring Contrastive Learning", "authorids": ["~Nicholas_Carlini1", "~Andreas_Terzis1"], "authors": ["Nicholas Carlini", "Andreas Terzis"], "keywords": ["Contrastive Learning", "Poisoning attack", "Backdoor attack", "CLIP"], "abstract": "Multimodal contrastive learning methods like CLIP train on noisy and uncurated training datasets. This is cheaper than labeling datasets manually, and even improves out-of-distribution robustness. We show that this practice makes backdoor and poisoning attacks a significant threat. By poisoning just 0.01% of a dataset (e.g., just 300 images of the 3 million-example Conceptual Captions dataset), we can cause the model to misclassify test images by overlaying a small patch. Targeted poisoning attacks, whereby the model misclassifies a particular test input  with an adversarially-desired label, are even easier requiring control of 0.0001% of the dataset (e.g., just three out of the 3 million images). Our attacks call into question whether training on noisy and uncurated Internet scrapes is desirable.", "code_of_ethics": "", "submission_guidelines": "", "resubmission": "", "student_author": "", "serve_as_reviewer": "", "paperhash": "carlini|poisoning_and_backdooring_contrastive_learning", "pdf": "/pdf/abd77f0543a72cd26da355efc5680de233f120af.pdf", "one-sentence_summary": "We argue poisoning and backdooring attacks are a serious threat to multimodal contrastive classifiers, because they are explicitly designed to be trained on uncurated datasets from the Internet.", "data": "", "_bibtex": "@inproceedings{\ncarlini2022poisoning,\ntitle={Poisoning and Backdooring Contrastive Learning},\nauthor={Nicholas Carlini and Andreas Terzis},\nbooktitle={International Conference on Learning Representations},\nyear={2022},\nurl={https://openreview.net/forum?id=iC4UHbQ01Mp}\n}", "venue": "ICLR 2022 Oral", "venueid": "ICLR.cc/2022/Conference"}, "signatures": ["ICLR.cc/2022/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2022/Conference"], "pdate": 1643407560000, "odate": 1633539600000, "details": {"replyCount": 11}}, {"id": "w1UbdvWH_R3", "original": "PfF-bAeOLGi", "number": 3870, "cdate": 1632875715232, "mdate": null, "ddate": null, "tcdate": 1632875715232, "tmdate": 1676330484890, "tddate": null, "forum": "w1UbdvWH_R3", "replyto": null, "invitation": "ICLR.cc/2022/Conference/-/Blind_Submission", "content": {"title": "Neural Collapse Under MSE Loss: Proximity to and Dynamics on the Central Path", "authorids": ["~X.Y._Han1", "~Vardan_Papyan1", "~David_L._Donoho1"], "authors": ["X.Y. Han", "Vardan Papyan", "David L. Donoho"], "keywords": ["neural collapse", "deep learning theory", "deep learning", "inductive bias", "equiangular tight frame", "ETF", "nearest class center", "mean squared error loss", "MSE loss", "invariance", "renormalization", "gradient flow", "dynamics", "adversarial robustness"], "abstract": "The recently discovered Neural Collapse (NC) phenomenon occurs pervasively in today's deep net training paradigm of driving cross-entropy (CE) loss towards zero. During NC, last-layer features collapse to their class-means, both classifiers and class-means collapse to the same Simplex Equiangular Tight Frame, and classifier behavior collapses to the nearest-class-mean decision rule. Recent works demonstrated that deep nets trained with mean squared error (MSE) loss perform comparably to those trained with CE. As a preliminary, we empirically establish that NC emerges in such MSE-trained deep nets as well through experiments on three canonical networks and five benchmark datasets. We provide, in a Google Colab notebook, PyTorch code for reproducing MSE-NC and CE-NC: https://colab.research.google.com/github/neuralcollapse/neuralcollapse/blob/main/neuralcollapse.ipynb. The analytically-tractable MSE loss offers more mathematical opportunities than the hard-to-analyze CE loss, inspiring us to leverage MSE loss towards the theoretical investigation of NC. We develop three main contributions: (I) We show a new decomposition of the MSE loss into (A) terms directly interpretable through the lens of NC and which assume the last-layer classifier is exactly the least-squares classifier; and (B) a term capturing the deviation from this least-squares classifier. (II) We exhibit experiments on canonical datasets and networks demonstrating that term-(B) is negligible during training. This motivates us to introduce a new theoretical construct: the central path, where the linear classifier stays MSE-optimal for feature activations throughout the dynamics. (III) By studying renormalized gradient flow along the central path, we derive exact dynamics that predict NC.", "one-sentence_summary": "Neural Collapse occurs empirically on deep nets trained with MSE loss and studying this setting leads to insightful closed-form dynamics.", "code_of_ethics": "", "submission_guidelines": "", "resubmission": "", "student_author": "", "serve_as_reviewer": "", "paperhash": "han|neural_collapse_under_mse_loss_proximity_to_and_dynamics_on_the_central_path", "pdf": "/pdf/75799bbe466f7240935655cbfaa930c9628a915e.pdf", "code": "", "data": "", "_bibtex": "@inproceedings{\nhan2022neural,\ntitle={Neural Collapse Under {MSE} Loss: Proximity to and Dynamics on the Central Path},\nauthor={X.Y. Han and Vardan Papyan and David L. Donoho},\nbooktitle={International Conference on Learning Representations},\nyear={2022},\nurl={https://openreview.net/forum?id=w1UbdvWH_R3}\n}", "venue": "ICLR 2022 Oral", "venueid": "ICLR.cc/2022/Conference"}, "signatures": ["ICLR.cc/2022/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2022/Conference"], "pdate": 1643407560000, "odate": 1633539600000, "details": {"replyCount": 19}}, {"id": "ltM1RMZntpu", "original": "C9sNq2kirGt", "number": 3861, "cdate": 1632875714616, "mdate": null, "ddate": null, "tcdate": 1632875714616, "tmdate": 1697934575036, "tddate": null, "forum": "ltM1RMZntpu", "replyto": null, "invitation": "ICLR.cc/2022/Conference/-/Blind_Submission", "content": {"title": "Weighted Training for Cross-Task Learning", "authorids": ["~Shuxiao_Chen1", "~Koby_Crammer1", "~Hangfeng_He3", "~Dan_Roth3", "~Weijie_J_Su1"], "authors": ["Shuxiao Chen", "Koby Crammer", "Hangfeng He", "Dan Roth", "Weijie J Su"], "keywords": ["Cross-task learning", "Natural language processing", "Representation learning"], "abstract": "In this paper, we introduce Target-Aware Weighted Training (TAWT), a weighted training algorithm for cross-task learning based on minimizing a representation-based task distance between the source and target tasks. We show that TAWT is easy to implement, is computationally efficient, requires little hyperparameter tuning, and enjoys non-asymptotic learning-theoretic guarantees. The effectiveness of TAWT is corroborated through extensive experiments with BERT on four sequence tagging tasks in natural language processing (NLP), including part-of-speech (PoS) tagging, chunking, predicate detection, and named entity recognition (NER). As a byproduct, the proposed representation-based task distance allows one to reason in a theoretically principled way about several critical aspects of cross-task learning, such as the choice of the source data and the impact of fine-tuning.", "one-sentence_summary": "We introduce a weighted training algorithm for cross-task learning based on minimizing a representation-based task distance between the source and target tasks.", "code_of_ethics": "", "submission_guidelines": "", "resubmission": "", "student_author": "", "serve_as_reviewer": "", "paperhash": "chen|weighted_training_for_crosstask_learning", "pdf": "/pdf/579ed2f74ecc130396039eae33e13de66b8de08b.pdf", "supplementary_material": "/attachment/4554ccf3b03ed539601ba4727c22f5b6646fff7a.zip", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2105.14095/code)", "_bibtex": "@inproceedings{\nchen2022weighted,\ntitle={Weighted Training for Cross-Task Learning},\nauthor={Shuxiao Chen and Koby Crammer and Hangfeng He and Dan Roth and Weijie J Su},\nbooktitle={International Conference on Learning Representations},\nyear={2022},\nurl={https://openreview.net/forum?id=ltM1RMZntpu}\n}", "venue": "ICLR 2022 Oral", "venueid": "ICLR.cc/2022/Conference"}, "signatures": ["ICLR.cc/2022/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2022/Conference"], "pdate": 1643407560000, "odate": 1633539600000, "details": {"replyCount": 9}}, {"id": "wRODLDHaAiW", "original": "fG6b5Ima65Pa", "number": 3763, "cdate": 1632875708125, "mdate": null, "ddate": null, "tcdate": 1632875708125, "tmdate": 1676330490879, "tddate": null, "forum": "wRODLDHaAiW", "replyto": null, "invitation": "ICLR.cc/2022/Conference/-/Blind_Submission", "content": {"title": "iLQR-VAE : control-based learning of input-driven dynamics with applications to neural data", "authorids": ["~Marine_Schimel1", "~Ta-Chu_Kao1", "~Kristopher_T_Jensen1", "~Guillaume_Hennequin1"], "authors": ["Marine Schimel", "Ta-Chu Kao", "Kristopher T Jensen", "Guillaume Hennequin"], "keywords": ["neuroscience", "latent variable models", "RNN", "VAE", "motor control", "control theory", "dynamical systems"], "abstract": "Understanding how neural dynamics give rise to behaviour is one of the most fundamental questions in systems neuroscience. To achieve this, a common approach is to record neural populations in behaving animals, and model these data as emanating from a latent dynamical system whose state trajectories can then be related back to behavioural observations via some form of decoding. As recordings are typically performed in localized circuits that form only a part of the wider implicated network, it is important to simultaneously learn the local dynamics and infer any unobserved external input that might drive them. Here, we introduce iLQR-VAE, a novel control-based approach to variational inference in nonlinear dynamical systems, capable of learning both latent dynamics, initial conditions, and ongoing external inputs. As in recent deep learning approaches, our method is based on an input-driven sequential variational autoencoder (VAE). The main novelty lies in the use of the powerful iterative linear quadratic regulator algorithm (iLQR) in the recognition model. Optimization of the standard evidence lower-bound requires differentiating through iLQR solutions, which is made possible by recent advances in differentiable control. Importantly, having the recognition model be implicitly defined by the generative model greatly reduces the number of free parameters and allows for flexible, high-quality inference. This makes it possible for instance to evaluate the model on a single long trial after training on smaller chunks. We demonstrate the effectiveness of iLQR-VAE on a range of synthetic systems, with autonomous as well as input-driven dynamics. We further apply it to neural and behavioural recordings in non-human primates performing two different reaching tasks, and show that iLQR-VAE yields high-quality kinematic reconstructions from the neural data. ", "code_of_ethics": "", "submission_guidelines": "", "resubmission": "", "student_author": "", "serve_as_reviewer": "", "paperhash": "schimel|ilqrvae_controlbased_learning_of_inputdriven_dynamics_with_applications_to_neural_data", "pdf": "/pdf/c4b2a10a835b79e5cbaff71f6577c29236e964b5.pdf", "one-sentence_summary": "We develop a novel autoencoder that uses iLQR as an inference model and apply it to synthetic data as well as neural recordings from primate motor cortex.", "supplementary_material": "/attachment/d56eef08c847ab2b7a4c4bdea44fe6464442601c.zip", "data": "", "_bibtex": "@inproceedings{\nschimel2022ilqrvae,\ntitle={i{LQR}-{VAE} : control-based learning of input-driven dynamics with applications to neural data},\nauthor={Marine Schimel and Ta-Chu Kao and Kristopher T Jensen and Guillaume Hennequin},\nbooktitle={International Conference on Learning Representations},\nyear={2022},\nurl={https://openreview.net/forum?id=wRODLDHaAiW}\n}", "venue": "ICLR 2022 Oral", "venueid": "ICLR.cc/2022/Conference"}, "signatures": ["ICLR.cc/2022/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2022/Conference"], "pdate": 1643407560000, "odate": 1633539600000, "details": {"replyCount": 4}}, {"id": "z7p2V6KROOV", "original": "KyyloJWcvUm", "number": 3653, "cdate": 1632875701063, "mdate": null, "ddate": null, "tcdate": 1632875701063, "tmdate": 1697934595146, "tddate": null, "forum": "z7p2V6KROOV", "replyto": null, "invitation": "ICLR.cc/2022/Conference/-/Blind_Submission", "content": {"title": "Extending the WILDS Benchmark for Unsupervised Adaptation", "authorids": ["~Shiori_Sagawa1", "~Pang_Wei_Koh1", "tonyhlee@stanford.edu", "~Irena_Gao1", "~Sang_Michael_Xie1", "~Kendrick_Shen1", "~Ananya_Kumar1", "~Weihua_Hu1", "~Michihiro_Yasunaga1", "~Henrik_Marklund2", "~Sara_Beery1", "etienne.david@inrae.fr", "~Ian_Stavness1", "guowei@g.ecc.u-tokyo.ac.jp", "~Jure_Leskovec1", "~Kate_Saenko1", "~Tatsunori_Hashimoto1", "~Sergey_Levine1", "~Chelsea_Finn1", "~Percy_Liang1"], "authors": ["Shiori Sagawa", "Pang Wei Koh", "Tony Lee", "Irena Gao", "Sang Michael Xie", "Kendrick Shen", "Ananya Kumar", "Weihua Hu", "Michihiro Yasunaga", "Henrik Marklund", "Sara Beery", "Etienne David", "Ian Stavness", "Wei Guo", "Jure Leskovec", "Kate Saenko", "Tatsunori Hashimoto", "Sergey Levine", "Chelsea Finn", "Percy Liang"], "keywords": ["distribution shifts", "adaptation", "unlabeled data"], "abstract": "Machine learning systems deployed in the wild are often trained on a source distribution but deployed on a different target distribution. Unlabeled data can be a powerful point of leverage for mitigating these distribution shifts, as it is frequently much more available than labeled data and can often be obtained from distributions beyond the source distribution as well. However, existing distribution shift benchmarks with unlabeled data do not reflect the breadth of scenarios that arise in real-world applications. In this work, we present the WILDS 2.0 update, which extends 8 of the 10 datasets in the WILDS benchmark of distribution shifts to include curated unlabeled data that would be realistically obtainable in deployment. These datasets span a wide range of applications (from histology to wildlife conservation), tasks (classification, regression, and detection), and modalities (photos, satellite images, microscope slides, text, molecular graphs). The update maintains consistency with the original WILDS benchmark by using identical labeled training, validation, and test sets, as well as identical evaluation metrics. We systematically benchmark state-of-the-art methods that use unlabeled data, including domain-invariant, self-training, and self-supervised methods, and show that their success on WILDS is limited. To facilitate method development, we provide an open-source package that automates data loading and contains the model architectures and methods used in this paper. Code and leaderboards are available at https://wilds.stanford.edu.", "code_of_ethics": "", "submission_guidelines": "", "resubmission": "", "student_author": "", "serve_as_reviewer": "", "paperhash": "sagawa|extending_the_wilds_benchmark_for_unsupervised_adaptation", "pdf": "/pdf/16bc69d47c7ff67867bfc50009d6b9fc5043a00f.pdf", "one-sentence_summary": "We introduce U-WILDS, which augments the WILDS distribution shift benchmark with realistic unlabeled data, and benchmark existing methods for unlabeled data on these in-the-wild distribution shifts.", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2112.05090/code)", "_bibtex": "@inproceedings{\nsagawa2022extending,\ntitle={Extending the {WILDS} Benchmark for Unsupervised Adaptation},\nauthor={Shiori Sagawa and Pang Wei Koh and Tony Lee and Irena Gao and Sang Michael Xie and Kendrick Shen and Ananya Kumar and Weihua Hu and Michihiro Yasunaga and Henrik Marklund and Sara Beery and Etienne David and Ian Stavness and Wei Guo and Jure Leskovec and Kate Saenko and Tatsunori Hashimoto and Sergey Levine and Chelsea Finn and Percy Liang},\nbooktitle={International Conference on Learning Representations},\nyear={2022},\nurl={https://openreview.net/forum?id=z7p2V6KROOV}\n}", "venue": "ICLR 2022 Oral", "venueid": "ICLR.cc/2022/Conference"}, "signatures": ["ICLR.cc/2022/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2022/Conference"], "pdate": 1643407560000, "odate": 1633539600000, "details": {"replyCount": 23}}, {"id": "avgclFZ221l", "original": "e7T577bHOjs", "number": 3526, "cdate": 1632875693128, "mdate": null, "ddate": null, "tcdate": 1632875693128, "tmdate": 1676330501825, "tddate": null, "forum": "avgclFZ221l", "replyto": null, "invitation": "ICLR.cc/2022/Conference/-/Blind_Submission", "content": {"title": "Asymmetry Learning for Counterfactually-invariant Classification in OOD Tasks", "authorids": ["~S_Chandra_Mouli1", "~Bruno_Ribeiro1"], "authors": ["S Chandra Mouli", "Bruno Ribeiro"], "keywords": ["out-of-distribution classification", "symmetries", "counterfactual invariances", "geometric deep learning"], "abstract": "Generalizing from observed to new related environments (out-of-distribution) is central to the reliability of classifiers. However, most classifiers fail to predict label $Y$ from input $X$ when the change in environment is due a (stochastic) input transformation $T^\\text{te} \\circ X'$ not observed in training, as in training we observe $T^\\text{tr} \\circ X'$, where $X'$ is a hidden variable. This work argues that when the transformations in train $T^\\text{tr}$ and test $T^\\text{te}$ are (arbitrary) symmetry transformations induced by a collection of known $m$ equivalence relations, the task of finding a robust OOD classifier can be defined as finding the simplest causal model that defines a causal connection between the target labels and the symmetry transformations that are associated with label changes. We then propose a new learning paradigm, asymmetry learning, that identifies which symmetries the classifier must break in order to correctly predict $Y$ in both train and test. Asymmetry learning performs a causal model search that, under certain identifiability conditions, finds classifiers that perform equally well in-distribution and out-of-distribution. Finally, we show how to learn counterfactually-invariant representations with asymmetry learning in two physics tasks.", "code_of_ethics": "", "submission_guidelines": "", "resubmission": "", "student_author": "", "serve_as_reviewer": "", "paperhash": "mouli|asymmetry_learning_for_counterfactuallyinvariant_classification_in_ood_tasks", "pdf": "/pdf/f15da1dc02ded9aba4a26e8ade750b28429da30f.pdf", "one-sentence_summary": "Counterfactual-invariant representations for symmetry transformations", "_bibtex": "@inproceedings{\nmouli2022asymmetry,\ntitle={Asymmetry Learning for Counterfactually-invariant Classification in {OOD} Tasks},\nauthor={S Chandra Mouli and Bruno Ribeiro},\nbooktitle={International Conference on Learning Representations},\nyear={2022},\nurl={https://openreview.net/forum?id=avgclFZ221l}\n}", "venue": "ICLR 2022 Oral", "venueid": "ICLR.cc/2022/Conference"}, "signatures": ["ICLR.cc/2022/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2022/Conference"], "pdate": 1643407560000, "odate": 1633539600000, "details": {"replyCount": 13}}, {"id": "KB5onONJIAU", "original": "i5pNeiiDN5E", "number": 3521, "cdate": 1632875692798, "mdate": null, "ddate": null, "tcdate": 1632875692798, "tmdate": 1676330502057, "tddate": null, "forum": "KB5onONJIAU", "replyto": null, "invitation": "ICLR.cc/2022/Conference/-/Blind_Submission", "content": {"title": "Comparing Distributions by Measuring Differences that Affect Decision Making", "authorids": ["~Shengjia_Zhao1", "~Abhishek_Sinha1", "~Yutong_He1", "~Aidan_Perreault1", "~Jiaming_Song1", "~Stefano_Ermon1"], "authors": ["Shengjia Zhao", "Abhishek Sinha", "Yutong He", "Aidan Perreault", "Jiaming Song", "Stefano Ermon"], "keywords": ["probability divergence", "two sample test", "generative model"], "abstract": "Measuring the discrepancy between two probability distributions is a fundamental problem in machine learning and statistics. We propose a new class of discrepancies based on the optimal loss for a decision task -- two distributions are different if the optimal decision loss is higher on their mixture than on each individual distribution. By suitably choosing the decision task, this generalizes the Jensen-Shannon divergence and the maximum mean discrepancy family. We apply our approach to two-sample tests, and on various benchmarks, we achieve superior test power compared to competing methods. In addition, a modeler can directly specify their preferences when comparing distributions through the decision loss. We apply this property to understanding the effects of climate change on different social and economic activities, evaluating sample quality, and selecting features targeting different decision tasks.", "code_of_ethics": "", "submission_guidelines": "", "resubmission": "", "student_author": "", "serve_as_reviewer": "", "paperhash": "zhao|comparing_distributions_by_measuring_differences_that_affect_decision_making", "pdf": "/pdf/e99719a7a6796b569cc6afdf6f42024d0df2fbea.pdf", "_bibtex": "@inproceedings{\nzhao2022comparing,\ntitle={Comparing Distributions by Measuring Differences that Affect Decision Making},\nauthor={Shengjia Zhao and Abhishek Sinha and Yutong He and Aidan Perreault and Jiaming Song and Stefano Ermon},\nbooktitle={International Conference on Learning Representations},\nyear={2022},\nurl={https://openreview.net/forum?id=KB5onONJIAU}\n}", "venue": "ICLR 2022 Oral", "venueid": "ICLR.cc/2022/Conference"}, "signatures": ["ICLR.cc/2022/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2022/Conference"], "pdate": 1643407560000, "odate": 1633539600000, "details": {"replyCount": 8}}, {"id": "UseMOjWENv", "original": "38vikcem8l6D", "number": 3403, "cdate": 1632875685133, "mdate": null, "ddate": null, "tcdate": 1632875685133, "tmdate": 1676330506873, "tddate": null, "forum": "UseMOjWENv", "replyto": null, "invitation": "ICLR.cc/2022/Conference/-/Blind_Submission", "content": {"title": "MIDI-DDSP: Detailed Control of Musical Performance via Hierarchical Modeling", "authorids": ["~Yusong_Wu1", "~Ethan_Manilow1", "~Yi_Deng4", "rigeljs@google.com", "~Kyle_Kastner1", "~Tim_Cooijmans1", "~Aaron_Courville3", "~Cheng-Zhi_Anna_Huang1", "~Jesse_Engel1"], "authors": ["Yusong Wu", "Ethan Manilow", "Yi Deng", "Rigel Swavely", "Kyle Kastner", "Tim Cooijmans", "Aaron Courville", "Cheng-Zhi Anna Huang", "Jesse Engel"], "keywords": ["Audio Synthesis", "Generative Model", "Hierarchical", "DDSP", "Music", "Audio", "Structured Models"], "abstract": "Musical expression requires control of both what notes that are played, and how they are performed. Conventional audio synthesizers provide detailed expressive controls, but at the cost of realism. Black-box neural audio synthesis and concatenative samplers can produce realistic audio, but have few mechanisms for control. In this work, we introduce MIDI-DDSP a hierarchical model of musical instruments that enables both realistic neural audio synthesis and detailed user control. Starting from interpretable Differentiable Digital Signal Processing (DDSP) synthesis parameters, we infer musical notes and high-level properties of their expressive performance (such as timbre, vibrato, dynamics, and articulation). This creates a 3-level hierarchy (notes, performance, synthesis) that affords individuals the option to intervene at each level, or utilize trained priors (performance given notes, synthesis given performance) for creative assistance. Through quantitative experiments and listening tests, we demonstrate that this hierarchy can reconstruct high-fidelity audio, accurately predict performance attributes for a note sequence, independently manipulate the attributes of a given performance,  and as a complete system, generate realistic audio from a novel note sequence. By utilizing an interpretable hierarchy, with multiple levels of granularity, MIDI-DDSP opens the door to assistive tools to empower individuals across a diverse range of musical experience.", "code_of_ethics": "", "submission_guidelines": "", "resubmission": "", "student_author": "", "serve_as_reviewer": "", "paperhash": "wu|mididdsp_detailed_control_of_musical_performance_via_hierarchical_modeling", "pdf": "/pdf/e26b385d95d67af36d02a385047be6f7a0d6f47b.pdf", "one-sentence_summary": "Controlling musical performance and synthesis with a structured hierarchical generative model", "_bibtex": "@inproceedings{\nwu2022mididdsp,\ntitle={{MIDI}-{DDSP}: Detailed Control of Musical Performance via Hierarchical Modeling},\nauthor={Yusong Wu and Ethan Manilow and Yi Deng and Rigel Swavely and Kyle Kastner and Tim Cooijmans and Aaron Courville and Cheng-Zhi Anna Huang and Jesse Engel},\nbooktitle={International Conference on Learning Representations},\nyear={2022},\nurl={https://openreview.net/forum?id=UseMOjWENv}\n}", "venue": "ICLR 2022 Oral", "venueid": "ICLR.cc/2022/Conference"}, "signatures": ["ICLR.cc/2022/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2022/Conference"], "pdate": 1643407560000, "odate": 1633539600000, "details": {"replyCount": 7}}, {"id": "N0n_QyQ5lBF", "original": "-B1cyn585zea", "number": 3278, "cdate": 1632875677007, "mdate": null, "ddate": null, "tcdate": 1632875677007, "tmdate": 1676330513633, "tddate": null, "forum": "N0n_QyQ5lBF", "replyto": null, "invitation": "ICLR.cc/2022/Conference/-/Blind_Submission", "content": {"title": "Unsupervised Vision-Language Grammar Induction with Shared Structure Modeling", "authorids": ["~Bo_Wan1", "~Wenjuan_Han1", "~Zilong_Zheng1", "~Tinne_Tuytelaars1"], "authors": ["Bo Wan", "Wenjuan Han", "Zilong Zheng", "Tinne Tuytelaars"], "keywords": ["Grammar Induction", "Vision-Language Matching", "Unsupervised Learning"], "abstract": "We introduce a new task, unsupervised vision-language (VL) grammar induction. Given an image-caption pair, the goal is to extract a shared hierarchical structure for both image and language simultaneously.  We argue that such structured output, grounded in both modalities, is a clear step towards the high-level understanding of multimodal information. Besides challenges existing in conventional visually grounded grammar induction tasks, VL grammar induction requires a model to capture contextual semantics and perform a fine-grained alignment. To address these challenges, we propose a novel method, CLIORA, which constructs a shared vision-language constituency tree structure with context-dependent semantics for all possible phrases in different levels of the tree. It computes a matching score between each constituent and image region, trained via contrastive learning.  It integrates two levels of fusion, namely at feature-level and at score-level, so as to allow fine-grained alignment. We introduce a new evaluation metric for VL grammar induction, CCRA, and show a 3.3% improvement over a strong baseline on Flickr30k Entities. We also evaluate our model via two derived tasks, i.e., language grammar induction and phrase grounding, and improve over the state-of-the-art for both.", "one-sentence_summary": "We introduce a new unsupervised vision-language grammar induction task to explore the multimodal information and induce a shared hierarchical structure for both image and language simultaneously.", "code_of_ethics": "", "submission_guidelines": "", "resubmission": "", "student_author": "", "serve_as_reviewer": "", "paperhash": "wan|unsupervised_visionlanguage_grammar_induction_with_shared_structure_modeling", "pdf": "/pdf/5c104842d13e8d6efd55b6d7c04f4373a39eae18.pdf", "supplementary_material": "/attachment/d6b7ddd3bf6e5c1f4edc51b23b8cbe88b0db163d.zip", "data": "", "_bibtex": "@inproceedings{\nwan2022unsupervised,\ntitle={Unsupervised Vision-Language Grammar Induction with Shared Structure Modeling},\nauthor={Bo Wan and Wenjuan Han and Zilong Zheng and Tinne Tuytelaars},\nbooktitle={International Conference on Learning Representations},\nyear={2022},\nurl={https://openreview.net/forum?id=N0n_QyQ5lBF}\n}", "venue": "ICLR 2022 Oral", "venueid": "ICLR.cc/2022/Conference"}, "signatures": ["ICLR.cc/2022/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2022/Conference"], "pdate": 1643407560000, "odate": 1633539600000, "details": {"replyCount": 14}}, {"id": "EhYjZy6e1gJ", "original": "L55iCFnrUh_", "number": 3113, "cdate": 1632875666435, "mdate": null, "ddate": null, "tcdate": 1632875666435, "tmdate": 1697934646197, "tddate": null, "forum": "EhYjZy6e1gJ", "replyto": null, "invitation": "ICLR.cc/2022/Conference/-/Blind_Submission", "content": {"title": "PiCO: Contrastive Label Disambiguation for Partial Label Learning", "authorids": ["~Haobo_Wang1", "~Ruixuan_Xiao1", "~Yixuan_Li1", "~Lei_Feng1", "~Gang_Niu1", "~Gang_Chen6", "~Junbo_Zhao1"], "authors": ["Haobo Wang", "Ruixuan Xiao", "Yixuan Li", "Lei Feng", "Gang Niu", "Gang Chen", "Junbo Zhao"], "keywords": ["Partial Label Learning", "Contrastive Learning", "Prototype-based Disambiguation"], "abstract": "Partial label learning (PLL) is an important problem that allows each training example to be labeled with a coarse candidate set, which well suits many real-world data annotation scenarios with label ambiguity.  Despite the promise, the performance of PLL often lags behind the supervised counterpart. In this work, we bridge the gap by addressing two key research challenges in PLL---representation learning and label disambiguation---in one coherent framework. Specifically, our proposed framework PiCO consists of a contrastive learning module along with a novel class prototype-based label disambiguation algorithm. PiCO produces closely aligned representations for examples from the same classes and facilitates label disambiguation. Theoretically, we show that these two components are mutually beneficial, and can be rigorously justified from an expectation-maximization (EM) algorithm perspective. Extensive experiments demonstrate that PiCO significantly outperforms the current state-of-the-art approaches in PLL and even achieves comparable results to fully supervised learning. Code and data available: https://github.com/hbzju/PiCO.", "pdf": "/pdf/f9275b96d741f229db4e61a15ce5f2a499c9ee67.pdf", "one-sentence_summary": "A synergistic PLL framework that leverages contrastive learning for enhanced representation and improved label disambiguation.", "supplementary_material": "/attachment/23c0ecc1a1d5842f6f810a3a17d15f9016553246.zip", "code_of_ethics": "", "submission_guidelines": "", "resubmission": "", "student_author": "", "serve_as_reviewer": "", "paperhash": "wang|pico_contrastive_label_disambiguation_for_partial_label_learning", "data": "", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2201.08984/code)", "_bibtex": "@inproceedings{\nwang2022pico,\ntitle={Pi{CO}: Contrastive Label Disambiguation for Partial Label Learning},\nauthor={Haobo Wang and Ruixuan Xiao and Yixuan Li and Lei Feng and Gang Niu and Gang Chen and Junbo Zhao},\nbooktitle={International Conference on Learning Representations},\nyear={2022},\nurl={https://openreview.net/forum?id=EhYjZy6e1gJ}\n}", "venue": "ICLR 2022 Oral", "venueid": "ICLR.cc/2022/Conference"}, "signatures": ["ICLR.cc/2022/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2022/Conference"], "pdate": 1643407560000, "odate": 1633539600000, "details": {"replyCount": 15}}, {"id": "0EXmFzUn5I", "original": "JXowxbIofB", "number": 3064, "cdate": 1632875663297, "mdate": null, "ddate": null, "tcdate": 1632875663297, "tmdate": 1676330524554, "tddate": null, "forum": "0EXmFzUn5I", "replyto": null, "invitation": "ICLR.cc/2022/Conference/-/Blind_Submission", "content": {"title": "Pyraformer: Low-Complexity Pyramidal Attention for Long-Range Time Series Modeling and Forecasting", "authorids": ["~Shizhan_Liu1", "~Hang_Yu1", "~Cong_Liao1", "~Jianguo_Li2", "~Weiyao_Lin1", "~Alex_X._Liu1", "dustdar@dsg.tuwien.ac.at"], "authors": ["Shizhan Liu", "Hang Yu", "Cong Liao", "Jianguo Li", "Weiyao Lin", "Alex X. Liu", "Schahram Dustdar"], "keywords": ["sparse attention", "pyramidal graph", "Transformer", "time series forecasting", "long-range dependence", "multiresolution"], "abstract": "Accurate prediction of the future given the past based on time series data is of paramount importance, since it opens the door for decision making and risk management ahead of time. In practice, the challenge is to build a flexible but parsimonious model that can capture a wide range of temporal dependencies. In this paper, we propose Pyraformer by exploring the multiresolution representation of the time series. Specifically, we introduce the pyramidal attention module (PAM) in which the inter-scale tree structure summarizes features at different resolutions and the intra-scale neighboring connections model the temporal dependencies of different ranges. Under mild conditions, the maximum length of the signal traversing path in Pyraformer is a constant (i.e., $\\mathcal O(1)$) with regard to the sequence length $L$, while its time and space complexity scale linearly with $L$. Extensive numerical results show that Pyraformer typically achieves the highest prediction accuracy in both single-step and long-range forecasting tasks with the least amount of time and memory consumption, especially when the sequence is long.", "one-sentence_summary": "We propose a multiresolution pyramidal attention mechanism for long-range dependence modeling and time series forecasting, successfully reducing the maximum length of the signal traversing path to O(1) while achieving linear time and space complexity", "code_of_ethics": "", "submission_guidelines": "", "resubmission": "", "student_author": "", "serve_as_reviewer": "", "paperhash": "liu|pyraformer_lowcomplexity_pyramidal_attention_for_longrange_time_series_modeling_and_forecasting", "pdf": "/pdf/2ac159853cd001bbca6a8a12da497c8013914b31.pdf", "_bibtex": "@inproceedings{\nliu2022pyraformer,\ntitle={Pyraformer: Low-Complexity Pyramidal Attention for Long-Range Time Series Modeling and Forecasting},\nauthor={Shizhan Liu and Hang Yu and Cong Liao and Jianguo Li and Weiyao Lin and Alex X. Liu and Schahram Dustdar},\nbooktitle={International Conference on Learning Representations},\nyear={2022},\nurl={https://openreview.net/forum?id=0EXmFzUn5I}\n}", "venue": "ICLR 2022 Oral", "venueid": "ICLR.cc/2022/Conference"}, "signatures": ["ICLR.cc/2022/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2022/Conference"], "pdate": 1643407560000, "odate": 1633539600000, "details": {"replyCount": 29}}, {"id": "wIzUeM3TAU", "original": "hC7_y9bvVB", "number": 2877, "cdate": 1632875650762, "mdate": null, "ddate": null, "tcdate": 1632875650762, "tmdate": 1697934671725, "tddate": null, "forum": "wIzUeM3TAU", "replyto": null, "invitation": "ICLR.cc/2022/Conference/-/Blind_Submission", "content": {"title": "Expressiveness and Approximation Properties of Graph Neural Networks", "authorids": ["~Floris_Geerts1", "~Juan_L_Reutter1"], "authors": ["Floris Geerts", "Juan L Reutter"], "keywords": ["Graph Neural Networks", "Colour Refinement", "Weisfeiler-Leman", "Separation Power", "Universality"], "abstract": "Characterizing the separation power of graph neural networks (GNNs) provides an understanding of their limitations for graph learning tasks. Results regarding separation power are, however, usually geared at specific GNNs architectures, and tools for understanding arbitrary GNN architectures are generally lacking. We provide an elegant way to easily obtain bounds on the separation power of GNNs in terms of the Weisfeiler-Leman (WL) tests, which have become the yardstick to measure the separation power of GNNs. The crux is to view GNNs as expressions in a procedural tensor language describing the computations in the layers of the GNNs. Then, by a simple analysis of the obtained expressions, in terms of the number of indexes used and the nesting depth of summations, bounds on the separation power in terms of the WL-tests readily follow. We use tensor language to define Higher-Order Message-Passing Neural Networks (or k-MPNNs), a natural extension of MPNNs. Furthermore, the tensor language point of view allows for the derivation of universality results for classes of GNNs in a natural way. Our approach provides a toolbox with which GNN architecture designers can analyze the separation power of their GNNs, without needing to know the intricacies of the WL-tests. We also provide insights in what is needed to boost the separation power of GNNs.", "one-sentence_summary": "A general methodology for assessing the expressive and approximation power of GNNs is presented.", "code_of_ethics": "", "submission_guidelines": "", "resubmission": "", "student_author": "", "serve_as_reviewer": "", "paperhash": "geerts|expressiveness_and_approximation_properties_of_graph_neural_networks", "pdf": "/pdf/9d0fe7ff08261aae56611b7f670de9875c2a9cd9.pdf", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2204.04661/code)", "_bibtex": "@inproceedings{\ngeerts2022expressiveness,\ntitle={Expressiveness and Approximation Properties of Graph Neural Networks},\nauthor={Floris Geerts and Juan L Reutter},\nbooktitle={International Conference on Learning Representations},\nyear={2022},\nurl={https://openreview.net/forum?id=wIzUeM3TAU}\n}", "venue": "ICLR 2022 Oral", "venueid": "ICLR.cc/2022/Conference"}, "signatures": ["ICLR.cc/2022/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2022/Conference"], "pdate": 1643407560000, "odate": 1633539600000, "details": {"replyCount": 29}}, {"id": "1L0C5ROtFp", "original": "6MrDpFtlYVh", "number": 2819, "cdate": 1632875647051, "mdate": null, "ddate": null, "tcdate": 1632875647051, "tmdate": 1676330538192, "tddate": null, "forum": "1L0C5ROtFp", "replyto": null, "invitation": "ICLR.cc/2022/Conference/-/Blind_Submission", "content": {"title": "Filtered-CoPhy: Unsupervised Learning of Counterfactual Physics in Pixel Space", "authorids": ["~Steeven_JANNY2", "~Fabien_Baradel1", "~Natalia_Neverova1", "madiha.nadri-wolf@univ-lyon1.fr", "~Greg_Mori2", "~Christian_Wolf1"], "authors": ["Steeven JANNY", "Fabien Baradel", "Natalia Neverova", "Madiha Nadri", "Greg Mori", "Christian Wolf"], "keywords": [], "abstract": "Learning causal relationships in high-dimensional data (images, videos) is a hard task, as they are often defined on low dimensional manifolds and must be extracted from complex signals dominated by appearance, lighting, textures and also spurious correlations in the data. We present a method for learning counterfactual reasoning of physical processes in pixel space, which requires the prediction of the impact of interventions on initial conditions. Going beyond the identification of structural relationships, we deal with the challenging problem of forecasting raw video over long horizons. Our method does not require the knowledge or supervision of any ground truth positions or other object or scene properties. Our model learns and acts on a suitable hybrid latent representation based on a combination of dense features, sets of 2D keypoints and an additional latent vector per keypoint. We show that this better captures the dynamics of physical processes than purely dense or sparse representations. We introduce a new challenging and carefully designed counterfactual benchmark for predictions in pixel space and outperform strong baselines in physics-inspired ML and video prediction.", "code_of_ethics": "", "submission_guidelines": "", "resubmission": "", "student_author": "", "serve_as_reviewer": "", "paperhash": "janny|filteredcophy_unsupervised_learning_of_counterfactual_physics_in_pixel_space", "pdf": "/pdf/cbd75b662eaa377753b892113b221d062f26511e.pdf", "_bibtex": "@inproceedings{\njanny2022filteredcophy,\ntitle={Filtered-CoPhy: Unsupervised Learning of Counterfactual Physics in Pixel Space},\nauthor={Steeven JANNY and Fabien Baradel and Natalia Neverova and Madiha Nadri and Greg Mori and Christian Wolf},\nbooktitle={International Conference on Learning Representations},\nyear={2022},\nurl={https://openreview.net/forum?id=1L0C5ROtFp}\n}", "venue": "ICLR 2022 Oral", "venueid": "ICLR.cc/2022/Conference"}, "signatures": ["ICLR.cc/2022/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2022/Conference"], "pdate": 1643407560000, "odate": 1633539600000, "details": {"replyCount": 14}}, {"id": "p-BhZSz59o4", "original": "euPOworkzGp", "number": 2678, "cdate": 1632875637647, "mdate": null, "ddate": null, "tcdate": 1632875637647, "tmdate": 1697934693585, "tddate": null, "forum": "p-BhZSz59o4", "replyto": null, "invitation": "ICLR.cc/2022/Conference/-/Blind_Submission", "content": {"title": "BEiT: BERT Pre-Training of Image Transformers", "authorids": ["~Hangbo_Bao1", "~Li_Dong1", "~Songhao_Piao1", "~Furu_Wei1"], "authors": ["Hangbo Bao", "Li Dong", "Songhao Piao", "Furu Wei"], "keywords": ["self-supervised learning", "pre-training", "vision Transformer"], "abstract": "We introduce a self-supervised vision representation model BEiT, which stands for Bidirectional Encoder representation from Image Transformers. Following BERT developed in the natural language processing area, we propose a masked image modeling task to pretrain vision Transformers. Specifically, each image has two views in our pre-training, i.e., image patches (such as 16 x 16 pixels), and visual tokens (i.e., discrete tokens). We first ``tokenize'' the original image into visual tokens. Then we randomly mask some image patches and fed them into the backbone Transformer. The pre-training objective is to recover the original visual tokens based on the corrupted image patches. After pre-training BEiT, we directly fine-tune the model parameters on downstream tasks by appending task layers upon the pretrained encoder. Experimental results on image classification and semantic segmentation show that our model achieves competitive results with previous pre-training methods.", "code_of_ethics": "", "submission_guidelines": "", "resubmission": "", "student_author": "", "serve_as_reviewer": "", "paperhash": "bao|beit_bert_pretraining_of_image_transformers", "pdf": "/pdf/1be2cb0e0edf9af45f8ef450b802b459897cec3d.pdf", "one-sentence_summary": "We propose a masked image modeling task to pretrain vision Transformers.", "code": "", "data": "", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 2 code implementations](https://www.catalyzex.com/paper/arxiv:2106.08254/code)", "_bibtex": "@inproceedings{\nbao2022beit,\ntitle={{BE}iT: {BERT} Pre-Training of Image Transformers},\nauthor={Hangbo Bao and Li Dong and Songhao Piao and Furu Wei},\nbooktitle={International Conference on Learning Representations},\nyear={2022},\nurl={https://openreview.net/forum?id=p-BhZSz59o4}\n}", "venue": "ICLR 2022 Oral", "venueid": "ICLR.cc/2022/Conference"}, "signatures": ["ICLR.cc/2022/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2022/Conference"], "pdate": 1643407560000, "odate": 1633539600000, "details": {"replyCount": 12}}, {"id": "UYneFzXSJWh", "original": "0Xwek28shBZ", "number": 2660, "cdate": 1632875636440, "mdate": null, "ddate": null, "tcdate": 1632875636440, "tmdate": 1676330546303, "tddate": null, "forum": "UYneFzXSJWh", "replyto": null, "invitation": "ICLR.cc/2022/Conference/-/Blind_Submission", "content": {"title": "Fine-Tuning can Distort Pretrained Features and Underperform Out-of-Distribution", "authorids": ["~Ananya_Kumar1", "~Aditi_Raghunathan1", "~Robbie_Matthew_Jones1", "~Tengyu_Ma1", "~Percy_Liang1"], "authors": ["Ananya Kumar", "Aditi Raghunathan", "Robbie Matthew Jones", "Tengyu Ma", "Percy Liang"], "keywords": ["fine-tuning theory", "transfer learning theory", "fine-tuning", "distribution shift", "implicit regularization"], "abstract": "When transferring a pretrained model to a downstream task, two popular methods are full fine-tuning (updating all the model parameters) and linear probing (updating only the last linear layer---the \"head\"). It is well known that fine-tuning leads to better accuracy in-distribution (ID). However, in this paper, we find that fine-tuning can achieve worse accuracy than linear probing out-of-distribution (OOD) when the pretrained features are good and the distribution shift is large. On 10 distribution shift datasets (BREEDS-Living17, BREEDS-Entity30, DomainNet, CIFAR $\\to$ STL, CIFAR-10.1, FMoW, ImageNetV2, ImageNet-R, ImageNet-A, ImageNet-Sketch), fine-tuning obtains on average 2% higher accuracy ID but 7% lower accuracy OOD than linear probing. We show theoretically that this tradeoff between ID and OOD accuracy arises even in a simple setting: fine-tuning overparameterized two-layer linear networks. We prove that the OOD error of fine-tuning is high when we initialize with a fixed or random head---this is because while fine-tuning learns the head, the lower layers of the neural network change simultaneously and distort the pretrained features. Our analysis suggests that the easy two-step strategy of linear probing then full fine-tuning (LP-FT), sometimes used as a fine-tuning heuristic, combines the benefits of both fine-tuning and linear probing. Empirically, LP-FT outperforms both fine-tuning and linear probing on the above datasets (1% better ID, 10% better OOD than full fine-tuning).", "one-sentence_summary": "Fine-tuning does better than linear probing (training a linear classifier on pretrained features) in-distribution, but worse out-of-distribution (OOD)---we analyze why this happens and propose a way to get the benefits of both.", "code_of_ethics": "", "submission_guidelines": "", "resubmission": "", "student_author": "", "serve_as_reviewer": "", "paperhash": "kumar|finetuning_can_distort_pretrained_features_and_underperform_outofdistribution", "pdf": "/pdf/5d8a4ae4492042b22b07eabc7a9abcfa517f419c.pdf", "supplementary_material": "/attachment/34f81a5b333e131206e26a14e9de6125508dcbc8.zip", "data": "", "_bibtex": "@inproceedings{\nkumar2022finetuning,\ntitle={Fine-Tuning can Distort Pretrained Features and Underperform Out-of-Distribution},\nauthor={Ananya Kumar and Aditi Raghunathan and Robbie Matthew Jones and Tengyu Ma and Percy Liang},\nbooktitle={International Conference on Learning Representations},\nyear={2022},\nurl={https://openreview.net/forum?id=UYneFzXSJWh}\n}", "venue": "ICLR 2022 Oral", "venueid": "ICLR.cc/2022/Conference"}, "signatures": ["ICLR.cc/2022/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2022/Conference"], "pdate": 1643407560000, "odate": 1633539600000, "details": {"replyCount": 24}}, {"id": "Qg2vi4ZbHM9", "original": "GB2YMsrlWsL", "number": 2443, "cdate": 1632875622220, "mdate": null, "ddate": null, "tcdate": 1632875622220, "tmdate": 1697934714307, "tddate": null, "forum": "Qg2vi4ZbHM9", "replyto": null, "invitation": "ICLR.cc/2022/Conference/-/Blind_Submission", "content": {"title": "StyleAlign: Analysis and Applications of Aligned StyleGAN Models", "authorids": ["~Zongze_Wu2", "~Yotam_Nitzan1", "~Eli_Shechtman3", "~Dani_Lischinski2"], "authors": ["Zongze Wu", "Yotam Nitzan", "Eli Shechtman", "Dani Lischinski"], "keywords": ["StyleGAN", "transfer learning", "fine tuning", "model alignment", "image-to-image translation", "image morphing"], "abstract": "In this paper, we perform an in-depth study of the properties and applications of aligned generative models.\nWe refer to two models as aligned if they share the same architecture, and one of them (the child) is obtained from the other (the parent) via fine-tuning to another domain, a common practice in transfer learning. Several works already utilize some basic properties of aligned StyleGAN models to perform image-to-image translation. Here, we perform the first detailed exploration of model alignment, also focusing on StyleGAN. First, we empirically analyze aligned models and provide answers to important questions regarding their nature. In particular, we find that the child model's latent spaces are semantically aligned with those of the parent, inheriting incredibly rich semantics, even for distant data domains such as human faces and churches. Second, equipped with this better understanding, we leverage aligned models to solve a diverse set of tasks. In addition to image translation, we demonstrate fully automatic cross-domain image morphing. We further show that zero-shot vision tasks may be performed in the child domain, while relying exclusively on supervision in the parent domain. We demonstrate qualitatively and quantitatively that our approach yields state-of-the-art results, while requiring only simple fine-tuning and inversion. ", "code_of_ethics": "", "submission_guidelines": "", "resubmission": "", "student_author": "", "serve_as_reviewer": "", "paperhash": "wu|stylealign_analysis_and_applications_of_aligned_stylegan_models", "pdf": "/pdf/a75f48f49713ac38baaaee51cb3273177975f96b.pdf", "one-sentence_summary": "Analysis and applications of aligned generative models", "supplementary_material": "/attachment/feb237822a8f823627b38f1d6c8b71432d2daf0e.zip", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2110.11323/code)", "_bibtex": "@inproceedings{\nwu2022stylealign,\ntitle={StyleAlign: Analysis and Applications of Aligned Style{GAN} Models},\nauthor={Zongze Wu and Yotam Nitzan and Eli Shechtman and Dani Lischinski},\nbooktitle={International Conference on Learning Representations},\nyear={2022},\nurl={https://openreview.net/forum?id=Qg2vi4ZbHM9}\n}", "venue": "ICLR 2022 Oral", "venueid": "ICLR.cc/2022/Conference"}, "signatures": ["ICLR.cc/2022/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2022/Conference"], "pdate": 1643407560000, "odate": 1633539600000, "details": {"replyCount": 16}}, {"id": "qnQN4yr6FJz", "original": "nM1dUXRfVqQ", "number": 2336, "cdate": 1632875615131, "mdate": null, "ddate": null, "tcdate": 1632875615131, "tmdate": 1676330562484, "tddate": null, "forum": "qnQN4yr6FJz", "replyto": null, "invitation": "ICLR.cc/2022/Conference/-/Blind_Submission", "content": {"title": "Variational Inference for Discriminative Learning with Generative Modeling of Feature Incompletion", "authorids": ["~Kohei_Miyaguchi1", "~Takayuki_Katsuki2", "~Akira_Koseki1", "~Toshiya_Iwamori1"], "authors": ["Kohei Miyaguchi", "Takayuki Katsuki", "Akira Koseki", "Toshiya Iwamori"], "keywords": ["Black-box variational inference", "missing values", "evidence upper bound"], "abstract": "We are concerned with the problem of distributional prediction with incomplete features: The goal is to estimate the distribution of target variables given feature vectors with some of the elements missing. A typical approach to this problem is to perform missing-value imputation and regression, simultaneously or sequentially, which we call the generative approach. Another approach is to perform regression after appropriately encoding missing values into the feature, which we call the discriminative approach. In comparison, the generative approach is more robust to the feature corruption while the discriminative approach is more favorable to maximize the performance of prediction. \nIn this study, we propose a hybrid method to take the best of both worlds. Our method utilizes the black-box variational inference framework so that it can be applied to a wide variety of modern machine learning models, including the variational autoencoders. We also confirmed the effectiveness of the proposed method empirically.\n", "one-sentence_summary": "A new variational approximation and algorithm are proposed for discriminative inference with missing features.", "code_of_ethics": "", "submission_guidelines": "", "resubmission": "", "student_author": "", "serve_as_reviewer": "", "paperhash": "miyaguchi|variational_inference_for_discriminative_learning_with_generative_modeling_of_feature_incompletion", "pdf": "/pdf/537474668e8264be0d7e7963ad009564621ad25e.pdf", "_bibtex": "@inproceedings{\nmiyaguchi2022variational,\ntitle={Variational Inference for Discriminative Learning with Generative Modeling of Feature Incompletion},\nauthor={Kohei Miyaguchi and Takayuki Katsuki and Akira Koseki and Toshiya Iwamori},\nbooktitle={International Conference on Learning Representations},\nyear={2022},\nurl={https://openreview.net/forum?id=qnQN4yr6FJz}\n}", "venue": "ICLR 2022 Oral", "venueid": "ICLR.cc/2022/Conference"}, "signatures": ["ICLR.cc/2022/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2022/Conference"], "pdate": 1643407560000, "odate": 1633539600000, "details": {"replyCount": 13}}, {"id": "uYLFoz1vlAC", "original": "0AvOfAOXmyj", "number": 2218, "cdate": 1632875607416, "mdate": null, "ddate": null, "tcdate": 1632875607416, "tmdate": 1697934737161, "tddate": null, "forum": "uYLFoz1vlAC", "replyto": null, "invitation": "ICLR.cc/2022/Conference/-/Blind_Submission", "content": {"title": "Efficiently Modeling Long Sequences with Structured State Spaces", "authorids": ["~Albert_Gu1", "~Karan_Goel1", "~Christopher_Re1"], "authors": ["Albert Gu", "Karan Goel", "Christopher Re"], "keywords": ["sequence models", "state space", "RNN", "CNN", "Long Range Arena"], "abstract": "A central goal of sequence modeling is designing a single principled model that can address sequence data across a range of modalities and tasks, particularly on long-range dependencies.  Although conventional models including RNNs, CNNs, and Transformers have specialized variants for capturing long dependencies, they still struggle to scale to very long sequences of $10000$ or more steps.  A promising recent approach proposed modeling sequences by simulating the fundamental state space model (SSM) \\( x'(t) = Ax(t) + Bu(t), y(t) = Cx(t) + Du(t) \\), and showed that for appropriate choices of the state matrix \\( A \\), this system could handle long-range dependencies mathematically and empirically.  However, this method has prohibitive computation and memory requirements, rendering it infeasible as a general sequence modeling solution.  We propose the Structured State Space sequence model (S4) based on a new parameterization for the SSM, and show that it can be computed much more efficiently than prior approaches while preserving their theoretical strengths.  Our technique involves conditioning \\( A \\) with a low-rank correction, allowing it to be diagonalized stably and reducing the SSM to the well-studied computation of a Cauchy kernel.  S4 achieves strong empirical results across a diverse range of established benchmarks, including (i) 91\\% accuracy on sequential CIFAR-10 with no data augmentation or auxiliary losses, on par with a larger 2-D ResNet, (ii) substantially closing the gap to Transformers on image and language modeling tasks, while performing generation $60\\times$ faster (iii) SoTA on every task from the Long Range Arena benchmark, including solving the challenging Path-X task of length 16k that all prior work fails on, while being as efficient as all competitors.", "code_of_ethics": "", "submission_guidelines": "", "resubmission": "", "student_author": "", "serve_as_reviewer": "", "paperhash": "gu|efficiently_modeling_long_sequences_with_structured_state_spaces", "pdf": "/pdf/a8eedf494f6698cb467c310c59d3ea6488546805.pdf", "one-sentence_summary": "We introduce the S3 model based on new algorithms for state spaces that is particularly effective on long-range dependencies.", "supplementary_material": "/attachment/0eca97b47ae6f910c4be46fcb179d7790227b78a.zip", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2111.00396/code)", "_bibtex": "@inproceedings{\ngu2022efficiently,\ntitle={Efficiently Modeling Long Sequences with Structured State Spaces},\nauthor={Albert Gu and Karan Goel and Christopher Re},\nbooktitle={International Conference on Learning Representations},\nyear={2022},\nurl={https://openreview.net/forum?id=uYLFoz1vlAC}\n}", "venue": "ICLR 2022 Oral", "venueid": "ICLR.cc/2022/Conference"}, "signatures": ["ICLR.cc/2022/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2022/Conference"], "pdate": 1643407560000, "odate": 1633539600000, "details": {"replyCount": 15}}, {"id": "bVuP3ltATMz", "original": "_FI5SWIExWD", "number": 2196, "cdate": 1632875605732, "mdate": null, "ddate": null, "tcdate": 1632875605732, "tmdate": 1697934739819, "tddate": null, "forum": "bVuP3ltATMz", "replyto": null, "invitation": "ICLR.cc/2022/Conference/-/Blind_Submission", "content": {"title": "Large Language Models Can Be Strong Differentially Private Learners", "authorids": ["~Xuechen_Li1", "~Florian_Tramer1", "~Percy_Liang1", "~Tatsunori_Hashimoto1"], "authors": ["Xuechen Li", "Florian Tramer", "Percy Liang", "Tatsunori Hashimoto"], "keywords": ["language model", "differential privacy", "language generation", "fine-tuning", "NLP"], "abstract": "Differentially Private (DP) learning has seen limited success for building large deep learning models of text, and straightforward attempts at applying Differentially Private Stochastic Gradient Descent (DP-SGD) to NLP tasks have resulted in large performance drops and high computational overhead.\nWe show that this performance drop can be mitigated with (1) the use of large pretrained language models; (2) non-standard hyperparameters that suit DP optimization; and (3) fine-tuning objectives which are aligned with the pretraining procedure.\nWith the above, we obtain NLP models that outperform state-of-the-art DP-trained models under the same privacy budget and strong non-private baselines---by directly fine-tuning pretrained models with DP optimization on moderately-sized corpora. \nTo address the computational challenge of running DP-SGD with large Transformers, we propose a memory saving technique that allows clipping in DP-SGD to run without instantiating per-example gradients for any linear layer in the model. \nThe technique enables privately training Transformers with almost the same memory cost as non-private training at a modest run-time overhead. \nContrary to conventional wisdom that DP optimization fails at learning high-dimensional models (due to noise that scales with dimension) empirical results reveal that private learning with pretrained language models tends to not suffer from dimension-dependent performance degradation.\nCode to reproduce results can be found at https://github.com/lxuechen/private-transformers.\n", "code_of_ethics": "", "submission_guidelines": "", "resubmission": "", "student_author": "", "serve_as_reviewer": "", "paperhash": "li|large_language_models_can_be_strong_differentially_private_learners", "pdf": "/pdf/d88e1e721c4085b8a6403837f45b8c483ad0225b.pdf", "one-sentence_summary": "We show how to build highly performant differentially private NLP models by fine-tuning large pretrained models.", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 9 code implementations](https://www.catalyzex.com/paper/arxiv:2110.05679/code)", "_bibtex": "@inproceedings{\nli2022large,\ntitle={Large Language Models Can Be Strong Differentially Private Learners},\nauthor={Xuechen Li and Florian Tramer and Percy Liang and Tatsunori Hashimoto},\nbooktitle={International Conference on Learning Representations},\nyear={2022},\nurl={https://openreview.net/forum?id=bVuP3ltATMz}\n}", "venue": "ICLR 2022 Oral", "venueid": "ICLR.cc/2022/Conference"}, "signatures": ["ICLR.cc/2022/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2022/Conference"], "pdate": 1643407560000, "odate": 1633539600000, "details": {"replyCount": 17}}, {"id": "PzcvxEMzvQC", "original": "crdzU_r4SJH", "number": 2181, "cdate": 1632875604484, "mdate": null, "ddate": null, "tcdate": 1632875604484, "tmdate": 1676330570556, "tddate": null, "forum": "PzcvxEMzvQC", "replyto": null, "invitation": "ICLR.cc/2022/Conference/-/Blind_Submission", "content": {"title": "GeoDiff: A Geometric Diffusion Model for Molecular Conformation Generation", "authorids": ["~Minkai_Xu1", "~Lantao_Yu2", "~Yang_Song1", "~Chence_Shi1", "~Stefano_Ermon1", "~Jian_Tang1"], "authors": ["Minkai Xu", "Lantao Yu", "Yang Song", "Chence Shi", "Stefano Ermon", "Jian Tang"], "keywords": ["molecular conformation generation", "deep generative models", "diffusion probabilistic models"], "abstract": "Predicting molecular conformations from molecular graphs is a fundamental problem in cheminformatics and drug discovery. Recently, significant progress has been achieved with machine learning approaches, especially with deep generative models. Inspired by the diffusion process in classical non-equilibrium thermodynamics where heated particles will diffuse from original states to a noise distribution, in this paper, we propose a novel generative model named GeoDiff for molecular conformation prediction. GeoDiff treats each atom as a particle and learns to directly reverse the diffusion process (i.e., transforming from a noise distribution to stable conformations) as a Markov chain. Modeling such a generation process is however very challenging as the likelihood of conformations should be roto-translational invariant. We theoretically show that Markov chains evolving with equivariant Markov kernels can induce an invariant distribution by design, and further propose building blocks for the Markov kernels to preserve the desirable equivariance property. The whole framework can be efficiently trained in an end-to-end fashion by optimizing a weighted variational lower bound to the (conditional) likelihood. Experiments on multiple benchmarks show that GeoDiff is superior or comparable to existing state-of-the-art approaches, especially on large molecules. ", "code_of_ethics": "", "submission_guidelines": "", "resubmission": "", "student_author": "", "serve_as_reviewer": "", "paperhash": "xu|geodiff_a_geometric_diffusion_model_for_molecular_conformation_generation", "pdf": "/pdf/d6be0299d7f2d2bf947d450fffe98c8395458c75.pdf", "one-sentence_summary": "A novel probabilistic diffusion framework to generate accurate and diverse molecular conformations, achieving state-of-the-art results on conformation generation and property prediction", "supplementary_material": "/attachment/26791ee1444d8190c207fe60b1cb08e3eded683d.zip", "_bibtex": "@inproceedings{\nxu2022geodiff,\ntitle={GeoDiff: A Geometric Diffusion Model for Molecular Conformation Generation},\nauthor={Minkai Xu and Lantao Yu and Yang Song and Chence Shi and Stefano Ermon and Jian Tang},\nbooktitle={International Conference on Learning Representations},\nyear={2022},\nurl={https://openreview.net/forum?id=PzcvxEMzvQC}\n}", "venue": "ICLR 2022 Oral", "venueid": "ICLR.cc/2022/Conference"}, "signatures": ["ICLR.cc/2022/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2022/Conference"], "pdate": 1643407560000, "odate": 1633539600000, "details": {"replyCount": 16}}, {"id": "zIUyj55nXR", "original": "J2ALp-Gz0ui", "number": 2028, "cdate": 1632875560247, "mdate": null, "ddate": null, "tcdate": 1632875560247, "tmdate": 1676330579006, "tddate": null, "forum": "zIUyj55nXR", "replyto": null, "invitation": "ICLR.cc/2022/Conference/-/Blind_Submission", "content": {"title": "Frame Averaging for Invariant and Equivariant Network Design", "authorids": ["~Omri_Puny1", "~Matan_Atzmon1", "~Edward_J._Smith1", "~Ishan_Misra2", "~Aditya_Grover1", "~Heli_Ben-Hamu1", "~Yaron_Lipman1"], "authors": ["Omri Puny", "Matan Atzmon", "Edward J. Smith", "Ishan Misra", "Aditya Grover", "Heli Ben-Hamu", "Yaron Lipman"], "keywords": ["Invariant and equivariant neural network", "expressive power"], "abstract": "Many machine learning tasks involve learning functions that are known to be invariant or equivariant to certain symmetries of the input data. However, it is often challenging to design neural network architectures that respect these symmetries while being expressive and computationally efficient. For example, Euclidean motion invariant/equivariant graph or point cloud neural networks. \nWe introduce Frame Averaging (FA), a highly general purpose and systematic framework for adapting known (backbone) architectures to become invariant or equivariant to new symmetry types. Our framework builds on the well known group averaging operator that guarantees invariance or equivariance but is intractable. In contrast, we observe that for many important classes of symmetries, this operator can be replaced with an averaging operator over a small subset of the group elements, called a frame. We show that averaging over a frame guarantees exact invariance or equivariance while often being much simpler to compute than averaging over the entire group. Furthermore, we prove that FA-based models have maximal expressive power in a broad setting and in general preserve the expressive power of their backbone architectures. Using frame averaging, we propose a new class of universal Graph Neural Networks (GNNs), universal Euclidean motion invariant point cloud networks, and Euclidean motion invariant Message Passing (MP) GNNs. We demonstrate the practical effectiveness of FA on several applications including point cloud normal estimation, beyond $2$-WL graph separation, and $n$-body dynamics prediction, achieving state-of-the-art results in all of these benchmarks.", "one-sentence_summary": "Introducing a general methodology for building expressive and efficient invariant and equivariant networks.", "code_of_ethics": "", "submission_guidelines": "", "resubmission": "", "student_author": "", "serve_as_reviewer": "", "paperhash": "puny|frame_averaging_for_invariant_and_equivariant_network_design", "pdf": "/pdf/d7849f0ef0f911d06889785dc7116564d5342442.pdf", "data": "", "_bibtex": "@inproceedings{\npuny2022frame,\ntitle={Frame Averaging for Invariant and Equivariant Network Design},\nauthor={Omri Puny and Matan Atzmon and Edward J. Smith and Ishan Misra and Aditya Grover and Heli Ben-Hamu and Yaron Lipman},\nbooktitle={International Conference on Learning Representations},\nyear={2022},\nurl={https://openreview.net/forum?id=zIUyj55nXR}\n}", "venue": "ICLR 2022 Oral", "venueid": "ICLR.cc/2022/Conference"}, "signatures": ["ICLR.cc/2022/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2022/Conference"], "pdate": 1643407560000, "odate": 1633539600000, "details": {"replyCount": 19}}, {"id": "oapKSVM2bcj", "original": "C6bsX5c9aN", "number": 1830, "cdate": 1632875544119, "mdate": null, "ddate": null, "tcdate": 1632875544119, "tmdate": 1676330591387, "tddate": null, "forum": "oapKSVM2bcj", "replyto": null, "invitation": "ICLR.cc/2022/Conference/-/Blind_Submission", "content": {"title": "Einops: Clear and Reliable Tensor Manipulations with Einstein-like Notation", "authorids": ["~Alex_Rogozhnikov1"], "authors": ["Alex Rogozhnikov"], "keywords": ["tensor manipulations", "tensor transformation", "einops", "einstein notation", "einsum"], "abstract": "Tensor computations underlie modern scientific computing and deep learning.\nA number of tensor frameworks emerged varying in execution model, hardware support, memory management, model definition, etc.\nHowever, tensor operations in all frameworks follow the same paradigm.\nRecent neural network architectures demonstrate demand for higher expressiveness of tensor operations.\nThe current paradigm is not suited to write readable, reliable, or easy-to-modify code for multidimensional tensor manipulations. \nMoreover, some commonly used operations do not provide sufficient checks and can break a tensor structure.\nThese mistakes are elusive as no tools or tests can detect them.\nIndependently, API discrepancies complicate code transfer between frameworks.\nWe propose einops notation: a uniform and generic way to manipulate tensor structure, that significantly improves code readability and flexibility by focusing on the structure of input and output tensors.\nWe implement einops notation in a Python package that efficiently supports multiple widely used frameworks and provides framework-independent minimalist API for tensor manipulations.", "one-sentence_summary": "We propose a notation for clear and reliable tensor manipulations; we implented notation in Python package to handle multiple frameworks", "code_of_ethics": "", "submission_guidelines": "", "resubmission": "", "student_author": "", "serve_as_reviewer": "", "paperhash": "rogozhnikov|einops_clear_and_reliable_tensor_manipulations_with_einsteinlike_notation", "pdf": "/pdf/d568f6e36eaa377888611b8e0d84076777edc330.pdf", "_bibtex": "@inproceedings{\nrogozhnikov2022einops,\ntitle={Einops: Clear and Reliable Tensor Manipulations with Einstein-like Notation},\nauthor={Alex Rogozhnikov},\nbooktitle={International Conference on Learning Representations},\nyear={2022},\nurl={https://openreview.net/forum?id=oapKSVM2bcj}\n}", "venue": "ICLR 2022 Oral", "venueid": "ICLR.cc/2022/Conference"}, "signatures": ["ICLR.cc/2022/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2022/Conference"], "pdate": 1643407560000, "odate": 1633539600000, "details": {"replyCount": 16}}, {"id": "Dl4LetuLdyK", "original": "V37ADPU9Z2v", "number": 1663, "cdate": 1632875533281, "mdate": null, "ddate": null, "tcdate": 1632875533281, "tmdate": 1697934797988, "tddate": null, "forum": "Dl4LetuLdyK", "replyto": null, "invitation": "ICLR.cc/2022/Conference/-/Blind_Submission", "content": {"title": "A Fine-Grained Analysis on Distribution Shift", "authorids": ["~Olivia_Wiles1", "~Sven_Gowal2", "~Florian_Stimberg1", "~Sylvestre-Alvise_Rebuffi1", "iraktena@google.com", "~Krishnamurthy_Dj_Dvijotham1", "~Ali_Taylan_Cemgil2"], "authors": ["Olivia Wiles", "Sven Gowal", "Florian Stimberg", "Sylvestre-Alvise Rebuffi", "Ira Ktena", "Krishnamurthy Dj Dvijotham", "Ali Taylan Cemgil"], "keywords": ["robustness", "distribution shifts"], "abstract": "Robustness to distribution shifts is critical for deploying machine learning models in the real world. Despite this necessity, there has been little work in defining the underlying mechanisms that cause these shifts and evaluating the robustness of algorithms across multiple, different distribution shifts. To this end, we introduce a framework that enables fine-grained analysis of various distribution shifts. We provide a holistic analysis of current state-of-the-art methods by evaluating 19 distinct methods grouped into five categories across both synthetic and real-world datasets.  Overall, we train more than 85K models. Our experimental framework can be easily extended to include new methods, shifts, and datasets. We find, unlike previous work (Gulrajani & Lopez-Paz, 2021), that progress has been made over a standard ERM baseline; in particular, pretraining and augmentations (learned or heuristic) offer large gains in many cases. However, the best methods are not consistent over different datasets and shifts. We will open source our experimental framework, allowing future work to evaluate new methods over multiple shifts to obtain a more complete picture of a method's effectiveness. \nCode is available at github.com/deepmind/distribution_shift_framework.\n", "one-sentence_summary": "We investigate and analyse the robustness of a variety of methods under distribution shifts using our flexible experimental framework.", "code_of_ethics": "", "submission_guidelines": "", "resubmission": "", "student_author": "", "serve_as_reviewer": "", "paperhash": "wiles|a_finegrained_analysis_on_distribution_shift", "pdf": "/pdf/6be366539738706234ad0b104ed82361a3c5f6e7.pdf", "supplementary_material": "/attachment/98bd936d076633fae496d57988805e933efaca79.zip", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 2 code implementations](https://www.catalyzex.com/paper/arxiv:2110.11328/code)", "_bibtex": "@inproceedings{\nwiles2022a,\ntitle={A Fine-Grained Analysis on Distribution Shift},\nauthor={Olivia Wiles and Sven Gowal and Florian Stimberg and Sylvestre-Alvise Rebuffi and Ira Ktena and Krishnamurthy Dj Dvijotham and Ali Taylan Cemgil},\nbooktitle={International Conference on Learning Representations},\nyear={2022},\nurl={https://openreview.net/forum?id=Dl4LetuLdyK}\n}", "venue": "ICLR 2022 Oral", "venueid": "ICLR.cc/2022/Conference"}, "signatures": ["ICLR.cc/2022/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2022/Conference"], "pdate": 1643407560000, "odate": 1633539600000, "details": {"replyCount": 18}}, {"id": "5hLP5JY9S2d", "original": "T9T8WUCV1Yi", "number": 1647, "cdate": 1632875532178, "mdate": null, "ddate": null, "tcdate": 1632875532178, "tmdate": 1697934799115, "tddate": null, "forum": "5hLP5JY9S2d", "replyto": null, "invitation": "ICLR.cc/2022/Conference/-/Blind_Submission", "content": {"title": "Open-Set Recognition: A Good Closed-Set Classifier is All You Need", "authorids": ["~Sagar_Vaze1", "~Kai_Han1", "~Andrea_Vedaldi1", "~Andrew_Zisserman1"], "authors": ["Sagar Vaze", "Kai Han", "Andrea Vedaldi", "Andrew Zisserman"], "keywords": ["open set recognition", "image recognition", "computer vision"], "abstract": "The ability to identify whether or not a test sample belongs to one of the semantic classes in a classifier's training set is critical to practical deployment of the model. This task is termed open-set recognition (OSR) and has received significant attention in recent years. In this paper, we first demonstrate that the ability of a classifier to make the 'none-of-above' decision is highly correlated with its accuracy on the closed-set classes. We find that this relationship holds across loss objectives and architectures, and further demonstrate the trend both on the standard OSR benchmarks as well as on a large-scale ImageNet evaluation. Second, we use this correlation to boost the performance of the maximum softmax probability OSR 'baseline' by improving its closed-set accuracy, and with this strong baseline achieve state-of-the-art on a number of OSR benchmarks. Similarly, we boost the performance of the existing state-of-the-art method by improving its closed-set accuracy, but the resulting discrepancy with the strong baseline is marginal. Our third contribution is to present the 'Semantic Shift Benchmark' (SSB), which better respects the task of detecting semantic novelty, as opposed to low-level distributional shifts as tackled by neighbouring machine learning fields. On this new evaluation, we again demonstrate that there is negligible difference between the strong baseline and the existing state-of-the-art. Code available at: https://github.com/sgvaze/osr_closed_set_all_you_need.", "one-sentence_summary": "We show that the baseline method for open-set recognition can achieve state-of-the-art performance and introduce new benchmark settings", "code_of_ethics": "", "submission_guidelines": "", "resubmission": "", "student_author": "", "serve_as_reviewer": "", "paperhash": "vaze|openset_recognition_a_good_closedset_classifier_is_all_you_need", "pdf": "/pdf/a9e422d293a936fe65575b5e1ea6a86549b84bca.pdf", "supplementary_material": "/attachment/77b537399e49faa19e972ac00c03fc55fab82141.zip", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2110.06207/code)", "_bibtex": "@inproceedings{\nvaze2022openset,\ntitle={Open-Set Recognition: A Good Closed-Set Classifier is All You Need},\nauthor={Sagar Vaze and Kai Han and Andrea Vedaldi and Andrew Zisserman},\nbooktitle={International Conference on Learning Representations},\nyear={2022},\nurl={https://openreview.net/forum?id=5hLP5JY9S2d}\n}", "venue": "ICLR 2022 Oral", "venueid": "ICLR.cc/2022/Conference"}, "signatures": ["ICLR.cc/2022/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2022/Conference"], "pdate": 1643407560000, "odate": 1633539600000, "details": {"replyCount": 14}}, {"id": "M752z9FKJP", "original": "BhWKRxGBVzn", "number": 1591, "cdate": 1632875528478, "mdate": null, "ddate": null, "tcdate": 1632875528478, "tmdate": 1697934805202, "tddate": null, "forum": "M752z9FKJP", "replyto": null, "invitation": "ICLR.cc/2022/Conference/-/Blind_Submission", "content": {"title": "Learning Strides in Convolutional Neural Networks", "authorids": ["~Rachid_Riad1", "~Olivier_Teboul2", "~David_Grangier1", "~Neil_Zeghidour1"], "authors": ["Rachid Riad", "Olivier Teboul", "David Grangier", "Neil Zeghidour"], "keywords": ["Strides", "Convolutional neural networks", "Downsampling", "Spectral representations", "Fourier"], "abstract": "Convolutional neural networks typically contain several downsampling operators, such as strided convolutions or pooling layers, that progressively reduce the resolution of intermediate representations. This provides some shift-invariance while reducing the computational complexity of the whole architecture. A critical hyperparameter of such layers is their stride: the integer factor of downsampling. As strides are not differentiable, finding the best configuration either requires cross-validation or discrete optimization (e.g. architecture search), which rapidly become prohibitive as the search space grows exponentially with the number of downsampling layers. Hence, exploring this search space by gradient descent would allow finding better configurations at a lower computational cost. This work introduces DiffStride, the first downsampling layer with learnable strides. Our layer learns the size of a cropping mask in the Fourier domain, that effectively performs resizing in a differentiable way. Experiments on audio and image classification show the generality and effectiveness of our solution: we use DiffStride as a drop-in replacement to standard downsampling layers and outperform them. In particular, we show that introducing our layer into a ResNet-18 architecture allows keeping consistent high performance on CIFAR10, CIFAR100 and ImageNet even when training starts from poor random stride configurations. Moreover, formulating strides as learnable variables allows us to introduce a regularization term that controls the computational complexity of the architecture. We show how this regularization allows trading off accuracy for efficiency on ImageNet.", "pdf": "/pdf/1bc01ea49b5a288387ac5de300847b1d6690d940.pdf", "one-sentence_summary": "We introduce DiffStride, the first downsampling layer with learnable strides for convolutional neural networks.", "code_of_ethics": "", "submission_guidelines": "", "resubmission": "", "student_author": "", "serve_as_reviewer": "", "paperhash": "riad|learning_strides_in_convolutional_neural_networks", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2202.01653/code)", "_bibtex": "@inproceedings{\nriad2022learning,\ntitle={Learning Strides in Convolutional Neural Networks},\nauthor={Rachid Riad and Olivier Teboul and David Grangier and Neil Zeghidour},\nbooktitle={International Conference on Learning Representations},\nyear={2022},\nurl={https://openreview.net/forum?id=M752z9FKJP}\n}", "venue": "ICLR 2022 Oral", "venueid": "ICLR.cc/2022/Conference"}, "signatures": ["ICLR.cc/2022/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2022/Conference"], "pdate": 1643407560000, "odate": 1633539600000, "details": {"replyCount": 13}}, {"id": "7UmjRGzp-A", "original": "95kF2ii9GNk", "number": 1302, "cdate": 1632875509706, "mdate": null, "ddate": null, "tcdate": 1632875509706, "tmdate": 1676330621739, "tddate": null, "forum": "7UmjRGzp-A", "replyto": null, "invitation": "ICLR.cc/2022/Conference/-/Blind_Submission", "content": {"title": "Understanding over-squashing and bottlenecks on graphs via curvature", "authorids": ["~Jake_Topping1", "~Francesco_Di_Giovanni1", "~Benjamin_Paul_Chamberlain1", "~Xiaowen_Dong1", "~Michael_M._Bronstein1"], "authors": ["Jake Topping", "Francesco Di Giovanni", "Benjamin Paul Chamberlain", "Xiaowen Dong", "Michael M. Bronstein"], "keywords": ["Graph neural networks", "Geometric deep learning", "Differential geometry", "Ricci curvature"], "abstract": "Most graph neural networks (GNNs) use the message passing paradigm, in which node features are propagated on the input graph. Recent works pointed to the distortion of information flowing from distant nodes as a factor limiting the efficiency of message passing for tasks relying on long-distance interactions. This phenomenon, referred to as 'over-squashing', has been heuristically attributed to graph bottlenecks where the number of $k$-hop neighbors grows rapidly with $k$. We provide a precise description of the over-squashing phenomenon in GNNs and analyze how it arises from bottlenecks in the graph. For this purpose, we introduce a new edge-based combinatorial curvature and prove that negatively curved edges are responsible for the over-squashing issue. We also propose and experimentally test a  curvature-based graph rewiring method to alleviate the over-squashing.", "code_of_ethics": "", "submission_guidelines": "", "resubmission": "", "student_author": "", "serve_as_reviewer": "", "paperhash": "topping|understanding_oversquashing_and_bottlenecks_on_graphs_via_curvature", "pdf": "/pdf/f6b974eac8792a0d8d59633044276dabbf9d01c9.pdf", "_bibtex": "@inproceedings{\ntopping2022understanding,\ntitle={Understanding over-squashing and bottlenecks on graphs via curvature},\nauthor={Jake Topping and Francesco Di Giovanni and Benjamin Paul Chamberlain and Xiaowen Dong and Michael M. Bronstein},\nbooktitle={International Conference on Learning Representations},\nyear={2022},\nurl={https://openreview.net/forum?id=7UmjRGzp-A}\n}", "venue": "ICLR 2022 Oral", "venueid": "ICLR.cc/2022/Conference"}, "signatures": ["ICLR.cc/2022/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2022/Conference"], "pdate": 1643407560000, "odate": 1633539600000, "details": {"replyCount": 23}}, {"id": "8c50f-DoWAu", "original": "fht-uJDgI8", "number": 1253, "cdate": 1632875506634, "mdate": null, "ddate": null, "tcdate": 1632875506634, "tmdate": 1676330624552, "tddate": null, "forum": "8c50f-DoWAu", "replyto": null, "invitation": "ICLR.cc/2022/Conference/-/Blind_Submission", "content": {"title": "Diffusion-Based Voice Conversion with Fast Maximum Likelihood Sampling Scheme", "authorids": ["~Vadim_Popov1", "~Ivan_Vovk1", "~Vladimir_Gogoryan1", "~Tasnima_Sadekova1", "~Mikhail_Sergeevich_Kudinov1", "~Jiansheng_Wei1"], "authors": ["Vadim Popov", "Ivan Vovk", "Vladimir Gogoryan", "Tasnima Sadekova", "Mikhail Sergeevich Kudinov", "Jiansheng Wei"], "keywords": ["speech", "voice conversion", "diffusion models", "stochastic differential equations"], "abstract": "Voice conversion is a common speech synthesis task which can be solved in different ways depending on a particular real-world scenario. The most challenging one often referred to as one-shot many-to-many voice conversion consists in copying target voice from only one reference utterance in the most general case when both source and target speakers do not belong to the training dataset. We present a scalable high-quality solution based on diffusion probabilistic modeling and demonstrate its superior quality compared to state-of-the-art one-shot voice conversion approaches. Moreover, focusing on real-time applications, we investigate general principles which can make diffusion models faster while keeping synthesis quality at a high level. As a result, we develop a novel Stochastic Differential Equations solver suitable for various diffusion model types and generative tasks as shown through empirical studies and justify it by theoretical analysis.", "pdf": "/pdf/468145b46e459c5ba69e7017b6ef4eaece277e94.pdf", "code_of_ethics": "", "submission_guidelines": "", "resubmission": "", "student_author": "", "serve_as_reviewer": "", "paperhash": "popov|diffusionbased_voice_conversion_with_fast_maximum_likelihood_sampling_scheme", "data": "", "_bibtex": "@inproceedings{\npopov2022diffusionbased,\ntitle={Diffusion-Based Voice Conversion with Fast Maximum Likelihood Sampling Scheme},\nauthor={Vadim Popov and Ivan Vovk and Vladimir Gogoryan and Tasnima Sadekova and Mikhail Sergeevich Kudinov and Jiansheng Wei},\nbooktitle={International Conference on Learning Representations},\nyear={2022},\nurl={https://openreview.net/forum?id=8c50f-DoWAu}\n}", "venue": "ICLR 2022 Oral", "venueid": "ICLR.cc/2022/Conference"}, "signatures": ["ICLR.cc/2022/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2022/Conference"], "pdate": 1643407560000, "odate": 1633539600000, "details": {"replyCount": 9}}, {"id": "EskfH0bwNVn", "original": "ZYvkKrujUT8", "number": 938, "cdate": 1632875486153, "mdate": null, "ddate": null, "tcdate": 1632875486153, "tmdate": 1676330642683, "tddate": null, "forum": "EskfH0bwNVn", "replyto": null, "invitation": "ICLR.cc/2022/Conference/-/Blind_Submission", "content": {"title": "Resolving Training Biases via Influence-based Data Relabeling", "authorids": ["~Shuming_Kong1", "~Yanyan_Shen1", "~Linpeng_Huang1"], "authors": ["Shuming Kong", "Yanyan Shen", "Linpeng Huang"], "keywords": ["Training bias", "influence functions", "data relabeling"], "abstract": "The performance of supervised learning methods easily suffers from the training bias issue caused by train-test distribution mismatch or label noise. Influence function is a  technique that estimates the impacts of a training sample on the model\u2019s predictions. Recent studies on \\emph{data resampling} have employed influence functions to identify \\emph{harmful} training samples that will degrade model's test performance. They have shown that discarding or downweighting the identified harmful training samples is an effective way to resolve training biases. In this work, we move one step forward and propose an influence-based relabeling framework named RDIA for reusing harmful training samples toward better model performance. To achieve this, we use influence functions to estimate how relabeling a training sample would affect model's test performance and further develop a novel relabeling function R. We theoretically prove that applying R to relabel harmful training samples allows the model to achieve lower test loss than simply discarding them for any classification tasks using cross-entropy loss. Extensive experiments on ten real-world datasets demonstrate RDIA outperforms the state-of-the-art data resampling methods and improves model's robustness against label noise. ", "code_of_ethics": "", "submission_guidelines": "", "resubmission": "", "student_author": "", "serve_as_reviewer": "", "paperhash": "kong|resolving_training_biases_via_influencebased_data_relabeling", "pdf": "/pdf/64c51657be7bb5a9efecafe39344c719ccb4d394.pdf", "one-sentence_summary": "We propose an influence-based relabeling framework for solving training bias with a theoretical guarantee", "supplementary_material": "/attachment/7ef8b8e51f37c9823d3d6cd707735960abd6a147.zip", "_bibtex": "@inproceedings{\nkong2022resolving,\ntitle={Resolving Training Biases via Influence-based Data Relabeling},\nauthor={Shuming Kong and Yanyan Shen and Linpeng Huang},\nbooktitle={International Conference on Learning Representations},\nyear={2022},\nurl={https://openreview.net/forum?id=EskfH0bwNVn}\n}", "venue": "ICLR 2022 Oral", "venueid": "ICLR.cc/2022/Conference"}, "signatures": ["ICLR.cc/2022/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2022/Conference"], "pdate": 1643407560000, "odate": 1633539600000, "details": {"replyCount": 24}}, {"id": "9Hrka5PA7LW", "original": "rQsLyX65O2M", "number": 934, "cdate": 1632875485868, "mdate": null, "ddate": null, "tcdate": 1632875485868, "tmdate": 1676330643065, "tddate": null, "forum": "9Hrka5PA7LW", "replyto": null, "invitation": "ICLR.cc/2022/Conference/-/Blind_Submission", "content": {"title": "Representational Continuity for Unsupervised Continual Learning", "authorids": ["~Divyam_Madaan1", "~Jaehong_Yoon1", "~Yuanchun_Li1", "~Yunxin_Liu2", "~Sung_Ju_Hwang1"], "authors": ["Divyam Madaan", "Jaehong Yoon", "Yuanchun Li", "Yunxin Liu", "Sung Ju Hwang"], "keywords": ["Continual Learning", "Representational Learning", "Deep Learning"], "abstract": "Continual learning (CL) aims to learn a sequence of tasks without forgetting the previously acquired knowledge. However, recent CL advances are restricted to supervised continual learning (SCL) scenarios. Consequently, they are not scalable to real-world applications where the data distribution is often biased and unannotated. In this work, we focus on unsupervised continual learning (UCL), where we learn the feature representations on an unlabelled sequence of tasks and show that reliance on annotated data is not necessary for continual learning. We conduct a systematic study analyzing the learned feature representations and show that unsupervised visual representations are surprisingly more robust to catastrophic forgetting, consistently achieve better performance, and generalize better to out-of-distribution tasks than SCL. Furthermore, we find that UCL achieves a smoother loss landscape through qualitative analysis of the learned representations and learns meaningful feature representations. Additionally, we propose Lifelong Unsupervised Mixup (LUMP), a simple yet effective technique that interpolates between the current task and previous tasks' instances to alleviate catastrophic forgetting for unsupervised representations. ", "code_of_ethics": "", "submission_guidelines": "", "resubmission": "", "student_author": "", "serve_as_reviewer": "", "paperhash": "madaan|representational_continuity_for_unsupervised_continual_learning", "pdf": "/pdf/947f2c6dc3cd63a83d402bf9cbaddf42e362709e.pdf", "one-sentence_summary": "We attempt to bridge the gap between continual learning & representation learning and show that unsupervised continual learning achieves better performance and learns perceptual features with a smoother loss landscape than SCL.", "_bibtex": "@inproceedings{\nmadaan2022representational,\ntitle={Representational Continuity for Unsupervised Continual Learning},\nauthor={Divyam Madaan and Jaehong Yoon and Yuanchun Li and Yunxin Liu and Sung Ju Hwang},\nbooktitle={International Conference on Learning Representations},\nyear={2022},\nurl={https://openreview.net/forum?id=9Hrka5PA7LW}\n}", "venue": "ICLR 2022 Oral", "venueid": "ICLR.cc/2022/Conference"}, "signatures": ["ICLR.cc/2022/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2022/Conference"], "pdate": 1643407560000, "odate": 1633539600000, "details": {"replyCount": 16}}, {"id": "RJkAHKp7kNZ", "original": "6JzCbdNgWUe", "number": 870, "cdate": 1632875481559, "mdate": null, "ddate": null, "tcdate": 1632875481559, "tmdate": 1676330646468, "tddate": null, "forum": "RJkAHKp7kNZ", "replyto": null, "invitation": "ICLR.cc/2022/Conference/-/Blind_Submission", "content": {"title": "Vision-Based Manipulators Need to Also See from Their Hands", "authorids": ["~Kyle_Hsu1", "~Moo_Jin_Kim1", "~Rafael_Rafailov1", "~Jiajun_Wu1", "~Chelsea_Finn1"], "authors": ["Kyle Hsu", "Moo Jin Kim", "Rafael Rafailov", "Jiajun Wu", "Chelsea Finn"], "keywords": ["reinforcement learning", "observation space", "out-of-distribution generalization", "visuomotor control", "robotics", "manipulation"], "abstract": "We study how the choice of visual perspective affects learning and generalization in the context of physical manipulation from raw sensor observations. Compared with the more commonly used global third-person perspective, a hand-centric (eye-in-hand) perspective affords reduced observability, but we find that it consistently improves training efficiency and out-of-distribution generalization. These benefits hold across a variety of learning algorithms, experimental settings, and distribution shifts, and for both simulated and real robot apparatuses. However, this is only the case when hand-centric observability is sufficient; otherwise, including a third-person perspective is necessary for learning, but also harms out-of-distribution generalization. To mitigate this, we propose to regularize the third-person information stream via a variational information bottleneck. On six representative manipulation tasks with varying hand-centric observability adapted from the Meta-World benchmark, this results in a state-of-the-art reinforcement learning agent operating from both perspectives improving its out-of-distribution generalization on every task. While some practitioners have long put cameras in the hands of robots, our work systematically analyzes the benefits of doing so and provides simple and broadly applicable insights for improving end-to-end learned vision-based robotic manipulation.", "one-sentence_summary": "Appropriately designing the observation space of a vision-based manipulator and regularizing its representations leads to clear gains in learning stability and out-of-distribution generalization.", "code_of_ethics": "", "submission_guidelines": "", "resubmission": "", "student_author": "", "serve_as_reviewer": "", "paperhash": "hsu|visionbased_manipulators_need_to_also_see_from_their_hands", "pdf": "/pdf/bf5308ad68220347e7cbf2dcbedbf7bb4e0a21b1.pdf", "data": "", "_bibtex": "@inproceedings{\nhsu2022visionbased,\ntitle={Vision-Based Manipulators Need to Also See from Their Hands},\nauthor={Kyle Hsu and Moo Jin Kim and Rafael Rafailov and Jiajun Wu and Chelsea Finn},\nbooktitle={International Conference on Learning Representations},\nyear={2022},\nurl={https://openreview.net/forum?id=RJkAHKp7kNZ}\n}", "venue": "ICLR 2022 Oral", "venueid": "ICLR.cc/2022/Conference"}, "signatures": ["ICLR.cc/2022/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2022/Conference"], "pdate": 1643407560000, "odate": 1633539600000, "details": {"replyCount": 14}}, {"id": "ajXWF7bVR8d", "original": "b_6Nm9CNNV6", "number": 868, "cdate": 1632875481384, "mdate": null, "ddate": null, "tcdate": 1632875481384, "tmdate": 1697934881874, "tddate": null, "forum": "ajXWF7bVR8d", "replyto": null, "invitation": "ICLR.cc/2022/Conference/-/Blind_Submission", "content": {"title": "Meta-Learning with Fewer Tasks through Task Interpolation", "authorids": ["~Huaxiu_Yao1", "~Linjun_Zhang1", "~Chelsea_Finn1"], "authors": ["Huaxiu Yao", "Linjun Zhang", "Chelsea Finn"], "keywords": ["meta-learning", "task interpolation", "meta-regularization"], "abstract": "Meta-learning enables algorithms to quickly learn a newly encountered task with just a few labeled examples by transferring previously learned knowledge. However, the bottleneck of current meta-learning algorithms is the requirement of a large number of meta-training tasks, which may not be accessible in real-world scenarios. To address the challenge that available tasks may not densely sample the space of tasks, we propose to augment the task set through interpolation. By meta-learning with task interpolation (MLTI), our approach effectively generates additional tasks by randomly sampling a pair of tasks and interpolating the corresponding features and labels. Under both gradient-based and metric-based meta-learning settings, our theoretical analysis shows MLTI corresponds to a data-adaptive meta-regularization and further improves the generalization. Empirically, in our experiments on eight datasets from diverse domains including image recognition, pose prediction, molecule property prediction, and medical image classification, we find that the proposed general MLTI framework is compatible with representative meta-learning algorithms and consistently outperforms other state-of-the-art strategies.", "one-sentence_summary": "A new framework to densify the task distribution via task interpolation", "code_of_ethics": "", "submission_guidelines": "", "resubmission": "", "student_author": "", "serve_as_reviewer": "", "paperhash": "yao|metalearning_with_fewer_tasks_through_task_interpolation", "pdf": "/pdf/ebbfc5841da414394c96beeba92500546061461a.pdf", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2106.02695/code)", "_bibtex": "@inproceedings{\nyao2022metalearning,\ntitle={Meta-Learning with Fewer Tasks through Task Interpolation},\nauthor={Huaxiu Yao and Linjun Zhang and Chelsea Finn},\nbooktitle={International Conference on Learning Representations},\nyear={2022},\nurl={https://openreview.net/forum?id=ajXWF7bVR8d}\n}", "venue": "ICLR 2022 Oral", "venueid": "ICLR.cc/2022/Conference"}, "signatures": ["ICLR.cc/2022/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2022/Conference"], "pdate": 1643407560000, "odate": 1633539600000, "details": {"replyCount": 15}}, {"id": "iRCUlgmdfHJ", "original": "KF9AsbUiL9Q", "number": 822, "cdate": 1632875478354, "mdate": null, "ddate": null, "tcdate": 1632875478354, "tmdate": 1697934887138, "tddate": null, "forum": "iRCUlgmdfHJ", "replyto": null, "invitation": "ICLR.cc/2022/Conference/-/Blind_Submission", "content": {"title": "DISCOVERING AND EXPLAINING THE REPRESENTATION BOTTLENECK OF DNNS", "authorids": ["~Huiqi_Deng1", "~Qihan_Ren1", "~Hao_Zhang22", "~Quanshi_Zhang1"], "authors": ["Huiqi Deng", "Qihan Ren", "Hao Zhang", "Quanshi Zhang"], "keywords": ["representation bottleneck", "representation ability", "interaction", "explanation"], "abstract": "This paper explores the bottleneck of feature representations of deep neural networks (DNNs), from the perspective of the complexity of interactions between input variables encoded in DNNs. To this end, we focus on the multi-order interaction between input variables, where the order represents the complexity of interactions. We discover that a DNN is more likely to encode both too simple and too complex interactions, but usually fails to learn interactions of intermediate complexity. Such a phenomenon is widely shared by different DNNs for different tasks. This phenomenon indicates a cognition gap between DNNs and humans, and we call it a representation bottleneck. We theoretically prove the underlying reason for the representation bottleneck. Furthermore, we propose losses to encourage/penalize the learning of interactions of specific complexities, and analyze the representation capacities of interactions of different complexities. The code is available at https://github.com/Nebularaid2000/bottleneck.", "code_of_ethics": "", "submission_guidelines": "", "resubmission": "", "student_author": "", "serve_as_reviewer": "", "paperhash": "deng|discovering_and_explaining_the_representation_bottleneck_of_dnns", "pdf": "/pdf/e470657e4d47a20411713a973ed0282f87c9f9a9.pdf", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2111.06236/code)", "_bibtex": "@inproceedings{\ndeng2022discovering,\ntitle={{DISCOVERING} {AND} {EXPLAINING} {THE} {REPRESENTATION} {BOTTLENECK} {OF} {DNNS}},\nauthor={Huiqi Deng and Qihan Ren and Hao Zhang and Quanshi Zhang},\nbooktitle={International Conference on Learning Representations},\nyear={2022},\nurl={https://openreview.net/forum?id=iRCUlgmdfHJ}\n}", "venue": "ICLR 2022 Oral", "venueid": "ICLR.cc/2022/Conference"}, "signatures": ["ICLR.cc/2022/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2022/Conference"], "pdate": 1643407560000, "odate": 1633539600000, "details": {"replyCount": 5}}, {"id": "WAid50QschI", "original": "OkF3NoK3gpU", "number": 689, "cdate": 1632875469395, "mdate": null, "ddate": null, "tcdate": 1632875469395, "tmdate": 1697934904445, "tddate": null, "forum": "WAid50QschI", "replyto": null, "invitation": "ICLR.cc/2022/Conference/-/Blind_Submission", "content": {"title": "Sparse Communication via Mixed Distributions", "authorids": ["~Ant\u00f3nio_Farinhas1", "~Wilker_Aziz1", "~Vlad_Niculae2", "~Andre_Martins1"], "authors": ["Ant\u00f3nio Farinhas", "Wilker Aziz", "Vlad Niculae", "Andre Martins"], "keywords": [], "abstract": "Neural networks and other machine learning models compute continuous representations, while humans communicate mostly through discrete symbols. Reconciling these two forms of communication is desirable for generating human-readable interpretations or learning discrete latent variable models, while maintaining end-to-end differentiability. Some existing approaches (such as the Gumbel-Softmax transformation) build continuous relaxations that are discrete approximations in the zero-temperature limit, while others (such as sparsemax transformations and the Hard Concrete distribution) produce discrete/continuous hybrids. In this paper, we build rigorous theoretical foundations for these hybrids, which we call \"mixed random variables.'' Our starting point is a new \"direct sum'' base measure defined on the face lattice of the probability simplex. From this measure, we introduce new entropy and Kullback-Leibler divergence functions that subsume the discrete and differential cases and have interpretations in terms of code optimality. Our framework suggests two strategies for representing and sampling mixed random variables, an extrinsic (\"sample-and-project'\u2019) and an intrinsic one (based on face stratification). We experiment with both approaches on an  emergent communication benchmark and on modeling MNIST and Fashion-MNIST data with variational auto-encoders with mixed latent variables.", "pdf": "/pdf/f8c966f98befffb0bfbd9af921a4e4dd831d549f.pdf", "code_of_ethics": "", "submission_guidelines": "", "resubmission": "", "student_author": "", "serve_as_reviewer": "", "paperhash": "farinhas|sparse_communication_via_mixed_distributions", "supplementary_material": "/attachment/92722c31871512945eb4d2c789e94cd2ba73b3b0.zip", "code": "", "data": "", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 3 code implementations](https://www.catalyzex.com/paper/arxiv:2108.02658/code)", "_bibtex": "@inproceedings{\nfarinhas2022sparse,\ntitle={Sparse Communication via Mixed Distributions},\nauthor={Ant{\\'o}nio Farinhas and Wilker Aziz and Vlad Niculae and Andre Martins},\nbooktitle={International Conference on Learning Representations},\nyear={2022},\nurl={https://openreview.net/forum?id=WAid50QschI}\n}", "venue": "ICLR 2022 Oral", "venueid": "ICLR.cc/2022/Conference"}, "signatures": ["ICLR.cc/2022/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2022/Conference"], "pdate": 1643407560000, "odate": 1633539600000, "details": {"replyCount": 10}}, {"id": "gEZrGCozdqR", "original": "c8q9w3uWfYn", "number": 598, "cdate": 1632875463165, "mdate": null, "ddate": null, "tcdate": 1632875463165, "tmdate": 1697934914376, "tddate": null, "forum": "gEZrGCozdqR", "replyto": null, "invitation": "ICLR.cc/2022/Conference/-/Blind_Submission", "content": {"title": "Finetuned Language Models are Zero-Shot Learners", "authorids": ["~Jason_Wei1", "bosma@google.com", "vzhao@google.com", "~Kelvin_Guu1", "~Adams_Wei_Yu1", "~Brian_Lester1", "~Nan_Du1", "~Andrew_M._Dai1", "~Quoc_V_Le1"], "authors": ["Jason Wei", "Maarten Bosma", "Vincent Zhao", "Kelvin Guu", "Adams Wei Yu", "Brian Lester", "Nan Du", "Andrew M. Dai", "Quoc V Le"], "keywords": ["natural language processing", "zero-shot learning", "language models"], "abstract": "This paper explores a simple method for improving the zero-shot learning abilities of language models. We show that instruction tuning\u2014finetuning language models on a collection of datasets described via instructions\u2014substantially improves zero-shot performance on unseen tasks. We take a 137B parameter pretrained language model and instruction tune it on over 60 NLP datasets verbalized via natural language instruction templates. We evaluate this instruction-tuned model, which we call FLAN, on unseen task types. FLAN substantially improves the performance of its unmodified counterpart and surpasses zero-shot 175B GPT-3 on 20 of 25 datasets that we evaluate. FLAN even outperforms few-shot GPT-3 by a large margin on ANLI, RTE, BoolQ, AI2-ARC, OpenbookQA, and StoryCloze. Ablation studies reveal that number of finetuning datasets, model scale, and natural language instructions are key to the success of instruction tuning.", "one-sentence_summary": "\"Instruction tuning\", which finetunes language models on a collection of tasks described via instructions, substantially boosts zero-shot performance on unseen tasks.", "code_of_ethics": "", "submission_guidelines": "", "resubmission": "", "student_author": "", "serve_as_reviewer": "", "paperhash": "wei|finetuned_language_models_are_zeroshot_learners", "pdf": "/pdf/16b50405ab1e3ac1e2f76190ee62a48c496c568d.pdf", "supplementary_material": "/attachment/8e92660ea3d04e3380af73ef67555377395930c1.zip", "code": "", "data": "", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2109.01652/code)", "_bibtex": "@inproceedings{\nwei2022finetuned,\ntitle={Finetuned Language Models are Zero-Shot Learners},\nauthor={Jason Wei and Maarten Bosma and Vincent Zhao and Kelvin Guu and Adams Wei Yu and Brian Lester and Nan Du and Andrew M. Dai and Quoc V Le},\nbooktitle={International Conference on Learning Representations},\nyear={2022},\nurl={https://openreview.net/forum?id=gEZrGCozdqR}\n}", "venue": "ICLR 2022 Oral", "venueid": "ICLR.cc/2022/Conference"}, "signatures": ["ICLR.cc/2022/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2022/Conference"], "pdate": 1643407560000, "odate": 1633539600000, "details": {"replyCount": 14}}, {"id": "_CfpJazzXT2", "original": "no7qORAZON5", "number": 570, "cdate": 1632875461373, "mdate": null, "ddate": null, "tcdate": 1632875461373, "tmdate": 1697934917641, "tddate": null, "forum": "_CfpJazzXT2", "replyto": null, "invitation": "ICLR.cc/2022/Conference/-/Blind_Submission", "content": {"title": "F8Net: Fixed-Point 8-bit Only Multiplication for Network Quantization", "authorids": ["~Qing_Jin1", "~Jian_Ren2", "rzhuang@snapchat.com", "shanumante@snapchat.com", "~Zhengang_Li2", "~Zhiyu_Chen3", "~Yanzhi_Wang3", "~Kaiyuan_Yang1", "~Sergey_Tulyakov1"], "authors": ["Qing Jin", "Jian Ren", "Richard Zhuang", "Sumant Hanumante", "Zhengang Li", "Zhiyu Chen", "Yanzhi Wang", "Kaiyuan Yang", "Sergey Tulyakov"], "keywords": ["Neural Network Quantization", "Fixed-Point Arithmetic"], "abstract": "Neural network quantization is a promising compression technique to reduce memory footprint and save energy consumption, potentially leading to real-time inference. However, there is a performance gap between quantized and full-precision models. To reduce it, existing quantization approaches require high-precision INT32 or full-precision multiplication during inference for scaling or dequantization. This introduces a noticeable cost in terms of memory, speed, and required energy. To tackle these issues, we present F8Net, a novel quantization framework consisting in only \ufb01xed-point 8-bit multiplication. To derive our method, we \ufb01rst discuss the advantages of \ufb01xed-point multiplication with different formats of \ufb01xed-point numbers and study the statistical behavior of the associated \ufb01xed-point numbers. Second, based on the statistical and algorithmic analysis, we apply different \ufb01xed-point formats for weights and activations of different layers. We introduce a novel algorithm to automatically determine the right format for each layer during training. Third, we analyze a previous quantization algorithm\u2014parameterized clipping activation (PACT)\u2014and reformulate it using \ufb01xed-point arithmetic. Finally, we unify the recently proposed method for quantization \ufb01ne-tuning and our \ufb01xed-point approach to show the potential of our method. We verify F8Net on ImageNet for MobileNet V1/V2 and ResNet18/50. Our approach achieves comparable and better performance, when compared not only to existing quantization techniques with INT32 multiplication or \ufb02oating point arithmetic, but also to the full-precision counterparts, achieving state-of-the-art performance.", "one-sentence_summary": "We propose a method for neural network quantization with only 8-bit fixed-point multiplication.", "code_of_ethics": "", "submission_guidelines": "", "resubmission": "", "student_author": "", "serve_as_reviewer": "", "paperhash": "jin|f8net_fixedpoint_8bit_only_multiplication_for_network_quantization", "pdf": "/pdf/aed69dd0c10990a2c4948e6d230de04c5719fb7d.pdf", "data": "", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2202.05239/code)", "_bibtex": "@inproceedings{\njin2022fnet,\ntitle={F8Net: Fixed-Point 8-bit Only Multiplication for Network Quantization},\nauthor={Qing Jin and Jian Ren and Richard Zhuang and Sumant Hanumante and Zhengang Li and Zhiyu Chen and Yanzhi Wang and Kaiyuan Yang and Sergey Tulyakov},\nbooktitle={International Conference on Learning Representations},\nyear={2022},\nurl={https://openreview.net/forum?id=_CfpJazzXT2}\n}", "venue": "ICLR 2022 Oral", "venueid": "ICLR.cc/2022/Conference"}, "signatures": ["ICLR.cc/2022/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2022/Conference"], "pdate": 1643407560000, "odate": 1633539600000, "details": {"replyCount": 30}}, {"id": "UcDUxjPYWSr", "original": "cgqy1hO0mQ1", "number": 565, "cdate": 1632875461007, "mdate": null, "ddate": null, "tcdate": 1632875461007, "tmdate": 1676330664819, "tddate": null, "forum": "UcDUxjPYWSr", "replyto": null, "invitation": "ICLR.cc/2022/Conference/-/Blind_Submission", "content": {"title": "Transform2Act: Learning a Transform-and-Control Policy for Efficient Agent Design", "authorids": ["~Ye_Yuan5", "~Yuda_Song2", "~Zhengyi_Luo1", "~Wen_Sun1", "~Kris_M._Kitani1"], "authors": ["Ye Yuan", "Yuda Song", "Zhengyi Luo", "Wen Sun", "Kris M. Kitani"], "keywords": ["Agent Design", "Morphology Optimization", "Reinforcement Learning"], "abstract": "An agent's functionality is largely determined by its design, i.e., skeletal structure and joint attributes (e.g., length, size, strength). However, finding the optimal agent design for a given function is extremely challenging since the problem is inherently combinatorial and the design space is prohibitively large. Additionally, it can be costly to evaluate each candidate design which requires solving for its optimal controller. To tackle these problems, our key idea is to incorporate the design procedure of an agent into its decision-making process. Specifically, we learn a conditional policy that, in an episode, first applies a sequence of transform actions to modify an agent's skeletal structure and joint attributes, and then applies control actions under the new design. To handle a variable number of joints across designs, we use a graph-based policy where each graph node represents a joint and uses message passing with its neighbors to output joint-specific actions. Using policy gradient methods, our approach enables joint optimization of agent design and control as well as experience sharing across different designs, which improves sample efficiency substantially.  Experiments show that our approach, Transform2Act, outperforms prior methods significantly in terms of convergence speed and final performance. Notably, Transform2Act can automatically discover plausible designs similar to giraffes, squids, and spiders. Code and videos are available at https://sites.google.com/view/transform2act.", "code_of_ethics": "", "submission_guidelines": "", "resubmission": "", "student_author": "", "serve_as_reviewer": "", "paperhash": "yuan|transform2act_learning_a_transformandcontrol_policy_for_efficient_agent_design", "pdf": "/pdf/511a5c95afacad18125605721a8d1e530c07018b.pdf", "one-sentence_summary": "We learn a transform-and-control policy to both design and control an agent.", "data": "", "_bibtex": "@inproceedings{\nyuan2022transformact,\ntitle={Transform2Act: Learning a Transform-and-Control Policy for Efficient Agent Design},\nauthor={Ye Yuan and Yuda Song and Zhengyi Luo and Wen Sun and Kris M. Kitani},\nbooktitle={International Conference on Learning Representations},\nyear={2022},\nurl={https://openreview.net/forum?id=UcDUxjPYWSr}\n}", "venue": "ICLR 2022 Oral", "venueid": "ICLR.cc/2022/Conference"}, "signatures": ["ICLR.cc/2022/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2022/Conference"], "pdate": 1643407560000, "odate": 1633539600000, "details": {"replyCount": 15}}, {"id": "s03AQxehtd_", "original": "GAbPuxefj7f", "number": 549, "cdate": 1632875459918, "mdate": null, "ddate": null, "tcdate": 1632875459918, "tmdate": 1676330665972, "tddate": null, "forum": "s03AQxehtd_", "replyto": null, "invitation": "ICLR.cc/2022/Conference/-/Blind_Submission", "content": {"title": "ProtoRes: Proto-Residual Network for Pose Authoring via Learned Inverse Kinematics", "authorids": ["~Boris_N._Oreshkin1", "~Florent_Bocquelet1", "~Felix_G._Harvey1", "~Bay_Raitt1", "~Dominic_Laflamme1"], "authors": ["Boris N. Oreshkin", "Florent Bocquelet", "Felix G. Harvey", "Bay Raitt", "Dominic Laflamme"], "keywords": ["inverse kinematics", "deep learning", "pose modeling"], "abstract": "Our work focuses on the development of a learnable neural representation of human pose for advanced AI assisted animation tooling. Specifically, we tackle the problem of constructing a full static human pose based on sparse and variable user inputs (e.g. locations and/or orientations of a subset of body joints). To solve this problem, we propose a novel neural architecture that combines residual connections with prototype encoding of a partially specified pose to create a new complete pose from the learned latent space. We show that our architecture outperforms a baseline based on Transformer, both in terms of accuracy and computational efficiency. Additionally, we develop a user interface to integrate our neural model in Unity, a real-time 3D development platform. Furthermore, we introduce two new datasets representing the static human pose modeling problem, based on high-quality human motion capture data, which will be released publicly along with model code.", "pdf": "/pdf/72eadcfe21558f0be18ff071adc50adc3ae85e5e.pdf", "code_of_ethics": "", "submission_guidelines": "", "resubmission": "", "student_author": "", "serve_as_reviewer": "", "paperhash": "oreshkin|protores_protoresidual_network_for_pose_authoring_via_learned_inverse_kinematics", "supplementary_material": "/attachment/ff67a06a7330e8faefa4288da4c1ce1b2e39fbb7.zip", "_bibtex": "@inproceedings{\noreshkin2022protores,\ntitle={ProtoRes: Proto-Residual Network for Pose Authoring via Learned Inverse Kinematics},\nauthor={Boris N. Oreshkin and Florent Bocquelet and Felix G. Harvey and Bay Raitt and Dominic Laflamme},\nbooktitle={International Conference on Learning Representations},\nyear={2022},\nurl={https://openreview.net/forum?id=s03AQxehtd_}\n}", "venue": "ICLR 2022 Oral", "venueid": "ICLR.cc/2022/Conference"}, "signatures": ["ICLR.cc/2022/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2022/Conference"], "pdate": 1643407560000, "odate": 1633539600000, "details": {"replyCount": 25}}, {"id": "-70L8lpp9DF", "original": "joG-Vjs6G4k", "number": 287, "cdate": 1632875441798, "mdate": null, "ddate": null, "tcdate": 1632875441798, "tmdate": 1676330678565, "tddate": null, "forum": "-70L8lpp9DF", "replyto": null, "invitation": "ICLR.cc/2022/Conference/-/Blind_Submission", "content": {"title": "Hyperparameter Tuning with Renyi Differential Privacy", "authorids": ["~Nicolas_Papernot1", "~Thomas_Steinke2"], "authors": ["Nicolas Papernot", "Thomas Steinke"], "keywords": ["differential privacy", "hyperparameter tuning"], "abstract": "For many differentially private algorithms, such as the prominent noisy stochastic gradient descent (DP-SGD), the analysis needed to bound the privacy leakage of a single training run is well understood. However, few studies have reasoned about the privacy leakage resulting from the multiple training runs needed to fine tune the value of the training algorithm\u2019s hyperparameters. In this work, we first illustrate how simply setting hyperparameters based on non-private training runs can leak private information. Motivated by this observation, we then provide privacy guarantees for hyperparameter search procedures within the framework of Renyi Differential Privacy. Our results improve and extend the work of Liu and Talwar (STOC 2019). Our analysis supports our previous observation that tuning hyperparameters does indeed leak private information, but we prove that, under certain assumptions, this leakage is modest, as long as each candidate training run needed to select hyperparameters is itself differentially private.", "one-sentence_summary": "We provide privacy guarantees for hyperparameter search procedures, showing that tuning hyperparameters leaks private information, but that, under certain assumptions, this leakage is modest.", "code_of_ethics": "", "submission_guidelines": "", "resubmission": "", "student_author": "", "serve_as_reviewer": "", "paperhash": "papernot|hyperparameter_tuning_with_renyi_differential_privacy", "pdf": "/pdf/8832d0e112b9fd6c5c8f0be8a093625e4de6e337.pdf", "_bibtex": "@inproceedings{\npapernot2022hyperparameter,\ntitle={Hyperparameter Tuning with Renyi Differential Privacy},\nauthor={Nicolas Papernot and Thomas Steinke},\nbooktitle={International Conference on Learning Representations},\nyear={2022},\nurl={https://openreview.net/forum?id=-70L8lpp9DF}\n}", "venue": "ICLR 2022 Oral", "venueid": "ICLR.cc/2022/Conference"}, "signatures": ["ICLR.cc/2022/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2022/Conference"], "pdate": 1643407560000, "odate": 1633539600000, "details": {"replyCount": 15}}, {"id": "qj1IZ-6TInc", "original": "C1GKpcAunT2", "number": 284, "cdate": 1632875441653, "mdate": null, "ddate": null, "tcdate": 1632875441653, "tmdate": 1697934946114, "tddate": null, "forum": "qj1IZ-6TInc", "replyto": null, "invitation": "ICLR.cc/2022/Conference/-/Blind_Submission", "content": {"title": "Real-Time Neural Voice Camouflage", "authorids": ["~Mia_Chiquier1", "~Chengzhi_Mao2", "~Carl_Vondrick2"], "authors": ["Mia Chiquier", "Chengzhi Mao", "Carl Vondrick"], "keywords": ["automatic speech recognition", "predictive models", "privacy"], "abstract": "Automatic speech recognition systems have created exciting possibilities for applications, however they also enable opportunities for systematic eavesdropping.We propose a method to camouflage a person's voice from these systems without inconveniencing the conversation between people in the room. Standard adversarial attacks are not effective in real-time streaming situations because the characteristics of the signal will have changed by the time the attack is executed. We introduce predictive adversarial attacks, which achieves real-time performance by forecasting the attack vector that will be the most effective in the future. Under real-time constraints, our method jams the established speech recognition system DeepSpeech 3.9x more than online projected gradient descent as measured through word error rate, and 6.6x more as measured through character error rate. We furthermore demonstrate our approach is practically effective in realistic environments with complex scene geometries. ", "code_of_ethics": "", "submission_guidelines": "", "resubmission": "", "student_author": "", "serve_as_reviewer": "", "paperhash": "chiquier|realtime_neural_voice_camouflage", "pdf": "/pdf/e2b96a38db73636bfa51d5ee4097373ddda15329.pdf", "one-sentence_summary": "We introduce predictive attacks, which achieve real-time performance in breaking automatic speech recognition models by forecasting the attack vector that will be the most effective in the future. ", "supplementary_material": "/attachment/15a7fedce4527cfd5286ff5ab74da7a6be0319c1.zip", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2112.07076/code)", "_bibtex": "@inproceedings{\nchiquier2022realtime,\ntitle={Real-Time Neural Voice Camouflage},\nauthor={Mia Chiquier and Chengzhi Mao and Carl Vondrick},\nbooktitle={International Conference on Learning Representations},\nyear={2022},\nurl={https://openreview.net/forum?id=qj1IZ-6TInc}\n}", "venue": "ICLR 2022 Oral", "venueid": "ICLR.cc/2022/Conference"}, "signatures": ["ICLR.cc/2022/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2022/Conference"], "pdate": 1643407560000, "odate": 1633539600000, "details": {"replyCount": 9}}, {"id": "NMEceG4v69Y", "original": "wCro7kZRt1x", "number": 224, "cdate": 1632875437739, "mdate": null, "ddate": null, "tcdate": 1632875437739, "tmdate": 1697934953366, "tddate": null, "forum": "NMEceG4v69Y", "replyto": null, "invitation": "ICLR.cc/2022/Conference/-/Blind_Submission", "content": {"title": "CycleMLP: A MLP-like Architecture for Dense Prediction", "authorids": ["~Shoufa_Chen1", "~Enze_Xie1", "~Chongjian_GE1", "~Runjian_Chen1", "~Ding_Liang1", "~Ping_Luo2"], "authors": ["Shoufa Chen", "Enze Xie", "Chongjian GE", "Runjian Chen", "Ding Liang", "Ping Luo"], "keywords": ["MLP", "Dense Prediction"], "abstract": "This paper presents a simple MLP-like architecture, CycleMLP, which is a versatile backbone for visual recognition and dense predictions. As compared to modern MLP architectures, e.g. , MLP-Mixer, ResMLP, and gMLP, whose architectures are correlated to image size and thus are infeasible in object detection and segmentation, CycleMLP has two advantages compared to modern approaches. (1) It can cope\nwith various image sizes. (2) It achieves linear computational complexity to image size by using local windows. In contrast, previous MLPs have $O(N^2)$ computations due to fully spatial connections. We build a family of models which surpass existing MLPs and even state-of-the-art Transformer-based models, e.g. Swin Transformer, while using fewer parameters and FLOPs. We expand the MLP-like models\u2019 applicability, making them a versatile backbone for dense prediction tasks. CycleMLP achieves competitive results on object detection, instance segmentation, and semantic segmentation. In particular, CycleMLP-Tiny outperforms Swin-Tiny by 1.3% mIoU on ADE20K dataset with fewer FLOPs. Moreover, CycleMLP also shows excellent zero-shot robustness on ImageNet-C dataset.", "one-sentence_summary": "A versatile MLP-like architecture for both recognition and dense prediction.", "code_of_ethics": "", "submission_guidelines": "", "resubmission": "", "student_author": "", "serve_as_reviewer": "", "paperhash": "chen|cyclemlp_a_mlplike_architecture_for_dense_prediction", "pdf": "/pdf/0ff0f728cbc430b36ea84288793e887e216cff59.pdf", "supplementary_material": "/attachment/fd8f09073416a32a523ca794fda894d24f943625.zip", "code": "", "data": "", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2107.10224/code)", "_bibtex": "@inproceedings{\nchen2022cyclemlp,\ntitle={Cycle{MLP}: A {MLP}-like Architecture for Dense Prediction},\nauthor={Shoufa Chen and Enze Xie and Chongjian GE and Runjian Chen and Ding Liang and Ping Luo},\nbooktitle={International Conference on Learning Representations},\nyear={2022},\nurl={https://openreview.net/forum?id=NMEceG4v69Y}\n}", "venue": "ICLR 2022 Oral", "venueid": "ICLR.cc/2022/Conference"}, "signatures": ["ICLR.cc/2022/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2022/Conference"], "pdate": 1643407560000, "odate": 1633539600000, "details": {"replyCount": 5}}, {"id": "0xiJLKH-ufZ", "original": "_LdAAf-69yi", "number": 222, "cdate": 1632875437587, "mdate": null, "ddate": null, "tcdate": 1632875437587, "tmdate": 1676330682692, "tddate": null, "forum": "0xiJLKH-ufZ", "replyto": null, "invitation": "ICLR.cc/2022/Conference/-/Blind_Submission", "content": {"title": "Analytic-DPM: an Analytic Estimate of the Optimal Reverse Variance in Diffusion Probabilistic Models", "authorids": ["~Fan_Bao1", "~Chongxuan_Li1", "~Jun_Zhu2", "~Bo_Zhang2"], "authors": ["Fan Bao", "Chongxuan Li", "Jun Zhu", "Bo Zhang"], "keywords": ["diffusion probabilistic models", "generative models"], "abstract": "Diffusion probabilistic models (DPMs) represent a class of powerful generative models. Despite their success, the inference of DPMs is expensive since it generally needs to iterate over thousands of timesteps. A key problem in the inference is to estimate the variance in each timestep of the reverse process. In this work, we present a surprising result that both the optimal reverse variance and the corresponding optimal KL divergence of a DPM have analytic forms w.r.t. its score function. Building upon it, we propose \\textit{Analytic-DPM}, a training-free inference framework that estimates the analytic forms of the variance and KL divergence using the Monte Carlo method and a pretrained score-based model. Further, to correct the potential bias caused by the score-based model, we derive both lower and upper bounds of the optimal variance and clip the estimate for a better result. Empirically, our analytic-DPM improves the log-likelihood of various DPMs, produces high-quality samples, and meanwhile enjoys a $20\\times$ to $80\\times$ speed up.", "one-sentence_summary": "We propose an analytic framework of estimating the optimal reverse variance in DPMs.", "code_of_ethics": "", "submission_guidelines": "", "resubmission": "", "student_author": "", "serve_as_reviewer": "", "paperhash": "bao|analyticdpm_an_analytic_estimate_of_the_optimal_reverse_variance_in_diffusion_probabilistic_models", "pdf": "/pdf/541cdc9e000367bb0bd3fc42201573ed434094c8.pdf", "supplementary_material": "/attachment/82cdf46f2e4104c5546cc812a2654ad6d79347f0.zip", "_bibtex": "@inproceedings{\nbao2022analyticdpm,\ntitle={Analytic-{DPM}: an Analytic Estimate of the Optimal Reverse Variance in Diffusion Probabilistic Models},\nauthor={Fan Bao and Chongxuan Li and Jun Zhu and Bo Zhang},\nbooktitle={International Conference on Learning Representations},\nyear={2022},\nurl={https://openreview.net/forum?id=0xiJLKH-ufZ}\n}", "venue": "ICLR 2022 Oral", "venueid": "ICLR.cc/2022/Conference"}, "signatures": ["ICLR.cc/2022/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2022/Conference"], "pdate": 1643407560000, "odate": 1633539600000, "details": {"replyCount": 21}}, {"id": "uSE03demja", "original": "FKMa_FVIkM", "number": 208, "cdate": 1632875436603, "mdate": null, "ddate": null, "tcdate": 1632875436603, "tmdate": 1676330683312, "tddate": null, "forum": "uSE03demja", "replyto": null, "invitation": "ICLR.cc/2022/Conference/-/Blind_Submission", "content": {"title": "RISP: Rendering-Invariant State Predictor with Differentiable Simulation and Rendering for Cross-Domain Parameter Estimation", "authorids": ["~Pingchuan_Ma3", "~Tao_Du1", "~Joshua_B._Tenenbaum1", "~Wojciech_Matusik2", "~Chuang_Gan1"], "authors": ["Pingchuan Ma", "Tao Du", "Joshua B. Tenenbaum", "Wojciech Matusik", "Chuang Gan"], "keywords": ["differentiable rendering", "differentiable simulation", "system identification"], "abstract": "This work considers identifying parameters characterizing a physical system's dynamic motion directly from a video whose rendering configurations are inaccessible. Existing solutions require massive training data or lack generalizability to unknown rendering configurations. We propose a novel approach that marries domain randomization and differentiable rendering gradients to address this problem. Our core idea is to train a rendering-invariant state-prediction (RISP) network that transforms image differences into state differences independent of rendering configurations, e.g., lighting, shadows, or material reflectance. To train this predictor, we formulate a new loss on rendering variances using gradients from differentiable rendering. Moreover, we present an efficient, second-order method to compute the gradients of this loss, allowing it to be integrated seamlessly into modern deep learning frameworks. We evaluate our method in rigid-body and deformable-body simulation environments using four tasks: state estimation, system identification, imitation learning, and visuomotor control. We further demonstrate the efficacy of our approach on a real-world example: inferring the state and action sequences of a quadrotor from a video of its motion sequences. Compared with existing methods, our approach achieves significantly lower reconstruction errors and has better generalizability among unknown rendering configurations.", "code_of_ethics": "", "submission_guidelines": "", "resubmission": "", "student_author": "", "serve_as_reviewer": "", "paperhash": "ma|risp_renderinginvariant_state_predictor_with_differentiable_simulation_and_rendering_for_crossdomain_parameter_estimation", "pdf": "/pdf/999353870633727a2d50bc5b4ee873b50401eba7.pdf", "one-sentence_summary": "We propose a novel approach to address the problem of identifying parameters characterizing a physical system's dynamic motion directly from a video whose rendering configurations are inaccessible.", "_bibtex": "@inproceedings{\nma2022risp,\ntitle={{RISP}: Rendering-Invariant State Predictor with Differentiable Simulation and Rendering for Cross-Domain Parameter Estimation},\nauthor={Pingchuan Ma and Tao Du and Joshua B. Tenenbaum and Wojciech Matusik and Chuang Gan},\nbooktitle={International Conference on Learning Representations},\nyear={2022},\nurl={https://openreview.net/forum?id=uSE03demja}\n}", "venue": "ICLR 2022 Oral", "venueid": "ICLR.cc/2022/Conference"}, "signatures": ["ICLR.cc/2022/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2022/Conference"], "pdate": 1643407560000, "odate": 1633539600000, "details": {"replyCount": 13}}, {"id": "3wU2UX0voE", "original": "hBtGNPlTLpL", "number": 154, "cdate": 1632875432784, "mdate": null, "ddate": null, "tcdate": 1632875432784, "tmdate": 1697934960648, "tddate": null, "forum": "3wU2UX0voE", "replyto": null, "invitation": "ICLR.cc/2022/Conference/-/Blind_Submission", "content": {"title": "The Information Geometry of Unsupervised Reinforcement Learning", "authorids": ["~Benjamin_Eysenbach1", "~Ruslan_Salakhutdinov1", "~Sergey_Levine1"], "authors": ["Benjamin Eysenbach", "Ruslan Salakhutdinov", "Sergey Levine"], "keywords": ["unsupervised skill learning", "reward-free RL", "mutual information", "DIAYN"], "abstract": "How can a reinforcement learning (RL) agent prepare to solve downstream tasks if those tasks are not known a priori? One approach is unsupervised skill discovery, a class of algorithms that learn a set of policies without access to a reward function. Such algorithms bear a close resemblance to representation learning algorithms (e.g., contrastive learning) in supervised learning, in that both are pretraining algorithms that maximize some approximation to a mutual information objective. While prior work has shown that the set of skills learned by such methods can accelerate downstream RL tasks, prior work offers little analysis into whether these skill learning algorithms are optimal, or even what notion of optimality would be appropriate to apply to them. In this work, we show that unsupervised skill discovery algorithms based on mutual information maximization do not learn skills that are optimal for every possible reward function. However, we show that the distribution over skills provides an optimal initialization minimizing regret against adversarially-chosen reward functions, assuming a certain type of adaptation procedure. Our analysis also provides a geometric perspective on these skill learning methods.", "one-sentence_summary": "We show that mutual information skill learning is optimal in one sense but not optimal in another sense.", "code_of_ethics": "", "submission_guidelines": "", "resubmission": "", "student_author": "", "serve_as_reviewer": "", "paperhash": "eysenbach|the_information_geometry_of_unsupervised_reinforcement_learning", "pdf": "/pdf/4709236cdf10497a057511e94fe99f87770c5bf6.pdf", "supplementary_material": "/attachment/70a8d05ec738c35895783c0cb17f52610301f6df.zip", "code": "", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2110.02719/code)", "_bibtex": "@inproceedings{\neysenbach2022the,\ntitle={The Information Geometry of Unsupervised Reinforcement Learning},\nauthor={Benjamin Eysenbach and Ruslan Salakhutdinov and Sergey Levine},\nbooktitle={International Conference on Learning Representations},\nyear={2022},\nurl={https://openreview.net/forum?id=3wU2UX0voE}\n}", "venue": "ICLR 2022 Oral", "venueid": "ICLR.cc/2022/Conference"}, "signatures": ["ICLR.cc/2022/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2022/Conference"], "pdate": 1643407560000, "odate": 1633539600000, "details": {"replyCount": 4}}, {"id": "pMQwKL1yctf", "original": "KRuLmnaxeCk", "number": 86, "cdate": 1632875427626, "mdate": null, "ddate": null, "tcdate": 1632875427626, "tmdate": 1697934968362, "tddate": null, "forum": "pMQwKL1yctf", "replyto": null, "invitation": "ICLR.cc/2022/Conference/-/Blind_Submission", "content": {"title": "Language modeling via stochastic processes", "authorids": ["~Rose_E_Wang1", "~Esin_Durmus1", "~Noah_Goodman1", "~Tatsunori_Hashimoto1"], "authors": ["Rose E Wang", "Esin Durmus", "Noah Goodman", "Tatsunori Hashimoto"], "keywords": ["contrastive learning", "language modelling", "stochastic processes"], "abstract": "Modern language models can generate high-quality short texts. However, they often meander or are incoherent when generating longer texts. These issues arise from the next-token-only language modeling objective. To address these issues, we introduce Time Control (TC), a language model that implicitly plans via a latent stochastic process. TC does this by learning a representation which maps the dynamics of how text changes in a document to the dynamics of a stochastic process of interest. Using this representation, the language model can generate text by first implicitly generating a document plan via a stochastic process, and then generating text that is consistent with this latent plan. Compared to domain-specific methods and fine-tuning GPT2 across a variety of text domains, TC improves performance on text infilling and discourse coherence. On long text generation settings, TC preserves the text structure both in terms of ordering (up to +40% better) and text length consistency (up to +17% better).  Human evaluators also prefer TC's output 28.6% more than the baselines.", "code_of_ethics": "", "submission_guidelines": "", "resubmission": "", "student_author": "", "serve_as_reviewer": "", "paperhash": "wang|language_modeling_via_stochastic_processes", "pdf": "/pdf/ceeec650a60b1f87ad4dda26ecd02c9df0e3ed9d.pdf", "one-sentence_summary": "We introduce a language model that implicitly plans via a latent stochastic process.", "supplementary_material": "/attachment/3c726fd45d501529d53d01a306dac4372f0175aa.zip", "data": "", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2203.11370/code)", "_bibtex": "@inproceedings{\nwang2022language,\ntitle={Language modeling via stochastic processes},\nauthor={Rose E Wang and Esin Durmus and Noah Goodman and Tatsunori Hashimoto},\nbooktitle={International Conference on Learning Representations},\nyear={2022},\nurl={https://openreview.net/forum?id=pMQwKL1yctf}\n}", "venue": "ICLR 2022 Oral", "venueid": "ICLR.cc/2022/Conference"}, "signatures": ["ICLR.cc/2022/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2022/Conference"], "pdate": 1643407560000, "odate": 1633539600000, "details": {"replyCount": 11}}], "count": 55}