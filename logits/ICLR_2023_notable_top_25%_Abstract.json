{"notes": [{"id": "N_g8TT9Cy7f", "original": "6G3gROtLNj6", "number": 6549, "cdate": 1663850582549, "mdate": null, "ddate": null, "tcdate": 1663850582549, "tmdate": 1697935193047, "tddate": null, "forum": "N_g8TT9Cy7f", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Human-Guided Fair Classification for Natural Language Processing", "authorids": ["~Florian_E._Dorner1", "~Momchil_Peychev1", "~Nikola_Konstantinov1", "~Naman_Goel1", "~Elliott_Ash1", "~Martin_Vechev1"], "authors": ["Florian E. Dorner", "Momchil Peychev", "Nikola Konstantinov", "Naman Goel", "Elliott Ash", "Martin Vechev"], "keywords": ["Individual Fairness", "Style Transfer", "NLP", "Crowdsourcing", "Human Evaluation"], "TL;DR": "We provide new methods for generating individual fairness specifications for NLP based on LLMs and validate them in a human study. ", "abstract": "Text classifiers have promising applications in high-stake tasks such as resume screening and content moderation. These classifiers must be fair and avoid discriminatory decisions by being invariant to perturbations of sensitive attributes such as gender or ethnicity. However, there is a gap between human intuition about these perturbations and the formal similarity specifications capturing them. While existing research has started to address this gap, current methods are based on hardcoded word replacements, resulting in specifications with limited expressivity or ones that fail to fully align with human intuition (e.g., in cases of asymmetric counterfactuals). This work proposes novel methods for bridging this gap by discovering expressive and intuitive individual fairness specifications. We show how to leverage unsupervised style transfer and GPT-3's zero-shot capabilities to automatically generate expressive candidate pairs of semantically similar sentences that differ along sensitive attributes. We then validate the generated pairs via an extensive crowdsourcing study, which confirms that a lot of these pairs align with human intuition about fairness in the context of toxicity classification. Finally, we show how limited amounts of human feedback can be leveraged to learn a similarity specification that can be used to train downstream fairness-aware models. ", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)", "paperhash": "dorner|humanguided_fair_classification_for_natural_language_processing", "pdf": "/pdf/09b5568016529de9fe0127852626c933cb6af627.pdf", "supplementary_material": "", "_bibtex": "@inproceedings{\ndorner2023humanguided,\ntitle={Human-Guided Fair Classification for Natural Language Processing},\nauthor={Florian E. Dorner and Momchil Peychev and Nikola Konstantinov and Naman Goel and Elliott Ash and Martin Vechev},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=N_g8TT9Cy7f}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2212.10154/code)"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279440616, "odate": 1664468100000, "details": {"replyCount": 16}}, {"id": "X5ZMzRYqUjB", "original": "DVRbY6gJTQ", "number": 6465, "cdate": 1663850572142, "mdate": null, "ddate": null, "tcdate": 1663850572142, "tmdate": 1677491770884, "tddate": null, "forum": "X5ZMzRYqUjB", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Humanly Certifying Superhuman Classifiers", "authorids": ["~Qiongkai_Xu1", "~Christian_Walder1", "~Chenchen_Xu1"], "authors": ["Qiongkai Xu", "Christian Walder", "Chenchen Xu"], "keywords": ["Evaluation theory", "Oracle accuracy", "Superhuman classifier"], "TL;DR": "A theory for estimating the performance of a classifier by comparing with human annotators, even when the humans are inferior to the classifier.", "abstract": "This paper addresses a key question in current machine learning research: if we believe that a model's predictions might be better than those given by human experts, how can we (humans) verify these beliefs? In some cases, this ``superhuman'' performance is readily demonstrated; for example by defeating top-tier human players in traditional two player games. On the other hand, it can be challenging to evaluate classification models that potentially surpass human performance. Indeed, human annotations are often treated as a ground truth, which implicitly assumes the superiority of the human over any models trained on human annotations. In reality, human annotators are subjective and can make mistakes. Evaluating the performance with respect to a genuine oracle is more objective and reliable, even when querying the oracle is more expensive or sometimes impossible. In this paper, we first raise the challenge of evaluating the performance of both humans and models with respect to an oracle which is $\\textit{unobserved}$. We develop a theory for estimating the accuracy compared to the oracle, using only imperfect human annotations for reference. Our analysis provides an executable recipe for detecting and certifying superhuman performance in this setting, which we believe will assist in understanding the stage of current research on classification. We validate the convergence of the bounds and the assumptions of our theory on carefully designed toy experiments with known oracles. Moreover, we demonstrate the utility of our theory by meta-analyzing large-scale natural language processing tasks, for which an oracle does not exist, and show that under our mild assumptions a number of models from recent years have already achieved superhuman performance with high probability---suggesting that our new oracle based performance evaluation metrics are overdue as an alternative to the widely used accuracy metrics that are naively based on imperfect human annotations.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)", "paperhash": "xu|humanly_certifying_superhuman_classifiers", "pdf": "/pdf/cd3013d0326b50c5c63ae8604d438ed46e8c664c.pdf", "_bibtex": "@inproceedings{\nxu2023humanly,\ntitle={Humanly Certifying Superhuman Classifiers},\nauthor={Qiongkai Xu and Christian Walder and Chenchen Xu},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=X5ZMzRYqUjB}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279437331, "odate": 1664468100000, "details": {"replyCount": 12}}, {"id": "4F1gvduDeL", "original": "-i0yq60xf8", "number": 6412, "cdate": 1663850565552, "mdate": null, "ddate": null, "tcdate": 1663850565552, "tmdate": 1677756920154, "tddate": null, "forum": "4F1gvduDeL", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Few-Shot Domain Adaptation For End-to-End Communication", "authorids": ["~Jayaram_Raghuram1", "~Yijing_Zeng1", "~Dolores_Garcia1", "~Rafael_Ruiz1", "~Somesh_Jha1", "~Joerg_Widmer1", "~Suman_Banerjee3"], "authors": ["Jayaram Raghuram", "Yijing Zeng", "Dolores Garcia", "Rafael Ruiz", "Somesh Jha", "Joerg Widmer", "Suman Banerjee"], "keywords": ["domain adaptation", "end-to-end communication", "autoencoders", "Gaussian mixtures", "mixture density networks", "few-shot", "wireless channel"], "TL;DR": "We propose a sample-efficient domain adaptation method for the autoencoder based end-to-end communication problem", "abstract": "The problem of end-to-end learning of a communication system using an autoencoder -- consisting of an encoder, channel, and decoder modeled using neural networks -- has recently been shown to be an effective approach. A challenge faced in the practical adoption of this learning approach is that under changing channel conditions (e.g. a wireless link), it requires frequent retraining of the autoencoder in order to maintain a low decoding error rate. Since retraining is both time consuming and requires a large number of samples, it becomes impractical when the channel distribution is changing quickly. We propose to address this problem using a fast and sample-efficient (few-shot) domain adaptation method that does not change the encoder and decoder networks. Different from conventional training-time unsupervised or semi-supervised domain adaptation, here we have a trained autoencoder from a source distribution that we want to adapt (at test time) to a target distribution using only a small labeled dataset, and no unlabeled data. We focus on a generative channel model based on the Gaussian mixture density network (MDN), and propose a regularized, parameter-efficient adaptation of the MDN using a set of affine transformations. The learned affine transformations are then used to design an optimal transformation at the decoder input to compensate for the distribution shift, and effectively present to the decoder inputs close to the source distribution. Experiments on many simulated distribution changes common to the wireless setting, and a real mmWave FPGA testbed demonstrate the effectiveness of our method at adaptation using very few target domain samples~\\footnote{Code for our work: \\url{https://github.com/jayaram-r/domain-adaptation-autoencoder}}.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Applications (eg, speech processing, computer vision, NLP)", "paperhash": "raghuram|fewshot_domain_adaptation_for_endtoend_communication", "pdf": "/pdf/502da8335c25f515d1b0a7b57057ac446ce9f67b.pdf", "supplementary_material": "/attachment/86158f485ce842a56e030f8d01bcf535bbab4d9f.zip", "_bibtex": "@inproceedings{\nraghuram2023fewshot,\ntitle={Few-Shot Domain Adaptation For End-to-End Communication},\nauthor={Jayaram Raghuram and Yijing Zeng and Dolores Garcia and Rafael Ruiz and Somesh Jha and Joerg Widmer and Suman Banerjee},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=4F1gvduDeL}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279435641, "odate": 1664468100000, "details": {"replyCount": 9}}, {"id": "688hNNMigVX", "original": "2cet0r2UcAb", "number": 6357, "cdate": 1663850559191, "mdate": null, "ddate": null, "tcdate": 1663850559191, "tmdate": 1677760429814, "tddate": null, "forum": "688hNNMigVX", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Learning a Data-Driven Policy Network for Pre-Training Automated Feature Engineering", "authorids": ["~Liyao_Li1", "~Haobo_Wang1", "~Liangyu_Zha1", "~Qingyi_Huang1", "~Sai_Wu2", "~Gang_Chen6", "~Junbo_Zhao1"], "authors": ["Liyao Li", "Haobo Wang", "Liangyu Zha", "Qingyi Huang", "Sai Wu", "Gang Chen", "Junbo Zhao"], "keywords": ["Automated Feature Engineering", "Reinforcement Learning", "Tabular Data", "Data-Driven", "Pre-Training"], "abstract": "Feature engineering is widely acknowledged to be pivotal in tabular data analysis and prediction. Automated feature engineering (AutoFE) emerged to automate this process managed by experienced data scientists and engineers conventionally. In this area, most \u2014 if not all \u2014 prior work adopted an identical framework from the neural architecture search (NAS) method. While feasible, we posit that the NAS framework very much contradicts the way how human experts cope with the data since the inherent Markov decision process (MDP) setup differs. We point out that its data-unobserved setup consequentially results in an incapability to generalize across different datasets as well as also high computational cost. This paper proposes a novel AutoFE framework Feature Set Data-Driven Search (FETCH), a pipeline mainly for feature generation and selection. Notably, FETCH is built on a brand-new data-driven MDP setup using the tabular dataset as the state fed into the policy network. Further, we posit that the crucial merit of FETCH is its transferability where the yielded policy network trained on a variety of datasets is indeed capable to enact feature engineering on unseen data, without requiring additional exploration. To the best of our knowledge, this is a pioneer attempt to build a tabular data pre-training paradigm via AutoFE. Extensive experiments show that FETCH systematically surpasses the current state-of-the-art AutoFE methods and validates the transferability of AutoFE pre-training.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "General Machine Learning (ie none of the above)", "paperhash": "li|learning_a_datadriven_policy_network_for_pretraining_automated_feature_engineering", "TL;DR": "We propose a data-driven automated feature engineering framework Fetch.", "pdf": "/pdf/1c15c68dc3b8354cfb9326758f23b4ffaddbca2d.pdf", "supplementary_material": "/attachment/56034b2cc3d9067f2e11f522ad69d1914f47261d.zip", "_bibtex": "@inproceedings{\nli2023learning,\ntitle={Learning a Data-Driven Policy Network for Pre-Training Automated Feature Engineering},\nauthor={Liyao Li and Haobo Wang and Liangyu Zha and Qingyi Huang and Sai Wu and Gang Chen and Junbo Zhao},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=688hNNMigVX}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279433267, "odate": 1664468100000, "details": {"replyCount": 15}}, {"id": "75O7S_L4oY", "original": "dUxIL9yrA", "number": 6350, "cdate": 1663850558333, "mdate": null, "ddate": null, "tcdate": 1663850558333, "tmdate": 1677681019395, "tddate": null, "forum": "75O7S_L4oY", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Learning Group Importance using the Differentiable Hypergeometric Distribution", "authorids": ["~Thomas_M._Sutter1", "~Laura_Manduchi2", "~Alain_Ryser1", "~Julia_E_Vogt1"], "authors": ["Thomas M. Sutter", "Laura Manduchi", "Alain Ryser", "Julia E Vogt"], "keywords": ["hypergeometric distribution", "weakly-supervised learning", "reparameterization trick", "group importance", "variational clustering", "gumbel softmax"], "TL;DR": "We propose the differentiable hypergeometric distribution and show the advantage of explicitly learning subset sizes.", "abstract": "Partitioning a set of elements into subsets of a priori unknown sizes is essential in many applications. These subset sizes are rarely explicitly learned - be it the cluster sizes in clustering applications or the number of shared versus independent generative latent factors in weakly-supervised learning. Probability distributions over correct combinations of subset sizes are non-differentiable due to hard constraints, which prohibit gradient-based optimization. In this work, we propose the differentiable hypergeometric distribution. The hypergeometric distribution models the probability of different group sizes based on their relative importance. We introduce reparameterizable gradients to learn the importance between groups and highlight the advantage of explicitly learning the size of subsets in two typical applications: weakly-supervised learning and clustering. In both applications, we outperform previous approaches, which rely on suboptimal heuristics to model the unknown size of groups.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Deep Learning and representational learning", "paperhash": "sutter|learning_group_importance_using_the_differentiable_hypergeometric_distribution", "pdf": "/pdf/eaa362d272c28b62b383ba46f668c0058f49115c.pdf", "supplementary_material": "/attachment/3a50a5ec4d177ec36491d983c78f270688dc764f.zip", "_bibtex": "@inproceedings{\nsutter2023learning,\ntitle={Learning Group Importance using the Differentiable Hypergeometric Distribution},\nauthor={Thomas M. Sutter and Laura Manduchi and Alain Ryser and Julia E Vogt},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=75O7S_L4oY}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279433100, "odate": 1664468100000, "details": {"replyCount": 5}}, {"id": "oiwXWPDTyNk", "original": "gyfC0yluwx-", "number": 6296, "cdate": 1663850551790, "mdate": null, "ddate": null, "tcdate": 1663850551790, "tmdate": 1697935211108, "tddate": null, "forum": "oiwXWPDTyNk", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Concept-level Debugging of Part-Prototype Networks", "authorids": ["~Andrea_Bontempelli1", "~Stefano_Teso1", "katya.tentori@unitn.it", "~Fausto_Giunchiglia1", "~Andrea_Passerini2"], "authors": ["Andrea Bontempelli", "Stefano Teso", "Katya Tentori", "Fausto Giunchiglia", "Andrea Passerini"], "keywords": ["explainability", "debugging", "self-explainable networks", "part-prototype networks", "concept-based models"], "TL;DR": "A novel and human-friendly concept-level debugger for part-prototype networks.", "abstract": "Part-prototype Networks (ProtoPNets) are concept-based classifiers designed to achieve the same performance as black-box models without compromising transparency. ProtoPNets compute predictions based on similarity to class-specific part-prototypes learned to recognize parts of training examples, making it easy to faithfully determine what examples are responsible for any target prediction and why. However, like other models, they are prone to picking up confounders and shortcuts from the data, thus suffering from compromised prediction accuracy and limited generalization. We propose ProtoPDebug, an effective concept-level debugger for ProtoPNets in which a human supervisor, guided by the model\u2019s explanations, supplies feedback in the form of what part-prototypes must be forgotten or kept, and the model is fine-tuned to align with this supervision. Our experimental evaluation shows that ProtoPDebug outperforms state-of-the-art debuggers for a fraction of the annotation cost. An online experiment with laypeople confirms the simplicity of the feedback requested to the users and the effectiveness of the collected feedback for learning confounder-free part-prototypes. ProtoPDebug is a promising tool for trustworthy interactive learning in critical applications, as suggested by a preliminary evaluation on a medical decision making task.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)", "paperhash": "bontempelli|conceptlevel_debugging_of_partprototype_networks", "pdf": "/pdf/c62dc701dcd52c5bdceeac7478072e161f7d982d.pdf", "_bibtex": "@inproceedings{\nbontempelli2023conceptlevel,\ntitle={Concept-level Debugging of Part-Prototype Networks},\nauthor={Andrea Bontempelli and Stefano Teso and Katya Tentori and Fausto Giunchiglia and Andrea Passerini},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=oiwXWPDTyNk}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2205.15769/code)"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279430780, "odate": 1664468100000, "details": {"replyCount": 14}}, {"id": "6BHlZgyPOZY", "original": "Rs77I8srXhV", "number": 6262, "cdate": 1663850547728, "mdate": null, "ddate": null, "tcdate": 1663850547728, "tmdate": 1677754266627, "tddate": null, "forum": "6BHlZgyPOZY", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Neuroevolution is a Competitive Alternative to Reinforcement Learning for Skill Discovery", "authorids": ["~Felix_Chalumeau1", "~Raphael_Boige1", "~Bryan_Lim2", "~Valentin_Mac\u00e91", "~Maxime_Allard1", "~Arthur_Flajolet2", "~Antoine_Cully1", "~Thomas_PIERROT1"], "authors": ["Felix Chalumeau", "Raphael Boige", "Bryan Lim", "Valentin Mac\u00e9", "Maxime Allard", "Arthur Flajolet", "Antoine Cully", "Thomas PIERROT"], "keywords": [], "abstract": "Deep Reinforcement Learning (RL) has emerged as a powerful paradigm for training neural policies to solve complex control tasks. However, these policies tend to be overfit to the exact specifications of the task and environment they were trained on, and thus do not perform well when conditions deviate slightly or when composed hierarchically to solve even more complex tasks. Recent work has shown that training a mixture of policies, as opposed to a single one, that are driven to explore different regions of the state-action space can address this shortcoming by generating a diverse set of behaviors, referred to as skills, that can be collectively used to great effect in adaptation tasks or for hierarchical planning. This is typically realized by including a diversity term - often derived from information theory - in the objective function optimized by RL. However these approaches often require careful hyperparameter tuning to be effective. In this work, we demonstrate that less widely-used neuroevolution methods, specifically Quality Diversity (QD), are a competitive alternative to information-theory-augmented RL for skill discovery. Through an extensive empirical evaluation comparing eight state-of-the-art algorithms (four flagship algorithms from each line of work) on the basis of (i) metrics directly evaluating the skills' diversity, (ii) the skills' performance on adaptation tasks, and (iii) the skills' performance when used as primitives for hierarchical planning; QD methods are found to provide equal, and sometimes improved, performance whilst being less sensitive to hyperparameters and more scalable. As no single method is found to provide near-optimal performance across all environments, there is a rich scope for further research which we support by proposing future directions and providing optimized open-source implementations.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)", "paperhash": "chalumeau|neuroevolution_is_a_competitive_alternative_to_reinforcement_learning_for_skill_discovery", "pdf": "/pdf/1c63093c2dc46ae51a5d9ec802a0d85f3455069d.pdf", "supplementary_material": "", "_bibtex": "@inproceedings{\nchalumeau2023neuroevolution,\ntitle={Neuroevolution is a Competitive Alternative to Reinforcement Learning for Skill Discovery},\nauthor={Felix Chalumeau and Raphael Boige and Bryan Lim and Valentin Mac{\\'e} and Maxime Allard and Arthur Flajolet and Antoine Cully and Thomas PIERROT},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=6BHlZgyPOZY}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279429696, "odate": 1664468100000, "details": {"replyCount": 15}}, {"id": "JpbLyEI5EwW", "original": "TG377wMH0wn", "number": 6233, "cdate": 1663850544098, "mdate": null, "ddate": null, "tcdate": 1663850544098, "tmdate": 1677725435984, "tddate": null, "forum": "JpbLyEI5EwW", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Implicit Bias in Leaky ReLU Networks Trained on High-Dimensional Data ", "authorids": ["~Spencer_Frei1", "~Gal_Vardi1", "~Peter_Bartlett1", "~Nathan_Srebro1", "~Wei_Hu1"], "authors": ["Spencer Frei", "Gal Vardi", "Peter Bartlett", "Nathan Srebro", "Wei Hu"], "keywords": ["implicit bias", "gradient descent", "gradient flow", "neural networks"], "abstract": "The implicit biases of gradient-based optimization algorithms are conjectured to be a major factor in the success of modern deep learning.  In this work, we investigate the implicit bias of gradient flow and gradient descent in two-layer fully-connected neural networks with leaky ReLU activations when the training data are nearly-orthogonal, a common property of high-dimensional data.  For gradient flow, we leverage recent work on the implicit bias for homogeneous neural networks to show that asymptotically, gradient flow produces a neural network with rank at most two.  Moreover, this network is an $\\ell_2$-max-margin solution (in parameter space), and has a linear decision boundary that corresponds to an approximate-max-margin linear predictor.  For gradient descent, provided the random initialization variance is small enough, we show that a single step of gradient descent suffices to drastically reduce the rank of the network, and that the rank remains small throughout training.  We provide experiments which suggest that a small initialization scale is important for finding low-rank neural networks with gradient descent. ", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Deep Learning and representational learning", "paperhash": "frei|implicit_bias_in_leaky_relu_networks_trained_on_highdimensional_data", "pdf": "/pdf/aa62c3225873e9b019b0e053bf4f2ab35a42de9c.pdf", "_bibtex": "@inproceedings{\nfrei2023implicit,\ntitle={Implicit Bias in Leaky Re{LU} Networks Trained on High-Dimensional Data },\nauthor={Spencer Frei and Gal Vardi and Peter Bartlett and Nathan Srebro and Wei Hu},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=JpbLyEI5EwW}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279428162, "odate": 1664468100000, "details": {"replyCount": 9}}, {"id": "O5rKg7IRQIO", "original": "QGdhHQfoRLQ", "number": 6202, "cdate": 1663850540265, "mdate": null, "ddate": null, "tcdate": 1663850540265, "tmdate": 1697935217555, "tddate": null, "forum": "O5rKg7IRQIO", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Guarded Policy Optimization with Imperfect Online Demonstrations", "authorids": ["~Zhenghai_Xue1", "~Zhenghao_Peng1", "~Quanyi_Li1", "~Zhihan_Liu1", "~Bolei_Zhou5"], "authors": ["Zhenghai Xue", "Zhenghao Peng", "Quanyi Li", "Zhihan Liu", "Bolei Zhou"], "keywords": ["reinforcement learning", "guarded policy optimization", "imperfect demonstrations", "shared control", "metadrive simulator"], "TL;DR": "Introducing a new policy optimization method exploiting imperfect online demonstrations from a guardian policy.", "abstract": "The Teacher-Student Framework (TSF) is a reinforcement learning setting where a teacher agent guards the training of a student agent by intervening and providing online demonstrations. Assuming optimal, the teacher policy has the perfect timing and capability to intervene in the learning process of the student agent, providing safety guarantee and exploration guidance. Nevertheless, in many real-world settings it is expensive or even impossible to obtain a well-performing teacher policy. In this work, we relax the assumption of a well-performing teacher and develop a new method that can incorporate arbitrary teacher policies with modest or inferior performance. We instantiate an Off-Policy Reinforcement Learning algorithm, termed Teacher-Student Shared Control (TS2C), which incorporates teacher intervention based on trajectory-based value estimation. Theoretical analysis validates that the proposed TS2C algorithm attains efficient exploration and substantial safety guarantee without being affected by the teacher's own performance. Experiments on various continuous control tasks show that our method can exploit teacher policies at different performance levels while maintaining a low training cost. Moreover, the student policy surpasses the imperfect teacher policy in terms of higher accumulated reward in held-out testing environments. Code is available at https://metadriverse.github.io/TS2C.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)", "paperhash": "xue|guarded_policy_optimization_with_imperfect_online_demonstrations", "pdf": "/pdf/e19dee281e43ab70ef8f8640d6ccb689bed45bd8.pdf", "supplementary_material": "/attachment/62129eec9c12aca7f6493309a41f209bc9dca059.zip", "_bibtex": "@inproceedings{\nxue2023guarded,\ntitle={Guarded Policy Optimization with Imperfect Online Demonstrations},\nauthor={Zhenghai Xue and Zhenghao Peng and Quanyi Li and Zhihan Liu and Bolei Zhou},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=O5rKg7IRQIO}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2303.01728/code)"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279426640, "odate": 1664468100000, "details": {"replyCount": 17}}, {"id": "M2unceRvqhh", "original": "IN30kA64QpU", "number": 6190, "cdate": 1663850538952, "mdate": null, "ddate": null, "tcdate": 1663850538952, "tmdate": 1677286865492, "tddate": null, "forum": "M2unceRvqhh", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Learning with Logical Constraints but without Shortcut Satisfaction", "authorids": ["~Zenan_Li3", "~Zehua_Liu3", "~Yuan_Yao7", "~Jingwei_Xu3", "~Taolue_Chen2", "~Xiaoxing_Ma1", "lj@nju.edu.cn"], "authors": ["Zenan Li", "Zehua Liu", "Yuan Yao", "Jingwei Xu", "Taolue Chen", "Xiaoxing Ma", "Jian L\\\"{u}"], "keywords": ["training with logical constraints", "logical formula encoding", "variational learning", "stochastic gradient descent ascent"], "abstract": "Recent studies have started to explore the integration of logical knowledge into deep learning via encoding logical constraints as an additional loss function. However, existing approaches tend to vacuously satisfy logical constraints through shortcuts, failing to fully exploit the knowledge. In this paper, we present a new framework for learning with logical constraints. Specifically, we address the shortcut satisfaction issue by introducing dual variables for logical connectives, encoding how the constraint is satisfied. We further propose a variational framework where the encoded logical constraint is expressed as a distributional loss that is compatible with the model's original training loss. The theoretical analysis shows that the proposed approach bears some nice properties, and the experimental evaluations demonstrate its superior performance in both model generalizability and constraint satisfaction.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Deep Learning and representational learning", "paperhash": "li|learning_with_logical_constraints_but_without_shortcut_satisfaction", "pdf": "/pdf/172ef390502d417f43730d591512cda9247cb5fa.pdf", "_bibtex": "@inproceedings{\nli2023learning,\ntitle={Learning with Logical Constraints but without Shortcut Satisfaction},\nauthor={Zenan Li and Zehua Liu and Yuan Yao and Jingwei Xu and Taolue Chen and Xiaoxing Ma and Jian L{\\textbackslash}''{\\{}u{\\}}},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=M2unceRvqhh}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279426283, "odate": 1664468100000, "details": {"replyCount": 12}}, {"id": "7oFuxtJtUMH", "original": "jdII7t0GXzw", "number": 6189, "cdate": 1663850538830, "mdate": null, "ddate": null, "tcdate": 1663850538830, "tmdate": 1697935218731, "tddate": null, "forum": "7oFuxtJtUMH", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Certified Training: Small Boxes are All You Need", "authorids": ["~Mark_Niklas_Mueller2", "~Franziska_Eckert1", "~Marc_Fischer1", "~Martin_Vechev1"], "authors": ["Mark Niklas Mueller", "Franziska Eckert", "Marc Fischer", "Martin Vechev"], "keywords": ["Certified Training", "Certified Robustness", "Adversarial Robustness", "Robustness Verification"], "TL;DR": "We propose a novel certified training method based on propagating small input regions, establishing a new state of the art for certified accuracy.", "abstract": "To obtain, deterministic guarantees of adversarial robustness, specialized training methods are used. We propose, SABR, a novel such certified training method, based on the key insight that propagating interval bounds for a small but carefully selected subset of the adversarial input region is sufficient to approximate the worst-case loss over the whole region while significantly reducing approximation errors. We show in an extensive empirical evaluation that SABR outperforms existing certified defenses in terms of both standard and certifiable accuracies across perturbation magnitudes and datasets, pointing to a new class of certified training methods promising to alleviate the robustness-accuracy trade-off.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)", "paperhash": "mueller|certified_training_small_boxes_are_all_you_need", "pdf": "/pdf/e61a2e061488e943012e445b9549adde476fd159.pdf", "supplementary_material": "/attachment/741a992c2ae6a717f45866c6ee3328d96fde92e7.zip", "_bibtex": "@inproceedings{\nmueller2023certified,\ntitle={Certified Training: Small Boxes are All You Need},\nauthor={Mark Niklas Mueller and Franziska Eckert and Marc Fischer and Martin Vechev},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=7oFuxtJtUMH}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2210.04871/code)"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279425963, "odate": 1664468100000, "details": {"replyCount": 20}}, {"id": "dKkMnCWfVmm", "original": "nL2poC-Jsre", "number": 6099, "cdate": 1663850527658, "mdate": null, "ddate": null, "tcdate": 1663850527658, "tmdate": 1681538088223, "tddate": null, "forum": "dKkMnCWfVmm", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Multi-Objective Online Learning", "authorids": ["~Jiyan_Jiang1", "~Wenpeng_Zhang1", "~Shiji_Zhou1", "~Lihong_Gu1", "~Xiaodong_Zeng2", "~Wenwu_Zhu1"], "authors": ["Jiyan Jiang", "Wenpeng Zhang", "Shiji Zhou", "Lihong Gu", "Xiaodong Zeng", "Wenwu Zhu"], "keywords": [], "abstract": "This paper presents a systematic study of multi-objective online learning. We first formulate the framework of Multi-Objective Online Convex Optimization, which encompasses a novel multi-objective regret. This regret is built upon a sequence-wise extension of the commonly used discrepancy metric Pareto suboptimality gap in zero-order multi-objective bandits. We then derive an equivalent form of the regret, making it amenable to be optimized via first-order iterative methods. To motivate the algorithm design, we give an explicit example in which equipping OMD with the vanilla min-norm solver for gradient composition will incur a linear regret, which shows that merely regularizing the iterates, as in single-objective online learning, is not enough to guarantee sublinear regrets in the multi-objective setting. To resolve this issue, we propose a novel min-regularized-norm solver that regularizes the composite weights. Combining min-regularized-norm with OMD results in the Doubly Regularized Online Mirror Multiple Descent algorithm. We further derive the multi-objective regret bound for the proposed algorithm, which matches the optimal bound in the single-objective setting. Extensive experiments on several real-world datasets verify the effectiveness of the proposed algorithm.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Optimization (eg, convex and non-convex optimization)", "paperhash": "jiang|multiobjective_online_learning", "pdf": "/pdf/e427cee744afa5b7154df61d9ed0fad7ea26144a.pdf", "supplementary_material": "/attachment/b0bf9532ee7cd368c23239260172c8102c3c82b0.zip", "_bibtex": "@inproceedings{\njiang2023multiobjective,\ntitle={Multi-Objective Online Learning},\nauthor={Jiyan Jiang and Wenpeng Zhang and Shiji Zhou and Lihong Gu and Xiaodong Zeng and Wenwu Zhu},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=dKkMnCWfVmm}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279422761, "odate": 1664468100000, "details": {"replyCount": 5}}, {"id": "3ULaIHxn9u7", "original": "GuYtbCWKJos", "number": 6056, "cdate": 1663850522453, "mdate": null, "ddate": null, "tcdate": 1663850522453, "tmdate": 1681374128642, "tddate": null, "forum": "3ULaIHxn9u7", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Seeing Differently, Acting Similarly: Heterogeneously Observable Imitation Learning", "authorids": ["~Xin-Qiang_Cai1", "~Yao-Xiang_Ding2", "~Zixuan_Chen4", "~Yuan_Jiang1", "~Masashi_Sugiyama1", "~Zhi-Hua_Zhou2"], "authors": ["Xin-Qiang Cai", "Yao-Xiang Ding", "Zixuan Chen", "Yuan Jiang", "Masashi Sugiyama", "Zhi-Hua Zhou"], "keywords": ["Imitation Learning", "Heterogeneous Observation", "Importance Weighting", "Learning with Rejection"], "abstract": "In many real-world imitation learning tasks, the demonstrator and the learner have to act under different observation spaces. This situation brings significant obstacles to existing imitation learning approaches, since most of them learn policies under homogeneous observation spaces. On the other hand, previous studies under different observation spaces have strong assumptions that these two observation spaces coexist during the entire learning process. However, in reality, the observation coexistence will be limited due to the high cost of acquiring expert observations. In this work, we study this challenging problem with limited observation coexistence under heterogeneous observations: Heterogeneously Observable Imitation Learning (HOIL). We identify two underlying issues in HOIL: the dynamics mismatch and the support mismatch, and further propose the Importance Weighting with REjection (IWRE) algorithm based on importance weighting and learning with rejection to solve HOIL problems. Experimental results show that IWRE can solve various HOIL tasks, including the challenging tasks of transforming the vision-based demonstrations to random access memory (RAM)-based policies in the Atari domain, even with limited visual observations.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)", "paperhash": "cai|seeing_differently_acting_similarly_heterogeneously_observable_imitation_learning", "pdf": "/pdf/38e823cd3fba73660cf9a28932a2ba5cad391a39.pdf", "supplementary_material": "", "_bibtex": "@inproceedings{\ncai2023seeing,\ntitle={Seeing Differently, Acting Similarly: Heterogeneously Observable Imitation Learning},\nauthor={Xin-Qiang Cai and Yao-Xiang Ding and Zixuan Chen and Yuan Jiang and Masashi Sugiyama and Zhi-Hua Zhou},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=3ULaIHxn9u7}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279420682, "odate": 1664468100000, "details": {"replyCount": 20}}, {"id": "wkg_b4-IwTZ", "original": "c7lSmkEYVuG", "number": 6041, "cdate": 1663850520623, "mdate": null, "ddate": null, "tcdate": 1663850520623, "tmdate": 1677643018123, "tddate": null, "forum": "wkg_b4-IwTZ", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "A Closer Look at Model Adaptation using Feature Distortion and Simplicity Bias", "authorids": ["~Puja_Trivedi1", "~Danai_Koutra1", "~Jayaraman_J._Thiagarajan3"], "authors": ["Puja Trivedi", "Danai Koutra", "Jayaraman J. Thiagarajan"], "keywords": ["Transfer Learning", "Robustness", "Adaptation", "Data Augmentation"], "TL;DR": "Mitigating feature distortion is not enough to ensure that transfer learning from large-scale, pretrained models leads to better safety and generalization on downstream tasks.", "abstract": "Advances in the expressivity of pretrained models have increased interest in the design of adaptation protocols which enable safe and effective transfer learning. Going beyond conventional linear probing (LP) and fine tuning (FT) strategies, protocols that can effectively control feature distortion, i.e., the failure to update features orthogonal to the in-distribution, have been found to achieve improved out-of-distribution generalization (OOD). In order to limit this distortion, the LP+FT protocol, which first learns a linear probe and then uses this initialization for subsequent FT, was proposed. However, in this paper, we find when adaptation protocols (LP, FT, LP+FT) are also evaluated on a variety of safety objectives (e.g., calibration, robustness, etc.), a complementary perspective to feature distortion is helpful to explain protocol behavior. To this end, we study the susceptibility of protocols to simplicity bias (SB), i.e. the well-known propensity of deep neural networks to rely upon simple features, as SB has recently been shown to underlie several problems in robust generalization. Using a synthetic dataset, we demonstrate the susceptibility of existing protocols to SB. Given the strong effectiveness of LP+FT, we then propose modified linear probes that help mitigate SB, and lead to better initializations for subsequent FT. We verify the effectiveness of the proposed LP+FT variants for decreasing SB in a controlled setting, and their ability to improve OOD generalization and safety on three adaptation datasets.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Deep Learning and representational learning", "paperhash": "trivedi|a_closer_look_at_model_adaptation_using_feature_distortion_and_simplicity_bias", "pdf": "/pdf/a96c8869749346661838b9c685006ca0e44e9011.pdf", "supplementary_material": "/attachment/6c36e7732269f96411e46480685cfedf68085798.zip", "_bibtex": "@inproceedings{\ntrivedi2023a,\ntitle={A Closer Look at Model Adaptation using Feature Distortion and Simplicity Bias},\nauthor={Puja Trivedi and Danai Koutra and Jayaraman J. Thiagarajan},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=wkg_b4-IwTZ}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279420290, "odate": 1664468100000, "details": {"replyCount": 19}}, {"id": "WzGdBqcBicl", "original": "PjCrmZdFZnY", "number": 6033, "cdate": 1663850519779, "mdate": null, "ddate": null, "tcdate": 1663850519779, "tmdate": 1677720791597, "tddate": null, "forum": "WzGdBqcBicl", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Understanding and Adopting Rational Behavior by Bellman Score Estimation", "authorids": ["~Kuno_Kim1", "~Stefano_Ermon1"], "authors": ["Kuno Kim", "Stefano Ermon"], "keywords": ["Inverse Reinforcement Learning"], "TL;DR": "We estimate the Bellman score in order to solve IRL, reward transfer, and counterfactual prediction problems", "abstract": "We are interested in solving a class of problems that seek to understand and adopt rational behavior from demonstrations. We may broadly classify these problems into four categories of reward identification, counterfactual analysis, behavior imitation, and behavior transfer. In this work, we make a key observation that knowing how changes in the underlying rewards affect the optimal behavior allows one to solve a variety of aforementioned problems. To a local approximation, this quantity is precisely captured by what we term the Bellman score, i.e gradient of log probabilities of the optimal policy with respect to the reward. We introduce the Bellman score operator which provably converges to the gradient of the infinite-horizon optimal Q-values with respect to the reward which can then be used to directly estimate the score. Guided by our theory, we derive a practical score-learning algorithm which can be used for score estimation in high-dimensional state-actions spaces. We show that score-learning can be used to reliably identify rewards, perform counterfactual predictions, achieve state-of-the-art behavior imitation, and transfer policies across environments. ", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)", "paperhash": "kim|understanding_and_adopting_rational_behavior_by_bellman_score_estimation", "pdf": "/pdf/88eb87ddbc76eb74567b04754a1b2ffc9ad31fbf.pdf", "supplementary_material": "/attachment/96fca7400e24213c65601d68fd4ddccc8e3665a5.zip", "_bibtex": "@inproceedings{\nkim2023understanding,\ntitle={Understanding and Adopting Rational Behavior by Bellman Score Estimation},\nauthor={Kuno Kim and Stefano Ermon},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=WzGdBqcBicl}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279419581, "odate": 1664468100000, "details": {"replyCount": 39}}, {"id": "_xlsjehDvlY", "original": "50ZEE6FWWb", "number": 5994, "cdate": 1663850515067, "mdate": null, "ddate": null, "tcdate": 1663850515067, "tmdate": 1697935234404, "tddate": null, "forum": "_xlsjehDvlY", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "STUNT: Few-shot Tabular Learning with Self-generated Tasks from Unlabeled Tables", "authorids": ["~Jaehyun_Nam2", "~Jihoon_Tack1", "~Kyungmin_Lee1", "~Hankook_Lee1", "~Jinwoo_Shin1"], "authors": ["Jaehyun Nam", "Jihoon Tack", "Kyungmin Lee", "Hankook Lee", "Jinwoo Shin"], "keywords": ["Tabular representation learning", "Few-shot learning", "Unsupervised meta-learning"], "TL;DR": "We propose a few-shot tabular learning framework that meta-learns over the self-generated tasks from unlabeled tables.", "abstract": "Learning with few labeled tabular samples is often an essential requirement for industrial machine learning applications as varieties of tabular data suffer from high annotation costs or have difficulties in collecting new samples for novel tasks. Despite the utter importance, such a problem is quite under-explored in the field of tabular learning, and existing few-shot learning schemes from other domains are not straightforward to apply, mainly due to the heterogeneous characteristics of tabular data. In this paper, we propose a simple yet effective framework for few-shot semi-supervised tabular learning, coined Self-generated Tasks from UNlabeled Tables (STUNT). Our key idea is to self-generate diverse few-shot tasks by treating randomly chosen columns as a target label. We then employ a meta-learning scheme to learn generalizable knowledge with the constructed tasks. Moreover, we introduce an unsupervised validation scheme for hyperparameter search (and early stopping) by generating a pseudo-validation set using STUNT from unlabeled data. Our experimental results demonstrate that our simple framework brings significant performance gain under various tabular few-shot learning benchmarks, compared to prior semi- and self-supervised baselines. Code is available at https://github.com/jaehyun513/STUNT.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Unsupervised and Self-supervised learning", "paperhash": "nam|stunt_fewshot_tabular_learning_with_selfgenerated_tasks_from_unlabeled_tables", "pdf": "/pdf/119c2e47ecfab89ce208c770994cdb25ae1c39c8.pdf", "supplementary_material": "/attachment/b3ced962eb6c7a2223b09534aaa5c2e919028a92.zip", "_bibtex": "@inproceedings{\nnam2023stunt,\ntitle={{STUNT}: Few-shot Tabular Learning with Self-generated Tasks from Unlabeled Tables},\nauthor={Jaehyun Nam and Jihoon Tack and Kyungmin Lee and Hankook Lee and Jinwoo Shin},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=_xlsjehDvlY}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2303.00918/code)"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279418228, "odate": 1664468100000, "details": {"replyCount": 17}}, {"id": "bhUPJnS2g0X", "original": "yTPepnI6ZRV", "number": 5912, "cdate": 1663850505275, "mdate": null, "ddate": null, "tcdate": 1663850505275, "tmdate": 1697935239794, "tddate": null, "forum": "bhUPJnS2g0X", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Ask Me Anything: A simple strategy for prompting language models", "authorids": ["~Simran_Arora1", "~Avanika_Narayan1", "~Mayee_F_Chen1", "~Laurel_Orr1", "~Neel_Guha1", "~Kush_Bhatia3", "~Ines_Chami1", "~Christopher_Re1"], "authors": ["Simran Arora", "Avanika Narayan", "Mayee F Chen", "Laurel Orr", "Neel Guha", "Kush Bhatia", "Ines Chami", "Christopher Re"], "keywords": ["large language models", "prompt-engineering", "in-context learning"], "TL;DR": "We propose a prompting strategy based on aggregating the predictions of multiple prompts, which enables a 6B parameter model to exceed the few-shot performance of GPT3-175B on 15/20 popular benchmarks.", "abstract": "Large language models (LLMs) transfer well to new tasks out-of-the-box simply given a natural language prompt that demonstrates how to perform the task and no additional training. Prompting is a brittle process wherein small modifications to the prompt can cause large variations in the model predictions, and therefore significant effort is dedicated towards designing a painstakingly crafted \"perfect prompt\" for a task. To mitigate the high degree of effort, we instead ask whether collecting multiple decent, yet imperfect, prompts and aggregating them can lead to a high quality prompting strategy. Our observations motivate our proposed method, Ask Me Anything (AMA). We first develop an understanding of the effective prompt formats, finding question-answering (QA) prompts, which encourage open-ended generation (\"Who went to the park?\") tend to outperform those that restrict the model outputs (\"John went to the park. True or False?\"). AMA recursively uses the LLM to transform task inputs to the effective QA format. AM generates multiple questions per input and applies these prompts to collect several noisy \"votes\" for the input's true label. We find the prompts have varying accuracies and dependencies and thus propose to use weak supervision, a procedure for combining the noisy predictions, to produce the final predictions. We evaluate AMA across open-source model families (EleutherAI, BLOOM, OPT, and T0) and sizes (125M-175B parameters), demonstrating an average performance lift of 10.2\\% over the few-shot baseline. This simple strategy enables the open-source GPT-J-6B model to match and exceed the performance of few-shot GPT3-175B  on 15 of 20 popular benchmarks. Averaged across these tasks, the GPT-J-6B model outperforms few-shot GPT3-175B. We release our code here: https://github.com/HazyResearch/ama_prompting.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Applications (eg, speech processing, computer vision, NLP)", "paperhash": "arora|ask_me_anything_a_simple_strategy_for_prompting_language_models", "pdf": "/pdf/5b1bcdac167fa4b294480f303ac3722afa8a9aac.pdf", "supplementary_material": "/attachment/77b9d0d39dbcaaf2926ea4b4d840a1a0a1c47f15.zip", "_bibtex": "@inproceedings{\narora2023ask,\ntitle={Ask Me Anything: A simple strategy for prompting language models},\nauthor={Simran Arora and Avanika Narayan and Mayee F Chen and Laurel Orr and Neel Guha and Kush Bhatia and Ines Chami and Christopher Re},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=bhUPJnS2g0X}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 2 code implementations](https://www.catalyzex.com/paper/arxiv:2210.02441/code)"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279415784, "odate": 1664468100000, "details": {"replyCount": 30}}, {"id": "cP2QVK-uygd", "original": "O2IwPF7mQW", "number": 5874, "cdate": 1663850500860, "mdate": null, "ddate": null, "tcdate": 1663850500860, "tmdate": 1697935243085, "tddate": null, "forum": "cP2QVK-uygd", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "On Representing Linear Programs by Graph Neural Networks", "authorids": ["~Ziang_Chen1", "~Jialin_Liu1", "~Xinshang_Wang1", "~Wotao_Yin1"], "authors": ["Ziang Chen", "Jialin Liu", "Xinshang Wang", "Wotao Yin"], "keywords": [], "abstract": "Learning to optimize is a rapidly growing area that aims to solve optimization problems or improve existing optimization algorithms using machine learning (ML). In particular, the graph neural network (GNN) is considered a suitable ML model for optimization problems whose variables and constraints are permutation--invariant, for example, the linear program (LP). While the literature has reported encouraging numerical results, this paper establishes the theoretical foundation of applying GNNs to solving LPs. Given any size limit of LPs, we construct a GNN that maps different LPs to different outputs. We show that properly built GNNs can reliably predict feasibility, boundedness, and an optimal solution for each LP in a broad class. Our proofs are based upon the recently--discovered connections between the Weisfeiler--Lehman isomorphism test and the GNN. To validate our results, we train a simple GNN and present its accuracy in mapping LPs to their feasibilities and solutions.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Theory (eg, control theory, learning theory, algorithmic game theory)", "paperhash": "chen|on_representing_linear_programs_by_graph_neural_networks", "pdf": "/pdf/155020e920d47414c7089209e49eaadf7b34a960.pdf", "_bibtex": "@inproceedings{\nchen2023on,\ntitle={On Representing Linear Programs by Graph Neural Networks},\nauthor={Ziang Chen and Jialin Liu and Xinshang Wang and Wotao Yin},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=cP2QVK-uygd}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2209.12288/code)"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279414305, "odate": 1664468100000, "details": {"replyCount": 8}}, {"id": "VZ5EaTI6dqa", "original": "lshi56Rzcs0", "number": 5870, "cdate": 1663850500386, "mdate": null, "ddate": null, "tcdate": 1663850500386, "tmdate": 1677640091729, "tddate": null, "forum": "VZ5EaTI6dqa", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Scale-invariant Bayesian Neural Networks with Connectivity Tangent Kernel", "authorids": ["~SungYub_Kim1", "~Sihwan_Park1", "~Kyung-Su_Kim1", "~Eunho_Yang1"], "authors": ["SungYub Kim", "Sihwan Park", "Kyung-Su Kim", "Eunho Yang"], "keywords": [], "abstract": "Studying the loss landscapes of neural networks is critical to identifying generalizations and avoiding overconfident predictions. Flatness, which measures the perturbation resilience of pre-trained parameters for loss values, is widely acknowledged as an essential predictor of generalization. While the concept of flatness has been formalized as a PAC-Bayes bound, it has been observed that the generalization bounds can vary arbitrarily depending on the scale of the model parameters. Despite previous attempts to address this issue, generalization bounds remain vulnerable to function-preserving scaling transformations or are limited to impractical network structures. In this paper, we introduce new PAC-Bayes prior and posterior distributions invariant to scaling transformations, achieved through the \\textit{decomposition of perturbations into scale and connectivity components}. In this way, this approach expands the range of networks to which the resulting generalization bound can be applied, including those with practical transformations such as weight decay with batch normalization. Moreover, we demonstrate that scale-dependency issues of flatness can adversely affect the uncertainty calibration of Laplace approximation, and we propose a solution using our invariant posterior. Our proposed invariant posterior allows for effective measurement of flatness and calibration with low complexity while remaining invariant to practical parameter transformations, also applying it as a reliable predictor of neural network generalization.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Deep Learning and representational learning", "paperhash": "kim|scaleinvariant_bayesian_neural_networks_with_connectivity_tangent_kernel", "pdf": "/pdf/a23231458e686af85e35285f01c8e2aa3ee3cf3b.pdf", "_bibtex": "@inproceedings{\nkim2023scaleinvariant,\ntitle={Scale-invariant Bayesian Neural Networks with Connectivity Tangent Kernel},\nauthor={SungYub Kim and Sihwan Park and Kyung-Su Kim and Eunho Yang},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=VZ5EaTI6dqa}\n}", "supplementary_material": "/attachment/6c001c2afb5f6f7d9cdcce0654b59b8f1dbb639c.zip", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279413820, "odate": 1664468100000, "details": {"replyCount": 21}}, {"id": "nN_nBVKAhhD", "original": "5VAw3SME8nB", "number": 5861, "cdate": 1663850499432, "mdate": null, "ddate": null, "tcdate": 1663850499432, "tmdate": 1677745174992, "tddate": null, "forum": "nN_nBVKAhhD", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Minimalistic Unsupervised Representation Learning with the Sparse Manifold Transform", "authorids": ["~Yubei_Chen1", "chobitstian@berkeley.edu", "~Yi_Ma4", "~Bruno_Olshausen1", "~Yann_LeCun1"], "authors": ["Yubei Chen", "Zeyu Yun", "Yi Ma", "Bruno Olshausen", "Yann LeCun"], "keywords": ["Unsupervised Learning", "Sparsity", "Low-rank", "Manifold learning", "Spectral Embedding"], "TL;DR": "We build a \"white-box\" unsupervised learning model with two parsimonious principles: sparsity and low-rankness, the model can be viewed as the simplest form of VICReg.", "abstract": "We describe a minimalistic and interpretable method for unsupervised representation learning that does not require data augmentation, hyperparameter tuning, or other engineering designs, but nonetheless achieves performance close to the state-of-the-art (SOTA) SSL methods. Our approach leverages the sparse manifold transform, which unifies sparse coding, manifold learning, and slow feature analysis. With a one-layer deterministic (one training epoch) sparse manifold transform, it is possible to achieve $99.3\\%$ KNN top-1 accuracy on MNIST, $81.1\\%$ KNN top-1 accuracy on CIFAR-10, and $53.2\\%$ on CIFAR-100. With simple gray-scale augmentation, the model achieves $83.2\\%$ KNN top-1 accuracy on CIFAR-10 and $57\\%$ on CIFAR-100. These results significantly close the gap between simplistic ``white-box'' methods and SOTA methods. We also provide visualization to illustrate how an unsupervised representation transform is formed. The proposed method is closely connected to latent-embedding self-supervised methods and can be treated as the simplest form of VICReg. Though a small performance gap remains between our simple constructive model and SOTA methods, the evidence points to this as a promising direction for achieving a principled and white-box approach to unsupervised representation learning, which has potential to significantly improve learning efficiency.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Unsupervised and Self-supervised learning", "paperhash": "chen|minimalistic_unsupervised_representation_learning_with_the_sparse_manifold_transform", "pdf": "/pdf/ad011e948fd7b2e72ff6dd869898255569519076.pdf", "_bibtex": "@inproceedings{\nchen2023minimalistic,\ntitle={Minimalistic Unsupervised Representation Learning with the Sparse Manifold Transform},\nauthor={Yubei Chen and Zeyu Yun and Yi Ma and Bruno Olshausen and Yann LeCun},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=nN_nBVKAhhD}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279413592, "odate": 1664468100000, "details": {"replyCount": 18}}, {"id": "aKcS3xojnwY", "original": "hT7PK4cfIe5", "number": 5804, "cdate": 1663850492337, "mdate": null, "ddate": null, "tcdate": 1663850492337, "tmdate": 1677718991197, "tddate": null, "forum": "aKcS3xojnwY", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "GEASS: Neural causal feature selection for high-dimensional biological data", "authorids": ["~Mingze_Dong1", "~Yuval_Kluger1"], "authors": ["Mingze Dong", "Yuval Kluger"], "keywords": ["Granger causality", "feature selection", "neural networks", "single-cell genomics", "spatial transcriptomics"], "TL;DR": " We propose a new method (GEASS) to identify causally interacting features for high-dimensional spatial/temporal structured data, and apply it to several biological data to infer causal regulatory patterns.", "abstract": "Identifying nonlinear causal relationships in high-dimensional biological data is an important task. However, current neural network based causality detection approaches for such data suffer from poor interpretability and cannot scale well to the high dimensional regime. Here we present GEASS (Granger fEAture Selection of Spatiotemporal data), which identifies sparse Granger causality mechanisms of high dimensional spatiotemporal data by a single neural network. GEASS maximizes sparsity-regularized modified transfer entropy with a theoretical guarantee of recovering features with spatial/temporal Granger causal relationships. The sparsity regularization is achieved by a novel combinatorial stochastic gate layer to select sparse non-overlapping feature subsets. We demonstrate the efficacy of GEASS in several synthetic datasets and real biological data from single-cell RNA sequencing and spatial transcriptomics.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )", "paperhash": "dong|geass_neural_causal_feature_selection_for_highdimensional_biological_data", "pdf": "/pdf/cae8ae2947fab56338cdfefd11f686b7a431f9f7.pdf", "_bibtex": "@inproceedings{\ndong2023geass,\ntitle={{GEASS}: Neural causal feature selection for high-dimensional biological data},\nauthor={Mingze Dong and Yuval Kluger},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=aKcS3xojnwY}\n}", "supplementary_material": "/attachment/02f211cce102e477415e863b3f562433da521061.zip", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279411598, "odate": 1664468100000, "details": {"replyCount": 11}}, {"id": "i9UlAr1T_xl", "original": "d87lo94y6d", "number": 5792, "cdate": 1663850490913, "mdate": null, "ddate": null, "tcdate": 1663850490913, "tmdate": 1677635350887, "tddate": null, "forum": "i9UlAr1T_xl", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "SmartFRZ: An Efficient Training Framework using Attention-Based Layer Freezing", "authorids": ["~Sheng_Li16", "~Geng_Yuan1", "~Yue_Dai1", "~Youtao_Zhang1", "~Yanzhi_Wang3", "~Xulong_Tang1"], "authors": ["Sheng Li", "Geng Yuan", "Yue Dai", "Youtao Zhang", "Yanzhi Wang", "Xulong Tang"], "keywords": [], "abstract": "There has been a proliferation of artificial intelligence applications, where model training is key to promising high-quality services for these applications. However, the model training process is both time-intensive and energy-intensive, inevitably affecting the user's demand for application efficiency. Layer freezing, an efficient model training technique, has been proposed to improve training efficiency. Although existing layer freezing methods demonstrate the great potential to reduce model training costs, they still remain shortcomings such as lacking generalizability and compromised accuracy. For instance, existing layer freezing methods either require the freeze configurations to be manually defined before training, which does not apply to different networks, or use heuristic freezing criteria that is hard to guarantee decent accuracy in different scenarios. Therefore, there lacks a generic and smart layer freezing method that can automatically perform ``in-situation'' layer freezing for different networks during training processes. To this end, we propose a generic and efficient training framework (SmartFRZ). The core proposed technique in SmartFRZ is attention-guided layer freezing, which can automatically select the appropriate layers to freeze without compromising accuracy. Experimental results show that SmartFRZ effectively reduces the amount of computation in training and achieves significant training acceleration, and outperforms the state-of-the-art layer freezing approaches.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Deep Learning and representational learning", "paperhash": "li|smartfrz_an_efficient_training_framework_using_attentionbased_layer_freezing", "pdf": "/pdf/df204364dd4dd09467e128971f66612149d1171b.pdf", "_bibtex": "@inproceedings{\nli2023smartfrz,\ntitle={Smart{FRZ}: An Efficient Training Framework using Attention-Based Layer Freezing},\nauthor={Sheng Li and Geng Yuan and Yue Dai and Youtao Zhang and Yanzhi Wang and Xulong Tang},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=i9UlAr1T_xl}\n}", "supplementary_material": "/attachment/a8faa2b1575165584345af2167840412af0ed52b.zip", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279410914, "odate": 1664468100000, "details": {"replyCount": 36}}, {"id": "u-RuvyDYqCM", "original": "fcA2XAgEaDT", "number": 5763, "cdate": 1663850487481, "mdate": null, "ddate": null, "tcdate": 1663850487481, "tmdate": 1697935251532, "tddate": null, "forum": "u-RuvyDYqCM", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "The In-Sample Softmax for Offline Reinforcement Learning", "authorids": ["~Chenjun_Xiao1", "~Han_Wang8", "~Yangchen_Pan2", "~Adam_White1", "~Martha_White1"], "authors": ["Chenjun Xiao", "Han Wang", "Yangchen Pan", "Adam White", "Martha White"], "keywords": ["Offline Reinforcement Learning"], "TL;DR": "A novel Bellman operator that avoids bootstrapping on out-of-sample actions. ", "abstract": "Reinforcement learning (RL) agents can leverage batches of previously collected data to extract a reasonable control policy. An emerging issue in this offline RL setting, however, is that the bootstrapping update underlying many of our methods suffers from insufficient action-coverage: standard max operator may select a maximal action that has not been seen in the dataset. Bootstrapping from these inaccurate values can lead to overestimation and even divergence. There are a growing number of methods that attempt to approximate an in-sample max, that only uses actions well-covered by the dataset. We highlight a simple fact: it is more straightforward to approximate an in-sample softmax using only actions in the dataset. We show that policy iteration based on the in-sample softmax converges, and that for decreasing temperatures it approaches the in-sample max. We derive an In-Sample Actor-Critic (AC), using this in-sample softmax, and show that it is consistently better or comparable to existing offline RL methods, and is also well-suited to fine-tuning. We release the code at github.com/hwang-ua/inac_pytorch.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)", "paperhash": "xiao|the_insample_softmax_for_offline_reinforcement_learning", "pdf": "/pdf/69f475d9352b20ebc3fc03da590f54192f7856ec.pdf", "supplementary_material": "", "_bibtex": "@inproceedings{\nxiao2023the,\ntitle={The In-Sample Softmax for Offline Reinforcement Learning},\nauthor={Chenjun Xiao and Han Wang and Yangchen Pan and Adam White and Martha White},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=u-RuvyDYqCM}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2302.14372/code)"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279409875, "odate": 1664468100000, "details": {"replyCount": 8}}, {"id": "TdTGGj7fYYJ", "original": "d9Ct9qhB55", "number": 5686, "cdate": 1663850478001, "mdate": null, "ddate": null, "tcdate": 1663850478001, "tmdate": 1697935258707, "tddate": null, "forum": "TdTGGj7fYYJ", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Unsupervised Meta-learning via Few-shot Pseudo-supervised Contrastive Learning", "authorids": ["~Huiwon_Jang1", "~Hankook_Lee1", "~Jinwoo_Shin1"], "authors": ["Huiwon Jang", "Hankook Lee", "Jinwoo Shin"], "keywords": ["unsupervised meta-learning", "supervised contrastive learning", "self-supervised learning"], "abstract": "Unsupervised meta-learning aims to learn generalizable knowledge across a distribution of tasks constructed from unlabeled data. Here, the main challenge is how to construct diverse tasks for meta-learning without label information; recent works have proposed to create, e.g., pseudo-labeling via pretrained representations or creating synthetic samples via generative models. However, such a task construction strategy is fundamentally limited due to heavy reliance on the immutable pseudo-labels during meta-learning and the quality of the representations or the generated samples. To overcome the limitations, we propose a simple yet effective unsupervised meta-learning framework, coined Pseudo-supervised Contrast (PsCo), for few-shot classification. We are inspired by the recent self-supervised learning literature; PsCo utilizes a momentum network and a queue of previous batches to improve pseudo-labeling and construct diverse tasks in a progressive manner. Our extensive experiments demonstrate that PsCo outperforms existing unsupervised meta-learning methods under various in-domain and cross-domain few-shot classification benchmarks. We also validate that PsCo is easily scalable to a large-scale benchmark, while recent prior-art meta-schemes are not.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Unsupervised and Self-supervised learning", "paperhash": "jang|unsupervised_metalearning_via_fewshot_pseudosupervised_contrastive_learning", "pdf": "/pdf/65c63b72201856c7d08ce81fba8f12b50947aa77.pdf", "supplementary_material": "", "_bibtex": "@inproceedings{\njang2023unsupervised,\ntitle={Unsupervised Meta-learning via Few-shot Pseudo-supervised Contrastive Learning},\nauthor={Huiwon Jang and Hankook Lee and Jinwoo Shin},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=TdTGGj7fYYJ}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2303.00996/code)"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279406080, "odate": 1664468100000, "details": {"replyCount": 14}}, {"id": "CZmHHj9MgkP", "original": "YmNkqvxNm2", "number": 5678, "cdate": 1663850477049, "mdate": null, "ddate": null, "tcdate": 1663850477049, "tmdate": 1697935259576, "tddate": null, "forum": "CZmHHj9MgkP", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Guiding Energy-based Models via Contrastive Latent Variables", "authorids": ["~Hankook_Lee1", "~Jongheon_Jeong1", "~Sejun_Park1", "~Jinwoo_Shin1"], "authors": ["Hankook Lee", "Jongheon Jeong", "Sejun Park", "Jinwoo Shin"], "keywords": ["energy-based model", "contrastive representation learning"], "TL;DR": "We propose a simple yet effective framework for improving energy-based models (EBMs) via contrastive representation learning.", "abstract": "An energy-based model (EBM) is a popular generative framework that offers both explicit density and architectural flexibility, but training them is difficult since it is often unstable and time-consuming. In recent years, various training techniques have been developed, e.g., better divergence measures or stabilization in MCMC sampling, but there often exists a large gap between EBMs and other generative frameworks like GANs in terms of generation quality. In this paper, we propose a novel and effective framework for improving EBMs via contrastive representation learning (CRL). To be specific, we consider representations learned by contrastive methods as the true underlying latent variable. This contrastive latent variable could guide EBMs to understand the data structure better, so it can improve and accelerate EBM training significantly. To enable the joint training of EBM and CRL, we also design a new class of latent-variable EBMs for learning the joint density of data and the contrastive latent variable. Our experimental results demonstrate that our scheme achieves lower FID scores, compared to prior-art EBM methods (e.g., additionally using variational autoencoders or diffusion techniques), even with significantly faster and more memory-efficient training. We also show conditional and compositional generation abilities of our latent-variable EBMs as their additional benefits, even without explicit conditional training. The code is available at https://github.com/hankook/CLEL.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Generative models", "paperhash": "lee|guiding_energybased_models_via_contrastive_latent_variables", "pdf": "/pdf/9c51d101c5d336bf5bc034b2876d79796069ac59.pdf", "supplementary_material": "", "_bibtex": "@inproceedings{\nlee2023guiding,\ntitle={Guiding Energy-based Models via Contrastive Latent Variables},\nauthor={Hankook Lee and Jongheon Jeong and Sejun Park and Jinwoo Shin},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=CZmHHj9MgkP}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2303.03023/code)"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279405606, "odate": 1664468100000, "details": {"replyCount": 15}}, {"id": "ZzdBhtEH9yB", "original": "_fcwktoL2F-", "number": 5633, "cdate": 1663850471485, "mdate": null, "ddate": null, "tcdate": 1663850471485, "tmdate": 1676585683784, "tddate": null, "forum": "ZzdBhtEH9yB", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Implicit regularization in Heavy-ball momentum accelerated stochastic gradient descent", "authorids": ["~Avrajit_Ghosh1", "~He_Lyu1", "~Xitong_Zhang1", "~Rongrong_Wang1"], "authors": ["Avrajit Ghosh", "He Lyu", "Xitong Zhang", "Rongrong Wang"], "keywords": [], "abstract": "It is well known that the finite step-size ($h$) in Gradient descent (GD) implicitly regularizes solutions to flatter minimas. A natural question to ask is \\textit{Does the momentum parameter $\\beta$ (say) play a role in implicit regularization in Heavy-ball (H.B) momentum accelerated gradient descent (GD+M)?}. To answer this question, first, we show that  the trajectory traced by discrete H.B momentum update (GD+M) is $O(h^2)$ close to a continuous trajectory induced by a modified loss, which consists of an original loss and an implicit regularizer. This implicit regularizer for (GD+M) is indeed stronger than that of (GD) by factor of $(\\frac{1+\\beta}{1-\\beta})$, thus explaining why (GD+M) shows better generalization performance and higher test accuracy than (GD). Furthermore, we extend our analysis to stochastic version of gradient descent with momentum (SGD+M) and propose a deterministic continuous trajectory that is $O(h^2)$ close to the discrete update of (SGD+M) in a strong approximation sense. We explore the implicit regularization in (SGD+M) and (GD+M) through a series of experiments validating our theory. ", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Deep Learning and representational learning", "paperhash": "ghosh|implicit_regularization_in_heavyball_momentum_accelerated_stochastic_gradient_descent", "pdf": "/pdf/dbc1161118a53cfa8a20ab379843b210af71728b.pdf", "supplementary_material": "/attachment/f48c4cfb4bceec1751bfdf6b77478939950cea5d.zip", "_bibtex": "@inproceedings{\nghosh2023implicit,\ntitle={Implicit regularization in Heavy-ball momentum accelerated stochastic gradient descent},\nauthor={Avrajit Ghosh and He Lyu and Xitong Zhang and Rongrong Wang},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=ZzdBhtEH9yB}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279403702, "odate": 1664468100000, "details": {"replyCount": 20}}, {"id": "M_MvkWgQSt", "original": "Huc1tx08doB", "number": 5628, "cdate": 1663850470893, "mdate": null, "ddate": null, "tcdate": 1663850470893, "tmdate": 1677531948068, "tddate": null, "forum": "M_MvkWgQSt", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Real-time variational method for learning neural trajectory and its dynamics", "authorids": ["~Matthew_Dowling2", "~Yuan_Zhao1", "~Il_Memming_Park1"], "authors": ["Matthew Dowling", "Yuan Zhao", "Il Memming Park"], "keywords": ["neural dynamics", "neural trajectory", "online variational inference"], "TL;DR": "A real-time variational Bayesian method aimed at uncovering latent neural trajectories and their dynamical systems.", "abstract": "Latent variable models have become instrumental in computational neuroscience for reasoning about neural computation.  This has fostered the development of powerful offline algorithms for extracting latent neural trajectories from neural recordings.  However, despite the potential of real-time alternatives to give immediate feedback to experimentalists, and enhance experimental design, they have received markedly less attention.  In this work, we introduce the exponential family variational Kalman filter (eVKF), an online recursive Bayesian method aimed at inferring latent trajectories while simultaneously learning the dynamical system generating them.  eVKF works for arbitrary likelihoods and utilizes the constant base measure exponential family to model the latent state stochasticity. We derive a closed-form variational analog to the predict step of the Kalman filter which leads to a provably tighter bound on the ELBO compared to another online variational method. We validate our method on synthetic and real-world data, and, notably, show that it achieves competitive performance.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Neuroscience and Cognitive Science (e.g., neural coding, brain-computer interfaces)", "paperhash": "dowling|realtime_variational_method_for_learning_neural_trajectory_and_its_dynamics", "pdf": "/pdf/f2a3ae5af4f08eb6ca19ee6d8642f0023b244943.pdf", "_bibtex": "@inproceedings{\ndowling2023realtime,\ntitle={Real-time variational method for learning neural trajectory and its dynamics},\nauthor={Matthew Dowling and Yuan Zhao and Il Memming Park},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=M_MvkWgQSt}\n}", "supplementary_material": "/attachment/7fafd529937b69307412f151ca86fa33c950131d.zip", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279403625, "odate": 1664468100000, "details": {"replyCount": 5}}, {"id": "ZMz-sW6gCLF", "original": "bxClH-utEz", "number": 5512, "cdate": 1663850456721, "mdate": null, "ddate": null, "tcdate": 1663850456721, "tmdate": 1677742339609, "tddate": null, "forum": "ZMz-sW6gCLF", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Energy-Inspired Self-Supervised Pretraining for Vision Models", "authorids": ["~Ze_Wang3", "~Jiang_Wang1", "~Zicheng_Liu1", "~Qiang_Qiu1"], "authors": ["Ze Wang", "Jiang Wang", "Zicheng Liu", "Qiang Qiu"], "keywords": [], "abstract": "Motivated by the fact that forward and backward passes of a deep network naturally form symmetric mappings between input and output representations, we introduce a simple yet effective self-supervised vision model pretraining framework inspired by energy-based models (EBMs). In the proposed framework, we model energy estimation and data restoration as the forward and backward passes of a single network without any auxiliary components, e.g., an extra decoder. For the forward pass, we fit a network to an energy function that assigns low energy scores to samples that belong to an unlabeled dataset, and high energy otherwise. For the backward pass, we restore data from corrupted versions iteratively using gradient-based optimization along the direction of energy minimization. In this way, we naturally fold the encoder-decoder architecture widely used in masked image modeling into the forward and backward passes of a single vision model. Our framework accepts a wide range of pretext tasks with different data corruption methods, and permits models to be pretrained from masked image modeling, patch sorting, and image restoration, including super-resolution, denoising, and colorization. We support our findings with extensive experiments, and show the proposed method delivers comparable and even better performance with remarkably fewer epochs of training compared to the state-of-the-art self-supervised vision model pretraining methods. Our findings shed light on further exploring self-supervised vision model pretraining and pretext tasks beyond masked image modeling. ", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Deep Learning and representational learning", "paperhash": "wang|energyinspired_selfsupervised_pretraining_for_vision_models", "pdf": "/pdf/36e3907af9186c722c512ea75c280aaae585101e.pdf", "_bibtex": "@inproceedings{\nwang2023energyinspired,\ntitle={Energy-Inspired Self-Supervised Pretraining for Vision Models},\nauthor={Ze Wang and Jiang Wang and Zicheng Liu and Qiang Qiu},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=ZMz-sW6gCLF}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279397808, "odate": 1664468100000, "details": {"replyCount": 24}}, {"id": "lH1PV42cbF", "original": "pp0d43HaDW", "number": 5444, "cdate": 1663850447263, "mdate": null, "ddate": null, "tcdate": 1663850447263, "tmdate": 1697935284560, "tddate": null, "forum": "lH1PV42cbF", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Binding Language Models in Symbolic Languages", "authorids": ["~Zhoujun_Cheng1", "~Tianbao_Xie1", "~Peng_Shi2", "~Chengzu_Li1", "~Rahul_Nadkarni1", "~Yushi_Hu1", "~Caiming_Xiong1", "~Dragomir_Radev2", "~Mari_Ostendorf1", "~Luke_Zettlemoyer1", "~Noah_A._Smith2", "~Tao_Yu5"], "authors": ["Zhoujun Cheng", "Tianbao Xie", "Peng Shi", "Chengzu Li", "Rahul Nadkarni", "Yushi Hu", "Caiming Xiong", "Dragomir Radev", "Mari Ostendorf", "Luke Zettlemoyer", "Noah A. Smith", "Tao Yu"], "keywords": ["semantic parsing", "large language model", "neural symbolic", "code generation"], "TL;DR": "binding language models in symbolic languages", "abstract": "Though end-to-end neural approaches have recently been dominating NLP tasks in both performance and ease-of-use, they lack interpretability and robustness. We propose Binder, a training-free neural-symbolic framework that maps the task input to a program, which (1) allows binding a unified API of language model (LM) functionalities to a programming language (e.g., SQL, Python) to extend its grammar coverage and thus tackle more diverse questions, (2) adopts an LM as both the program parser and the underlying model called by the API during execution, and (3) requires only a few in-context exemplar annotations. Specifically, we employ GPT-3 Codex as the LM. In the parsing stage, with only a few in-context exemplars, Codex is able to identify the part of the task input that cannot be answerable by the original programming language, correctly generate API calls to prompt Codex to solve the unanswerable part, and identify where to place the API calls while being compatible with the original grammar. In the execution stage, Codex can perform versatile functionalities (e.g., commonsense QA, information extraction) given proper prompts in the API calls. Binder achieves state-of-the-art results on WikiTableQuestions and TabFact datasets, with explicit output programs that benefit human debugging. Note that previous best systems are all finetuned on tens of thousands of task-specific samples, while Binder only uses dozens of annotations as in-context exemplars without any training. Our code is available at anonymized.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Applications (eg, speech processing, computer vision, NLP)", "paperhash": "cheng|binding_language_models_in_symbolic_languages", "pdf": "/pdf/d226e827fb59bcd4253c7eb8ce07d339ef5d519d.pdf", "supplementary_material": "/attachment/6a923fcd3f5045ac988359515e04fd051beb1e33.zip", "_bibtex": "@inproceedings{\ncheng2023binding,\ntitle={Binding Language Models in Symbolic Languages},\nauthor={Zhoujun Cheng and Tianbao Xie and Peng Shi and Chengzu Li and Rahul Nadkarni and Yushi Hu and Caiming Xiong and Dragomir Radev and Mari Ostendorf and Luke Zettlemoyer and Noah A. Smith and Tao Yu},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=lH1PV42cbF}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 2 code implementations](https://www.catalyzex.com/paper/arxiv:2210.02875/code)"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279394147, "odate": 1664468100000, "details": {"replyCount": 10}}, {"id": "Z4s73sJYQM", "original": "el7T3sQC18", "number": 5418, "cdate": 1663850443455, "mdate": null, "ddate": null, "tcdate": 1663850443455, "tmdate": 1676330810326, "tddate": null, "forum": "Z4s73sJYQM", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Evolve Smoothly, Fit Consistently: Learning Smooth Latent Dynamics For Advection-Dominated Systems", "authorids": ["~Zhong_Yi_Wan1", "~Leonardo_Zepeda-Nunez1", "~Anudhyan_Boral1", "~Fei_Sha3"], "authors": ["Zhong Yi Wan", "Leonardo Zepeda-Nunez", "Anudhyan Boral", "Fei Sha"], "keywords": [], "abstract": "We present a data-driven, space-time continuous framework to learn surrogate models for complex physical systems described by advection-dominated partial differential equations. Those systems have slow-decaying Kolmogorov n-width that hinders standard methods, including reduced order modeling, from producing high-fidelity simulations at low cost. In this work, we construct hypernetwork-based latent dynamical models directly on the parameter space of a compact representation network. We leverage the expressive power of the network and a specially designed consistency-inducing regularization to obtain latent trajectories that are both low-dimensional and smooth. These properties render our surrogate models highly efficient at inference time. We show the efficacy of our framework by learning models that generate accurate multi-step rollout predictions at much faster inference speed compared to competitors, for several challenging examples.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )", "paperhash": "wan|evolve_smoothly_fit_consistently_learning_smooth_latent_dynamics_for_advectiondominated_systems", "pdf": "/pdf/fc201e7d56b972a927ba9abff6846d2e611de461.pdf", "_bibtex": "@inproceedings{\nwan2023evolve,\ntitle={Evolve Smoothly, Fit Consistently: Learning Smooth Latent Dynamics For Advection-Dominated Systems},\nauthor={Zhong Yi Wan and Leonardo Zepeda-Nunez and Anudhyan Boral and Fei Sha},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=Z4s73sJYQM}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279393240, "odate": 1664468100000, "details": {"replyCount": 14}}, {"id": "Ovnwe_sDQW", "original": "Gcx2EsMSa4S", "number": 5413, "cdate": 1663850442848, "mdate": null, "ddate": null, "tcdate": 1663850442848, "tmdate": 1677639147112, "tddate": null, "forum": "Ovnwe_sDQW", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "BC-IRL: Learning Generalizable Reward Functions from Demonstrations", "authorids": ["~Andrew_Szot1", "~Amy_Zhang1", "~Dhruv_Batra1", "~Zsolt_Kira1", "~Franziska_Meier2"], "authors": ["Andrew Szot", "Amy Zhang", "Dhruv Batra", "Zsolt Kira", "Franziska Meier"], "keywords": ["inverse reinforcement learning", "reward learning", "reinforcement learning", "imitation learning"], "abstract": "How well do reward functions learned with inverse reinforcement learning (IRL) generalize? We illustrate that state-of-the-art IRL algorithms, which maximize a maximum-entropy objective, learn rewards that overfit to the demonstrations. Such rewards struggle to provide meaningful rewards for states not covered by the demonstrations, a major detriment when using the reward to learn policies in new situations. We introduce BC-IRL a new inverse reinforcement learning method that learns reward functions that generalize better when compared to maximum-entropy IRL approaches. In contrast to the MaxEnt framework, which learns to maximize rewards around demonstrations, BC-IRL updates reward parameters such that the policy trained with the new reward matches the expert demonstrations better. We show that BC-IRL learns rewards that generalize better on an illustrative simple task and two continuous robotic control tasks, achieving over twice the success rate of baselines in challenging generalization settings.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)", "paperhash": "szot|bcirl_learning_generalizable_reward_functions_from_demonstrations", "pdf": "/pdf/214dd3d4f346964ae17621ab8b33fe8cd5a4a444.pdf", "supplementary_material": "/attachment/bd04a0d3d1c932ab9fcbdde395e15b935331669f.zip", "_bibtex": "@inproceedings{\nszot2023bcirl,\ntitle={{BC}-{IRL}: Learning Generalizable Reward Functions from Demonstrations},\nauthor={Andrew Szot and Amy Zhang and Dhruv Batra and Zsolt Kira and Franziska Meier},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=Ovnwe_sDQW}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279392718, "odate": 1664468100000, "details": {"replyCount": 10}}, {"id": "z9C5dGip90", "original": "7E2P2Z2rz-7", "number": 5403, "cdate": 1663850441604, "mdate": null, "ddate": null, "tcdate": 1663850441604, "tmdate": 1677623956159, "tddate": null, "forum": "z9C5dGip90", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Phase2vec: dynamical systems embedding with a physics-informed convolutional network", "authorids": ["~Matt_Ricci1", "~Noa_Moriel1", "~Zoe_Piran1", "~Mor_Nitzan1"], "authors": ["Matt Ricci", "Noa Moriel", "Zoe Piran", "Mor Nitzan"], "keywords": ["dynamical systems", "convolutional networks", "computational physics", "physics-informed"], "TL;DR": "Unsupervised framework for learning high-quality, physically-meaningful embeddings of dynamical systems. ", "abstract": "Dynamical systems are found in innumerable forms across the physical and biological sciences, yet all these systems fall naturally into equivalence classes: conservative or dissipative, stable or unstable, compressible or incompressible. Predicting these classes from data remains an essential open challenge in computational physics on which existing time-series classification methods struggle. Here, we propose, phase2vec, an embedding method that learns high-quality, physically-meaningful representations of low-dimensional dynamical systems without supervision. Our embeddings are produced by a convolutional backbone that extracts geometric features from flow data and minimizes a physically-informed vector field reconstruction loss. The trained architecture can not only predict the equations of unseen data, but also produces embeddings that encode meaningful physical properties of input data (e.g. stability of fixed points, conservation of energy, and the incompressibility of flows) more faithfully than standard blackbox classifiers and state-of-the-art time series classification techniques. We additionally apply our embeddings to the analysis of meteorological data, showing we can detect climatically meaningful features. Collectively, our results demonstrate the viability of embedding approaches for the discovery of dynamical features in physical systems.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )", "paperhash": "ricci|phase2vec_dynamical_systems_embedding_with_a_physicsinformed_convolutional_network", "pdf": "/pdf/be58512bd70dfcd1702f2a09b66d60dfce307f20.pdf", "_bibtex": "@inproceedings{\nricci2023phasevec,\ntitle={Phase2vec: dynamical systems embedding with a physics-informed convolutional network},\nauthor={Matt Ricci and Noa Moriel and Zoe Piran and Mor Nitzan},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=z9C5dGip90}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279392187, "odate": 1664468100000, "details": {"replyCount": 19}}, {"id": "1hKE9qjvz-", "original": "JihZVsBLs9", "number": 5381, "cdate": 1663850438813, "mdate": null, "ddate": null, "tcdate": 1663850438813, "tmdate": 1697935291070, "tddate": null, "forum": "1hKE9qjvz-", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "gDDIM: Generalized denoising diffusion implicit models", "authorids": ["~Qinsheng_Zhang1", "~Molei_Tao1", "~Yongxin_Chen1"], "authors": ["Qinsheng Zhang", "Molei Tao", "Yongxin Chen"], "keywords": ["Fast sampling", "diffusion model"], "TL;DR": "a small but delicate modification in parameterization to accelerate general diffusion models", "abstract": "Our goal is to extend the denoising diffusion implicit model (DDIM) to general diffusion models~(DMs) besides isotropic diffusions. Instead of constructing a non-Markov noising process as in the original DDIM, we examine the mechanism of DDIM from a numerical perspective.  We discover that the DDIM can be obtained by using some specific approximations of the score when solving the corresponding stochastic differential equation. We present an interpretation of the accelerating effects of DDIM that also explains the advantages of a deterministic sampling scheme over the stochastic one for fast sampling. Building on this insight, we extend DDIM to general DMs, coined generalized DDIM (gDDIM), with a small but delicate modification in parameterizing the score network. We validate gDDIM in two non-isotropic DMs: Blurring diffusion model (BDM) and Critically-damped Langevin diffusion model (CLD). We observe more than 20 times acceleration in BDM. In the CLD, a diffusion model by augmenting the diffusion process with velocity, our algorithm achieves an FID score of 2.26, on CIFAR10, with only 50 number of score function evaluations~(NFEs) and an FID score of 2.86 with only 27 NFEs.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Generative models", "paperhash": "zhang|gddim_generalized_denoising_diffusion_implicit_models", "pdf": "/pdf/101656f96f6c22373cb9bf570b89250c966aedd5.pdf", "supplementary_material": "/attachment/37f034deb16520ec8ca12fdd83464d87fdd6bf3d.zip", "_bibtex": "@inproceedings{\nzhang2023gddim,\ntitle={g{DDIM}: Generalized denoising diffusion implicit models},\nauthor={Qinsheng Zhang and Molei Tao and Yongxin Chen},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=1hKE9qjvz-}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 4 code implementations](https://www.catalyzex.com/paper/arxiv:2206.05564/code)"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279390712, "odate": 1664468100000, "details": {"replyCount": 13}}, {"id": "IPrzNbddXV", "original": "QITZqPNHS4c", "number": 5311, "cdate": 1663850430344, "mdate": null, "ddate": null, "tcdate": 1663850430344, "tmdate": 1677638404431, "tddate": null, "forum": "IPrzNbddXV", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "FedExP: Speeding Up Federated Averaging via Extrapolation", "authorids": ["~Divyansh_Jhunjhunwala1", "~Shiqiang_Wang1", "~Gauri_Joshi1"], "authors": ["Divyansh Jhunjhunwala", "Shiqiang Wang", "Gauri Joshi"], "keywords": ["Federated Learning", "Optimization", "Step Size"], "TL;DR": "We propose FedExP, a method to adaptively determine the server step size in FedAvg for faster convergence.  ", "abstract": "Federated Averaging (FedAvg) remains the most popular algorithm for Federated Learning (FL) optimization due to its simple implementation, stateless nature, and privacy guarantees combined with secure aggregation. Recent work has sought to generalize the vanilla averaging in FedAvg to a generalized gradient descent step by treating client updates as pseudo-gradients and using a server step size. While the use of a server step size has been shown to provide performance improvement theoretically, the practical benefit of the server step size has not been seen in most existing works. In this work, we present FedExP, a method to adaptively determine the server step size in FL based on dynamically varying pseudo-gradients throughout the FL process. We begin by considering the overparameterized convex regime, where we reveal an interesting similarity between FedAvg and the Projection Onto Convex Sets (POCS) algorithm. We then show how FedExP can be motivated as a novel extension to the extrapolation mechanism that is used to speed up POCS. Our theoretical analysis later also discusses the implications of FedExP in underparameterized and non-convex settings. Experimental results show that FedExP consistently converges faster than FedAvg and competing baselines on a range of realistic FL datasets.\u00a0", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Optimization (eg, convex and non-convex optimization)", "paperhash": "jhunjhunwala|fedexp_speeding_up_federated_averaging_via_extrapolation", "pdf": "/pdf/8f9800051e3387ff23fc9a42a792d5ace5e665aa.pdf", "_bibtex": "@inproceedings{\njhunjhunwala2023fedexp,\ntitle={FedExP: Speeding Up Federated Averaging via Extrapolation},\nauthor={Divyansh Jhunjhunwala and Shiqiang Wang and Gauri Joshi},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=IPrzNbddXV}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279387240, "odate": 1664468100000, "details": {"replyCount": 10}}, {"id": "T-qVtA3pAxG", "original": "x5PkySFRYC", "number": 5210, "cdate": 1663850417685, "mdate": null, "ddate": null, "tcdate": 1663850417685, "tmdate": 1677865153994, "tddate": null, "forum": "T-qVtA3pAxG", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Serving Graph Compression for Graph Neural Networks", "authorids": ["~Si_Si1", "~Felix_Yu1", "~Ankit_Singh_Rawat1", "~Cho-Jui_Hsieh1", "~Sanjiv_Kumar1"], "authors": ["Si Si", "Felix Yu", "Ankit Singh Rawat", "Cho-Jui Hsieh", "Sanjiv Kumar"], "keywords": ["Model compression", "Graph Neural Networks"], "TL;DR": "Compressing the graph for graph neural networks inference", "abstract": "Serving a GNN model online is challenging --- in many applications when testing nodes are connected to training nodes, one has to propagate information from training nodes to testing nodes to achieve the best performance, and storing the whole training set (including training graph and node features) during inference stage is prohibitive for large-scale problems. In this paper, we study graph compression to reduce the storage requirement for GNN in serving. Given a GNN model to be served, we propose to construct a compressed graph with  a smaller number of nodes. In serving time, one just needs to replace the original training set graph by this compressed graph, without the need of changing the actual GNN model and the forward pass. We carefully analyze the error in the forward pass and derive simple ways to construct the compressed graph to minimize the approximation error. Experimental results on semi-supervised node classification demonstrate that the proposed method can significantly reduce the serving space requirement for GNN inference.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Deep Learning and representational learning", "paperhash": "si|serving_graph_compression_for_graph_neural_networks", "pdf": "/pdf/8063bd2baf3253b8b89e0478ff49c81f80ed3305.pdf", "_bibtex": "@inproceedings{\nsi2023serving,\ntitle={Serving Graph Compression for Graph Neural Networks},\nauthor={Si Si and Felix Yu and Ankit Singh Rawat and Cho-Jui Hsieh and Sanjiv Kumar},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=T-qVtA3pAxG}\n}", "supplementary_material": "/attachment/4c30433bc328a7ef55391e8799ca724098e60305.zip", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279382469, "odate": 1664468100000, "details": {"replyCount": 15}}, {"id": "Cs3r5KLdoj", "original": "2_JTnrYxPrb", "number": 5203, "cdate": 1663850416821, "mdate": null, "ddate": null, "tcdate": 1663850416821, "tmdate": 1677683813535, "tddate": null, "forum": "Cs3r5KLdoj", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Learning MLPs on Graphs: A Unified View of Effectiveness, Robustness, and Efficiency", "authorids": ["~Yijun_Tian1", "~Chuxu_Zhang2", "~Zhichun_Guo1", "~Xiangliang_Zhang1", "~Nitesh_Chawla1"], "authors": ["Yijun Tian", "Chuxu Zhang", "Zhichun Guo", "Xiangliang Zhang", "Nitesh Chawla"], "keywords": ["Graph Representation Learning", "Knowledge Distillation"], "TL;DR": "We propose NOSMOG, a novel method to learn noise-robust and structure-aware MLPs on graphs, with superior effectiveness, outstanding robustness, and exceptional efficiency.", "abstract": "While Graph Neural Networks (GNNs) have demonstrated their efficacy in dealing with non-Euclidean structural data, they are difficult to be deployed in real applications due to the scalability constraint imposed by the multi-hop data dependency. Existing methods attempt to address this scalability issue by training student multi-layer perceptrons (MLPs) exclusively on node content features using labels derived from the teacher GNNs. However, the trained MLPs are neither effective nor robust. In this paper, we ascribe the lack of effectiveness and robustness to three significant challenges: 1) the misalignment between content feature and label spaces, 2) the strict hard matching to teacher's output, and 3) the sensitivity to node feature noises. To address the challenges, we propose NOSMOG, a novel method to learn NOise-robust Structure-aware MLPs On Graphs, with remarkable effectiveness, robustness, and efficiency. Specifically, we first address the misalignment by complementing node content with position features to capture the graph structural information. We then design an innovative representational similarity distillation strategy to inject soft node similarities into MLPs. Finally, we introduce adversarial feature augmentation to ensure stable learning against feature noises. Extensive experiments and theoretical analyses demonstrate the superiority of NOSMOG by comparing it to GNNs and the state-of-the-art method in both transductive and inductive settings across seven datasets. Codes are available at https://github.com/meettyj/NOSMOG.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Deep Learning and representational learning", "paperhash": "tian|learning_mlps_on_graphs_a_unified_view_of_effectiveness_robustness_and_efficiency", "pdf": "/pdf/38ae9a6d49f8c8de73c63c07dd1bb214b1e1d1e0.pdf", "supplementary_material": "", "_bibtex": "@inproceedings{\ntian2023learning,\ntitle={Learning {MLP}s on Graphs: A Unified View of Effectiveness, Robustness, and Efficiency},\nauthor={Yijun Tian and Chuxu Zhang and Zhichun Guo and Xiangliang Zhang and Nitesh Chawla},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=Cs3r5KLdoj}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279382090, "odate": 1664468100000, "details": {"replyCount": 10}}, {"id": "QPtMRyk5rb", "original": "737gaAFJow5", "number": 5172, "cdate": 1663850413010, "mdate": null, "ddate": null, "tcdate": 1663850413010, "tmdate": 1681322760770, "tddate": null, "forum": "QPtMRyk5rb", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Contrastive Audio-Visual Masked Autoencoder", "authorids": ["~Yuan_Gong3", "~Andrew_Rouditchenko1", "~Alexander_H._Liu1", "~David_Harwath1", "~Leonid_Karlinsky3", "~Hilde_Kuehne5", "~James_R._Glass1"], "authors": ["Yuan Gong", "Andrew Rouditchenko", "Alexander H. Liu", "David Harwath", "Leonid Karlinsky", "Hilde Kuehne", "James R. Glass"], "keywords": ["multi-modal learning", "audio-visual learning", "self-supervised learning", "masked autoencoder", "contrastive learning"], "TL;DR": "We propose the Contrastive Audio-Visual Masked Auto-Encoder that combines contrastive learning and masked data modeling, two major self-supervised learning frameworks, to learn a joint and coordinated audio-visual representation.", "abstract": "In this paper, we first extend the recent Masked Auto-Encoder (MAE) model from a single modality to audio-visual multi-modalities. Subsequently, we propose the Contrastive Audio-Visual Masked Auto-Encoder (CAV-MAE) by combining contrastive learning and masked data modeling, two major self-supervised learning frameworks, to learn a joint and coordinated audio-visual representation.\nOur experiments show that the contrastive audio-visual correspondence learning objective not only enables the model to perform audio-visual retrieval tasks, but also helps the model learn a better joint representation. As a result, our fully self-supervised pretrained CAV-MAE achieves a new SOTA accuracy of 65.9% on VGGSound, and is comparable with the previous best supervised pretrained model on AudioSet in the audio-visual event classification task. Code and pretrained models are at https://github.com/yuangongnd/cav-mae.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Applications (eg, speech processing, computer vision, NLP)", "paperhash": "gong|contrastive_audiovisual_masked_autoencoder", "pdf": "/pdf/6de0262994e10ffd87b06b9ad0e8b4f86c84f044.pdf", "_bibtex": "@inproceedings{\ngong2023contrastive,\ntitle={Contrastive Audio-Visual Masked Autoencoder},\nauthor={Yuan Gong and Andrew Rouditchenko and Alexander H. Liu and David Harwath and Leonid Karlinsky and Hilde Kuehne and James R. Glass},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=QPtMRyk5rb}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279379450, "odate": 1664468100000, "details": {"replyCount": 27}}, {"id": "IM4xp7kGI5V", "original": "eilrjhHNXIG", "number": 5168, "cdate": 1663850412503, "mdate": null, "ddate": null, "tcdate": 1663850412503, "tmdate": 1676593156801, "tddate": null, "forum": "IM4xp7kGI5V", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "The Asymmetric Maximum Margin Bias of Quasi-Homogeneous Neural Networks", "authorids": ["~Daniel_Kunin1", "~Atsushi_Yamamura1", "~Chao_Ma8", "~Surya_Ganguli1"], "authors": ["Daniel Kunin", "Atsushi Yamamura", "Chao Ma", "Surya Ganguli"], "keywords": ["margin", "maximum-margin", "implicit regularization", "neural networks", "neural collapse", "gradient flow", "implicit bias", "robustness", "homogeneous", "symmetry", "classification"], "abstract": "In this work, we explore the maximum-margin bias of quasi-homogeneous neural networks trained with gradient flow on an exponential loss and past a point of separability. We introduce the class of quasi-homogeneous models, which is expressive enough to describe nearly all neural networks with homogeneous activations, even those with biases, residual connections, and normalization layers, while structured enough to enable geometric analysis of its gradient dynamics. Using this analysis, we generalize the existing results of maximum-margin bias for homogeneous networks to this richer class of models. We find that gradient flow implicitly favors a subset of the parameters, unlike in the case of a homogeneous model where all parameters are treated equally. We demonstrate through simple examples how this strong favoritism toward minimizing an asymmetric norm can degrade the robustness of quasi-homogeneous models. On the other hand, we conjecture that this norm-minimization discards, when possible, unnecessary higher-order parameters, reducing the model to a sparser parameterization. Lastly, by applying our theorem to sufficiently expressive neural networks with normalization layers, we reveal a universal mechanism behind the empirical phenomenon of Neural Collapse.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Deep Learning and representational learning", "paperhash": "kunin|the_asymmetric_maximum_margin_bias_of_quasihomogeneous_neural_networks", "TL;DR": "We generalize implicit max-margin bias to a class of models which describes nearly all networks, identifying a competition between maximizing margin and minimizing an asymmetric parameter norm, which can degrade robustness and explain Neural Collapse", "pdf": "/pdf/35e901e92e53dbfee861403dfbe3d0044bfb91a7.pdf", "supplementary_material": "/attachment/3925e5817c49a6672c09f716a394f166eb62ed96.zip", "_bibtex": "@inproceedings{\nkunin2023the,\ntitle={The Asymmetric Maximum Margin Bias of Quasi-Homogeneous Neural Networks},\nauthor={Daniel Kunin and Atsushi Yamamura and Chao Ma and Surya Ganguli},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=IM4xp7kGI5V}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279379385, "odate": 1664468100000, "details": {"replyCount": 16}}, {"id": "MhuFzFsrfvH", "original": "7klVh5wTOv", "number": 5154, "cdate": 1663850410798, "mdate": null, "ddate": null, "tcdate": 1663850410798, "tmdate": 1697935314672, "tddate": null, "forum": "MhuFzFsrfvH", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Optimal Transport for Offline Imitation Learning", "authorids": ["~Yicheng_Luo1", "~zhengyao_jiang2", "~Samuel_Cohen1", "~Edward_Grefenstette1", "~Marc_Peter_Deisenroth1"], "authors": ["Yicheng Luo", "zhengyao jiang", "Samuel Cohen", "Edward Grefenstette", "Marc Peter Deisenroth"], "keywords": ["offline reinforcement learning", "optimal transport", "imitation learning"], "TL;DR": "We present an offline imitation learning based on optimal transport that demonstrates strong performance and sample efficiency", "abstract": "With the advent of large datasets, offline reinforcement learning is a promising framework for learning good decision-making policies without the need to interact with the real environment.\nHowever, offline RL requires the dataset to be reward-annotated, which presents practical challenges when reward engineering is difficult or when obtaining reward annotations is labor-intensive.\nIn this paper, we introduce Optimal Transport Relabeling (OTR), an imitation learning algorithm that can automatically relabel offline data of mixed and unknown quality with rewards from a few good demonstrations. OTR's key idea is to use optimal transport to compute an optimal alignment between an unlabeled trajectory in the dataset and an expert demonstration to obtain a similarity measure that can be interpreted as a reward, which can then be used by an offline RL algorithm to learn the policy. OTR is easy to implement and computationally efficient. On D4RL benchmarks, we demonstrate that OTR with a single demonstration can consistently match the performance of offline RL with ground-truth rewards.\n", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)", "paperhash": "luo|optimal_transport_for_offline_imitation_learning", "pdf": "/pdf/3c2503af4f49d5f2f79a720075d8cfc042c50960.pdf", "_bibtex": "@inproceedings{\nluo2023optimal,\ntitle={Optimal Transport for Offline Imitation Learning},\nauthor={Yicheng Luo and zhengyao jiang and Samuel Cohen and Edward Grefenstette and Marc Peter Deisenroth},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=MhuFzFsrfvH}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 4 code implementations](https://www.catalyzex.com/paper/arxiv:2303.13971/code)"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279378647, "odate": 1664468100000, "details": {"replyCount": 23}}, {"id": "8aHzds2uUyB", "original": "BwlUm-AAcjF", "number": 5151, "cdate": 1663850410434, "mdate": null, "ddate": null, "tcdate": 1663850410434, "tmdate": 1677758265898, "tddate": null, "forum": "8aHzds2uUyB", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Is Reinforcement Learning (Not) for Natural Language Processing: Benchmarks, Baselines, and Building Blocks for Natural Language Policy Optimization", "authorids": ["~Rajkumar_Ramamurthy1", "~Prithviraj_Ammanabrolu1", "~Kiant\u00e9_Brantley2", "~Jack_Hessel1", "~Rafet_Sifa1", "~Christian_Bauckhage1", "~Hannaneh_Hajishirzi1", "~Yejin_Choi1"], "authors": ["Rajkumar Ramamurthy", "Prithviraj Ammanabrolu", "Kiant\u00e9 Brantley", "Jack Hessel", "Rafet Sifa", "Christian Bauckhage", "Hannaneh Hajishirzi", "Yejin Choi"], "keywords": ["natural language processing", "reinforcement learning", "language models", "feedback learning"], "TL;DR": "We provide an open-source framework, benchmark, and novel algorithm to train large language models to better align to automated measures of human preferences.", "abstract": "We tackle the problem of aligning pre-trained large language models (LMs) with human preferences. If we view text generation as a sequential decision-making problem, reinforcement learning (RL) appears to be a natural conceptual framework. However, using RL for LM-based generation faces empirical challenges, including training instability due to the combinatorial action space, as well as a lack of open-source libraries and benchmarks customized for LM alignment. Thus, a question rises in the research community: is RL a practical paradigm for NLP?\n\nTo help answer this, we first introduce an open-source modular library, $RL4LMs$ (Reinforcement Learning for Language Models), for optimizing language generators with RL. The library consists of on-policy RL algorithms that can be used to train any encoder or encoder-decoder LM in the HuggingFace library (Wolf et al. 2020) with an arbitrary reward function. Next, we present the $GRUE$ (General Reinforced-language Understanding Evaluation) benchmark, a set of 6 language generation tasks which are supervised not by target strings, but by reward functions which capture automated measures of human preference.GRUE is the first leaderboard-style evaluation of RL algorithms for NLP tasks. Finally, we introduce an easy-to-use, performant RL algorithm, $NLPO$ (Natural Language Policy Optimization)} that learns to effectively reduce the combinatorial action space in language generation. We show 1) that RL techniques are generally better than supervised methods at aligning LMs to human preferences; and 2) that NLPO exhibits greater stability and performance than previous policy gradient methods (e.g., PPO (Schulman et al. 2017)), based on both automatic and human evaluations.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Applications (eg, speech processing, computer vision, NLP)", "paperhash": "ramamurthy|is_reinforcement_learning_not_for_natural_language_processing_benchmarks_baselines_and_building_blocks_for_natural_language_policy_optimization", "pdf": "/pdf/e7b48c662a15dbddc1a3d5c9a2b338c13189506e.pdf", "_bibtex": "@inproceedings{\nramamurthy2023is,\ntitle={Is Reinforcement Learning (Not) for Natural Language Processing: Benchmarks, Baselines, and Building Blocks for Natural Language Policy Optimization},\nauthor={Rajkumar Ramamurthy and Prithviraj Ammanabrolu and Kiant{\\'e} Brantley and Jack Hessel and Rafet Sifa and Christian Bauckhage and Hannaneh Hajishirzi and Yejin Choi},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=8aHzds2uUyB}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279378589, "odate": 1664468100000, "details": {"replyCount": 10}}, {"id": "VZX2I_VVJKH", "original": "GdauYZhtXyK", "number": 5149, "cdate": 1663850410199, "mdate": null, "ddate": null, "tcdate": 1663850410199, "tmdate": 1697935315304, "tddate": null, "forum": "VZX2I_VVJKH", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Learning multi-scale local conditional probability models of images", "authorids": ["~Zahra_Kadkhodaie1", "~Florentin_Guth1", "~St\u00e9phane_Mallat1", "~Eero_P_Simoncelli1"], "authors": ["Zahra Kadkhodaie", "Florentin Guth", "St\u00e9phane Mallat", "Eero P Simoncelli"], "keywords": ["Image priors", "Markov wavelet conditional models", "multi-scale score-based image synthesis", "denoising", "super-resolution"], "TL;DR": "We develop a spatially Markov wavelet conditional probability model for images, and demonstrate (through, denoising, super-resolution and synthesis) its effectiveness in capturing global dependencies.", "abstract": "Deep neural networks can learn powerful prior probability models for images, as evidenced by the high-quality generations obtained with recent score-based diffusion methods. But the means by which these networks capture complex global statistical structure, apparently without suffering from the curse of dimensionality, remain a mystery. To study this, we incorporate diffusion methods into a multi-scale decomposition, reducing dimensionality by assuming a stationary local Markov model for wavelet coefficients conditioned on coarser-scale coefficients. We instantiate this model using convolutional neural networks (CNNs) with local receptive fields, which enforce both the stationarity and Markov properties. Global structures are captured using a CNN with receptive fields covering the entire (but small) low-pass image. We test this model on a dataset of face images, which are highly non-stationary and contain large-scale geometric structures.\nRemarkably, denoising, super-resolution, and image synthesis results all demonstrate that these structures can be captured with significantly smaller conditioning neighborhoods than required by a Markov model implemented in the pixel domain. Our results show that score estimation for large complex images can be reduced to low-dimensional Markov conditional models across scales,  alleviating the curse of dimensionality. ", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Generative models", "paperhash": "kadkhodaie|learning_multiscale_local_conditional_probability_models_of_images", "pdf": "/pdf/df0e89dd7728d64bf15f64a0771ede4c857aad7c.pdf", "_bibtex": "@inproceedings{\nkadkhodaie2023learning,\ntitle={Learning multi-scale local conditional probability models of images},\nauthor={Zahra Kadkhodaie and Florentin Guth and St{\\'e}phane Mallat and Eero P Simoncelli},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=VZX2I_VVJKH}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2303.02984/code)"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279378552, "odate": 1664468100000, "details": {"replyCount": 11}}, {"id": "9Z_GfhZnGH", "original": "jKD83eX_FB", "number": 5109, "cdate": 1663850405311, "mdate": null, "ddate": null, "tcdate": 1663850405311, "tmdate": 1677652662482, "tddate": null, "forum": "9Z_GfhZnGH", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Disentanglement with Biological Constraints: A Theory of Functional Cell Types", "authorids": ["~James_C._R._Whittington1", "~Will_Dorrell1", "~Surya_Ganguli1", "behrens@fmrib.ox.ac.uk"], "authors": ["James C. R. Whittington", "Will Dorrell", "Surya Ganguli", "Timothy Behrens"], "keywords": ["Disentangling", "neurosciece", "representation learning", "hippocampus", "cortex"], "abstract": "Neurons in the brain are often finely tuned for specific task variables. Moreover, such disentangled representations are highly sought after in machine learning. Here we mathematically prove that simple biological constraints on neurons, namely nonnegativity and energy efficiency in both activity and weights, promote such sought after disentangled representations by enforcing neurons to become selective for single factors of task variation. We demonstrate these constraints lead to disentanglement in a variety of tasks and architectures, including variational autoencoders. We also use this theory to explain why the brain partitions its cells into distinct cell types such as grid and object-vector cells, and also explain when the brain instead entangles representations in response to entangled task factors. Overall, this work provides a mathematical understanding of why single neurons in the brain often represent single human-interpretable factors, and steps towards an understanding task structure shapes the structure of brain representation.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Neuroscience and Cognitive Science (e.g., neural coding, brain-computer interfaces)", "paperhash": "whittington|disentanglement_with_biological_constraints_a_theory_of_functional_cell_types", "TL;DR": "We prove biological constraints of nonnegativity and energy efficiency lead to disentanged representations, and empirically demonstrate this in machine learning and neuroscience tasks.", "pdf": "/pdf/263cc7c08a3dc723c277184b709aa922ef1fc5d5.pdf", "_bibtex": "@inproceedings{\nwhittington2023disentanglement,\ntitle={Disentanglement with Biological Constraints: A Theory of Functional Cell Types},\nauthor={James C. R. Whittington and Will Dorrell and Surya Ganguli and Timothy Behrens},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=9Z_GfhZnGH}\n}", "supplementary_material": "/attachment/e164cdd96c9fc3eb8f7bb808af24fed55db04d69.zip", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279376272, "odate": 1664468100000, "details": {"replyCount": 23}}, {"id": "J7Uh781A05p", "original": "7OHJo20tHeQ", "number": 5105, "cdate": 1663850404834, "mdate": null, "ddate": null, "tcdate": 1663850404834, "tmdate": 1697935320287, "tddate": null, "forum": "J7Uh781A05p", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Learning rigid dynamics with face interaction graph networks", "authorids": ["~Kelsey_R_Allen1", "~Yulia_Rubanova2", "~Tatiana_Lopez-Guevara1", "~William_F_Whitney1", "~Alvaro_Sanchez-Gonzalez1", "~Peter_Battaglia1", "~Tobias_Pfaff1"], "authors": ["Kelsey R Allen", "Yulia Rubanova", "Tatiana Lopez-Guevara", "William F Whitney", "Alvaro Sanchez-Gonzalez", "Peter Battaglia", "Tobias Pfaff"], "keywords": ["graph networks", "rigid body dynamics", "physics"], "TL;DR": "Face to face, multi-index collisions improve accuracy and efficiency of graph network models for rigid body dynamics", "abstract": "Simulating rigid collisions among arbitrary shapes is notoriously difficult due to complex geometry and the strong non-linearity of the interactions. While graph neural network (GNN)-based models are effective at learning to simulate complex physical dynamics, such as fluids, cloth and articulated bodies, they have been less effective and efficient on rigid-body physics, except with very simple shapes. Existing methods that model collisions through the meshes' nodes are often inaccurate because they struggle when collisions occur on faces far from nodes. Alternative approaches that represent the geometry densely with many particles are prohibitively expensive for complex shapes. Here we introduce the ``Face Interaction Graph Network'' (FIGNet) which extends beyond GNN-based methods, and computes interactions between mesh faces, rather than nodes. Compared to learned node- and particle-based methods, FIGNet is around 4x more accurate in simulating complex shape interactions, while also 8x more computationally efficient on sparse, rigid meshes. Moreover, FIGNet can learn frictional dynamics directly from real-world data, and can be more accurate than analytical solvers given modest amounts of training data. FIGNet represents a key step forward in one of the few remaining physical domains which have seen little competition from learned simulators, and offers allied fields such as robotics, graphics and mechanical design a new tool for simulation and model-based planning.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Deep Learning and representational learning", "paperhash": "allen|learning_rigid_dynamics_with_face_interaction_graph_networks", "pdf": "/pdf/ce59b39a6e91536851b8532e573580c0b40de1fc.pdf", "supplementary_material": "/attachment/462f8b4ff1957cd17d5c3be1f255932873d86438.zip", "_bibtex": "@inproceedings{\nallen2023learning,\ntitle={Learning rigid dynamics with face interaction graph networks},\nauthor={Kelsey R Allen and Yulia Rubanova and Tatiana Lopez-Guevara and William F Whitney and Alvaro Sanchez-Gonzalez and Peter Battaglia and Tobias Pfaff},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=J7Uh781A05p}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 3 code implementations](https://www.catalyzex.com/paper/arxiv:2212.03574/code)"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279376080, "odate": 1664468100000, "details": {"replyCount": 14}}, {"id": "6iDHce-0B-a", "original": "3RpkkMNzWrs", "number": 5072, "cdate": 1663850400820, "mdate": null, "ddate": null, "tcdate": 1663850400820, "tmdate": 1677354046635, "tddate": null, "forum": "6iDHce-0B-a", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Implicit Bias of Large Depth Networks: a Notion of Rank for Nonlinear Functions", "authorids": ["~Arthur_Jacot1"], "authors": ["Arthur Jacot"], "keywords": ["Deep Neural Networks", "implicit bias", "representation cost", "sparsity"], "TL;DR": "The representation cost of DNNs converges to a notion of nonlinear rank as the depth grows to infinity. This bias towards low-rank functions extends to large but finite widths.", "abstract": "We show that the representation cost of fully connected neural networks with homogeneous nonlinearities - which describes the implicit bias in function space of networks with $L_2$-regularization or with losses such as the cross-entropy - converges as the depth of the network goes to infinity to a notion of rank over nonlinear functions. We then inquire under which conditions the global minima of the loss recover the `true' rank of the data: we show that for too large depths the global minimum will be approximately rank 1 (underestimating the rank); we then argue that there is a range of depths which grows with the number of datapoints where the true rank is recovered. Finally, we discuss the effect of the rank of a classifier on the topology of the resulting class boundaries and show that autoencoders with optimal nonlinear rank are naturally denoising.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Theory (eg, control theory, learning theory, algorithmic game theory)", "paperhash": "jacot|implicit_bias_of_large_depth_networks_a_notion_of_rank_for_nonlinear_functions", "pdf": "/pdf/856dc287ae646e9b77bfe6f682ad16ce86f0e148.pdf", "supplementary_material": "/attachment/c0db0dc2d580fa92feba1bdaf423793fc17a29a8.zip", "_bibtex": "@inproceedings{\njacot2023implicit,\ntitle={Implicit Bias of Large Depth Networks: a Notion of Rank for Nonlinear Functions},\nauthor={Arthur Jacot},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=6iDHce-0B-a}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279374143, "odate": 1664468100000, "details": {"replyCount": 15}}, {"id": "uzFQpkEzOo", "original": "vX8YFsYCA1e", "number": 5071, "cdate": 1663850400702, "mdate": null, "ddate": null, "tcdate": 1663850400702, "tmdate": 1676330822871, "tddate": null, "forum": "uzFQpkEzOo", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Depth Separation with Multilayer Mean-Field Networks", "authorids": ["~Yunwei_Ren1", "~Mo_Zhou3", "~Rong_Ge1"], "authors": ["Yunwei Ren", "Mo Zhou", "Rong Ge"], "keywords": ["depth separation", "mean-\ufb01eld", "nonconvex optimization"], "abstract": "Depth separation\u2014why a deeper network is more powerful than a shallow one\u2014has been a major problem in deep learning theory. Previous results often focus on representation power, for example, Safran et al. (2019) constructed a function that is easy to approximate using a 3-layer network but not approximable by any 2-layer network. In this paper, we show that this separation is in fact algorithmic: one can learn the function constructed by Safran et al. (2019) using an overparametrized network with polynomially many neurons ef\ufb01ciently. Our result relies on a new way of extending the mean-\ufb01eld limit to multilayer networks, and a decomposition of loss that factors out the error introduced by the discretization of in\ufb01nite-width mean-\ufb01eld networks.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Theory (eg, control theory, learning theory, algorithmic game theory)", "paperhash": "ren|depth_separation_with_multilayer_meanfield_networks", "TL;DR": "We show that, using gradient flow, 3-layer networks can efficiently learn a function that no 2-layer networks can efficiently approximate.", "pdf": "/pdf/ceeae99121e997ccdd6046c0ebad91895125624b.pdf", "_bibtex": "@inproceedings{\nren2023depth,\ntitle={Depth Separation with Multilayer Mean-Field Networks},\nauthor={Yunwei Ren and Mo Zhou and Rong Ge},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=uzFQpkEzOo}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279374106, "odate": 1664468100000, "details": {"replyCount": 14}}, {"id": "i_1rbq8yFWC", "original": "uRtwGl7Fopc", "number": 5008, "cdate": 1663850393094, "mdate": null, "ddate": null, "tcdate": 1663850393094, "tmdate": 1678139328694, "tddate": null, "forum": "i_1rbq8yFWC", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Rhino: Deep Causal Temporal Relationship Learning with History-dependent Noise", "authorids": ["~Wenbo_Gong1", "joeljennings@microsoft.com", "~Cheng_Zhang1", "~Nick_Pawlowski2"], "authors": ["Wenbo Gong", "Joel Jennings", "Cheng Zhang", "Nick Pawlowski"], "keywords": ["Structure learning", "Causal discovery", "Time series", "Structure equation model", "deep generative model"], "TL;DR": "We propose a causal discovery method for time series, which combines deep learning and variational inference to model instantaneous effect and history-dependent noise with structure identifiability guarantee.", "abstract": "Discovering causal relationships between different variables from time series data has been a long-standing challenge for many domains. For example, in stock markets, the announcement of acquisitions from leading companies may have immediate effects on stock prices and increase the uncertainty of the future market due to this past action. To discover causal relations in such case, the model needs to consider non-linear relations between variables, instantaneous effect and the change of noise distribution due to past actions. We name the latter as history-dependent noise. However, previous works do not offer a solution addressing all these problems together. In this paper, we propose a structural equation model, called Rhino, which combines vector auto-regression, deep learning and variational inference to model non-linear relationships with instantaneous effects while allowing the noise distribution to be modulated by history observations. Theoretically, we prove the structural identifiability of Rhino. Our empirical results from extensive synthetic experiments and two real-world benchmarks demonstrate better discovery performance compared to relevant baselines, with ablation studies revealing its robustness under model misspecification.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Probabilistic Methods (eg, variational inference, causal inference, Gaussian processes)", "paperhash": "gong|rhino_deep_causal_temporal_relationship_learning_with_historydependent_noise", "pdf": "/pdf/fbac1494936fa6cf98eb5c4fb5a71e68dee7d101.pdf", "_bibtex": "@inproceedings{\ngong2023rhino,\ntitle={Rhino: Deep Causal Temporal Relationship Learning with History-dependent Noise},\nauthor={Wenbo Gong and Joel Jennings and Cheng Zhang and Nick Pawlowski},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=i_1rbq8yFWC}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279370792, "odate": 1664468100000, "details": {"replyCount": 15}}, {"id": "VD-AYtP0dve", "original": "iPv919xY3Ga", "number": 4985, "cdate": 1663850390291, "mdate": null, "ddate": null, "tcdate": 1663850390291, "tmdate": 1677620105998, "tddate": null, "forum": "VD-AYtP0dve", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Semantic Uncertainty: Linguistic Invariances for Uncertainty Estimation in Natural Language Generation", "authorids": ["~Lorenz_Kuhn1", "~Yarin_Gal1", "~Sebastian_Farquhar1"], "authors": ["Lorenz Kuhn", "Yarin Gal", "Sebastian Farquhar"], "keywords": ["uncertainty estimation", "natural language generation"], "abstract": "We introduce a method to measure uncertainty in large language models. For tasks like question answering, it is essential to know when we can trust the natural language outputs of foundation models. We show that measuring uncertainty in natural language is challenging because of \"semantic equivalence\"\u2014different sentences can mean the same thing. To overcome these challenges we introduce semantic entropy\u2014an entropy which incorporates linguistic invariances created by shared meanings. Our method is unsupervised, uses only a single model, and requires no modifications to off-the-shelf language models. In comprehensive ablation studies we show that the semantic entropy is more predictive of model accuracy on question answering data sets than comparable baselines. ", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)", "paperhash": "kuhn|semantic_uncertainty_linguistic_invariances_for_uncertainty_estimation_in_natural_language_generation", "TL;DR": "Semantic entropy is a novel uncertainty estimation method for natural language generation that captures uncertainty over meanings rather than sequences.", "pdf": "/pdf/535617ff3bfc4d3297922f5c320dee127d1ce6cc.pdf", "_bibtex": "@inproceedings{\nkuhn2023semantic,\ntitle={Semantic Uncertainty: Linguistic Invariances for Uncertainty Estimation in Natural Language Generation},\nauthor={Lorenz Kuhn and Yarin Gal and Sebastian Farquhar},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=VD-AYtP0dve}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279369724, "odate": 1664468100000, "details": {"replyCount": 17}}, {"id": "cMJo1FTwBTQ", "original": "dX1_QARfgIQ", "number": 4981, "cdate": 1663850389816, "mdate": null, "ddate": null, "tcdate": 1663850389816, "tmdate": 1677715200023, "tddate": null, "forum": "cMJo1FTwBTQ", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "DINO as a von Mises-Fisher mixture model", "authorids": ["~Hariprasath_Govindarajan1", "~Per_Sid\u00e9n1", "~Jacob_Roll1", "~Fredrik_Lindsten1"], "authors": ["Hariprasath Govindarajan", "Per Sid\u00e9n", "Jacob Roll", "Fredrik Lindsten"], "keywords": ["self-supervised learning", "vision transformers", "mixture models"], "abstract": "Self-distillation methods using Siamese networks are popular for self-supervised pre-training. DINO is one such method based on a cross-entropy loss between $K$-dimensional probability vectors, obtained by applying a softmax function to the dot product between representations and learnt prototypes. Given the fact that the learned representations are $L^2$-normalized, we show that DINO and its derivatives, such as iBOT, can be interpreted as a mixture model of von Mises-Fisher components. With this interpretation, DINO assumes equal precision for all components when the prototypes are also $L^2$-normalized. Using this insight we propose DINO-vMF, that adds appropriate normalization constants when computing the cluster assignment probabilities. Unlike DINO, DINO-vMF is stable also for the larger ViT-Base model with unnormalized prototypes. We show that the added flexibility of the mixture model is beneficial in terms of better image representations. The DINO-vMF pre-trained model consistently performs better than DINO on a range of downstream tasks. We obtain similar improvements for iBOT-vMF vs iBOT and thereby show the relevance of our proposed modification also for other methods derived from DINO.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Unsupervised and Self-supervised learning", "paperhash": "govindarajan|dino_as_a_von_misesfisher_mixture_model", "TL;DR": "Improving DINO with unnormalized prototypes based on a flexible von Mises-Fisher mixture model interpretation.", "pdf": "/pdf/7c0fa9125fa53c842a7c216fd9f1b16ee517710f.pdf", "_bibtex": "@inproceedings{\ngovindarajan2023dino,\ntitle={{DINO} as a von Mises-Fisher mixture model},\nauthor={Hariprasath Govindarajan and Per Sid{\\'e}n and Jacob Roll and Fredrik Lindsten},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=cMJo1FTwBTQ}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279369229, "odate": 1664468100000, "details": {"replyCount": 19}}, {"id": "ZCStthyW-TD", "original": "MGlDAHsTqQ", "number": 4974, "cdate": 1663850388980, "mdate": null, "ddate": null, "tcdate": 1663850388980, "tmdate": 1677738711695, "tddate": null, "forum": "ZCStthyW-TD", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Associative Memory Augmented Asynchronous Spatiotemporal Representation Learning for Event-based Perception", "authorids": ["~Uday_Kamal1", "~Saurabh_Dash1", "~Saibal_Mukhopadhyay2"], "authors": ["Uday Kamal", "Saurabh Dash", "Saibal Mukhopadhyay"], "keywords": ["associative memory", "memory augmented neural network", "spatiotemporal representation", "event-based camera", "event-based perception", "object recognition", "attention", "set processing"], "TL;DR": "We propose EventFormer, an asynchronous spatiotemporal representation learning framework augmented by an associative memory to efficiently perform event-based perception.", "abstract": "We propose $\\textit{EventFormer}$, a computationally efficient event-based representation learning framework for asynchronously processing event camera data. EventFormer treats sparse input events as a spatially unordered set and models their spatial interactions using self-attention mechanism. An associative memory-augmented recurrent module is used to correlate with the stored representation computed from past events. A memory addressing mechanism is proposed to store and retrieve the latent states only $\\textit{where}$ these events occur and update them only $\\textit{when}$ they occur. The representation learning shift from input space to the latent memory space resulting in reduced computation cost for processing each event. We show that EventFormer achieves 0.5$\\%$ and 9$\\%$ better accuracy with 30000$\\times$ and 200$\\times$ less computation compared to the state-of-the-art dense and event-based method, respectively, on event-based object recognition datasets.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Applications (eg, speech processing, computer vision, NLP)", "paperhash": "kamal|associative_memory_augmented_asynchronous_spatiotemporal_representation_learning_for_eventbased_perception", "pdf": "/pdf/5b3db5aabca57a5bd0c832c0a96cd9c75e9462bb.pdf", "_bibtex": "@inproceedings{\nkamal2023associative,\ntitle={Associative Memory Augmented Asynchronous Spatiotemporal Representation Learning for Event-based Perception},\nauthor={Uday Kamal and Saurabh Dash and Saibal Mukhopadhyay},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=ZCStthyW-TD}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279368844, "odate": 1664468100000, "details": {"replyCount": 17}}, {"id": "9piH3Hg8QEf", "original": "g3g4nx1xfK", "number": 4962, "cdate": 1663850387519, "mdate": null, "ddate": null, "tcdate": 1663850387519, "tmdate": 1697935335418, "tddate": null, "forum": "9piH3Hg8QEf", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "SMART: Self-supervised Multi-task pretrAining with contRol Transformers", "authorids": ["~Yanchao_Sun1", "~Shuang_Ma3", "~Ratnesh_Madaan1", "~Rogerio_Bonatti1", "~Furong_Huang1", "~Ashish_Kapoor1"], "authors": ["Yanchao Sun", "Shuang Ma", "Ratnesh Madaan", "Rogerio Bonatti", "Furong Huang", "Ashish Kapoor"], "keywords": ["pretrain", "transformer", "multi-task reinforcement learning", "sequential decision making", "self-supervised"], "TL;DR": "We propose a pretraining framework for sequential decision making based on a self-supervised objectives and a control transformer architecture, leading to significantly higher learning efficiency in various downstram control tasks.", "abstract": "Self-supervised pretraining has been extensively studied in language and vision domains, where a unified model can be easily adapted to various downstream tasks by pretraining representations without explicit labels. When it comes to sequential decision-making tasks, however, it is difficult to properly design such a pretraining approach that can cope with both high-dimensional perceptual information and the complexity of sequential control over long interaction horizons. The challenge becomes combinatorially more complex if we want to pretrain representations amenable to a large variety of tasks. To tackle this problem, in this work, we formulate a general pretraining-finetuning pipeline for sequential decision making, under which we propose a generic pretraining framework \\textit{Self-supervised Multi-task pretrAining with contRol Transformer (SMART)}. By systematically investigating pretraining regimes, we carefully design a Control Transformer (CT) coupled with a novel control-centric pretraining objective in a self-supervised manner. SMART encourages the representation to capture the common essential information relevant to short-term control and long-term control, which is transferrable across tasks. We show by extensive experiments in DeepMind Control Suite that SMART significantly improves the learning efficiency among seen and unseen downstream tasks and domains under different learning scenarios including Imitation Learning (IL) and Reinforcement Learning (RL). Benefiting from the proposed control-centric objective, SMART is resilient to distribution shift between pretraining and finetuning, and even works well with low-quality pretraining datasets that are randomly collected. The codebase, pretrained models and datasets are provided at https://github.com/microsoft/smart.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)", "paperhash": "sun|smart_selfsupervised_multitask_pretraining_with_control_transformers", "pdf": "/pdf/0bed689d4b0c72cb2f2561862218853290e48ce5.pdf", "supplementary_material": "/attachment/d2ca26ed0a3d656e825de541268d8a6f064318a7.zip", "_bibtex": "@inproceedings{\nsun2023smart,\ntitle={{SMART}: Self-supervised Multi-task pretrAining with contRol Transformers},\nauthor={Yanchao Sun and Shuang Ma and Ratnesh Madaan and Rogerio Bonatti and Furong Huang and Ashish Kapoor},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=9piH3Hg8QEf}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2301.09816/code)"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279368234, "odate": 1664468100000, "details": {"replyCount": 17}}, {"id": "gSHyqBijPFO", "original": "DeDHif6Yb6", "number": 4932, "cdate": 1663850383750, "mdate": null, "ddate": null, "tcdate": 1663850383750, "tmdate": 1677631245031, "tddate": null, "forum": "gSHyqBijPFO", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "TEMPERA: Test-Time Prompt Editing via Reinforcement Learning", "authorids": ["~Tianjun_Zhang1", "~Xuezhi_Wang3", "~Denny_Zhou1", "~Dale_Schuurmans1", "~Joseph_E._Gonzalez1"], "authors": ["Tianjun Zhang", "Xuezhi Wang", "Denny Zhou", "Dale Schuurmans", "Joseph E. Gonzalez"], "keywords": [], "abstract": "Careful prompt design is critical to the use of large language models in zero-shot or few-shot learning.  As a consequence, there is a growing interest in automated methods to design optimal prompts. In this work, we propose Test-time Prompt Editing using Reinforcement learning (TEMPERA). In contrast to prior prompt generation methods, TEMPERA can efficiently leverage prior knowledge, is adaptive to different queries and provides an interpretable prompt for every query. To achieve this, we design a novel action space that allows flexible editing of the initial prompts covering a wide set of commonly-used components like instructions, few-shot exemplars, and verbalizers. The proposed method achieves significant gains compared with recent SoTA approaches like prompt tuning, AutoPrompt, and RLPrompt, across a variety of tasks including sentiment analysis, topic classification, natural language inference, and reading comprehension. Our method achieves 5.33x on average improvement in sample efficiency when compared to the traditional fine-tuning methods.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Applications (eg, speech processing, computer vision, NLP)", "paperhash": "zhang|tempera_testtime_prompt_editing_via_reinforcement_learning", "pdf": "/pdf/1cf8438e4df114f4ea13408da5952d5636eabb99.pdf", "supplementary_material": "/attachment/76033955a163925f75da8170d19f2baa61508594.zip", "_bibtex": "@inproceedings{\nzhang2023tempera,\ntitle={{TEMPERA}: Test-Time Prompt Editing via Reinforcement Learning},\nauthor={Tianjun Zhang and Xuezhi Wang and Denny Zhou and Dale Schuurmans and Joseph E. Gonzalez},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=gSHyqBijPFO}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279366593, "odate": 1664468100000, "details": {"replyCount": 19}}, {"id": "ThXqBsRI-cY", "original": "CPmN5HS7pj6", "number": 4927, "cdate": 1663850383143, "mdate": null, "ddate": null, "tcdate": 1663850383143, "tmdate": 1677848128052, "tddate": null, "forum": "ThXqBsRI-cY", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Provable Defense Against Geometric Transformations", "authorids": ["~Rem_Yang1", "jlaurel2@illinois.edu", "~Sasa_Misailovic1", "~Gagandeep_Singh1"], "authors": ["Rem Yang", "Jacob Laurel", "Sasa Misailovic", "Gagandeep Singh"], "keywords": ["Certified robustness", "geometric transformations"], "TL;DR": "We present a training framework and verifier for deterministic certified robustness against geometric transformations.", "abstract": "Geometric image transformations that arise in the real world, such as scaling and rotation, have been shown to easily deceive deep neural networks (DNNs). Hence, training DNNs to be certifiably robust to these perturbations is critical. However, no prior work has been able to incorporate the objective of deterministic certified robustness against geometric transformations into the training procedure, as existing verifiers are exceedingly slow. To address these challenges, we propose the first provable defense for deterministic certified geometric robustness. Our framework leverages a novel GPU-optimized verifier that can certify images between 60$\\times$ to 42,600$\\times$ faster than existing geometric robustness verifiers, and thus unlike existing works, is fast enough for use in training. Across multiple datasets, our results show that networks trained via our framework consistently achieve state-of-the-art deterministic certified geometric robustness and clean accuracy. Furthermore, for the first time, we verify the geometric robustness of a neural network for the challenging, real-world setting of autonomous driving.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)", "paperhash": "yang|provable_defense_against_geometric_transformations", "pdf": "/pdf/5f45f6724426cb1196f8d2e3bd7a227feec2b203.pdf", "_bibtex": "@inproceedings{\nyang2023provable,\ntitle={Provable Defense Against Geometric Transformations},\nauthor={Rem Yang and Jacob Laurel and Sasa Misailovic and Gagandeep Singh},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=ThXqBsRI-cY}\n}", "supplementary_material": "/attachment/72bc01e492e6937873d1263a5a126ccd29e51154.zip", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279366401, "odate": 1664468100000, "details": {"replyCount": 16}}, {"id": "Zb6c8A-Fghk", "original": "9meQCszFP3h", "number": 4917, "cdate": 1663850381953, "mdate": null, "ddate": null, "tcdate": 1663850381953, "tmdate": 1697935339959, "tddate": null, "forum": "Zb6c8A-Fghk", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Last Layer Re-Training is Sufficient for Robustness to Spurious Correlations", "authorids": ["~Polina_Kirichenko1", "~Pavel_Izmailov1", "~Andrew_Gordon_Wilson1"], "authors": ["Polina Kirichenko", "Pavel Izmailov", "Andrew Gordon Wilson"], "keywords": ["spurious correlations", "robustness"], "TL;DR": "We propose a simple method based on retraining the last layer of a neural network which achieves strong results on spurious correlation benchmarks.", "abstract": "Neural network classifiers can largely rely on simple spurious features, such as image backgrounds, to make predictions. However, even in these cases, we show that they still often learn core features associated with the desired attributes of the data, contrary to recent findings. Inspired by this insight, we demonstrate that simple last layer retraining can match or outperform state-of-the-art approaches on spurious correlation benchmarks, but with profoundly lower complexity and computational expenses. Moreover, we show that last layer retraining on large ImageNet-trained models can also significantly reduce reliance on background and texture information, improving robustness to covariate shift, after only minutes of training on a single GPU.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Deep Learning and representational learning", "paperhash": "kirichenko|last_layer_retraining_is_sufficient_for_robustness_to_spurious_correlations", "pdf": "/pdf/f0a7c2996eab5d56791cb5d7feebe23aa9ca27c4.pdf", "supplementary_material": "/attachment/5ac1f5b816813072c13581cf7cdf7d70cb56496c.zip", "_bibtex": "@inproceedings{\nkirichenko2023last,\ntitle={Last Layer Re-Training is Sufficient for Robustness to Spurious Correlations},\nauthor={Polina Kirichenko and Pavel Izmailov and Andrew Gordon Wilson},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=Zb6c8A-Fghk}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2204.02937/code)"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279365658, "odate": 1664468100000, "details": {"replyCount": 18}}, {"id": "hWwY_Jq0xsN", "original": "wtuDt1luKe", "number": 4902, "cdate": 1663850380065, "mdate": null, "ddate": null, "tcdate": 1663850380065, "tmdate": 1677600228858, "tddate": null, "forum": "hWwY_Jq0xsN", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Towards Interpretable Deep Reinforcement Learning with Human-Friendly Prototypes", "authorids": ["~Eoin_M._Kenny1", "~Mycal_Tucker1", "~Julie_Shah2"], "authors": ["Eoin M. Kenny", "Mycal Tucker", "Julie Shah"], "keywords": ["Interpretable Machine Learning", "Deep Reinforcement Learning", "Prototypes", "User Study"], "TL;DR": "An \"interpretable-by-design\" deep reinforcement learning agent is proposed which uses prototypes for decision making.", "abstract": "Despite recent success of deep learning models in research settings, their application in sensitive domains remains limited because of their opaque decision-making processes. Taking to this challenge, people have proposed various eXplainable AI (XAI) techniques designed to calibrate trust and understandability of black-box models, with the vast majority of work focused on supervised learning. Here, we focus on making an \"interpretable-by-design\" deep reinforcement learning agent which is forced to use human-friendly prototypes in its decisions, thus making its reasoning process clear. Our proposed method, dubbed Prototype-Wrapper Network (PW-Net), wraps around any neural agent backbone, and results indicate that it does not worsen performance relative to black-box models. Most importantly, we found in a user study that PW-Nets supported better trust calibration and task performance relative to standard interpretability approaches and black-boxes.\n", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)", "paperhash": "kenny|towards_interpretable_deep_reinforcement_learning_with_humanfriendly_prototypes", "pdf": "/pdf/89dc907add1447b8730b63f4562410d7d9346676.pdf", "supplementary_material": "/attachment/70c531f36824c21ff1dec583a9aa3971b476d3dd.zip", "_bibtex": "@inproceedings{\nkenny2023towards,\ntitle={Towards Interpretable Deep Reinforcement Learning with Human-Friendly Prototypes},\nauthor={Eoin M. Kenny and Mycal Tucker and Julie Shah},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=hWwY_Jq0xsN}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279364743, "odate": 1664468100000, "details": {"replyCount": 14}}, {"id": "P4MUGRM4Acu", "original": "d7jIIY6nwIk", "number": 4892, "cdate": 1663850378886, "mdate": null, "ddate": null, "tcdate": 1663850378886, "tmdate": 1676330829009, "tddate": null, "forum": "P4MUGRM4Acu", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "The Surprising Effectiveness of Equivariant Models in Domains with Latent Symmetry", "authorids": ["~Dian_Wang1", "~Jung_Yeon_Park1", "sortur.n@northeastern.edu", "~Lawson_L.S._Wong2", "~Robin_Walters1", "~Robert_Platt1"], "authors": ["Dian Wang", "Jung Yeon Park", "Neel Sortur", "Lawson L.S. Wong", "Robin Walters", "Robert Platt"], "keywords": ["Equivariant Learning", "Reinforcement Learning", "Robotics"], "TL;DR": "This paper discovers that equivariant models are surprisingly effective in domains with latent or partial symmetries. ", "abstract": "Extensive work has demonstrated that equivariant neural networks can significantly improve sample efficiency and generalization by enforcing an inductive bias in the network architecture. These applications typically assume that the domain symmetry is fully described by explicit transformations of the model inputs and outputs. However, many real-life applications contain only latent or partial symmetries which cannot be easily described by simple transformations of the input. In these cases, it is necessary to learn symmetry in the environment instead of imposing it mathematically on the network architecture. We discover, surprisingly, that imposing equivariance constraints that do not exactly match the domain symmetry is very helpful in learning the true symmetry in the environment. We differentiate between extrinsic and incorrect symmetry constraints and show that while imposing incorrect symmetry can impede the model's performance, imposing extrinsic symmetry can actually improve performance. We demonstrate that an equivariant model can significantly outperform non-equivariant methods on domains with latent symmetries both in supervised learning and in reinforcement learning for robotic manipulation and control problems.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)", "paperhash": "wang|the_surprising_effectiveness_of_equivariant_models_in_domains_with_latent_symmetry", "pdf": "/pdf/e89d07093752cddf94cde0b8379f518fd4d8e233.pdf", "_bibtex": "@inproceedings{\nwang2023the,\ntitle={The Surprising Effectiveness of Equivariant Models in Domains with Latent Symmetry},\nauthor={Dian Wang and Jung Yeon Park and Neel Sortur and Lawson L.S. Wong and Robin Walters and Robert Platt},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=P4MUGRM4Acu}\n}", "supplementary_material": "/attachment/c0cb7b1efe7121012642d1d53dc6d13a7df7a3ef.zip", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279364021, "odate": 1664468100000, "details": {"replyCount": 13}}, {"id": "j8IiQUM33s", "original": "GdRirFRGdcT", "number": 4851, "cdate": 1663850374146, "mdate": null, "ddate": null, "tcdate": 1663850374146, "tmdate": 1677583366376, "tddate": null, "forum": "j8IiQUM33s", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Task-customized Masked Autoencoder via Mixture of Cluster-conditional Experts", "authorids": ["~Zhili_LIU1", "~Kai_Chen11", "~Jianhua_Han1", "~Lanqing_HONG1", "~Hang_Xu1", "~Zhenguo_Li1", "~James_Kwok1"], "authors": ["Zhili LIU", "Kai Chen", "Jianhua Han", "Lanqing HONG", "Hang Xu", "Zhenguo Li", "James Kwok"], "keywords": [], "abstract": "Masked Autoencoder (MAE) is a prevailing self-supervised learning method that achieves promising results in model pre-training. However, when the various downstream tasks have data distributions different from the pre-training data, the semantically irrelevant pre-training information might result in negative transfer, impeding MAE\u2019s scalability. To address this issue, we propose a novel MAE-based pre-training paradigm, Mixture of Cluster-conditional Experts (MoCE), which can be trained once but provides customized pre-training models for diverse downstream tasks. Different from the mixture of experts (MoE), our MoCE trains each expert only with semantically relevant images by using cluster-conditional gates. Thus, each downstream task can be allocated to its customized model pre-trained with data most similar to the downstream data. Experiments on a collection of 11 downstream tasks show that MoCE outperforms the vanilla MAE by 2.45\\% on average. It also obtains new state-of-the-art self-supervised learning results on detection and segmentation.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Unsupervised and Self-supervised learning", "paperhash": "liu|taskcustomized_masked_autoencoder_via_mixture_of_clusterconditional_experts", "pdf": "/pdf/d19031c830199ada819326ce9c24b0d2f7cb6cf4.pdf", "_bibtex": "@inproceedings{\nliu2023taskcustomized,\ntitle={Task-customized Masked Autoencoder via Mixture of Cluster-conditional Experts},\nauthor={Zhili LIU and Kai Chen and Jianhua Han and Lanqing HONG and Hang Xu and Zhenguo Li and James Kwok},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=j8IiQUM33s}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference", "supplementary_material": ""}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279361626, "odate": 1664468100000, "details": {"replyCount": 19}}, {"id": "uyqks-LILZX", "original": "pXFL3Tm6WzY", "number": 4848, "cdate": 1663850373794, "mdate": null, "ddate": null, "tcdate": 1663850373794, "tmdate": 1677738022960, "tddate": null, "forum": "uyqks-LILZX", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Modeling the Data-Generating Process is Necessary for Out-of-Distribution Generalization", "authorids": ["~Jivat_Neet_Kaur1", "~Emre_Kiciman1", "~Amit_Sharma3"], "authors": ["Jivat Neet Kaur", "Emre Kiciman", "Amit Sharma"], "keywords": [], "abstract": "Recent empirical studies on domain generalization (DG) have shown that DG algorithms that perform well on some distribution shifts fail on others, and no state-of-the-art DG algorithm performs consistently well on all shifts. Moreover, real-world data often has multiple distribution shifts over different attributes; hence we introduce multi-attribute distribution shift datasets and find that the accuracy of existing DG algorithms falls even further. To explain these results, we provide a formal characterization of generalization under multi-attribute shifts using a canonical causal graph. Based on the relationship between spurious attributes and the classification label, we obtain realizations of the canonical causal graph that characterize common distribution shifts and show that each shift entails different independence constraints over observed variables. As a result, we prove that any algorithm based on a single, fixed constraint cannot work well across all shifts, providing theoretical evidence for mixed empirical results on DG algorithms. Based on this insight, we develop Causally Adaptive Constraint Minimization (CACM), an algorithm that uses knowledge about the data-generating process to adaptively identify and apply the correct independence constraints for regularization. Results on fully synthetic, MNIST, small NORB, and Waterbirds datasets, covering binary and multi-valued attributes and labels, show that adaptive dataset-dependent constraints lead to the highest accuracy on unseen domains whereas incorrect constraints fail to do so. Our results demonstrate the importance of modeling the causal relationships inherent in the data-generating process.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Deep Learning and representational learning", "paperhash": "kaur|modeling_the_datagenerating_process_is_necessary_for_outofdistribution_generalization", "pdf": "/pdf/4048ed797cd1ecee3eb0807128459f763f1cd777.pdf", "supplementary_material": "/attachment/23073f60dcc25181be64f75b391699060ffe6711.zip", "_bibtex": "@inproceedings{\nkaur2023modeling,\ntitle={Modeling the Data-Generating Process is Necessary for Out-of-Distribution Generalization},\nauthor={Jivat Neet Kaur and Emre Kiciman and Amit Sharma},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=uyqks-LILZX}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279361477, "odate": 1664468100000, "details": {"replyCount": 5}}, {"id": "eR2dG8yjnQ", "original": "U6ges0p9ZS", "number": 4835, "cdate": 1663850372267, "mdate": null, "ddate": null, "tcdate": 1663850372267, "tmdate": 1697935349612, "tddate": null, "forum": "eR2dG8yjnQ", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Using Language to Extend to Unseen Domains", "authorids": ["~Lisa_Dunlap1", "~Clara_Mohri1", "~Devin_Guillory1", "~Han_Zhang17", "~Trevor_Darrell2", "~Joseph_E._Gonzalez1", "~Aditi_Raghunathan1", "~Anna_Rohrbach1"], "authors": ["Lisa Dunlap", "Clara Mohri", "Devin Guillory", "Han Zhang", "Trevor Darrell", "Joseph E. Gonzalez", "Aditi Raghunathan", "Anna Rohrbach"], "keywords": ["vision and language", "robust training", "domain adaptation"], "TL;DR": "Transforming multimodal embeddings with language improves accuracy on an unseen domain. ", "abstract": "It is expensive to collect training data for every possible domain that a vision model may encounter when deployed. We instead consider how simply $\\textit{verbalizing}$ the training domain (e.g.``photos of birds'') as well as domains we want to extend to but do not have data for (e.g.``paintings of birds'') can improve robustness. Using a multimodal model with a joint image and language embedding space, our method $\\textit{LADS}$ learns a transformation of the image embeddings from the source domain to each target domain, while preserving task relevant information. Without using any images from the target domain, we show that over the $\\textit{extended}$ domain containing both source and target, $\\textit{LADS}$ outperforms standard fine-tuning and ensemble approaches over a suite of 4 benchmarks targeting domain adaptation and dataset bias.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Applications (eg, speech processing, computer vision, NLP)", "paperhash": "dunlap|using_language_to_extend_to_unseen_domains", "pdf": "/pdf/bb5314efba6d37a2ea4f8cdbdeccd9351dde3016.pdf", "supplementary_material": "/attachment/c07c0a6553acd8aed203995a00ea86ef449cc1ed.zip", "_bibtex": "@inproceedings{\ndunlap2023using,\ntitle={Using Language to Extend to Unseen Domains},\nauthor={Lisa Dunlap and Clara Mohri and Devin Guillory and Han Zhang and Trevor Darrell and Joseph E. Gonzalez and Aditi Raghunathan and Anna Rohrbach},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=eR2dG8yjnQ}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2210.09520/code)"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279360596, "odate": 1664468100000, "details": {"replyCount": 9}}, {"id": "eQzLwwGyQrb", "original": "jQxRJaNoYcg", "number": 4834, "cdate": 1663850372149, "mdate": null, "ddate": null, "tcdate": 1663850372149, "tmdate": 1677774076783, "tddate": null, "forum": "eQzLwwGyQrb", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Can We Find Nash Equilibria at a Linear Rate in Markov Games?", "authorids": ["~Zhuoqing_Song1", "~Jason_D._Lee1", "~Zhuoran_Yang1"], "authors": ["Zhuoqing Song", "Jason D. Lee", "Zhuoran Yang"], "keywords": ["Multi-Agent Reinforcement Learning", "Markov Games", "Linear Convergence", "Policy Optimization"], "TL;DR": "A decentralized algorithm for finding Nash equilibria in two-player zero-sum discounted Markov games with global linear convergence.", "abstract": "We study decentralized learning in two-player zero-sum discounted Markov games where the goal is to design a policy optimization algorithm for either agent satisfying two properties. First, the player does not need to know the policy of the opponent to update its policy. Second, when both players adopt the algorithm, their joint policy converges to a Nash equilibrium of the game. To this end, we construct a meta-algorithm, dubbed as $\\texttt{Homotopy-PO}$, which provably finds a Nash equilibrium at a global linear rate. In particular, $\\texttt{Homotopy-PO}$ interweaves two base algorithms $\\texttt{Local-Fast}$ and $\\texttt{Global-Slow}$ via homotopy continuation. $\\texttt{Local-Fast}$ is an algorithm that enjoys local linear convergence while $\\texttt{Global-Slow}$ is an algorithm that converges globally but at a slower sublinear rate. By switching between these two base algorithms, $\\texttt{Global-Slow}$ essentially serves as a ``guide'' which identifies a benign neighborhood where $\\texttt{Local-Fast}$ enjoys fast convergence. However, since the exact size of such a neighborhood is unknown, we apply a doubling trick to switch between these two base algorithms. The switching scheme is delicately designed so that the aggregated performance of the algorithm is driven by $\\texttt{Local-Fast}$. Furthermore, we prove that $\\texttt{Local-Fast}$ and $\\texttt{Global-Slow}$ can both be instantiated by variants of optimistic gradient descent/ascent (OGDA) method, which is of independent interest.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)", "paperhash": "song|can_we_find_nash_equilibria_at_a_linear_rate_in_markov_games", "pdf": "/pdf/f6285c79bac699974cbfa7334d3e42800b338c64.pdf", "_bibtex": "@inproceedings{\nsong2023can,\ntitle={Can We Find Nash Equilibria at a Linear Rate in Markov Games?},\nauthor={Zhuoqing Song and Jason D. Lee and Zhuoran Yang},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=eQzLwwGyQrb}\n}", "supplementary_material": "", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279360507, "odate": 1664468100000, "details": {"replyCount": 18}}, {"id": "8gd4M-_Rj1", "original": "YV2S6gyIJU", "number": 4783, "cdate": 1663850364675, "mdate": null, "ddate": null, "tcdate": 1663850364675, "tmdate": 1677629277466, "tddate": null, "forum": "8gd4M-_Rj1", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Hebbian Deep Learning Without Feedback", "authorids": ["~Adrien_Journ\u00e91", "hector.garcia.rodriguez@huawei.com", "~Qinghai_Guo1", "~Timoleon_Moraitis1"], "authors": ["Adrien Journ\u00e9", "Hector Garcia Rodriguez", "Qinghai Guo", "Timoleon Moraitis"], "keywords": ["Hebbian", "winner-take-all", "cortical circuits", "unsupervised", "online", "biologically plausible", "neuromorphic"], "TL;DR": "Advancing the state of the art in bio-plausible Deep Learning, and the plausibility of DL, through Hebbian plasticity and soft winner-take-all nets.", "abstract": "Recent approximations to backpropagation (BP) have mitigated many of BP's computational inefficiencies and incompatibilities with biology, but important limitations still remain. Moreover, the approximations significantly decrease accuracy in benchmarks, suggesting that an entirely different approach may be more fruitful. Here, grounded on recent theory for Hebbian learning in soft winner-take-all networks, we present multilayer SoftHebb, i.e. an algorithm that trains deep neural networks, without any feedback, target, or error signals. As a result, it achieves efficiency by avoiding weight transport, non-local plasticity, time-locking of layer updates, iterative equilibria, and (self-) supervisory or other feedback signals \u2013 which were necessary in other approaches. Its increased efficiency and biological compatibility do not trade off accuracy compared to state-of-the-art bio-plausible learning, but rather improve it. With up to five hidden layers and an added linear classifier, accuracies on MNIST, CIFAR-10, STL-10, and ImageNet, respectively reach 99.4%, 80.3%, 76.2%, and 27.3%. In conclusion, SoftHebb shows with a radically different approach from BP that Deep Learning over few layers may be plausible in the brain and increases the accuracy of bio-plausible machine learning. Code is available at https://github.com/NeuromorphicComputing/SoftHebb.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Neuroscience and Cognitive Science (e.g., neural coding, brain-computer interfaces)", "paperhash": "journ\u00e9|hebbian_deep_learning_without_feedback", "pdf": "/pdf/8069b75c93174254f8042cc114dad9bbd5b73989.pdf", "_bibtex": "@inproceedings{\njourn{\\'e}2023hebbian,\ntitle={Hebbian Deep Learning Without Feedback},\nauthor={Adrien Journ{\\'e} and Hector Garcia Rodriguez and Qinghai Guo and Timoleon Moraitis},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=8gd4M-_Rj1}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279357261, "odate": 1664468100000, "details": {"replyCount": 25}}, {"id": "kt-dcBQcSA", "original": "cOy1gFwHGVM", "number": 4716, "cdate": 1663850356815, "mdate": null, "ddate": null, "tcdate": 1663850356815, "tmdate": 1677187274125, "tddate": null, "forum": "kt-dcBQcSA", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "A probabilistic framework for task-aligned intra- and inter-area neural manifold estimation", "authorids": ["~Edoardo_Balzani1", "~Jean-Paul_G_Noel1", "~Pedro_Herrero-Vidal1", "da93@nyu.edu", "~Cristina_Savin1"], "authors": ["Edoardo Balzani", "Jean-Paul G Noel", "Pedro Herrero-Vidal", "Dora E Angelaki", "Cristina Savin"], "keywords": ["neuroscience", "dimensionality reduction", "probabilistic methods", "inter-area interactions"], "TL;DR": "New probabilistic estimator partitions multi-area neural variability into shared and private sources, aligned to meaningful task axes.", "abstract": "Latent manifolds provide a compact characterization of neural population activity and of shared co-variability across brain areas. Nonetheless, existing statistical tools for extracting neural manifolds face limitations in terms of interpretability of latents with respect to task variables, and can be hard to apply to datasets with no trial repeats. Here we propose a novel probabilistic framework that allows for interpretable partitioning of population variability within and across areas in the context of naturalistic behavior. Our approach for task aligned manifold estimation (TAME-GP) explicitly partitions variability into private and shared sources which can themselves be subdivided in task-relevant and task irrelevant components, uses a realistic Poisson noise model, and introduces temporal smoothing of latent trajectories in the form of a Gaussian Process prior. This TAME-GP graphical model allows for robust estimation of task-relevant variability in local population responses, and of shared co-variability between brain areas. We demonstrate the efficiency of our estimator on within model and biologically motivated simulated data. We also apply it to several datasets of neural population recordings during behavior. Overall, our results demonstrate the capacity of TAME-GP to capture meaningful intra- and inter-area neural variability with single trial resolution.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Neuroscience and Cognitive Science (e.g., neural coding, brain-computer interfaces)", "paperhash": "balzani|a_probabilistic_framework_for_taskaligned_intra_and_interarea_neural_manifold_estimation", "pdf": "/pdf/9e46e84807837851d4357f969ea06aa885cf4f5a.pdf", "_bibtex": "@inproceedings{\nbalzani2023a,\ntitle={A probabilistic framework for task-aligned intra- and inter-area neural manifold estimation},\nauthor={Edoardo Balzani and Jean-Paul G Noel and Pedro Herrero-Vidal and Dora E Angelaki and Cristina Savin},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=kt-dcBQcSA}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279353558, "odate": 1664468100000, "details": {"replyCount": 10}}, {"id": "PvLnIaJbt9", "original": "tqZJfhAuju", "number": 4707, "cdate": 1663850355741, "mdate": null, "ddate": null, "tcdate": 1663850355741, "tmdate": 1677585334079, "tddate": null, "forum": "PvLnIaJbt9", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Metadata Archaeology: Unearthing Data Subsets by Leveraging Training Dynamics", "authorids": ["~Shoaib_Ahmed_Siddiqui1", "~Nitarshan_Rajkumar1", "~Tegan_Maharaj1", "~David_Krueger1", "~Sara_Hooker1"], "authors": ["Shoaib Ahmed Siddiqui", "Nitarshan Rajkumar", "Tegan Maharaj", "David Krueger", "Sara Hooker"], "keywords": ["Metadata archaeology", "Learning curves", "Loss trajectory", "Data auditing"], "TL;DR": "Our work provides a unified and efficient framework for Metadata Archaeology -- uncovering and inferring metadata of examples in a dataset", "abstract": "Modern machine learning research relies on relatively few carefully curated datasets. Even in these datasets, and typically in `untidy' or raw data, practitioners are faced with significant issues of data quality and diversity which can be prohibitively labor intensive to address. Existing methods for dealing with these challenges tend to make strong assumptions about the particular issues at play, and often require a priori knowledge or metadata such as domain labels. Our work is orthogonal to these methods: we instead focus on providing a unified and efficient framework for Metadata Archaeology -- uncovering and inferring metadata of examples in a dataset. We curate different subsets of data that might exist in a dataset (e.g. mislabeled, atypical, or out-of-distribution examples) using simple transformations, and leverage differences in learning dynamics between these probe suites to infer metadata of interest. Our method is on par with far more sophisticated mitigation methods across different tasks: identifying and correcting mislabeled examples, classifying minority-group samples, prioritizing points relevant for training and enabling scalable human auditing of relevant examples.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "General Machine Learning (ie none of the above)", "paperhash": "siddiqui|metadata_archaeology_unearthing_data_subsets_by_leveraging_training_dynamics", "pdf": "/pdf/a2556369723de05dfed6645f353856e0f08459a8.pdf", "_bibtex": "@inproceedings{\nsiddiqui2023metadata,\ntitle={Metadata Archaeology: Unearthing Data Subsets by Leveraging Training Dynamics},\nauthor={Shoaib Ahmed Siddiqui and Nitarshan Rajkumar and Tegan Maharaj and David Krueger and Sara Hooker},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=PvLnIaJbt9}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279352868, "odate": 1664468100000, "details": {"replyCount": 12}}, {"id": "gm0VZ-h-hPy", "original": "qJnG3TmInkP", "number": 4681, "cdate": 1663850352619, "mdate": null, "ddate": null, "tcdate": 1663850352619, "tmdate": 1677756306953, "tddate": null, "forum": "gm0VZ-h-hPy", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Proposal-Contrastive Pretraining for Object Detection from Fewer Data", "authorids": ["~Quentin_Bouniot1", "~Romaric_Audigier1", "~Angelique_Loesch1", "~Amaury_Habrard1"], "authors": ["Quentin Bouniot", "Romaric Audigier", "Angelique Loesch", "Amaury Habrard"], "keywords": ["Object Detection", "Unsupervised", "Pretraining", "Contrastive Learning"], "abstract": "The use of pretrained deep neural networks represents an attractive way to achieve strong results with few data available. When specialized in dense problems such as object detection, learning local rather than global information in images has proven to be more efficient. However, for unsupervised pretraining, the popular contrastive learning requires a large batch size and, therefore, a lot of resources. To address this problem, we are interested in transformer-based object detectors that have recently gained traction in the community with good performance and with the particularity of generating many diverse object proposals. \n    In this work, we present Proposal Selection Contrast (ProSeCo), a novel unsupervised overall pretraining approach that leverages this property. ProSeCo uses the large number of object proposals generated by the detector for contrastive learning, which allows the use of a smaller batch size, combined with object-level features to learn local information in the images. To improve the effectiveness of the contrastive loss, we introduce the object location information in the selection of positive examples to take into account multiple overlapping object proposals. When reusing pretrained backbone, we advocate for consistency in learning local information between the backbone and the detection head. \n    We show that our method outperforms state of the art in unsupervised pretraining for object detection on standard and novel benchmarks in learning with fewer data. ", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Unsupervised and Self-supervised learning", "paperhash": "bouniot|proposalcontrastive_pretraining_for_object_detection_from_fewer_data", "TL;DR": "We present Proposal Selection Contrast (ProSeCo), a novel unsupervised overall pretraining approach for Object Detection that leverages the large number of object proposals generated by transformer-based detectors using an improved contrastive loss.", "pdf": "/pdf/409d076ce5528382d9695b832fdb2bebf4977300.pdf", "supplementary_material": "/attachment/b90edbef34514a2899a4134fa6b25985fd70fd76.zip", "_bibtex": "@inproceedings{\nbouniot2023proposalcontrastive,\ntitle={Proposal-Contrastive Pretraining for Object Detection from Fewer Data},\nauthor={Quentin Bouniot and Romaric Audigier and Angelique Loesch and Amaury Habrard},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=gm0VZ-h-hPy}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279351570, "odate": 1664468100000, "details": {"replyCount": 12}}, {"id": "HXz7Vcm3VgM", "original": "4bzYzyLvQ1", "number": 4666, "cdate": 1663850350789, "mdate": null, "ddate": null, "tcdate": 1663850350789, "tmdate": 1677513196421, "tddate": null, "forum": "HXz7Vcm3VgM", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "ImageNet-X: Understanding Model Mistakes with Factor of Variation Annotations", "authorids": ["~Badr_Youbi_Idrissi1", "~Diane_Bouchacourt3", "~Randall_Balestriero1", "~Ivan_Evtimov2", "~Caner_Hazirbas2", "~Nicolas_Ballas1", "~Pascal_Vincent1", "~Michal_Drozdzal1", "~David_Lopez-Paz2", "~Mark_Ibrahim1"], "authors": ["Badr Youbi Idrissi", "Diane Bouchacourt", "Randall Balestriero", "Ivan Evtimov", "Caner Hazirbas", "Nicolas Ballas", "Pascal Vincent", "Michal Drozdzal", "David Lopez-Paz", "Mark Ibrahim"], "keywords": [], "TL;DR": "we annotate ImageNet images with factor labels to explain model mistakes", "abstract": "Deep learning vision systems are widely deployed across applications where reliability is critical. However, even today's best models can fail to recognize an object when its pose, lighting, or background varies. While existing benchmarks surface examples challenging for models, they do not explain why such mistakes arise. To address this need, we introduce ImageNet-X\u2014a set of sixteen human annotations of factors such as pose, background, or lighting the entire ImageNet-1k validation set as well as a random subset of 12k training images. Equipped with ImageNet-X, we investigate 2,200 current recognition models and study the types of mistakes as a function of model\u2019s (1) architecture, e.g. transformer vs. convolutional, (2) learning paradigm, e.g. supervised vs. self-supervised, and (3) training procedures, e.g., data augmentation. Regardless of these choices, we find models have consistent failure modes across ImageNet-X categories. We also find that while data augmentation can improve robustness to certain factors, they induce spill-over effects to other factors. For example, color-jitter augmentation improves robustness to color and brightness, but surprisingly hurts robustness to pose. Together, these insights suggest to advance the robustness of modern vision models, future research should focus on collecting additional data and understanding data augmentation schemes. Along with these insights, we release a toolkit based on ImageNet-X to spur further study into the mistakes image recognition systems make.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Deep Learning and representational learning", "paperhash": "idrissi|imagenetx_understanding_model_mistakes_with_factor_of_variation_annotations", "pdf": "/pdf/33fbd8d8db5f01fb273b222f69e3719afd7a9778.pdf", "supplementary_material": "/attachment/f4ccd4ac9d0e4e4e00d846f33eca00d2809fb317.zip", "_bibtex": "@inproceedings{\nidrissi2023imagenetx,\ntitle={ImageNet-X: Understanding Model Mistakes with Factor of Variation Annotations},\nauthor={Badr Youbi Idrissi and Diane Bouchacourt and Randall Balestriero and Ivan Evtimov and Caner Hazirbas and Nicolas Ballas and Pascal Vincent and Michal Drozdzal and David Lopez-Paz and Mark Ibrahim},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=HXz7Vcm3VgM}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279350172, "odate": 1664468100000, "details": {"replyCount": 10}}, {"id": "b7SBTEBFnC", "original": "1-qTBLVPGob", "number": 4647, "cdate": 1663850348572, "mdate": null, "ddate": null, "tcdate": 1663850348572, "tmdate": 1697935371317, "tddate": null, "forum": "b7SBTEBFnC", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Canary in a Coalmine: Better Membership Inference with Ensembled Adversarial Queries", "authorids": ["~Yuxin_Wen2", "~Arpit_Bansal1", "~Hamid_Kazemi1", "~Eitan_Borgnia1", "~Micah_Goldblum1", "~Jonas_Geiping1", "~Tom_Goldstein1"], "authors": ["Yuxin Wen", "Arpit Bansal", "Hamid Kazemi", "Eitan Borgnia", "Micah Goldblum", "Jonas Geiping", "Tom Goldstein"], "keywords": [], "abstract": "As industrial applications are increasingly automated by machine learning models, enforcing personal data ownership and intellectual property rights requires tracing training data back to their rightful owners. Membership inference algorithms approach this problem by using statistical techniques to discern whether a target sample was included in a model's training set. However, existing methods only utilize the unaltered target sample or simple augmentations of the target to compute statistics. Such a sparse sampling of the model's behavior carries little information, leading to poor inference capabilities. In this work, we use adversarial tools to directly optimize for queries that are discriminative and diverse. Our improvements achieve significantly more accurate membership inference than existing methods, especially in offline scenarios and in the low false-positive regime which is critical in legal settings.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)", "paperhash": "wen|canary_in_a_coalmine_better_membership_inference_with_ensembled_adversarial_queries", "pdf": "/pdf/77e3d4474830ef1ec482bf7015ca9b61fa9f8264.pdf", "supplementary_material": "/attachment/e3662ca32b02af683d8c363ae502efc1066e59d1.zip", "_bibtex": "@inproceedings{\nwen2023canary,\ntitle={Canary in a Coalmine: Better Membership Inference with Ensembled Adversarial Queries},\nauthor={Yuxin Wen and Arpit Bansal and Hamid Kazemi and Eitan Borgnia and Micah Goldblum and Jonas Geiping and Tom Goldstein},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=b7SBTEBFnC}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2210.10750/code)"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279349205, "odate": 1664468100000, "details": {"replyCount": 11}}, {"id": "PhkWyijGi5b", "original": "2Y7PmhIcPjr", "number": 4622, "cdate": 1663850345719, "mdate": null, "ddate": null, "tcdate": 1663850345719, "tmdate": 1697935373488, "tddate": null, "forum": "PhkWyijGi5b", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Choreographer: Learning and Adapting Skills in Imagination", "authorids": ["~Pietro_Mazzaglia1", "~Tim_Verbelen1", "~Bart_Dhoedt1", "~Alexandre_Lacoste1", "~Sai_Rajeswar2"], "authors": ["Pietro Mazzaglia", "Tim Verbelen", "Bart Dhoedt", "Alexandre Lacoste", "Sai Rajeswar"], "keywords": ["unsupervised reinforcement learning", "skill learning", "world models"], "TL;DR": "Choreographer: a model-based agent that discovers and learns unsupervised skills in latent imagination, and it's able to efficiently coordinate and adapt the skills to solve downstream tasks.", "abstract": "Unsupervised skill learning aims to learn a rich repertoire of behaviors without external supervision, providing artificial agents with the ability to control and influence the environment. However, without appropriate knowledge and exploration, skills may provide control only over a restricted area of the environment, limiting their applicability. Furthermore, it is unclear how to leverage the learned skill behaviors for adapting to downstream tasks in a data-efficient manner. We present Choreographer, a model-based agent that exploits its world model to learn and adapt skills in imagination. Our method decouples the exploration and skill learning processes, being able to discover skills in the latent state space of the model. During adaptation, the agent uses a meta-controller to evaluate and adapt the learned skills efficiently by deploying them in parallel in imagination. Choreographer is able to learn skills both from offline data, and by collecting data simultaneously with an exploration policy. The skills can be used to effectively adapt to downstream tasks, as we show in the URL benchmark, where we outperform previous approaches from both pixels and states inputs. The skills also explore the environment thoroughly, finding sparse rewards more frequently, as shown in goal-reaching tasks from the DMC Suite and Meta-World. \nProject website: https://skillchoreographer.github.io/", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)", "paperhash": "mazzaglia|choreographer_learning_and_adapting_skills_in_imagination", "pdf": "/pdf/3b9c0c356a7760d7f70096b567ff2aef51b26f98.pdf", "_bibtex": "@inproceedings{\nmazzaglia2023choreographer,\ntitle={Choreographer: Learning and Adapting Skills in Imagination},\nauthor={Pietro Mazzaglia and Tim Verbelen and Bart Dhoedt and Alexandre Lacoste and Sai Rajeswar},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=PhkWyijGi5b}\n}", "supplementary_material": "", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 2 code implementations](https://www.catalyzex.com/paper/arxiv:2211.13350/code)"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279347944, "odate": 1664468100000, "details": {"replyCount": 12}}, {"id": "sKc6fgce1zs", "original": "iHURVRPG-uO", "number": 4590, "cdate": 1663850341934, "mdate": null, "ddate": null, "tcdate": 1663850341934, "tmdate": 1677604807972, "tddate": null, "forum": "sKc6fgce1zs", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Learning About Progress From Experts", "authorids": ["~Jake_Bruce1", "~Ankit_Anand4", "~Bogdan_Mazoure1", "~Rob_Fergus1"], "authors": ["Jake Bruce", "Ankit Anand", "Bogdan Mazoure", "Rob Fergus"], "keywords": ["learning from demonstrations", "reinforcement learning", "exploration", "nethack"], "TL;DR": "We learn a model of long-term progress using expert demonstrations, and show that it can be used to form an exploration reward that allows reinforcement learning agents to solve very challenging sparse tasks in NetHack.", "abstract": "Many important tasks involve some notion of long-term progress in multiple phases: e.g. to clean a shelf it must be cleared of items, cleaning products applied, and then the items placed back on the shelf. In this work, we explore the use of expert demonstrations in long-horizon tasks to learn a monotonically increasing function that summarizes progress. This function can then be used to aid agent exploration in environments with sparse rewards. As a case study we consider the NetHack environment, which requires long-term progress at a variety of scales and is far from being solved by existing approaches. In this environment, we demonstrate that by learning a model of long-term progress from expert data containing only observations, we can achieve efficient exploration in challenging sparse tasks, well beyond what is possible with current state-of-the-art approaches. We have made the curated gameplay dataset used in this work available at https://github.com/deepmind/nao_top10.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)", "paperhash": "bruce|learning_about_progress_from_experts", "pdf": "/pdf/6c536f4956e9ba6881ac817930a21ec1d8526220.pdf", "_bibtex": "@inproceedings{\nbruce2023learning,\ntitle={Learning About Progress From Experts},\nauthor={Jake Bruce and Ankit Anand and Bogdan Mazoure and Rob Fergus},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=sKc6fgce1zs}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279346444, "odate": 1664468100000, "details": {"replyCount": 9}}, {"id": "1_OGWcP1s9w", "original": "IpZfuXCIvIc", "number": 4588, "cdate": 1663850341688, "mdate": null, "ddate": null, "tcdate": 1663850341688, "tmdate": 1677519876002, "tddate": null, "forum": "1_OGWcP1s9w", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Learning Fair Graph Representations via Automated Data Augmentations", "authorids": ["~Hongyi_Ling1", "~Zhimeng_Jiang1", "~Youzhi_Luo1", "~Shuiwang_Ji1", "~Na_Zou2"], "authors": ["Hongyi Ling", "Zhimeng Jiang", "Youzhi Luo", "Shuiwang Ji", "Na Zou"], "keywords": [], "TL;DR": "We propose an automated graph data augmentation method to learn fair graph representations.", "abstract": "We consider fair graph representation learning via data augmentations. While this direction has been explored previously, existing methods invariably rely on certain assumptions on the properties of fair graph data in order to design fixed strategies on data augmentations. Nevertheless, the exact properties of fair graph data may vary significantly in different scenarios. Hence, heuristically designed augmentations may not always generate fair graph data in different application scenarios. In this work, we propose a method, known as Graphair, to learn fair representations based on automated graph data augmentations. Such fairness-aware augmentations are themselves learned from data. Our Graphair is designed to automatically discover fairness-aware augmentations from input graphs in order to circumvent sensitive information while preserving other useful information. Experimental results demonstrate that our Graphair consistently outperforms many baselines on multiple node classification datasets in terms of fairness-accuracy trade-off performance. In addition, results indicate that Graphair can automatically learn to generate fair graph data without prior knowledge on fairness-relevant graph properties.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)", "paperhash": "ling|learning_fair_graph_representations_via_automated_data_augmentations", "pdf": "/pdf/6bbe51476329fdae6f372b5d0c4f4e4051745eeb.pdf", "_bibtex": "@inproceedings{\nling2023learning,\ntitle={Learning Fair Graph Representations via Automated Data Augmentations},\nauthor={Hongyi Ling and Zhimeng Jiang and Youzhi Luo and Shuiwang Ji and Na Zou},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=1_OGWcP1s9w}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279346344, "odate": 1664468100000, "details": {"replyCount": 13}}, {"id": "lTt4KjHSsyl", "original": "GlL-Np0dE7", "number": 4579, "cdate": 1663850340697, "mdate": null, "ddate": null, "tcdate": 1663850340697, "tmdate": 1677447372385, "tddate": null, "forum": "lTt4KjHSsyl", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Emergence of Maps in the Memories of Blind Navigation Agents", "authorids": ["~Erik_Wijmans1", "~Manolis_Savva1", "~Irfan_Essa1", "~Stefan_Lee1", "~Ari_S._Morcos1", "~Dhruv_Batra1"], "authors": ["Erik Wijmans", "Manolis Savva", "Irfan Essa", "Stefan Lee", "Ari S. Morcos", "Dhruv Batra"], "keywords": ["embodied AI", "navigation", "characterizing representations"], "abstract": "Animal navigation research posits that organisms build and maintain internal spa- tial representations, or maps, of their environment. We ask if machines \u2013 specifically, artificial intelligence (AI) navigation agents \u2013 also build implicit (or \u2018mental\u2019) maps. A positive answer to this question would (a) explain the surprising phenomenon in recent literature of ostensibly map-free neural-networks achieving strong performance, and (b) strengthen the evidence of mapping as a fundamental mechanism for navigation by intelligent embodied agents, whether they be biological or artificial. Unlike animal navigation, we can judiciously design the agent\u2019s perceptual system and control the learning paradigm to nullify alternative navigation mechanisms. Specifically, we train \u2018blind\u2019 agents \u2013 with sensing limited to only egomotion and no other sensing of any kind \u2013 to perform PointGoal navigation (\u2018go to $\\Delta$x, $\\Delta$y\u2019) via reinforcement learning. Our agents are composed of navigation-agnostic components (fully-connected and recurrent neural networks), and our experimental setup provides no inductive bias towards mapping. Despite these harsh conditions, we find that blind agents are (1) surprisingly effective navigators in new environments (\u223c95% success); (2) they utilize memory over long horizons (remembering \u223c1,000 steps of past experience in an episode); (3) this memory enables them to exhibit intelligent behavior (following walls, detecting collisions, taking shortcuts); (4) there is emergence of maps and collision detection neurons in the representations of the environment built by a blind agent as it navigates; and (5) the emergent maps are selective and task dependent (e.g. the agent \u2018forgets\u2019 exploratory detours). Overall, this paper presents no new techniques for the AI audience, but a surprising finding, an insight, and an explanation.", "pdf": "/pdf/6aff51942ab3664378283e5da2b36db1cd04db62.pdf", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "supplementary_material": "/attachment/1a1fad87ef1140f6867ce0b4540e013b5ba9fa97.zip", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)", "paperhash": "wijmans|emergence_of_maps_in_the_memories_of_blind_navigation_agents", "TL;DR": "\u2018Blind\u2019 AI navigation agents (with only egomotion sensing) can learn to navigate new environments and build map-like representations (supporting the ability to take shortcuts, follow walls, and predict free-space and collisions) of their environment.", "_bibtex": "@inproceedings{\nwijmans2023emergence,\ntitle={Emergence of Maps in the Memories of Blind Navigation Agents},\nauthor={Erik Wijmans and Manolis Savva and Irfan Essa and Stefan Lee and Ari S. Morcos and Dhruv Batra},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=lTt4KjHSsyl}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279345865, "odate": 1664468100000, "details": {"replyCount": 22}}, {"id": "DjzBCrMBJ_p", "original": "4rT3UrxMloQ", "number": 4573, "cdate": 1663850339960, "mdate": null, "ddate": null, "tcdate": 1663850339960, "tmdate": 1677685375495, "tddate": null, "forum": "DjzBCrMBJ_p", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Spectral Augmentation for Self-Supervised Learning on Graphs", "authorids": ["~Lu_Lin2", "~Jinghui_Chen1", "~Hongning_Wang1"], "authors": ["Lu Lin", "Jinghui Chen", "Hongning Wang"], "keywords": ["graph self-supervised learning", "graph spectral theory", "graph augmentation"], "TL;DR": "We propose a novel spectral augmentation method which uses graph spectrum to capture structural properties and guide topology augmentations for graph self-supervised learning.", "abstract": "Graph contrastive learning (GCL), as an emerging self-supervised learning technique on graphs, aims to learn representations via instance discrimination. Its performance heavily relies on graph augmentation to reflect invariant patterns that are robust to small perturbations; yet it still remains unclear about what graph invariance GCL should capture. Recent studies mainly perform topology augmentations in a uniformly random manner in the spatial domain, ignoring its influence on the intrinsic structural properties embedded in the spectral domain. In this work, we aim to find a principled way for topology augmentations by exploring the invariance of graphs from the spectral perspective. We develop spectral augmentation which guides topology augmentations by maximizing the spectral change. Extensive experiments on both graph and node classification tasks demonstrate the effectiveness of our method in self-supervised representation learning. The proposed method also brings promising generalization capability in transfer learning, and is equipped with intriguing robustness property under adversarial attacks. Our study sheds light on a general principle for graph topology augmentation.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Unsupervised and Self-supervised learning", "paperhash": "lin|spectral_augmentation_for_selfsupervised_learning_on_graphs", "pdf": "/pdf/f3bc720be318c5e2d1b97759ef657ead63c87974.pdf", "supplementary_material": "", "_bibtex": "@inproceedings{\nlin2023spectral,\ntitle={Spectral Augmentation for Self-Supervised Learning on Graphs},\nauthor={Lu Lin and Jinghui Chen and Hongning Wang},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=DjzBCrMBJ_p}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279345453, "odate": 1664468100000, "details": {"replyCount": 15}}, {"id": "WOquZTLCBO1", "original": "DIB_MIb0Rvw", "number": 4525, "cdate": 1663850334257, "mdate": null, "ddate": null, "tcdate": 1663850334257, "tmdate": 1677716195948, "tddate": null, "forum": "WOquZTLCBO1", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "VIPeR: Provably Efficient Algorithm for Offline RL with Neural Function Approximation", "authorids": ["~Thanh_Nguyen-Tang1", "~Raman_Arora1"], "authors": ["Thanh Nguyen-Tang", "Raman Arora"], "keywords": ["Offline Reinforcement Learning", "Neural Networks"], "TL;DR": "A provably and computationally efficient algorithm for offline RL with deep neural networks ", "abstract": "We propose a novel algorithm for offline reinforcement learning called Value Iteration with Perturbed Rewards (VIPeR), which amalgamates the pessimism principle with random perturbations of the value function. Most current offline RL algorithms explicitly construct statistical confidence regions to obtain pessimism via lower confidence bounds (LCB), which cannot easily scale to complex problems where a neural network is used to estimate the value functions. Instead, VIPeR implicitly obtains pessimism by simply perturbing the offline data multiple times with carefully-designed i.i.d. Gaussian noises to learn an ensemble of estimated state-action {value functions} and acting greedily with respect to the minimum of the ensemble. The estimated state-action values are obtained by fitting a parametric model (e.g., neural networks) to the perturbed datasets using gradient descent. As a result, VIPeR only needs $\\mathcal{O}(1)$ time complexity for action selection, while LCB-based algorithms require at least $\\Omega(K^2)$, where $K$ is the total number of trajectories in the offline data. We also propose a novel data-splitting technique that helps remove a factor involving the log of the covering number in our bound. We prove that VIPeR yields a provable uncertainty quantifier with overparameterized neural networks and enjoys a bound on sub-optimality of $\\tilde{\\mathcal{O}}(  { \\kappa H^{5/2}  \\tilde{d} }/{\\sqrt{K}})$, where $\\tilde{d}$ is the effective dimension, $H$ is the horizon length and $\\kappa$ measures the distributional shift. We corroborate the statistical and computational efficiency of VIPeR with an empirical evaluation on a wide set of synthetic and real-world datasets. To the best of our knowledge, VIPeR is the first algorithm for offline RL that is provably efficient for general Markov decision processes (MDPs) with neural network function approximation. ", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)", "paperhash": "nguyentang|viper_provably_efficient_algorithm_for_offline_rl_with_neural_function_approximation", "pdf": "/pdf/9a8eb48070ffcd0332fa35d7aaa9229cea1438c4.pdf", "_bibtex": "@inproceedings{\nnguyen-tang2023viper,\ntitle={{VIP}eR: Provably Efficient Algorithm for Offline {RL} with Neural Function Approximation},\nauthor={Thanh Nguyen-Tang and Raman Arora},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=WOquZTLCBO1}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279342842, "odate": 1664468100000, "details": {"replyCount": 11}}, {"id": "8uu6JStuYm", "original": "YsN6WSqgto", "number": 4513, "cdate": 1663850332718, "mdate": null, "ddate": null, "tcdate": 1663850332718, "tmdate": 1697935384430, "tddate": null, "forum": "8uu6JStuYm", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Self-supervised learning with rotation-invariant kernels", "authorids": ["~L\u00e9on_Zheng1", "~Gilles_Puy2", "~Elisa_Riccietti1", "~Patrick_Perez1", "~R\u00e9mi_Gribonval1"], "authors": ["L\u00e9on Zheng", "Gilles Puy", "Elisa Riccietti", "Patrick Perez", "R\u00e9mi Gribonval"], "keywords": ["Self-supervised learning", "maximum mean discrepancy", "rotation-invariant kernel", "hypersphere"], "TL;DR": "A regularization loss based on kernel mean embeddings with rotation-invariant kernels on the hypersphere for self-supervised learning of image representations", "abstract": "We introduce a regularization loss based on kernel mean embeddings with rotation-invariant kernels on the hypersphere (also known as dot-product kernels) for self-supervised learning of image representations. Besides being fully competitive with the state of the art, our method significantly reduces time and memory complexity for self-supervised training, making it implementable for very large embedding dimensions on existing devices and more easily adjustable than previous methods to settings with limited resources. Our work follows the major paradigm where the model learns to be invariant to some predefined image transformations (cropping, blurring, color jittering, etc.), while avoiding a degenerate solution by regularizing the embedding distribution. Our particular contribution is to propose a loss family promoting the embedding distribution to be close to the uniform distribution on the hypersphere, with respect to the maximum mean discrepancy pseudometric. We demonstrate that this family encompasses several regularizers of former methods, including uniformity-based and information-maximization methods, which are variants of our flexible regularization loss with different kernels. Beyond its practical consequences for state of the art self-supervised learning with limited resources, the proposed generic regularization approach opens perspectives to leverage more widely the literature on kernel methods in order to improve self-supervised learning methods.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Unsupervised and Self-supervised learning", "paperhash": "zheng|selfsupervised_learning_with_rotationinvariant_kernels", "pdf": "/pdf/ef737455df9ff0ef5ebc958acb84991ccf4647e6.pdf", "_bibtex": "@inproceedings{\nzheng2023selfsupervised,\ntitle={Self-supervised learning with rotation-invariant kernels},\nauthor={L{\\'e}on Zheng and Gilles Puy and Elisa Riccietti and Patrick Perez and R{\\'e}mi Gribonval},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=8uu6JStuYm}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 5 code implementations](https://www.catalyzex.com/paper/arxiv:2208.00789/code)"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279342109, "odate": 1664468100000, "details": {"replyCount": 12}}, {"id": "QubsmJT_A0", "original": "BPVc6yDIuC5", "number": 4507, "cdate": 1663850331934, "mdate": null, "ddate": null, "tcdate": 1663850331934, "tmdate": 1677528124700, "tddate": null, "forum": "QubsmJT_A0", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Neuromechanical Autoencoders: Learning to Couple Elastic and Neural Network Nonlinearity", "authorids": ["~Deniz_Oktay2", "~Mehran_Mirramezani1", "~Eder_Medina1", "~Ryan_P_Adams1"], "authors": ["Deniz Oktay", "Mehran Mirramezani", "Eder Medina", "Ryan P Adams"], "keywords": ["morphological computation", "mechanical metamaterials", "computational mechanics", "mechanical co-design", "automatic differentiation", "differentiable simulation"], "abstract": "Intelligent biological systems are characterized by their embodiment in a complex environment and the intimate interplay between their nervous systems and the nonlinear mechanical properties of their bodies. This coordination, in which the dynamics of the motor system co-evolved to reduce the computational burden on the brain, is referred to as \"mechanical intelligence\" or \"morphological computation\". In this work, we seek to develop machine learning analogs of this process, in which we jointly learn the morphology of complex nonlinear elastic solids along with a deep neural network to control it. By using a specialized differentiable simulator of elastic mechanics coupled to conventional deep learning architectures---which we refer to as neuromechanical autoencoders---we are able to learn to perform morphological computation via gradient descent. Key to our approach is the use of mechanical metamaterials---cellular solids, in particular---as the morphological substrate. Just as deep neural networks provide flexible and massively-parametric function approximators for perceptual and control tasks, cellular solid metamaterials are promising as a rich and learnable space for approximating a variety of actuation tasks. In this work we take advantage of these complementary computational concepts to co-design materials and neural network controls to achieve nonintuitive mechanical behavior. We demonstrate in simulation how it is possible to achieve translation, rotation, and shape matching, as well as a \"digital MNIST\" task. We additionally manufacture and evaluate one of the designs to verify its real-world behavior.\n", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )", "paperhash": "oktay|neuromechanical_autoencoders_learning_to_couple_elastic_and_neural_network_nonlinearity", "TL;DR": "We introduce Neuromechanical Autoencoders, a framework for co-design of neural network and mechanical metamaterials for performing morphological computation.", "pdf": "/pdf/04faa9edbfcb1a55394ac2bf8a342b32638ba5a2.pdf", "supplementary_material": "/attachment/91d23574b61b3876ac2bed58ed46c39c43073be9.zip", "_bibtex": "@inproceedings{\noktay2023neuromechanical,\ntitle={Neuromechanical Autoencoders: Learning to Couple Elastic and Neural Network Nonlinearity},\nauthor={Deniz Oktay and Mehran Mirramezani and Eder Medina and Ryan P Adams},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=QubsmJT_A0}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279341498, "odate": 1664468100000, "details": {"replyCount": 13}}, {"id": "YJ7o2wetJ2", "original": "0m6Sv8zIIwS", "number": 4503, "cdate": 1663850331450, "mdate": null, "ddate": null, "tcdate": 1663850331450, "tmdate": 1677688010627, "tddate": null, "forum": "YJ7o2wetJ2", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "VIP: Towards Universal Visual Reward and Representation via Value-Implicit Pre-Training", "authorids": ["~Yecheng_Jason_Ma2", "~Shagun_Sodhani1", "~Dinesh_Jayaraman2", "~Osbert_Bastani1", "~Vikash_Kumar2", "~Amy_Zhang1"], "authors": ["Yecheng Jason Ma", "Shagun Sodhani", "Dinesh Jayaraman", "Osbert Bastani", "Vikash Kumar", "Amy Zhang"], "keywords": ["Pre-Training for Control", "Offline RL", "Goal-Conditioned RL", "Deep RL", "Robot Learning", "Self-Supervised Learning", "Visuomotor Control"], "TL;DR": "A method for pre-training a goal-conditioned value function on human videos that can be effectively used as zero-shot visual reward and representation for unseen robotics tasks in simulation and real-world.", "abstract": "Reward and representation learning are two long-standing challenges for learning an expanding set of robot manipulation skills from sensory observations. Given the inherent cost and scarcity of in-domain, task-specific robot data, learning from large, diverse, offline human videos has emerged as a promising path towards acquiring a generally useful visual representation for control; however, how these human videos can be used for general-purpose reward learning remains an open question. We introduce $\\textbf{V}$alue-$\\textbf{I}$mplicit $\\textbf{P}$re-training (VIP), a self-supervised pre-trained visual representation capable of generating dense and smooth reward functions for unseen robotic tasks. VIP casts representation learning from human videos as an offline goal-conditioned reinforcement learning problem and derives a self-supervised dual goal-conditioned value-function objective that does not depend on actions, enabling pre-training on unlabeled human videos. Theoretically, VIP can be understood as a novel implicit time contrastive objective that generates a temporally smooth embedding, enabling the value function to be implicitly defined via the embedding distance, which can then be used to construct the reward for any goal-image specified downstream task. Trained on large-scale Ego4D human videos and without any fine-tuning on in-domain, task-specific data, VIP can provide dense visual reward for an extensive set of simulated and $\\textbf{real-robot}$ tasks, enabling diverse reward-based visual control methods and significantly outperforming all prior pre-trained representations. Notably, VIP can enable simple, few-shot offline RL on a suite of real-world robot tasks with as few as 20 trajectories.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)", "paperhash": "ma|vip_towards_universal_visual_reward_and_representation_via_valueimplicit_pretraining", "pdf": "/pdf/56f5b528ba9ae4f7c40ca328636fffe7c8c0c7da.pdf", "supplementary_material": "", "_bibtex": "@inproceedings{\nma2023vip,\ntitle={{VIP}: Towards Universal Visual Reward and Representation via Value-Implicit Pre-Training},\nauthor={Yecheng Jason Ma and Shagun Sodhani and Dinesh Jayaraman and Osbert Bastani and Vikash Kumar and Amy Zhang},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=YJ7o2wetJ2}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279341145, "odate": 1664468100000, "details": {"replyCount": 15}}, {"id": "74A-FDAyiL", "original": "aSVVI4H495", "number": 4477, "cdate": 1663850327953, "mdate": null, "ddate": null, "tcdate": 1663850327953, "tmdate": 1677639635765, "tddate": null, "forum": "74A-FDAyiL", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Subquadratic Algorithms for Kernel Matrices via Kernel Density Estimation", "authorids": ["~Ainesh_Bakshi1", "~Piotr_Indyk1", "~Praneeth_Kacham1", "~Sandeep_Silwal1", "~Samson_Zhou1"], "authors": ["Ainesh Bakshi", "Piotr Indyk", "Praneeth Kacham", "Sandeep Silwal", "Samson Zhou"], "keywords": ["kernel density estimation", "sublinear time algorithms"], "abstract": "Kernel matrices, as well as weighted graphs represented by them, are ubiquitous objects in machine learning, statistics and other related fields. The main drawback of using kernel methods (learning and inference using kernel matrices) is efficiency -- given $n$ input points, most kernel-based algorithms need to materialize the full $n \\times n$ kernel matrix before performing any subsequent computation, thus incurring $\\Omega(n^2)$ runtime. Breaking this quadratic barrier for various problems has therefore, been a subject of extensive research efforts. \n\nWe break the quadratic barrier and obtain \\emph{subquadratic} time  algorithms for several fundamental linear-algebraic and graph processing primitives, including approximating the top eigenvalue and eigenvector, spectral sparsification, solving linear systems, local clustering, low-rank approximation, arboricity estimation and counting weighted triangles. We build on the recently developed Kernel Density Estimation framework, which (after preprocessing in time subquadratic in $n$) can return estimates of row/column sums of the kernel matrix. In particular, we develop efficient reductions from \\emph{weighted vertex} and \\emph{weighted edge sampling} on kernel graphs, \\emph{simulating random walks} on kernel graphs, and \\emph{importance sampling} on matrices to Kernel Density Estimation and show that we can generate samples from these distributions in \\emph{sublinear} (in the support of the distribution) time. Our reductions are the central ingredient in each of our applications and we believe they may be of independent interest. We empirically demonstrate the efficacy of our algorithms on low-rank approximation (LRA) and spectral sparsification, where we observe a $\\textbf{9x}$ decrease in the number of kernel evaluations over baselines for LRA and a $\\textbf{41x}$ reduction in the graph size for spectral sparsification.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Theory (eg, control theory, learning theory, algorithmic game theory)", "paperhash": "bakshi|subquadratic_algorithms_for_kernel_matrices_via_kernel_density_estimation", "TL;DR": "We give a framework for using recently developed tools for kernel density estimation to solve downstream kernel problems in sub-quadratic time.", "pdf": "/pdf/93ea27d82a23d0825a29366c4dc3af3944c6d41a.pdf", "supplementary_material": "/attachment/a36c54baf74da5bbc443f56a7881b0e97742cab7.zip", "_bibtex": "@inproceedings{\nbakshi2023subquadratic,\ntitle={Subquadratic Algorithms for Kernel Matrices via Kernel Density Estimation},\nauthor={Ainesh Bakshi and Piotr Indyk and Praneeth Kacham and Sandeep Silwal and Samson Zhou},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=74A-FDAyiL}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279339797, "odate": 1664468100000, "details": {"replyCount": 17}}, {"id": "aMXD8gqsIiC", "original": "52FRKPgAbcT", "number": 4467, "cdate": 1663850326615, "mdate": null, "ddate": null, "tcdate": 1663850326615, "tmdate": 1677699462432, "tddate": null, "forum": "aMXD8gqsIiC", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "A Higher Precision Algorithm for Computing the $1$-Wasserstein Distance", "authorids": ["~Pankaj_K_Agarwal1", "~Sharath_Raghvendra1", "~Pouyan_Shirzadian1", "~Rachita_Sowle1"], "authors": ["Pankaj K Agarwal", "Sharath Raghvendra", "Pouyan Shirzadian", "Rachita Sowle"], "keywords": ["Wasserstein Distance", "Earth Movers Distance", "Bipartite Matching"], "abstract": "We consider the problem of computing the $1$-Wasserstein distance $\\mathcal{W}(\\mu,\\nu)$ between two $d$-dimensional discrete distributions $\\mu$ and $\\nu$ whose support lie within the unit hypercube. There are several algorithms that estimate $\\mathcal{W}(\\mu,\\nu)$ within an additive error of $\\varepsilon$. However, when $\\mathcal{W}(\\mu,\\nu)$ is small, the additive error $\\varepsilon$ dominates, leading to noisy results. Consider any additive approximation algorithm with execution time $T(n,\\varepsilon)$. We propose an algorithm that runs in $O(T(n,\\varepsilon/d) \\log n)$ time and boosts the accuracy of estimating $\\mathcal{W}(\\mu,\\nu)$ from $\\varepsilon$ to an expected additive error of $\\min\\{\\varepsilon, (d\\log_{\\sqrt{d}/\\varepsilon} n)\\mathcal{W}(\\mu,\\nu)\\}$. For the special case where every point in the support of $\\mu$ and $\\nu$ has a mass of $1/n$ (also called the Euclidean Bipartite Matching problem), we describe an algorithm to boost the accuracy of any additive approximation algorithm from $\\varepsilon$ to an expected additive error of $\\min\\{\\varepsilon, (d\\log\\log n)\\mathcal{W}(\\mu,\\nu)\\}$ in $O(T(n, \\varepsilon/d)\\log\\log n)$ time. ", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Optimization (eg, convex and non-convex optimization)", "paperhash": "agarwal|a_higher_precision_algorithm_for_computing_the_1wasserstein_distance", "pdf": "/pdf/469fe4170141940b63599e6d0d1e5b3a205619b5.pdf", "_bibtex": "@inproceedings{\nagarwal2023a,\ntitle={A Higher Precision Algorithm for Computing the \\$1\\$-Wasserstein Distance},\nauthor={Pankaj K Agarwal and Sharath Raghvendra and Pouyan Shirzadian and Rachita Sowle},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=aMXD8gqsIiC}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference", "supplementary_material": "/attachment/a035d3ee4078749c6ec50a99c405657dc4017989.zip"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279339181, "odate": 1664468100000, "details": {"replyCount": 12}}, {"id": "HPdxC1THU8T", "original": "Ldijpdnx1Z", "number": 4463, "cdate": 1663850326139, "mdate": null, "ddate": null, "tcdate": 1663850326139, "tmdate": 1697935389526, "tddate": null, "forum": "HPdxC1THU8T", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Revisiting adapters with adversarial training", "authorids": ["~Sylvestre-Alvise_Rebuffi1", "~Francesco_Croce1", "~Sven_Gowal2"], "authors": ["Sylvestre-Alvise Rebuffi", "Francesco Croce", "Sven Gowal"], "keywords": ["adapters", "adversarial", "robustness", "soup"], "abstract": "While adversarial training is generally used as a defense mechanism, recent works show that it can also act as a regularizer. By co-training a neural network on clean and adversarial inputs, it is possible to improve classification accuracy on the clean, non-adversarial inputs. We demonstrate that, contrary to previous findings, it is not necessary to separate batch statistics when co-training on clean and adversarial inputs, and that it is sufficient to use adapters with few domain-specific parameters for each type of input. We establish that using the classification token of a Vision Transformer (ViT) as an adapter is enough to match the classification performance of dual normalization layers, while using significantly less additional parameters. First, we improve upon the top-1 accuracy of a non-adversarially trained ViT-B16 model by +1.12% on ImageNet (reaching 83.76% top-1 accuracy). Second, and more importantly, we show that training with adapters enables model soups through linear combinations of the clean and adversarial tokens. These model soups, which we call adversarial model soups, allow us to trade-off between clean and robust accuracy without sacrificing efficiency. Finally, we show that we can easily adapt the resulting models in the face of distribution shifts. Our ViT-B16 obtains top-1 accuracies on ImageNet variants that are on average +4.00% better than those obtained with Masked Autoencoders.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Deep Learning and representational learning", "paperhash": "rebuffi|revisiting_adapters_with_adversarial_training", "pdf": "/pdf/c986093cab366dcc82865df98b5906e39dc7c493.pdf", "_bibtex": "@inproceedings{\nrebuffi2023revisiting,\ntitle={Revisiting adapters with adversarial training},\nauthor={Sylvestre-Alvise Rebuffi and Francesco Croce and Sven Gowal},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=HPdxC1THU8T}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 2 code implementations](https://www.catalyzex.com/paper/arxiv:2210.04886/code)"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279339130, "odate": 1664468100000, "details": {"replyCount": 12}}, {"id": "Mj7K4lglGyj", "original": "MvptJVeqJU", "number": 4378, "cdate": 1663850314732, "mdate": null, "ddate": null, "tcdate": 1663850314732, "tmdate": 1697935397811, "tddate": null, "forum": "Mj7K4lglGyj", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "UNICORN: A Unified Backdoor Trigger Inversion Framework", "authorids": ["~Zhenting_Wang1", "~Kai_Mei1", "~Juan_Zhai1", "~Shiqing_Ma2"], "authors": ["Zhenting Wang", "Kai Mei", "Juan Zhai", "Shiqing Ma"], "keywords": [], "abstract": "The backdoor attack, where the adversary uses inputs stamped with triggers (e.g., a patch) to activate pre-planted malicious behaviors, is a severe threat to Deep Neural Network (DNN) models. Trigger inversion is an effective way of identifying backdoor models and understanding embedded adversarial behaviors. A challenge of trigger inversion is that there are many ways of constructing the trigger. Existing methods cannot generalize to various types of triggers by making certain assumptions or attack-specific constraints. The fundamental reason is that existing work does not formally define the trigger and the inversion problem. This work formally defines and analyzes the trigger and the inversion problem. Then, it proposes a unified framework to invert backdoor triggers based on the formalization of triggers and the identified inner behaviors of backdoor models from our analysis. Our prototype UNICORN is general and effective in inverting backdoor triggers in DNNs. The code can be found at https://github.com/RU-System-Software-and-Security/UNICORN.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)", "paperhash": "wang|unicorn_a_unified_backdoor_trigger_inversion_framework", "pdf": "/pdf/edd35173abda536a0bd486d49c34c8ce04e56652.pdf", "_bibtex": "@inproceedings{\nwang2023unicorn,\ntitle={{UNICORN}: A Unified Backdoor Trigger Inversion Framework},\nauthor={Zhenting Wang and Kai Mei and Juan Zhai and Shiqing Ma},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=Mj7K4lglGyj}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2304.02786/code)"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279334181, "odate": 1664468100000, "details": {"replyCount": 14}}, {"id": "xkev3_np08z", "original": "hX247tF4D9", "number": 4321, "cdate": 1663850307315, "mdate": null, "ddate": null, "tcdate": 1663850307315, "tmdate": 1697935404555, "tddate": null, "forum": "xkev3_np08z", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "ExpressivE: A Spatio-Functional Embedding For Knowledge Graph Completion", "authorids": ["~Aleksandar_Pavlovi\u01071", "~Emanuel_Sallinger1"], "authors": ["Aleksandar Pavlovi\u0107", "Emanuel Sallinger"], "keywords": ["knowledge graph embedding", "knowledge graph completion", "composition", "hierarchy", "geometric interpretation"], "TL;DR": "ExpressivE: A fully expressive KGC model that captures a rich set of patterns with an intuitive geometric interpretation and state-of-the-art performance.", "abstract": "Knowledge graphs are inherently incomplete. Therefore substantial research has been directed toward knowledge graph completion (KGC), i.e., predicting missing triples from the information represented in the knowledge graph (KG). KG embedding models (KGEs) have yielded promising results for KGC, yet any current KGE is incapable of: (1) fully capturing vital inference patterns (e.g., composition), (2) capturing prominent patterns jointly (e.g., hierarchy and composition), and (3) providing an intuitive interpretation of captured patterns. In this work, we propose ExpressivE, a fully expressive spatio-functional KGE that solves all these challenges simultaneously. ExpressivE embeds pairs of entities as points and relations as hyper-parallelograms in the virtual triple space $\\mathbb{R}^{2d}$. This model design allows ExpressivE not only to capture a rich set of inference patterns jointly but additionally to display any supported inference pattern through the spatial relation of hyper-parallelograms, offering an intuitive and consistent geometric interpretation of ExpressivE embeddings and their captured patterns. Experimental results on standard KGC benchmarks reveal that ExpressivE is competitive with state-of-the-art KGEs and even significantly outperforms them on WN18RR.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Deep Learning and representational learning", "paperhash": "pavlovi|expressive_a_spatiofunctional_embedding_for_knowledge_graph_completion", "pdf": "/pdf/071ed2e450ebd00e88fdcae80a0773cfe4c7aec8.pdf", "_bibtex": "@inproceedings{\npavlovic2023expressive,\ntitle={ExpressivE: A Spatio-Functional Embedding For Knowledge Graph Completion},\nauthor={Aleksandar Pavlovi\u0107 and Emanuel Sallinger},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=xkev3_np08z}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2206.04192/code)"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279330913, "odate": 1664468100000, "details": {"replyCount": 14}}, {"id": "-k7Lvk0GpBl", "original": "qIlMa-LA-o", "number": 4314, "cdate": 1663850306493, "mdate": null, "ddate": null, "tcdate": 1663850306493, "tmdate": 1697935405350, "tddate": null, "forum": "-k7Lvk0GpBl", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Localized Randomized Smoothing for Collective Robustness Certification", "authorids": ["~Jan_Schuchardt1", "~Tom_Wollschl\u00e4ger1", "~Aleksandar_Bojchevski1", "~Stephan_G\u00fcnnemann1"], "authors": ["Jan Schuchardt", "Tom Wollschl\u00e4ger", "Aleksandar Bojchevski", "Stephan G\u00fcnnemann"], "keywords": ["Robustness", "Certification", "Verification", "Trustworthiness", "Graph neural networks"], "TL;DR": "We propose a novel collective robustness certificate based on randomized smoothing that uses different anisotropic smoothign distribution for the different outputs of a multi-output model.", "abstract": "Models for image segmentation, node classification and many other tasks map a single input to multiple labels. By perturbing this single shared input (e.g. the image) an adversary can manipulate several predictions (e.g. misclassify several pixels). Collective robustness certification is the task of provably bounding the number of robust predictions under this threat model. The only dedicated method that goes beyond certifying each output independently is limited to strictly local models, where each prediction is associated with a small receptive field. We propose a more general collective robustness certificate for all types of models. We further show that this approach is beneficial for the larger class of softly local models, where each output is dependent on the entire input but assigns different levels of importance to different input regions (e.g. based on their proximity in the image). The certificate is based on our novel localized randomized smoothing approach, where the random perturbation strength for different input regions is proportional to their importance for the outputs. Localized smoothing Pareto-dominates existing certificates on both image segmentation and node classification tasks, simultaneously offering higher accuracy and stronger certificates.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)", "paperhash": "schuchardt|localized_randomized_smoothing_for_collective_robustness_certification", "pdf": "/pdf/2c33160f207d6fbfbc89af90d5f1b6d98446dab7.pdf", "supplementary_material": "", "_bibtex": "@inproceedings{\nschuchardt2023localized,\ntitle={Localized Randomized Smoothing for Collective Robustness Certification},\nauthor={Jan Schuchardt and Tom Wollschl{\\\"a}ger and Aleksandar Bojchevski and Stephan G{\\\"u}nnemann},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=-k7Lvk0GpBl}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2210.16140/code)"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279330674, "odate": 1664468100000, "details": {"replyCount": 11}}, {"id": "cXMHQD-xQas", "original": "yjRj2OMhwmE", "number": 4288, "cdate": 1663850303610, "mdate": null, "ddate": null, "tcdate": 1663850303610, "tmdate": 1677682510261, "tddate": null, "forum": "cXMHQD-xQas", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Learning Probabilistic Topological Representations Using Discrete Morse Theory", "authorids": ["~Xiaoling_Hu1", "~Dimitris_Samaras3", "~Chao_Chen1"], "authors": ["Xiaoling Hu", "Dimitris Samaras", "Chao Chen"], "keywords": ["Topological Representation", "Discrete Morse Theory", "Persistent Homology"], "TL;DR": "We use discrete Morse theory and persistent homology to construct an one-parameter family of structures as the topological/structural representation space to perform inference tasks.", "abstract": "Accurate delineation of fine-scale structures is a very important yet challenging problem. Existing methods use topological information as an additional training loss, but are ultimately making pixel-wise predictions. In this paper, we propose a novel deep learning based method to learn topological/structural. We use discrete Morse theory and persistent homology to construct a one-parameter family of structures as the topological/structural representation space. Furthermore, we learn a probabilistic model that can perform inference tasks in such a topological/structural representation space. Our method generates true structures rather than pixel-maps, leading to better topological integrity in automatic segmentation tasks. It also facilitates semi-automatic interactive annotation/proofreading via the sampling of structures and structure-aware uncertainty.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Deep Learning and representational learning", "paperhash": "hu|learning_probabilistic_topological_representations_using_discrete_morse_theory", "pdf": "/pdf/b5fd2b7efdc313e009b70b9dfc6af81a7350ff8e.pdf", "_bibtex": "@inproceedings{\nhu2023learning,\ntitle={Learning Probabilistic Topological Representations Using Discrete Morse Theory},\nauthor={Xiaoling Hu and Dimitris Samaras and Chao Chen},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=cXMHQD-xQas}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279329086, "odate": 1664468100000, "details": {"replyCount": 18}}, {"id": "Vk-34OQ7rFo", "original": "W7fHBI1vKll", "number": 4247, "cdate": 1663850298698, "mdate": null, "ddate": null, "tcdate": 1663850298698, "tmdate": 1697935412668, "tddate": null, "forum": "Vk-34OQ7rFo", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Model-based Causal Bayesian Optimization", "authorids": ["~Scott_Sussex1", "~Anastasia_Makarova1", "~Andreas_Krause1"], "authors": ["Scott Sussex", "Anastasia Makarova", "Andreas Krause"], "keywords": ["causal inference", "bayesian optimization"], "TL;DR": "A principled algorithm for causal bayesian optimization.", "abstract": "How should we intervene on an unknown structural equation model to maximize a downstream variable of interest? This setting, also known as causal Bayesian optimization (CBO), has important applications in medicine, ecology, and manufacturing. Standard Bayesian optimization algorithms fail to effectively leverage the underlying causal structure. Existing CBO approaches assume noiseless measurements and do not come with guarantees. We propose the {\\em model-based causal Bayesian optimization algorithm (MCBO)} that learns a full system model instead of only modeling intervention-reward pairs. MCBO propagates epistemic uncertainty about the causal mechanisms through the graph and trades off exploration and exploitation via the optimism principle. We bound its cumulative regret, and obtain the first non-asymptotic bounds for CBO. Unlike in standard Bayesian optimization, our acquisition function cannot be evaluated in closed form, so we show how the reparameterization trick can be used to apply gradient-based optimizers. The resulting practical implementation of MCBO compares favorably with state-of-the-art approaches empirically.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)", "paperhash": "sussex|modelbased_causal_bayesian_optimization", "pdf": "/pdf/4d05ca91171a6278984e77236a0ead44b9d44e48.pdf", "_bibtex": "@inproceedings{\nsussex2023modelbased,\ntitle={Model-based Causal Bayesian Optimization},\nauthor={Scott Sussex and Anastasia Makarova and Andreas Krause},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=Vk-34OQ7rFo}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2211.10257/code)"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279326790, "odate": 1664468100000, "details": {"replyCount": 15}}, {"id": "KzkLAE49H9b", "original": "62S999xsRYH", "number": 4168, "cdate": 1663850289170, "mdate": null, "ddate": null, "tcdate": 1663850289170, "tmdate": 1677591489466, "tddate": null, "forum": "KzkLAE49H9b", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Training language models to summarize narratives improves brain alignment", "authorids": ["~Khai_Loong_Aw1", "~Mariya_Toneva1"], "authors": ["Khai Loong Aw", "Mariya Toneva"], "keywords": ["language", "nlp", "neuroscience", "fMRI", "interpretability"], "TL;DR": "We show that training language models for deeper narrative understanding (characters, emotions, relationships) results in richer representations that have improved alignment to human brain activity.", "abstract": "Building systems that achieve a deeper understanding of language is one of the central goals of natural language processing (NLP). Towards this goal, recent works have begun to train language models on narrative datasets which require extracting the most critical information by integrating across long contexts. However, it is still an open question whether these models are learning a deeper understanding of the text, or if the models are simply learning a heuristic to complete the task. This work investigates this further by turning to the one language processing system that truly understands complex language: the human brain. We show that training language models for deeper narrative understanding results in richer representations that have improved alignment to human brain activity. We further find that the improvements in brain alignment are larger for character names than for other discourse features, which indicates that these models are learning important narrative elements. Taken together, these results suggest that this type of training can indeed lead to deeper language understanding. These findings have consequences both for cognitive neuroscience by revealing some of the significant factors behind brain-NLP alignment, and for NLP by highlighting that understanding of long-range context can be improved beyond language modeling.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Neuroscience and Cognitive Science (e.g., neural coding, brain-computer interfaces)", "paperhash": "aw|training_language_models_to_summarize_narratives_improves_brain_alignment", "pdf": "/pdf/c67334d169d975ca4c1f56fc722f9eb680ebf5b9.pdf", "_bibtex": "@inproceedings{\naw2023training,\ntitle={Training language models to summarize narratives improves brain alignment},\nauthor={Khai Loong Aw and Mariya Toneva},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=KzkLAE49H9b}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279321603, "odate": 1664468100000, "details": {"replyCount": 12}}, {"id": "hhvkdRdWt1F", "original": "VcDmS49Hj4", "number": 4112, "cdate": 1663850282534, "mdate": null, "ddate": null, "tcdate": 1663850282534, "tmdate": 1676330854953, "tddate": null, "forum": "hhvkdRdWt1F", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Dual Algorithmic Reasoning", "authorids": ["~Danilo_Numeroso1", "~Davide_Bacciu1", "~Petar_Veli\u010dkovi\u01071"], "authors": ["Danilo Numeroso", "Davide Bacciu", "Petar Veli\u010dkovi\u0107"], "keywords": ["Algorithmic Reasoning", "Deep Learning for Graphs"], "TL;DR": "A neural algorithmic reasoning approach exploiting the duality principle", "abstract": "Neural Algorithmic Reasoning is an emerging area of machine learning which seeks to infuse algorithmic computation in neural networks, typically by training neural models to approximate steps of classical algorithms. In this context, much of the current work has focused on learning reachability and shortest path graph algorithms, showing that joint learning on similar algorithms is beneficial for generalisation. However, when targeting more complex problems, such \"similar\" algorithms become more difficult to find. Here, we propose to learn algorithms by exploiting duality of the underlying algorithmic problem. Many algorithms solve optimisation problems. We demonstrate that simultaneously learning the dual definition of these optimisation problems in algorithmic learning allows for better learning and qualitatively better solutions. Specifically, we exploit the max-flow min-cut theorem to simultaneously learn these two algorithms over synthetically generated graphs, demonstrating the effectiveness of the proposed approach. We then validate the real-world utility of our dual algorithmic reasoner by deploying it on a challenging brain vessel classification task, which likely depends on the vessels\u2019 flow properties. We demonstrate a clear performance gain when using our model within such a context, and empirically show that learning the max-flow and min-cut algorithms together is critical for achieving such a result.", "pdf": "/pdf/68736260b81982cea120df8994f055abbfe1ec5c.pdf", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Deep Learning and representational learning", "paperhash": "numeroso|dual_algorithmic_reasoning", "_bibtex": "@inproceedings{\nnumeroso2023dual,\ntitle={Dual Algorithmic Reasoning},\nauthor={Danilo Numeroso and Davide Bacciu and Petar Veli{\\v{c}}kovi{\\'c}},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=hhvkdRdWt1F}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279319012, "odate": 1664468100000, "details": {"replyCount": 10}}, {"id": "U_T8-5hClV", "original": "4hGAyXw-6s4", "number": 4084, "cdate": 1663850279644, "mdate": null, "ddate": null, "tcdate": 1663850279644, "tmdate": 1677731171831, "tddate": null, "forum": "U_T8-5hClV", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "A Primal-Dual Framework for Transformers and Neural Networks", "authorids": ["~Tan_Minh_Nguyen1", "~Tam_Minh_Nguyen1", "~Nhat_Ho1", "~Andrea_L._Bertozzi2", "~Richard_Baraniuk1", "~Stanley_Osher1"], "authors": ["Tan Minh Nguyen", "Tam Minh Nguyen", "Nhat Ho", "Andrea L. Bertozzi", "Richard Baraniuk", "Stanley Osher"], "keywords": ["attention", "transformer", "neural network", "support vector regression", "primal", "dual"], "TL;DR": "We show that the self-attention corresponds to the support vector expansion derived from a support vector regression problem and provide a principled framework for constructing new attention mechanisms from popular neural network layers.", "abstract": "Self-attention is key to the remarkable success of transformers in sequence modeling tasks including many applications in natural language processing and computer vision. Like neural network layers, these attention mechanisms are often developed by heuristics and experience. To provide a principled framework for constructing attention layers in transformers, we show that the self-attention corresponds to the support vector expansion derived from a support vector regression problem, whose primal formulation has the form of a neural network layer. Using our framework, we derive popular attention layers used in practice and propose two new attentions: 1) the Batch Normalized Attention (Attention-BN) derived from the batch normalization layer and 2)  the Attention with Scaled Head (Attention-SH) derived from using less training data to fit the SVR model. We empirically demonstrate the advantages of the Attention-BN and Attention-SH in reducing head redundancy, increasing the model's accuracy, and improving the model's efficiency in a variety of practical applications including image and time-series classification. ", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Deep Learning and representational learning", "paperhash": "nguyen|a_primaldual_framework_for_transformers_and_neural_networks", "pdf": "/pdf/ea60565f7f50777889e3d7d4e95d5feb7f8df5cb.pdf", "supplementary_material": "/attachment/c316c6b33063ec494b94495c89ba989c550ffd08.zip", "_bibtex": "@inproceedings{\nnguyen2023a,\ntitle={A Primal-Dual Framework for Transformers and Neural Networks},\nauthor={Tan Minh Nguyen and Tam Minh Nguyen and Nhat Ho and Andrea L. Bertozzi and Richard Baraniuk and Stanley Osher},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=U_T8-5hClV}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279317396, "odate": 1664468100000, "details": {"replyCount": 40}}, {"id": "c9lAOPvQHS", "original": "2vrjijuDiQ7", "number": 4052, "cdate": 1663850275636, "mdate": null, "ddate": null, "tcdate": 1663850275636, "tmdate": 1677573866995, "tddate": null, "forum": "c9lAOPvQHS", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Fisher-Legendre (FishLeg) optimization of deep neural networks", "authorids": ["~Jezabel_R_Garcia1", "~Federica_Freddi1", "~Stathi_Fotiadis1", "~Maolin_Li1", "~Sattar_Vakili1", "~Alberto_Bernacchia1", "~Guillaume_Hennequin1"], "authors": ["Jezabel R Garcia", "Federica Freddi", "Stathi Fotiadis", "Maolin Li", "Sattar Vakili", "Alberto Bernacchia", "Guillaume Hennequin"], "keywords": ["Second-order optimization", "Natural Gradient", "Deep Learning", "Meta-learning", "Fisher information", "Legendre-Fenchel duality"], "TL;DR": "We introduce a new approach to estimate the natural gradient via Legendre-Fenchel duality, provide a convergence proof, and show competitive performance on a number of benchmarks.", "abstract": "Incorporating second-order gradient information (curvature) into optimization can dramatically reduce the number of iterations required to train machine learning models. In natural gradient descent, such information comes from the Fisher information matrix which yields a number of desirable properties. As exact natural gradient updates are intractable for large models, successful methods such as KFAC and sequels approximate the Fisher in a structured form that can easily be inverted. However, this requires model/layer-specific tensor algebra and certain approximations that are often difficult to justify. Here, we use ideas from Legendre-Fenchel duality to learn a direct and efficiently evaluated model for the product of the inverse Fisher with any vector, in an online manner, leading to natural gradient steps that get progressively more accurate over time despite noisy gradients. We prove that the resulting \u201cFisher-Legendre\u201d (FishLeg) optimizer converges to a (global) minimum of non-convex functions satisfying the PL condition, which applies in particular to deep linear networks. On standard auto-encoder benchmarks, we show empirically that FishLeg outperforms standard first-order optimization methods, and performs on par with or better than other second-order methods, especially when using small batches. Thanks to its generality, we expect our approach to facilitate the handling of a variety  neural network layers in future work.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Deep Learning and representational learning", "paperhash": "garcia|fisherlegendre_fishleg_optimization_of_deep_neural_networks", "pdf": "/pdf/7d525e39743734fab17afec726da606418b81613.pdf", "_bibtex": "@inproceedings{\ngarcia2023fisherlegendre,\ntitle={Fisher-Legendre (FishLeg) optimization of deep neural networks},\nauthor={Jezabel R Garcia and Federica Freddi and Stathi Fotiadis and Maolin Li and Sattar Vakili and Alberto Bernacchia and Guillaume Hennequin},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=c9lAOPvQHS}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279315769, "odate": 1664468100000, "details": {"replyCount": 18}}, {"id": "0Vv4H4Ch0la", "original": "eNwLTFrgw4l", "number": 3994, "cdate": 1663850268761, "mdate": null, "ddate": null, "tcdate": 1663850268761, "tmdate": 1697935438129, "tddate": null, "forum": "0Vv4H4Ch0la", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Capturing the Motion of Every Joint: 3D Human Pose and Shape Estimation with Independent Tokens", "authorids": ["~Sen_Yang3", "~Wen_Heng2", "~Gang_Liu1", "~GUOZHONG_LUO2", "~Wankou_Yang1", "~Gang_YU2"], "authors": ["Sen Yang", "Wen Heng", "Gang Liu", "GUOZHONG LUO", "Wankou Yang", "Gang YU"], "keywords": ["3D human pose and shape estimation", "3d human reconstruction", "transformer", "independent tokens", "temporal modeling", "joint rotational motion"], "TL;DR": "We present a novel, effective and robust model with designed independent tokens to estimate 3D human pose and shape from monocular videos", "abstract": "In this paper we present a novel method to estimate 3D human pose and shape from monocular videos. This task requires directly recovering pixel-alignment 3D human pose and body shape from monocular images or videos, which is challenging due to its inherent ambiguity. To improve precision, existing methods highly rely on the initialized mean pose and shape as prior estimates and parameter regression with an iterative error feedback manner. In addition, video-based approaches model the overall change over the image-level features to temporally enhance the single-frame feature, but fail to capture the rotational motion at the joint level, and cannot guarantee local temporal consistency. To address these issues, we propose a novel Transformer-based model with a design of independent tokens. First, we introduce three types of tokens independent of the image feature: \\textit{joint rotation tokens, shape token, and camera token}. \nBy progressively interacting with image features through Transformer layers, these tokens learn to encode the prior knowledge of human 3D joint rotations, body shape, and position information from large-scale data, and are updated to estimate SMPL parameters conditioned on a given image. Second, benefiting from the proposed token-based representation, we further use a temporal model to focus on capturing the rotational temporal information of each joint, which is empirically conducive to preventing large jitters in local parts. Despite being conceptually simple, the proposed method attains superior performances on the 3DPW and Human3.6M datasets. Using ResNet-50 and Transformer architectures, it obtains 42.0 mm error on the PA-MPJPE metric of the challenging 3DPW, outperforming state-of-the-art counterparts by a large margin. Code will be publicly available\\footnote{\\url{https://github.com/yangsenius/INT_HMR_Model}}.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Deep Learning and representational learning", "paperhash": "yang|capturing_the_motion_of_every_joint_3d_human_pose_and_shape_estimation_with_independent_tokens", "pdf": "/pdf/ac15036f14fc083ad641661d544085d5eaefef81.pdf", "supplementary_material": "/attachment/1d15422a02dd78bc59ea3be5022ed237cd8f84fc.zip", "_bibtex": "@inproceedings{\nyang2023capturing,\ntitle={Capturing the Motion of Every Joint: 3D Human Pose and Shape Estimation with Independent Tokens},\nauthor={Sen Yang and Wen Heng and Gang Liu and GUOZHONG LUO and Wankou Yang and Gang YU},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=0Vv4H4Ch0la}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2303.00298/code)"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279312600, "odate": 1664468100000, "details": {"replyCount": 12}}, {"id": "lJdOlWg8td", "original": "GujjV-E7YbM", "number": 3940, "cdate": 1663850262289, "mdate": null, "ddate": null, "tcdate": 1663850262289, "tmdate": 1677748149529, "tddate": null, "forum": "lJdOlWg8td", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Efficient recurrent architectures through activity sparsity and sparse back-propagation through time", "authorids": ["~Anand_Subramoney2", "~Khaleelulla_Khan_Nazeer1", "~Mark_Sch\u00f6ne1", "~Christian_Mayr1", "~David_Kappel2"], "authors": ["Anand Subramoney", "Khaleelulla Khan Nazeer", "Mark Sch\u00f6ne", "Christian Mayr", "David Kappel"], "keywords": ["RNN", "GRU", "recurrent network", "language modeling", "dvs", "gesture recognition", "activity sparsity", "efficiency"], "abstract": "Recurrent neural networks (RNNs) are well suited for solving sequence tasks in resource-constrained systems due to their expressivity and  low computational requirements. However, there is still a need to bridge the gap between what RNNs are capable of in terms of efficiency and performance and real-world application requirements. The memory and computational requirements arising from propagating the activations of all the neurons at every time step to every connected neuron, together with the sequential dependence of activations, contribute to the inefficiency of training and using RNNs. We propose a solution inspired by biological neuron dynamics that makes the communication between RNN units sparse and discrete. This makes the backward pass with backpropagation through time (BPTT) computationally sparse and efficient as well. We base our model on the gated recurrent unit (GRU), extending it with units that emit discrete events for communication triggered by a threshold so that no information is communicated to other units in the absence of events.  We show theoretically that the communication between units, and hence the computation required for both the forward and backward passes, scales with the number of events in the network. Our model achieves efficiency without compromising task performance, demonstrating competitive performance compared to state-of-the-art recurrent network models in real-world tasks, including language modeling. The dynamic activity sparsity mechanism also makes our model well suited for novel energy-efficient neuromorphic hardware. Code is available at https://github.com/KhaleelKhan/EvNN/.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Deep Learning and representational learning", "paperhash": "subramoney|efficient_recurrent_architectures_through_activity_sparsity_and_sparse_backpropagation_through_time", "TL;DR": "We add a activity sparsity mechanism to the GRU using a thresholding function, which makes both the forward and backward passes computationally sparse. This model achieves competitive performance on various benchmarks including language modeling.", "pdf": "/pdf/388663b8b91354ae6d68fc7eb3580a2b5f3431fa.pdf", "supplementary_material": "/attachment/75240e39fd4c4ff5229d358520d6122f8b00a590.zip", "_bibtex": "@inproceedings{\nsubramoney2023efficient,\ntitle={Efficient recurrent architectures through activity sparsity and sparse back-propagation through time},\nauthor={Anand Subramoney and Khaleelulla Khan Nazeer and Mark Sch{\\\"o}ne and Christian Mayr and David Kappel},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=lJdOlWg8td}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279309351, "odate": 1664468100000, "details": {"replyCount": 11}}, {"id": "XVjTT1nw5z", "original": "80IrrDsk-zu", "number": 3926, "cdate": 1663850260632, "mdate": null, "ddate": null, "tcdate": 1663850260632, "tmdate": 1677727426688, "tddate": null, "forum": "XVjTT1nw5z", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Flow Straight and Fast: Learning to Generate and Transfer Data with Rectified Flow", "authorids": ["~Xingchao_Liu1", "~Chengyue_Gong1", "~qiang_liu4"], "authors": ["Xingchao Liu", "Chengyue Gong", "qiang liu"], "keywords": [], "abstract": "We present rectified flow, a simple approach to learning (neural) ordinary differential equation (ODE) models to transport between two empirically observed distributions $\\pi_0$ and $\\pi_1$, hence providing a unified solution to generative modeling and domain transfer, among various other tasks involving distribution transport. The idea of rectified flow is to learn the ODE to follow the straight paths connecting the points drawn from $\\pi_0$ and $\\pi_1$ as much as possible. This is  achieved by solving a straightforward nonlinear least squares optimization problem, which can be easily scaled to large models without introducing extra parameters beyond standard supervised learning. The straight paths are the shortest paths between two points, and can be simulated exactly without time discretization and hence yield computationally efficient models. We show that, by learning a rectified flow from data, we effectively turn an arbitrary coupling of $\\pi_0$ and $\\pi_1$ to a  new deterministic coupling with provably non-increasing convex transport costs. In addition, with a ``reflow\" procedure that iteratively learns a new rectified flow from the data bootstrapped from the previous one, we obtain a sequence of flows with increasingly straight paths, which can be simulated accurately with coarse time discretization in the inference phase. In empirical studies, we show that rectified flow performs superbly on image generation, image-to-image translation, and domain adaptation. In particular, on image generation and translation, our method yields nearly straight flows that give high quality results even with \\emph{a single Euler discretization step}. Code is available at \\url{https://github.com/gnobitab/RectifiedFlow}.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Generative models", "paperhash": "liu|flow_straight_and_fast_learning_to_generate_and_transfer_data_with_rectified_flow", "pdf": "/pdf/910c5efa5739a5d2bef83d432da87d3096712ebe.pdf", "_bibtex": "@inproceedings{\nliu2023flow,\ntitle={Flow Straight and Fast: Learning to Generate and Transfer Data with Rectified Flow},\nauthor={Xingchao Liu and Chengyue Gong and qiang liu},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=XVjTT1nw5z}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference", "supplementary_material": "/attachment/cd1de2fa3adfa1430e27c4138c4e689d2b5d7b27.zip"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279308621, "odate": 1664468100000, "details": {"replyCount": 13}}, {"id": "4t9q35BxGr", "original": "Klttd5gnRud", "number": 3925, "cdate": 1663850260513, "mdate": null, "ddate": null, "tcdate": 1663850260513, "tmdate": 1676805699112, "tddate": null, "forum": "4t9q35BxGr", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Inequality phenomenon in $l_{\\infty}$-adversarial training, and its unrealized threats", "authorids": ["~Ranjie_Duan1", "~YueFeng_Chen1", "~Yao_Zhu2", "~Xiaojun_Jia1", "~Rong_Zhang2", "~Hui_Xue'1"], "authors": ["Ranjie Duan", "YueFeng Chen", "Yao Zhu", "Xiaojun Jia", "Rong Zhang", "Hui Xue'"], "keywords": ["Adversarial training", "Adversarial robustness", "Adversarial feature represenation"], "abstract": "The appearance of adversarial examples raises attention from both academia and industry. Along with the attack-defense arms race, adversarial training is the most effective against adversarial examples.\nHowever, we find inequality phenomena occur during the $l_{\\infty}$-adversarial training, that few features dominate the prediction made by the adversarially trained model. We systematically evaluate such inequality phenomena by extensive experiments and find such phenomena become more obvious when performing adversarial training with increasing adversarial strength (evaluated by $\\epsilon$). We hypothesize such inequality phenomena make $l_{\\infty}$-adversarially trained model less reliable than the standard trained model when few ``important features\" are influenced. To validate our hypothesis, we proposed two simple attacks that either perturb or replace important features with noise or occlusion. Experiments show that $l_{\\infty}$-adversarially trained model can be easily attacked when the few important features are influenced. \nOur work shed light on the limitation of the practicality of $l_{\\infty}$-adversarial training.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)", "paperhash": "duan|inequality_phenomenon_in_l_\\inftyadversarial_training_and_its_unrealized_threats", "TL;DR": "We find an intriguing phenomena of $l_{\\infty}$ adversarial training, and this phenomena brings unrealized threats to adversarially trained model.", "pdf": "/pdf/7ab5da22ccb9ac23b9d16fdd5e20f7d2d5da1b17.pdf", "_bibtex": "@inproceedings{\nduan2023inequality,\ntitle={Inequality phenomenon in \\$l\\_\\{{\\textbackslash}infty\\}\\$-adversarial training, and its unrealized threats},\nauthor={Ranjie Duan and YueFeng Chen and Yao Zhu and Xiaojun Jia and Rong Zhang and Hui Xue'},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=4t9q35BxGr}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279308597, "odate": 1664468100000, "details": {"replyCount": 18}}, {"id": "WH1yCa0TbB", "original": "ScvgVPciPt", "number": 3918, "cdate": 1663850259599, "mdate": null, "ddate": null, "tcdate": 1663850259599, "tmdate": 1677733302161, "tddate": null, "forum": "WH1yCa0TbB", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Learning Diffusion Bridges on Constrained Domains", "authorids": ["~Xingchao_Liu1", "~Lemeng_Wu1", "~Mao_Ye11", "~qiang_liu4"], "authors": ["Xingchao Liu", "Lemeng Wu", "Mao Ye", "qiang liu"], "keywords": [], "abstract": "Diffusion models have achieved promising results on generative learning recently. However, because diffusion processes are most naturally applied  on the unconstrained Euclidean space $\\mathrm{R}^d$, key challenges arise for developing diffusion based models for learning data on constrained and structured domains. We present a simple and unified framework to achieve this that can be easily adopted to various types of domains, including product spaces of any type (be it bounded/unbounded, continuous/discrete, categorical/ordinal, or  their mix). In our model, the diffusion process is driven by a drift force that is a sum of two terms: one singular force designed by $Doob's~ h$-$transform$ that ensures all outcomes of the process to belong to the desirable domain, and one non-singular neural force field that is trained to make sure the outcome follows the data distribution statistically. Experiments show that our methods perform superbly on generating tabular data, images, semantic segments and 3D point clouds. ", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Generative models", "paperhash": "liu|learning_diffusion_bridges_on_constrained_domains", "pdf": "/pdf/8cfc259b7bd52dd062abbfdf800fc63779766d37.pdf", "_bibtex": "@inproceedings{\nliu2023learning,\ntitle={Learning Diffusion Bridges on Constrained Domains},\nauthor={Xingchao Liu and Lemeng Wu and Mao Ye and qiang liu},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=WH1yCa0TbB}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference", "supplementary_material": "/attachment/ae11693801d063315e137ac9c603a792b7412c96.zip"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279307959, "odate": 1664468100000, "details": {"replyCount": 27}}, {"id": "1_jFneF07YC", "original": "qTEYbTANlmV", "number": 3900, "cdate": 1663850257394, "mdate": null, "ddate": null, "tcdate": 1663850257394, "tmdate": 1677658740396, "tddate": null, "forum": "1_jFneF07YC", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Unsupervised Semantic Segmentation with Self-supervised Object-centric Representations", "authorids": ["~Andrii_Zadaianchuk1", "matkle@amazon.de", "~Yi_Zhu1", "~Francesco_Locatello1", "~Thomas_Brox1"], "authors": ["Andrii Zadaianchuk", "Matthaeus Kleindessner", "Yi Zhu", "Francesco Locatello", "Thomas Brox"], "keywords": ["unsupervised semantic segmentation", "object segmentation", "object-centric learning"], "TL;DR": "Strong and simple baseline for unsupervised segmentation methods obtained by leveraging and combining object-centric priors.", "abstract": "In this paper, we show that recent advances in self-supervised representation learning enable unsupervised object discovery and semantic segmentation with a performance that matches the state of the field on supervised semantic segmentation 10 years ago. We propose a methodology based on unsupervised saliency masks and self-supervised feature clustering to kickstart object discovery followed by training a semantic segmentation network on pseudo-labels to bootstrap the system on images with multiple objects. We show that while being conceptually simple our proposed baseline is surprisingly strong. We present results on PASCAL VOC that go far beyond the current state of the art (50.0 mIoU), and we report for the first time results on MS COCO for the whole set of 81 classes: our method discovers 34 categories with more than 20% IoU, while obtaining an average IoU of 19.6 for all 81 categories.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Unsupervised and Self-supervised learning", "paperhash": "zadaianchuk|unsupervised_semantic_segmentation_with_selfsupervised_objectcentric_representations", "pdf": "/pdf/7b1fa6ddb8a0a13864f94d60cd015ca2274147b9.pdf", "_bibtex": "@inproceedings{\nzadaianchuk2023unsupervised,\ntitle={Unsupervised Semantic Segmentation with Self-supervised Object-centric Representations},\nauthor={Andrii Zadaianchuk and Matthaeus Kleindessner and Yi Zhu and Francesco Locatello and Thomas Brox},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=1_jFneF07YC}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279307157, "odate": 1664468100000, "details": {"replyCount": 11}}, {"id": "f0a_dWEYg-Td", "original": "x3N842Anf6t", "number": 3897, "cdate": 1663850257012, "mdate": null, "ddate": null, "tcdate": 1663850257012, "tmdate": 1697935448895, "tddate": null, "forum": "f0a_dWEYg-Td", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Indiscriminate Poisoning Attacks on Unsupervised Contrastive Learning", "authorids": ["~Hao_He1", "~Kaiwen_Zha3", "~Dina_Katabi1"], "authors": ["Hao He", "Kaiwen Zha", "Dina Katabi"], "keywords": ["data poisoning", "contrastive learning"], "abstract": "Indiscriminate data poisoning attacks are quite effective against supervised learning. However, not much is known about their impact on unsupervised contrastive learning (CL). This paper is the first to consider indiscriminate poisoning attacks of contrastive learning. We propose Contrastive Poisoning (CP), the first effective such attack on CL. We empirically show that Contrastive Poisoning, not only drastically reduces the performance of CL algorithms, but also attacks supervised learning models, making it the most generalizable indiscriminate poisoning attack. We also show that CL algorithms with a momentum encoder are more robust to indiscriminate poisoning, and propose a new countermeasure based on matrix completion. Code is available at: https://github.com/kaiwenzha/contrastive-poisoning.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "General Machine Learning (ie none of the above)", "paperhash": "he|indiscriminate_poisoning_attacks_on_unsupervised_contrastive_learning", "pdf": "/pdf/06017158fae111af5eb2c5e44b5b2c0c9a8d4526.pdf", "_bibtex": "@inproceedings{\nhe2023indiscriminate,\ntitle={Indiscriminate Poisoning Attacks on Unsupervised Contrastive Learning},\nauthor={Hao He and Kaiwen Zha and Dina Katabi},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=f0a_dWEYg-Td}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2202.11202/code)"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279306989, "odate": 1664468100000, "details": {"replyCount": 12}}, {"id": "lKOfilXucGB", "original": "hgdZvtpskU2", "number": 3896, "cdate": 1663850256890, "mdate": null, "ddate": null, "tcdate": 1663850256890, "tmdate": 1677578089854, "tddate": null, "forum": "lKOfilXucGB", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Decompositional Generation Process for Instance-Dependent Partial Label Learning", "authorids": ["~Congyu_Qiao3", "~Ning_Xu5", "~Xin_Geng1"], "authors": ["Congyu Qiao", "Ning Xu", "Xin Geng"], "keywords": ["partial label learning", "weakly supervised learning", "decompositional generation process"], "TL;DR": " We consider instance-dependent PLL and assume that the generation process of the candidate labels could decompose into two sequential parts.", "abstract": "Partial label learning (PLL) is a typical weakly supervised learning problem, where each training example is associated with a set of candidate labels among which only one is true. Most existing PLL approaches assume that the incorrect labels in each training example are randomly picked as the candidate labels and model the generation process of the candidate labels in a simple way.  However, these approaches usually do not perform as well as expected due to the fact that the generation process of the candidate labels is always instance-dependent. Therefore, it deserves to be modeled in a refined way.  In this paper, we consider instance-dependent PLL and assume that the generation process of the candidate labels could decompose into two sequential parts, where the correct label emerges first in the mind of the annotator but then the incorrect labels related to the feature are also selected with the correct label as candidate labels due to uncertainty of labeling. Motivated by this consideration, we propose a novel PLL method that performs Maximum A Posterior(MAP) based on an explicitly modeled generation process of candidate labels via decomposed probability distribution models. Extensive experiments on manually corrupted benchmark datasets and real-world datasets validate the effectiveness of the proposed method.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Deep Learning and representational learning", "paperhash": "qiao|decompositional_generation_process_for_instancedependent_partial_label_learning", "pdf": "/pdf/e5ce2d07910993cab2778e9cb83312b7e51599e4.pdf", "_bibtex": "@inproceedings{\nqiao2023decompositional,\ntitle={Decompositional Generation Process for Instance-Dependent Partial Label Learning},\nauthor={Congyu Qiao and Ning Xu and Xin Geng},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=lKOfilXucGB}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279306875, "odate": 1664468100000, "details": {"replyCount": 12}}, {"id": "UKr0MwZM6fL", "original": "_YVdiPUgmn1", "number": 3890, "cdate": 1663850256165, "mdate": null, "ddate": null, "tcdate": 1663850256165, "tmdate": 1697935450047, "tddate": null, "forum": "UKr0MwZM6fL", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Building a Subspace of Policies for Scalable Continual Learning", "authorids": ["~Jean-Baptiste_Gaya1", "~Thang_Doan1", "~Lucas_Caccia1", "~Laure_Soulier1", "~Ludovic_Denoyer1", "~Roberta_Raileanu2"], "authors": ["Jean-Baptiste Gaya", "Thang Doan", "Lucas Caccia", "Laure Soulier", "Ludovic Denoyer", "Roberta Raileanu"], "keywords": ["continual learning", "deep reinforcement learning"], "TL;DR": "We introduce a continual reinforcement learning method that incrementally builds a subspace of policies and adaptively prune it to preserve a good trade-off between model size and performance.", "abstract": "The ability to continuously acquire new knowledge and skills is crucial for autonomous agents. Existing methods are typically based on either fixed-size models that struggle to learn a large number of diverse behaviors, or growing-size models that scale poorly with the number of tasks. In this work, we aim to strike a better balance between scalability and performance by designing a method whose size grows adaptively depending on the task sequence. We introduce Continual Subspace of Policies (CSP), a new approach that incrementally builds a subspace of policies for training a reinforcement learning agent on a sequence of tasks. The subspace's high expressivity allows CSP to perform well for many different tasks while growing more slowly than the number of tasks. Our method does not suffer from forgetting and also displays positive transfer to new tasks. CSP outperforms a number of popular baselines on a wide range of scenarios from two challenging domains, Brax (locomotion) and Continual World (robotic manipulation). Interactive visualizations of the subspace can be found at https://share.streamlit.io/continual-subspace/policies/main.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)", "paperhash": "gaya|building_a_subspace_of_policies_for_scalable_continual_learning", "pdf": "/pdf/ab8b649c5427a1281f061c035a6c4c3a82699f57.pdf", "_bibtex": "@inproceedings{\ngaya2023building,\ntitle={Building a Subspace of Policies for Scalable Continual Learning},\nauthor={Jean-Baptiste Gaya and Thang Doan and Lucas Caccia and Laure Soulier and Ludovic Denoyer and Roberta Raileanu},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=UKr0MwZM6fL}\n}", "supplementary_material": "/attachment/023ad3c92bc06af97f46ebccf7b86c4510b169ac.zip", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 2 code implementations](https://www.catalyzex.com/paper/arxiv:2211.10445/code)"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279306336, "odate": 1664468100000, "details": {"replyCount": 20}}, {"id": "KGV-GBh8fb", "original": "rqZs0Uxzbmi", "number": 3883, "cdate": 1663850255336, "mdate": null, "ddate": null, "tcdate": 1663850255336, "tmdate": 1681400701696, "tddate": null, "forum": "KGV-GBh8fb", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Not All Tasks Are Born Equal: Understanding Zero-Shot Generalization", "authorids": ["~Jing_Zhou4", "~Zongyu_Lin1", "~Yanan_Zheng1", "~Jian_Li2", "~Zhilin_Yang2"], "authors": ["Jing Zhou", "Zongyu Lin", "Yanan Zheng", "Jian Li", "Zhilin Yang"], "keywords": ["Zero-Shot Learning", "Multi-Task Learning", "Transfer Learning"], "abstract": "Recent work has achieved remarkable zero-shot performance with multi-task prompted pretraining, but little has been understood. For the first time, we show that training on a small number of key tasks beats using all the training tasks, while removing these key tasks substantially hurts performance. We also find that these key tasks are mostly question answering (QA) tasks. These novel findings combined deepen our understanding about zero-shot generalization\u2014training on certain tasks such as QA encodes general knowledge transferable to a wide range of tasks. In addition, to automate this procedure, we devise a method that (1) identifies key training tasks without observing the test tasks by examining the pairwise generalization results and (2) resamples training tasks for better data distribution. Empirically, our approach achieves improved results across various model scales and tasks.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Deep Learning and representational learning", "paperhash": "zhou|not_all_tasks_are_born_equal_understanding_zeroshot_generalization", "pdf": "/pdf/1919d0fcb91288c02556462ba37d25845db2452f.pdf", "_bibtex": "@inproceedings{\nzhou2023not,\ntitle={Not All Tasks Are Born Equal: Understanding Zero-Shot Generalization},\nauthor={Jing Zhou and Zongyu Lin and Yanan Zheng and Jian Li and Zhilin Yang},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=KGV-GBh8fb}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279306280, "odate": 1664468100000, "details": {"replyCount": 11}}, {"id": "RQY2AXFMRiu", "original": "Eg0HwQlqteZ", "number": 3852, "cdate": 1663850251591, "mdate": null, "ddate": null, "tcdate": 1663850251591, "tmdate": 1677727859184, "tddate": null, "forum": "RQY2AXFMRiu", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Solving Constrained Variational Inequalities via a First-order Interior Point-based Method", "authorids": ["~Tong_Yang4", "~Michael_Jordan1", "~Tatjana_Chavdarova2"], "authors": ["Tong Yang", "Michael Jordan", "Tatjana Chavdarova"], "keywords": ["constrained variational inequality", "interior point", "admm"], "TL;DR": "We derive a first-order method for solving constrained variational inequality problem when given general constraints, by combining interior-point methods and ADMM.", "abstract": "We develop an interior-point approach to solve constrained variational inequality (cVI) problems. Inspired by the efficacy of the alternating direction method of multipliers (ADMM) method in the single-objective context, we generalize ADMM to derive a first-order method for cVIs, that we refer to as ADMM-based interior-point method for constrained VIs (ACVI). We provide convergence guarantees for ACVI in two general classes of problems: (i) when the operator is $\\xi$-monotone, and (ii) when it is monotone, some constraints are active and the game is not purely rotational. When the operator is in addition L-Lipschitz for the latter case, we match known lower bounds on rates for the gap function of $\\mathcal{O}(1/\\sqrt{K})$ and $\\mathcal{O}(1/K)$ for the last and average iterate, respectively. To the best of our knowledge, this is the first presentation of a first-order interior-point method for the general cVI problem that has a global convergence guarantee. Moreover, unlike previous work in this setting, ACVI provides a means to solve cVIs when the constraints are nontrivial. Empirical analyses demonstrate clear advantages of ACVI over common first-order methods. In particular, (i) cyclical behavior is notably reduced as our methods approach the solution from the analytic center, and (ii) unlike projection-based methods that zigzag when near a constraint, ACVI efficiently handles the constraints.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Optimization (eg, convex and non-convex optimization)", "paperhash": "yang|solving_constrained_variational_inequalities_via_a_firstorder_interior_pointbased_method", "pdf": "/pdf/7210cea0f1893a45604d73d4a566c6e439c1046f.pdf", "_bibtex": "@inproceedings{\nyang2023solving,\ntitle={Solving Constrained Variational Inequalities via a First-order Interior Point-based Method},\nauthor={Tong Yang and Michael Jordan and Tatjana Chavdarova},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=RQY2AXFMRiu}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279304562, "odate": 1664468100000, "details": {"replyCount": 12}}, {"id": "K96AogLDT2K", "original": "M-13s5IrYdJ", "number": 3849, "cdate": 1663850251236, "mdate": null, "ddate": null, "tcdate": 1663850251236, "tmdate": 1697935453782, "tddate": null, "forum": "K96AogLDT2K", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Symmetric Pruning in Quantum Neural Networks", "authorids": ["~Xinbiao_Wang1", "~Junyu_Liu4", "~Tongliang_Liu1", "~Yong_Luo2", "~Yuxuan_Du2", "~Dacheng_Tao1"], "authors": ["Xinbiao Wang", "Junyu Liu", "Tongliang Liu", "Yong Luo", "Yuxuan Du", "Dacheng Tao"], "keywords": ["quantum neural networks", "symmetry", "pruning", "quantum neural tangent kernel", "effective dimension"], "TL;DR": "We prove how the symmetry enhances the training performance of QNNs and then devise an efficient symmetric pruning scheme to distill a symmetric ansatz from an over-parameterized and asymmetric ansatz.", "abstract": "Many fundamental properties of a quantum system are captured by its Hamiltonian and ground state. Despite the significance,  ground states preparation (GSP) is classically intractable for large-scale Hamiltonians. Quantum neural networks (QNNs), which exert the power of modern quantum machines, have emerged as a leading protocol to conquer this issue. As such, the performance enhancement of QNNs becomes the core in GSP. Empirical evidence showed that QNNs with handcraft symmetric ans\\\"atze generally experience better trainability than those with asymmetric ans\\\"atze, while theoretical explanations remain vague. To fill this knowledge gap, here we propose the effective quantum neural tangent kernel (EQNTK) and connect this concept with over-parameterization theory to quantify the convergence of QNNs towards the global optima. We uncover that the advance of symmetric ans\\\"atze attributes to their large EQNTK value with low effective dimension, which requests few parameters and quantum circuit depth to reach the over-parameterization regime permitting a benign loss landscape and fast convergence. Guided by EQNTK, we further devise a symmetric pruning (SP) scheme to automatically tailor a symmetric ansatz from an over-parameterized and asymmetric one to greatly improve the performance of QNNs when the explicit symmetry information of Hamiltonian is unavailable. Extensive numerical simulations are conducted to validate the analytical results of EQNTK and the effectiveness of SP. ", "pdf": "/pdf/985ba693c6dc7d26909831bb66906ae4f3810a91.pdf", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "General Machine Learning (ie none of the above)", "paperhash": "wang|symmetric_pruning_in_quantum_neural_networks", "_bibtex": "@inproceedings{\nwang2023symmetric,\ntitle={Symmetric Pruning in Quantum Neural Networks},\nauthor={Xinbiao Wang and Junyu Liu and Tongliang Liu and Yong Luo and Yuxuan Du and Dacheng Tao},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=K96AogLDT2K}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2208.14057/code)"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279304370, "odate": 1664468100000, "details": {"replyCount": 8}}, {"id": "vuD2xEtxZcj", "original": "EwaFAnLCHM7", "number": 3846, "cdate": 1663850250887, "mdate": null, "ddate": null, "tcdate": 1663850250887, "tmdate": 1677060803158, "tddate": null, "forum": "vuD2xEtxZcj", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Minimum Variance Unbiased N:M Sparsity for the Neural Gradients", "authorids": ["~Brian_Chmiel1", "~Itay_Hubara1", "~Ron_Banner1", "~Daniel_Soudry1"], "authors": ["Brian Chmiel", "Itay Hubara", "Ron Banner", "Daniel Soudry"], "keywords": ["pruning", "compression", "structured sparsity", "acceleration"], "TL;DR": "A method to use structured N:M sparsity on all training GEMM operations", "abstract": "In deep learning, fine-grained N:M sparsity reduces the data footprint and bandwidth of a General Matrix multiply (GEMM) up to x2,  and doubles throughput by skipping computation of zero values. So far, it was mainly only used to prune weights to accelerate the forward and backward phases. We examine how this method can be used also for the neural gradients (i.e. loss gradients with respect to the intermediate neural layer outputs). To this end, we first establish a tensor-level optimality criteria. Previous works aimed to minimize the mean-square-error (MSE) of each pruned block. We show that while minimization of the MSE works fine for pruning the weights and activations, it catastrophically fails for the neural gradients. Instead, we show that accurate pruning of the neural gradients requires an unbiased minimum-variance pruning mask. We design such specialized masks, and find that in most cases, 1:2 sparsity is sufficient for training, and 2:4 sparsity is usually enough when this is not the case. Further, we suggest combining several such methods together in order to potentially speed up training even more. A reference implementation is supplied in the supplementary material.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Deep Learning and representational learning", "paperhash": "chmiel|minimum_variance_unbiased_nm_sparsity_for_the_neural_gradients", "pdf": "/pdf/b7b54047fdaf97f505713a0b6675abc7e120c460.pdf", "supplementary_material": "/attachment/1dfe7315d70cd8dfe7def990d003e7a63c0804c7.zip", "_bibtex": "@inproceedings{\nchmiel2023minimum,\ntitle={Minimum Variance Unbiased N:M Sparsity for the Neural Gradients},\nauthor={Brian Chmiel and Itay Hubara and Ron Banner and Daniel Soudry},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=vuD2xEtxZcj}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279303995, "odate": 1664468100000, "details": {"replyCount": 8}}, {"id": "a2jNdqE2102", "original": "SuK3BOueK7b", "number": 3834, "cdate": 1663850249455, "mdate": null, "ddate": null, "tcdate": 1663850249455, "tmdate": 1676927306933, "tddate": null, "forum": "a2jNdqE2102", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Knowledge-in-Context: Towards Knowledgeable Semi-Parametric Language Models", "authorids": ["~Xiaoman_Pan1", "~Wenlin_Yao1", "~Hongming_Zhang2", "~Dian_Yu3", "~Dong_Yu2", "~Jianshu_Chen1"], "authors": ["Xiaoman Pan", "Wenlin Yao", "Hongming Zhang", "Dian Yu", "Dong Yu", "Jianshu Chen"], "keywords": ["Semi-parametric language model", "text-to-text model", "mixture-of-experts", "natural language understanding"], "TL;DR": "We develop a novel knowledge-rich semi-parametric model, KiC, that is able to achieve superior zeros-hot performance on unseen task with a much smaller model size.", "abstract": "Fully-parametric language models generally require a huge number of model parameters to store the necessary knowledge for solving multiple natural language tasks in zero/few-shot settings. In addition, it is hard to adapt to the evolving world knowledge without the costly model re-training. In this paper, we develop a novel semi-parametric language model architecture, Knowledge-in-Context (KiC), which empowers a parametric text-to-text language model with a knowledge-rich external memory. Specifically, the external memory contains six different types of knowledge:  entity,  dictionary, commonsense, event, script, and causality knowledge. For each input instance, the KiC model adaptively selects a knowledge type and retrieves the most helpful pieces of knowledge. The input instance along with its knowledge augmentation is fed into a text-to-text model (e.g., T5) to generate the output answer, where both the input and the output are in natural language forms after prompting. Interestingly, we find that KiC can be identified as a special mixture-of-experts (MoE) model, where the knowledge selector plays the role of a router that is used to determine the sequence-to-expert assignment in MoE. This key observation inspires us to develop a novel algorithm for training KiC with an instance-adaptive knowledge selector. As a knowledge-rich semi-parametric language model, KiC only needs a much smaller parametric part to achieve superior zero-shot performance on unseen tasks. By evaluating on 40+ different tasks, we show that KiC-Large with 770M parameters easily outperforms large language models that are 4-39x larger. In addition, KiC also exhibits emergent abilities at a much smaller model scale compared to the fully-parametric models.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Applications (eg, speech processing, computer vision, NLP)", "paperhash": "pan|knowledgeincontext_towards_knowledgeable_semiparametric_language_models", "pdf": "/pdf/2f1a38a721bba2dcfa96af632678ce02c41b26bd.pdf", "_bibtex": "@inproceedings{\npan2023knowledgeincontext,\ntitle={Knowledge-in-Context: Towards Knowledgeable Semi-Parametric Language Models},\nauthor={Xiaoman Pan and Wenlin Yao and Hongming Zhang and Dian Yu and Dong Yu and Jianshu Chen},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=a2jNdqE2102}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279303538, "odate": 1664468100000, "details": {"replyCount": 14}}, {"id": "JAezPMehaUu", "original": "Q1pG7RHWTUm", "number": 3743, "cdate": 1663850238680, "mdate": null, "ddate": null, "tcdate": 1663850238680, "tmdate": 1677568279496, "tddate": null, "forum": "JAezPMehaUu", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Mosaic Representation Learning for Self-supervised Visual Pre-training", "authorids": ["~Zhaoqing_Wang1", "~Ziyu_Chen5", "~Yaqian_Li1", "~Yandong_Guo2", "~Jun_Yu3", "~Mingming_Gong1", "~Tongliang_Liu1"], "authors": ["Zhaoqing Wang", "Ziyu Chen", "Yaqian Li", "Yandong Guo", "Jun Yu", "Mingming Gong", "Tongliang Liu"], "keywords": ["self-supervised learning", "computer vision"], "TL;DR": "We propose a simple and effective mosaic representation learning framework consisting of a new data augmentation strategy, which aims to adequately learn discriminative feature representations.", "abstract": "Self-supervised learning has achieved significant success in learning visual representations without the need for manual annotation. To obtain generalizable representations, a meticulously designed data augmentation strategy is one of the most crucial parts. Recently, multi-crop strategies utilizing a set of small crops as positive samples have been shown to learn spatially structured features. However, it overlooks the diverse contextual backgrounds, which reduces the variance of the input views and degenerates the performance. To address this problem, we propose a mosaic representation learning framework (MosRep), consisting of a new data augmentation strategy that enriches the backgrounds of each small crop and improves the quality of visual representations. Specifically, we randomly sample numbers of small crops from different input images and compose them into a mosaic view, which is equivalent to introducing different background information for each small crop. Additionally, we further jitter the mosaic view to prevent memorizing the spatial locations of each crop. Along with optimization, our MosRep gradually extracts more discriminative features. Extensive experimental results demonstrate that our method improves the performance far greater than the multi-crop strategy on a series of downstream tasks, e.g., +7.4% and +4.9% than the multi-crop strategy on ImageNet-1K with 1% label and 10% label, respectively. Code is available at https://github.com/DerrickWang005/MosRep.git.\n", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Unsupervised and Self-supervised learning", "paperhash": "wang|mosaic_representation_learning_for_selfsupervised_visual_pretraining", "pdf": "/pdf/08d8aac0aaab473c9858de17885ada84ced0e940.pdf", "_bibtex": "@inproceedings{\nwang2023mosaic,\ntitle={Mosaic Representation Learning for Self-supervised Visual Pre-training},\nauthor={Zhaoqing Wang and Ziyu Chen and Yaqian Li and Yandong Guo and Jun Yu and Mingming Gong and Tongliang Liu},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=JAezPMehaUu}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279298359, "odate": 1664468100000, "details": {"replyCount": 11}}, {"id": "Cp-io_BoFaE", "original": "h5YX0MIyiM0", "number": 3740, "cdate": 1663850238314, "mdate": null, "ddate": null, "tcdate": 1663850238314, "tmdate": 1677914477009, "tddate": null, "forum": "Cp-io_BoFaE", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "FluidLab: A Differentiable Environment for Benchmarking Complex Fluid Manipulation", "authorids": ["~Zhou_Xian1", "~Bo_Zhu2", "~Zhenjia_Xu1", "~Hsiao-Yu_Tung2", "~Antonio_Torralba1", "~Katerina_Fragkiadaki1", "~Chuang_Gan1"], "authors": ["Zhou Xian", "Bo Zhu", "Zhenjia Xu", "Hsiao-Yu Tung", "Antonio Torralba", "Katerina Fragkiadaki", "Chuang Gan"], "keywords": ["Complex Fluid Manipulation", "Differentiable Physics"], "abstract": "Humans manipulate various kinds of fluids in their everyday life: creating latte art, scooping floating objects from water, rolling an ice cream cone, etc. Using robots to augment or replace human labors in these daily settings remain as a challenging task due to the multifaceted complexities of fluids. Previous research in robotic fluid manipulation mostly consider fluids governed by an ideal, Newtonian model in simple task settings (e.g., pouring water into a container). However, the vast majority of real-world fluid systems manifest their complexities in terms of the fluid\u2019s complex material behaviors (e.g., elastoplastic deformation) and multi-component interactions (e.g. coffee and frothed milk when making latte art), both of which were well beyond the scope of the current literature. To evaluate robot learning algorithms on understanding and interacting with such complex fluid systems, a comprehensive virtual platform with versatile simulation capabilities and well-established tasks is needed. In this work, we introduce FluidLab, a simulation environment with a diverse set of manipulation tasks involving complex fluid dynamics. These tasks address interactions between solid and fluid as well as among multiple fluids. At the heart of our platform is a fully differentiable physics simulator, FluidEngine, providing GPU-accelerated simulations and gradient calculations for various material types and their couplings, extending the scope of the existing differentiable simulation engines. We identify several challenges for fluid manipulation learning by evaluating a set of reinforcement learning and trajectory optimization methods on our platform. To address these challenges, we propose several domain-specific optimization schemes coupled with differentiable physics, which are empirically shown to be effective in tackling optimization problems featured by fluid system\u2019s non-convex and non-smooth properties. Furthermore, we demonstrate reasonable sim-to-real transfer by deploying optimized trajectories in real-world settings. FluidLab is publicly available at: https://fluidlab2023.github.io.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)", "paperhash": "xian|fluidlab_a_differentiable_environment_for_benchmarking_complex_fluid_manipulation", "pdf": "/pdf/6f396409f5100c7dca4d9a23810e4e4aefb8c5f2.pdf", "_bibtex": "@inproceedings{\nxian2023fluidlab,\ntitle={FluidLab: A Differentiable Environment for Benchmarking Complex Fluid Manipulation},\nauthor={Zhou Xian and Bo Zhu and Zhenjia Xu and Hsiao-Yu Tung and Antonio Torralba and Katerina Fragkiadaki and Chuang Gan},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=Cp-io_BoFaE}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279298263, "odate": 1664468100000, "details": {"replyCount": 20}}, {"id": "PqvMRDCJT9t", "original": "tglfdKadQhv", "number": 3719, "cdate": 1663850235793, "mdate": null, "ddate": null, "tcdate": 1663850235793, "tmdate": 1697935467865, "tddate": null, "forum": "PqvMRDCJT9t", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Flow Matching for Generative Modeling", "authorids": ["~Yaron_Lipman1", "~Ricky_T._Q._Chen1", "~Heli_Ben-Hamu1", "~Maximilian_Nickel1", "~Matthew_Le2"], "authors": ["Yaron Lipman", "Ricky T. Q. Chen", "Heli Ben-Hamu", "Maximilian Nickel", "Matthew Le"], "keywords": ["continuous normalizing flows", "generative models"], "abstract": "We introduce a new paradigm for generative modeling built on Continuous Normalizing Flows (CNFs), allowing us to train CNFs at unprecedented scale. Specifically, we present the notion of Flow Matching (FM), a simulation-free approach for training CNFs based on regressing vector fields of fixed conditional probability paths. Flow Matching is compatible with a general family of Gaussian probability paths for transforming between noise and data samples---which subsumes existing diffusion paths as specific instances. Interestingly, we find that employing FM with diffusion paths results in a more robust and stable alternative for training diffusion models. Furthermore, Flow Matching opens the door to training CNFs with other, non-diffusion probability paths. An instance of particular interest is using Optimal Transport (OT) displacement interpolation to define the conditional probability paths. These paths are more efficient than diffusion paths, provide faster training and sampling, and result in better generalization. Training CNFs using Flow Matching on ImageNet leads to consistently better performance than alternative diffusion-based methods in terms of both likelihood and sample quality, and allows fast and reliable sample generation using off-the-shelf numerical ODE solvers.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Generative models", "paperhash": "lipman|flow_matching_for_generative_modeling", "TL;DR": "We introduce a new simulation-free approach for training Continuous Normalizing Flows, generalizing the probability paths induced by simple diffusion processes. We obtain state-of-the-art on ImageNet in both NLL and FID among competing methods.", "pdf": "/pdf/e99034416acd1ca82991f5d63735e77130fc06a7.pdf", "_bibtex": "@inproceedings{\nlipman2023flow,\ntitle={Flow Matching for Generative Modeling},\nauthor={Yaron Lipman and Ricky T. Q. Chen and Heli Ben-Hamu and Maximilian Nickel and Matthew Le},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=PqvMRDCJT9t}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 2 code implementations](https://www.catalyzex.com/paper/arxiv:2210.02747/code)"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279297126, "odate": 1664468100000, "details": {"replyCount": 11}}, {"id": "tVkrbkz42vc", "original": "aodsyCjWX5D", "number": 3674, "cdate": 1663850230403, "mdate": null, "ddate": null, "tcdate": 1663850230403, "tmdate": 1681239335335, "tddate": null, "forum": "tVkrbkz42vc", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "PAC-NeRF: Physics Augmented Continuum Neural Radiance Fields for Geometry-Agnostic System Identification", "authorids": ["~Xuan_Li8", "~Yi-Ling_Qiao1", "~Peter_Yichen_Chen1", "~Krishna_Murthy_Jatavallabhula1", "~Ming_Lin2", "~Chenfanfu_Jiang3", "~Chuang_Gan1"], "authors": ["Xuan Li", "Yi-Ling Qiao", "Peter Yichen Chen", "Krishna Murthy Jatavallabhula", "Ming Lin", "Chenfanfu Jiang", "Chuang Gan"], "keywords": ["System Identification", "Neural Radiance Fields", "Differentiable Physics", "Material Point Method"], "abstract": "Existing approaches to system identification (estimating the physical parameters of an object) from videos assume known object geometries. This precludes their applicability in a vast majority of scenes where object geometries are complex or unknown. In this work, we aim to identify parameters characterizing a physical system from a set of multi-view videos without any assumption on object geometry or topology. To this end, we propose \"Physics Augmented Continuum Neural Radiance Fields\" (PAC-NeRF), to estimate both the unknown geometry and physical parameters of highly dynamic objects from multi-view videos. We design PAC-NeRF to only ever produce physically plausible states by enforcing the neural radiance field to follow the conservation laws of continuum mechanics. For this, we design a hybrid Eulerian-Lagrangian representation of the neural radiance field, i.e., we use the Eulerian grid representation for NeRF density and color fields, while advecting the neural radiance fields via Lagrangian particles. This hybrid Eulerian-Lagrangian representation seamlessly blends efficient neural rendering with the material point method (MPM) for robust differentiable physics simulation. We validate the effectiveness of our proposed framework on geometry and physical parameter estimation over a vast range of materials, including elastic bodies, plasticine, sand, Newtonian and non-Newtonian fluids, and demonstrate significant performance gain on most tasks.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )", "paperhash": "li|pacnerf_physics_augmented_continuum_neural_radiance_fields_for_geometryagnostic_system_identification", "pdf": "/pdf/f216a90079436d1252e5157ce9e925639303e624.pdf", "_bibtex": "@inproceedings{\nli2023pacnerf,\ntitle={{PAC}-Ne{RF}: Physics Augmented Continuum Neural Radiance Fields for Geometry-Agnostic System Identification},\nauthor={Xuan Li and Yi-Ling Qiao and Peter Yichen Chen and Krishna Murthy Jatavallabhula and Ming Lin and Chenfanfu Jiang and Chuang Gan},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=tVkrbkz42vc}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279294522, "odate": 1664468100000, "details": {"replyCount": 12}}, {"id": "iPWiwWHc1V", "original": "KMDFXu571_w", "number": 3643, "cdate": 1663850226847, "mdate": null, "ddate": null, "tcdate": 1663850226847, "tmdate": 1677755765886, "tddate": null, "forum": "iPWiwWHc1V", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "CLIP-Dissect: Automatic Description of Neuron Representations in Deep Vision Networks", "authorids": ["~Tuomas_Oikarinen1", "~Tsui-Wei_Weng1"], "authors": ["Tuomas Oikarinen", "Tsui-Wei Weng"], "keywords": ["Interpretability", "Explainability", "Network Dissection"], "abstract": "In this paper, we propose CLIP-Dissect, a new technique to automatically describe the function of individual hidden neurons inside vision networks. CLIP-Dissect leverages recent advances in multimodal vision/language models to label internal neurons with open-ended concepts without the need for any labeled data or human examples. We show that CLIP-Dissect provides more accurate descriptions than existing methods for last layer neurons where the ground-truth is available as well as qualitatively good descriptions for hidden layer neurons. In addition, our method is very flexible: it is model agnostic, can easily handle new concepts and can be extended to take advantage of better multimodal models in the future. Finally CLIP-Dissect is computationally efficient and can label all neurons from five layers of ResNet-50 in just 4 minutes, which is more than 10$\\times$ faster than existing methods. Our code is available at https://github.com/Trustworthy-ML-Lab/CLIP-dissect.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)", "paperhash": "oikarinen|clipdissect_automatic_description_of_neuron_representations_in_deep_vision_networks", "TL;DR": "We propose an automated method for generating descriptions of the representation learned by hidden layer neurons, leveraging the multimodal CLIP-model.", "pdf": "/pdf/a302e0072a6e15c8c0361c022bb9d3518f1a7127.pdf", "_bibtex": "@inproceedings{\noikarinen2023clipdissect,\ntitle={{CLIP}-Dissect: Automatic Description of Neuron Representations in Deep Vision Networks},\nauthor={Tuomas Oikarinen and Tsui-Wei Weng},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=iPWiwWHc1V}\n}", "supplementary_material": "/attachment/92d6623c3fefb1572ca2959fe584765a286cb2ec.zip", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279292679, "odate": 1664468100000, "details": {"replyCount": 20}}, {"id": "27uBgHuoSQ", "original": "AZspZ-Gt7dt", "number": 3637, "cdate": 1663850226135, "mdate": null, "ddate": null, "tcdate": 1663850226135, "tmdate": 1677637598114, "tddate": null, "forum": "27uBgHuoSQ", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Data Continuity Matters: Improving Sequence Modeling with Lipschitz Regularizer", "authorids": ["~Eric_Qu1", "~Xufang_Luo1", "~Dongsheng_Li2"], "authors": ["Eric Qu", "Xufang Luo", "Dongsheng Li"], "keywords": ["deep learning", "data continuity", "sequence modeling"], "abstract": "Sequence modeling is a core problem in machine learning, and various neural networks have been designed to process different types of sequence data. However, few attempts have been made to understand the inherent data property of sequence data, neglecting the critical factor that may significantly affect the performance of sequence modeling. In this paper, we theoretically and empirically analyze a generic property of sequence data, i.e., continuity, and connect this property with the performance of deep models. First, we empirically observe that different kinds of models for sequence modeling prefer data with different continuity. Then, we theoretically analyze the continuity preference of different models in both time and frequency domains. To further utilize continuity to improve sequence modeling, we propose a simple yet effective Lipschitz Regularizer, that can flexibly adjust data continuity according to model preferences, and bring very little extra computational cost. Extensive experiments on various tasks demonstrate that altering data continuity via Lipschitz Regularizer can largely improve the performance of many deep models for sequence modeling.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Deep Learning and representational learning", "paperhash": "qu|data_continuity_matters_improving_sequence_modeling_with_lipschitz_regularizer", "pdf": "/pdf/9377a798b9e647ef1515896beca548253de5e521.pdf", "supplementary_material": "/attachment/f4a12c7ae003c3a5a267a55c9c76b2662a2e5bd2.zip", "_bibtex": "@inproceedings{\nqu2023data,\ntitle={Data Continuity Matters: Improving Sequence Modeling with Lipschitz Regularizer},\nauthor={Eric Qu and Xufang Luo and Dongsheng Li},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=27uBgHuoSQ}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279292367, "odate": 1664468100000, "details": {"replyCount": 11}}, {"id": "iaYcJKpY2B_", "original": "7cC9CKuwsS", "number": 3618, "cdate": 1663850223968, "mdate": null, "ddate": null, "tcdate": 1663850223968, "tmdate": 1677533128555, "tddate": null, "forum": "iaYcJKpY2B_", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "CodeGen: An Open Large Language Model for Code with Multi-Turn Program Synthesis", "authorids": ["~Erik_Nijkamp2", "~Bo_Pang4", "~Hiroaki_Hayashi1", "~Lifu_Tu1", "~Huan_Wang1", "~Yingbo_Zhou1", "~Silvio_Savarese1", "~Caiming_Xiong1"], "authors": ["Erik Nijkamp", "Bo Pang", "Hiroaki Hayashi", "Lifu Tu", "Huan Wang", "Yingbo Zhou", "Silvio Savarese", "Caiming Xiong"], "keywords": ["Program synthesis", "multi-turn generation", "code generation", "large language models", "generative models"], "TL;DR": "We open-source a large language models, CodeGen, for program synthesis and propose a multi-turn program synthesis benchmark for evaluation.", "abstract": "Program synthesis strives to generate a computer program as a solution to a given problem specification, expressed with input-output examples or natural language descriptions. The prevalence of large language models advances the state-of-the-art for program synthesis, though limited training resources and data impede open access to such models. To democratize this, we train and release a family of large language models up to 16.1B parameters, called CODEGEN, on natural language and programming language data, and open source the training library JAXFORMER. We show the utility of the trained model by demonstrating that it is competitive with the previous state-of-the-art on zero-shot Python code generation on HumanEval. We further investigate the multi-step paradigm for program synthesis, where a single program is factorized into multiple prompts specifying subproblems. To this end, we construct an open benchmark, Multi-Turn Programming Benchmark (MTPB), consisting of 115 diverse problem sets that are factorized into multi-turn prompts. Our analysis on MTPB shows that the same intent provided to CODEGEN in multi-turn fashion significantly improves program synthesis over that provided as a single turn. We make the training library JAXFORMER and model checkpoints available as open source contribution: https://github.com/salesforce/CodeGen.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Deep Learning and representational learning", "paperhash": "nijkamp|codegen_an_open_large_language_model_for_code_with_multiturn_program_synthesis", "pdf": "/pdf/003bbce081e6ee9edeead69fcdba6fbe3882de42.pdf", "_bibtex": "@inproceedings{\nnijkamp2023codegen,\ntitle={CodeGen: An Open Large Language Model for Code with Multi-Turn Program Synthesis},\nauthor={Erik Nijkamp and Bo Pang and Hiroaki Hayashi and Lifu Tu and Huan Wang and Yingbo Zhou and Silvio Savarese and Caiming Xiong},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=iaYcJKpY2B_}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279291428, "odate": 1664468100000, "details": {"replyCount": 23}}, {"id": "xYlJRpzZtsY", "original": "FbWPGxxTq57", "number": 3608, "cdate": 1663850222754, "mdate": null, "ddate": null, "tcdate": 1663850222754, "tmdate": 1697935479489, "tddate": null, "forum": "xYlJRpzZtsY", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "ROSCOE: A Suite of Metrics for Scoring Step-by-Step Reasoning", "authorids": ["~Olga_Golovneva1", "~Moya_Peng_Chen1", "~Spencer_Poff1", "~Martin_Corredor1", "~Luke_Zettlemoyer1", "~Maryam_Fazel-Zarandi1", "~Asli_Celikyilmaz1"], "authors": ["Olga Golovneva", "Moya Peng Chen", "Spencer Poff", "Martin Corredor", "Luke Zettlemoyer", "Maryam Fazel-Zarandi", "Asli Celikyilmaz"], "keywords": ["step-by-step reasoning", "evaluation"], "TL;DR": "We propose a new taxonomy for reasoning errors and suite of metrics to score step-by-step reasoning in language models.", "abstract": "Large language models show improved downstream task performance when prompted to generate step-by-step reasoning to justify their final answers. These reasoning steps greatly improve model interpretability and verification, but objectively studying their correctness (independent of the final answer) is difficult without reliable methods for automatic evaluation. We simply do not know how often the stated reasoning steps actually support the final end task predictions. In this work, we present ROSCOE, a suite of interpretable, unsupervised automatic scores that improve and extend previous text generation evaluation metrics. To evaluate ROSCOE against baseline metrics, we design a typology of reasoning errors and collect synthetic and human evaluation scores on commonly used reasoning datasets. In contrast with existing metrics, ROSCOE can measure semantic consistency, logicality, informativeness, fluency, and factuality \u2014 among other traits \u2014 by leveraging properties of step-by-step rationales. We empirically verify the strength of our metrics on five human annotated and six programmatically perturbed diagnostics datasets - covering a diverse set of tasks that require reasoning skills and show that ROSCOE can consistently outperform baseline metrics.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Applications (eg, speech processing, computer vision, NLP)", "paperhash": "golovneva|roscoe_a_suite_of_metrics_for_scoring_stepbystep_reasoning", "pdf": "/pdf/3f6164615b8f835462171508e65f188740d76ee8.pdf", "_bibtex": "@inproceedings{\ngolovneva2023roscoe,\ntitle={{ROSCOE}: A Suite of Metrics for Scoring Step-by-Step Reasoning},\nauthor={Olga Golovneva and Moya Peng Chen and Spencer Poff and Martin Corredor and Luke Zettlemoyer and Maryam Fazel-Zarandi and Asli Celikyilmaz},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=xYlJRpzZtsY}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2212.07919/code)"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279290620, "odate": 1664468100000, "details": {"replyCount": 18}}, {"id": "WUWJIV2Yxtp", "original": "NJRge5GpSuH", "number": 3597, "cdate": 1663850221390, "mdate": null, "ddate": null, "tcdate": 1663850221390, "tmdate": 1681441636650, "tddate": null, "forum": "WUWJIV2Yxtp", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Re-calibrating Feature Attributions for Model Interpretation", "authorids": ["~Peiyu_Yang1", "~NAVEED_AKHTAR3", "wenzeyi@gmail.com", "~Mubarak_Shah3", "~Ajmal_Saeed_Mian1"], "authors": ["Peiyu Yang", "NAVEED AKHTAR", "Zeyi Wen", "Mubarak Shah", "Ajmal Saeed Mian"], "keywords": ["Feature Attribution", "Explainable Artifical Intelligence"], "abstract": "The ability to interpret machine learning models is critical for high-stakes applications. Due to its desirable theoretical properties, path integration is a widely used scheme for feature attribution to interpret model predictions. However, the methods implementing this scheme currently rely on absolute attribution scores to eventually provide sensible interpretations. This not only contradicts the premise that the features with larger attribution scores are more relevant to the model prediction, but also conflicts with the theoretical settings for which the desirable properties of the attributions are proven. We address this by devising a method to first compute an appropriate reference for the path integration scheme. This reference further helps in identifying valid interpolation points on a desired integration path. The reference is computed in a gradient ascending direction on the model's loss surface, while the interpolations are performed by analyzing the model gradients and variations between the reference and the input. The eventual integration is effectively performed along a non-linear path. Our scheme can be incorporated into the existing integral-based attribution methods. We also devise an effective sampling and integration procedure that enables employing our scheme with multi-reference path integration efficiently. We achieve a marked performance boost for a range of integral-based attribution methods on both local and global evaluation metrics by enhancing them with our scheme. Our extensive results also show improved sensitivity, sanity preservation and model robustness with the proposed re-calibration of the attribution techniques with our method.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Deep Learning and representational learning", "paperhash": "yang|recalibrating_feature_attributions_for_model_interpretation", "TL;DR": "We propose a re-calibration technique to calibrate existing integral-based attribution methods with valid references for a consistent explanation.", "pdf": "/pdf/27e850e1a146543993bd508afba29de6ac36bbdb.pdf", "supplementary_material": "/attachment/4713517e1fb9a6598ba34cadfa04fbc033ce1c5f.zip", "_bibtex": "@inproceedings{\nyang2023recalibrating,\ntitle={Re-calibrating Feature Attributions for Model Interpretation},\nauthor={Peiyu Yang and NAVEED AKHTAR and Zeyi Wen and Mubarak Shah and Ajmal Saeed Mian},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=WUWJIV2Yxtp}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279289997, "odate": 1664468100000, "details": {"replyCount": 11}}, {"id": "uLE3WF3-H_5", "original": "LjGjqS7aqO", "number": 3595, "cdate": 1663850221110, "mdate": null, "ddate": null, "tcdate": 1663850221110, "tmdate": 1677720191658, "tddate": null, "forum": "uLE3WF3-H_5", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Adversarial Diversity in Hanabi", "authorids": ["~Brandon_Cui1", "~Andrei_Lupu1", "~Samuel_Sokota1", "~Hengyuan_Hu2", "~David_J_Wu1", "~Jakob_Nicolaus_Foerster1"], "authors": ["Brandon Cui", "Andrei Lupu", "Samuel Sokota", "Hengyuan Hu", "David J Wu", "Jakob Nicolaus Foerster"], "keywords": ["coordination", "diversity", "multi-agent reinforcement learning"], "TL;DR": "We produce meaningfully diverse and reasonable joint policies using off-belief learning and adversarial reward shaping.", "abstract": "Many Dec-POMDPs admit a qualitatively diverse set of ''reasonable'' joint policies, where reasonableness is indicated by symmetry equivariance, non-sabotaging behaviour and the graceful degradation of performance when paired with ad-hoc partners. Some of the work in diversity literature is concerned with generating these policies. Unfortunately, existing methods fail to produce teams of agents that are simultaneously diverse, high performing, and reasonable. In this work, we propose a novel approach, adversarial diversity (ADVERSITY), which is designed for turn-based Dec-POMDPs with public actions. ADVERSITY relies on off-belief learning to encourage reasonableness and skill, and on ''repulsive'' fictitious transitions to encourage diversity. We use this approach to generate new agents with distinct but reasonable play styles for the card game Hanabi and open-source our agents to be used for future research on (ad-hoc) coordination.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)", "paperhash": "cui|adversarial_diversity_in_hanabi", "pdf": "/pdf/87e565d42543f1efac5413ce0bdc2276e4f99253.pdf", "supplementary_material": "/attachment/79b84beabc61c55356904a2b40deb1b48c578687.zip", "_bibtex": "@inproceedings{\ncui2023adversarial,\ntitle={Adversarial Diversity in Hanabi},\nauthor={Brandon Cui and Andrei Lupu and Samuel Sokota and Hengyuan Hu and David J Wu and Jakob Nicolaus Foerster},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=uLE3WF3-H_5}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279290014, "odate": 1664468100000, "details": {"replyCount": 16}}, {"id": "ZsvWb6mJnMv", "original": "htEBOEm503", "number": 3545, "cdate": 1663850214993, "mdate": null, "ddate": null, "tcdate": 1663850214993, "tmdate": 1677731498453, "tddate": null, "forum": "ZsvWb6mJnMv", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Optimal Conservative Offline RL with General Function Approximation via Augmented Lagrangian", "authorids": ["~Paria_Rashidinejad1", "~Hanlin_Zhu2", "~Kunhe_Yang1", "~Stuart_Russell1", "~Jiantao_Jiao1"], "authors": ["Paria Rashidinejad", "Hanlin Zhu", "Kunhe Yang", "Stuart Russell", "Jiantao Jiao"], "keywords": ["Offline RL", "Pessimism", "RL Theory"], "abstract": "Offline reinforcement learning (RL), which aims at learning good policies from historical data, has received significant attention over the past years. Much effort has focused on improving offline RL practicality by addressing the prevalent issue of partial data coverage through various forms of conservative policy learning. While the majority of algorithms do not have finite-\nsample guarantees, several provable conservative offline RL algorithms are designed and analyzed within the single-policy concentrability framework that handles partial coverage. Yet, in the nonlinear function approximation setting where confidence intervals are difficult to obtain, existing provable algorithms suffer from computational intractability, prohibitively strong assumptions, and suboptimal statistical rates. In this paper, we leverage the marginalized importance sampling (MIS) formulation of RL and present the first set of offline RL algorithms that are statistically optimal and practical under general function approximation and single-policy concentrability, bypassing the need for uncertainty quantification. We identify that the key to successfully solving the sample-based approximation of the MIS problem is ensuring that certain occupancy validity constraints are nearly satisfied. We enforce these constraints by a novel application of the augmented Lagrangian method and prove the following result: with the MIS formulation, augmented Lagrangian is enough for statistically optimal offline RL. In stark contrast to prior algorithms that induce additional conservatism through methods such as behavior regularization, our approach provably eliminates this need and reinterprets regularizers as \"enforcers of occupancy validity\" than \"promoters of conservatism.\"", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)", "paperhash": "rashidinejad|optimal_conservative_offline_rl_with_general_function_approximation_via_augmented_lagrangian", "TL;DR": "We present practical and statistically optimal offline RL algorithms under general function approximation and single-policy concentrability.", "pdf": "/pdf/1e66fdaab805cebe5a84c568baa5b2a817e6b6f3.pdf", "_bibtex": "@inproceedings{\nrashidinejad2023optimal,\ntitle={Optimal Conservative Offline {RL} with General Function Approximation via Augmented Lagrangian},\nauthor={Paria Rashidinejad and Hanlin Zhu and Kunhe Yang and Stuart Russell and Jiantao Jiao},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=ZsvWb6mJnMv}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279287581, "odate": 1664468100000, "details": {"replyCount": 20}}, {"id": "ZTCxT2t2Ru", "original": "Fd6-Tobenv", "number": 3503, "cdate": 1663850209747, "mdate": null, "ddate": null, "tcdate": 1663850209747, "tmdate": 1676743944778, "tddate": null, "forum": "ZTCxT2t2Ru", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "DocPrompting: Generating Code by Retrieving the Docs", "authorids": ["~Shuyan_Zhou1", "~Uri_Alon1", "~Frank_F._Xu1", "~Zhengbao_Jiang2", "~Graham_Neubig1"], "authors": ["Shuyan Zhou", "Uri Alon", "Frank F. Xu", "Zhengbao Jiang", "Graham Neubig"], "keywords": ["code generation", "retrieval-conditioned generation"], "abstract": "Publicly available source-code libraries are continuously growing and changing. This makes it impossible for models of code\nto keep current with all available APIs by simply training these models on existing code repositories. Thus, existing models inherently cannot generalize to using unseen functions and libraries, because these would never appear in the training data. In contrast, when human programmers use functions and libraries for the first time, they frequently refer to textual resources such as code manuals and documentation, to explore and understand the available functionality. Inspired by this observation, we introduce DocPrompting: a natural-language-to-code generation approach that explicitly leverages documentation by (1) retrieving the relevant documentation pieces given an NL intent, and (2) generating code based on the NL intent and the retrieved documentation. DocPrompting is general: it can be applied to any programming language and is agnostic to the underlying neural model. We demonstrate that DocPrompting consistently improves NL-to-code models: DocPrompting improves strong base models such as CodeT5 by 2.85% in pass@1 (52% relative gain) and 4.39% in pass@10 (30% relative gain) in execution-based evaluation on the popular Python CoNaLa benchmark; on a new Bash dataset tldr, DocPrompting improves CodeT5 and GPT-Neo1.3B by up to absolute 6.9% exact match.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Applications (eg, speech processing, computer vision, NLP)", "paperhash": "zhou|docprompting_generating_code_by_retrieving_the_docs", "TL;DR": "We propose to generalize the code generation models to unseen functions and usages through retrieving and reading code documentation", "pdf": "/pdf/c9881a374e0bce9d005809d63e83dfdae53d9d40.pdf", "supplementary_material": "/attachment/eba68a856c38114f00e52df57800061b9f41c5e3.zip", "_bibtex": "@inproceedings{\nzhou2023docprompting,\ntitle={DocPrompting: Generating Code by Retrieving the Docs},\nauthor={Shuyan Zhou and Uri Alon and Frank F. Xu and Zhengbao Jiang and Graham Neubig},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=ZTCxT2t2Ru}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279285142, "odate": 1664468100000, "details": {"replyCount": 14}}, {"id": "HcUf-QwZeFh", "original": "EywHbdc63y", "number": 3487, "cdate": 1663850207848, "mdate": null, "ddate": null, "tcdate": 1663850207848, "tmdate": 1676330874440, "tddate": null, "forum": "HcUf-QwZeFh", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "A System for Morphology-Task Generalization via Unified Representation and Behavior Distillation", "authorids": ["~Hiroki_Furuta1", "~Yusuke_Iwasawa1", "~Yutaka_Matsuo1", "~Shixiang_Shane_Gu1"], "authors": ["Hiroki Furuta", "Yusuke Iwasawa", "Yutaka Matsuo", "Shixiang Shane Gu"], "keywords": ["Morphology-Task Generalization", "Behavior Distillation", "Supervised RL", "Reinforcement Learning"], "TL;DR": "We explore a method for learning a single policy that manipulates various forms of agents to various goal positions by distilling a large amount of proficient behavioral data.", "abstract": "The rise of generalist large-scale models in natural language and vision has made us expect that a massive data-driven approach could achieve broader generalization in other domains such as continuous control. In this work, we explore a method for learning a single policy that manipulates various forms of agents to solve various tasks by distilling a large amount of proficient behavioral data. In order to align input-output (IO) interface among multiple tasks and diverse agent morphologies while preserving essential 3D geometric relations, we introduce morphology-task graph, which treats observations, actions and goals/task in a unified graph representation. We also develop MxT-Bench for fast large-scale behavior generation, which supports procedural generation of diverse morphology-task combinations with a minimal blueprint and hardware-accelerated simulator. Through efficient representation and architecture selection on MxT-Bench, we find out that a morphology-task graph representation coupled with Transformer architecture improves the multi-task performances compared to other baselines including recent discrete tokenization, and provides better prior knowledge for zero-shot transfer or sample efficiency in downstream multi-task imitation learning. Our work suggests large diverse offline datasets, unified IO representation, and policy representation and architecture selection through supervised learning form a promising approach for studying and advancing morphology-task generalization.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)", "paperhash": "furuta|a_system_for_morphologytask_generalization_via_unified_representation_and_behavior_distillation", "pdf": "/pdf/184fcbb9f9a73128759c56558e7ad476b59fa452.pdf", "_bibtex": "@inproceedings{\nfuruta2023a,\ntitle={A System for Morphology-Task Generalization via Unified Representation and Behavior Distillation},\nauthor={Hiroki Furuta and Yusuke Iwasawa and Yutaka Matsuo and Shixiang Shane Gu},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=HcUf-QwZeFh}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279284361, "odate": 1664468100000, "details": {"replyCount": 22}}, {"id": "9XFSbDPmdW", "original": "216Iuz2eJx", "number": 3386, "cdate": 1663850196033, "mdate": null, "ddate": null, "tcdate": 1663850196033, "tmdate": 1677734635338, "tddate": null, "forum": "9XFSbDPmdW", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Progress measures for grokking via mechanistic interpretability", "authorids": ["~Neel_Nanda1", "~Lawrence_Chan2", "~Tom_Lieberum1", "smith.jessk@gmail.com", "~Jacob_Steinhardt1"], "authors": ["Neel Nanda", "Lawrence Chan", "Tom Lieberum", "Jess Smith", "Jacob Steinhardt"], "keywords": ["interpretability", "grokking", "progress measures", "mechanistic interpretability", "circuits"], "TL;DR": "We fully reverse engineer how one-layer transformers implement modular addition, and use this knowledge to explain grokking. ", "abstract": "Neural networks often exhibit emergent behavior in which qualitatively new capabilities that arise from scaling up the number of parameters, training data, or even the number of steps. One approach to understanding emergence is to find the continuous \\textit{progress measures} that underlie the seemingly discontinuous qualitative changes. In this work, we argue that progress measures can be found via mechanistic interpretability---that is, by reverse engineering learned models into components and measuring the progress of each component over the course of training. As a case study, we study small transformers trained on a modular arithmetic tasks with emergent grokking behavior. We fully reverse engineer the algorithm learned by these networks, which uses discrete fourier transforms and trigonometric identities to convert addition to rotation about a circle. After confirming the algorithm via ablation, we then use our understanding of the algorithm to define progress measures that precede the grokking phase transition on this task. We see our result as demonstrating both that it is possible to fully reverse engineer trained networks, and that doing so can be invaluable to understanding their training dynamics. ", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)", "paperhash": "nanda|progress_measures_for_grokking_via_mechanistic_interpretability", "pdf": "/pdf/4a139897d29f8bd1c37ac9483d9e6ac2fa5ec8fb.pdf", "_bibtex": "@inproceedings{\nnanda2023progress,\ntitle={Progress measures for grokking via mechanistic interpretability},\nauthor={Neel Nanda and Lawrence Chan and Tom Lieberum and Jess Smith and Jacob Steinhardt},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=9XFSbDPmdW}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279278636, "odate": 1664468100000, "details": {"replyCount": 11}}, {"id": "oMsN9TYwJ0j", "original": "XzmDcd8iiIt", "number": 3370, "cdate": 1663850194380, "mdate": null, "ddate": null, "tcdate": 1663850194380, "tmdate": 1697935505625, "tddate": null, "forum": "oMsN9TYwJ0j", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "PiFold: Toward effective and efficient protein inverse folding", "authorids": ["~Zhangyang_Gao1", "~Cheng_Tan1", "~Stan_Z._Li2"], "authors": ["Zhangyang Gao", "Cheng Tan", "Stan Z. Li"], "keywords": [], "abstract": "How can we design protein sequences folding into the desired structures effectively and efficiently? AI methods for structure-based protein design have attracted increasing attention in recent years; however, few methods can simultaneously improve the accuracy and efficiency due to the lack of expressive features and autoregressive sequence decoder. To address these issues, we propose PiFold, which contains a novel residue featurizer and PiGNN layers to generate protein sequences in a one-shot way with improved recovery. Experiments show that PiFold could achieve 51.66\\% recovery on CATH 4.2, while the inference speed is 70 times faster than the autoregressive competitors. In addition, PiFold achieves 58.72\\% and 60.42\\% recovery scores on TS50 and TS500, respectively. We conduct comprehensive ablation studies to reveal the role of different types of protein features and model designs, inspiring further simplification and improvement. The PyTorch code is available at \\href{https://github.com/A4Bio/PiFold}{GitHub}.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )", "paperhash": "gao|pifold_toward_effective_and_efficient_protein_inverse_folding", "pdf": "/pdf/e1a0ac295d7e905fb72e78968e396731ad364a0b.pdf", "_bibtex": "@inproceedings{\ngao2023pifold,\ntitle={PiFold: Toward effective and efficient protein inverse folding},\nauthor={Zhangyang Gao and Cheng Tan and Stan Z. Li},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=oMsN9TYwJ0j}\n}", "supplementary_material": "/attachment/37747efdb155b4addeb8492c3921526ce7ab855a.zip", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2209.12643/code)"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279277685, "odate": 1664468100000, "details": {"replyCount": 4}}, {"id": "6qeBuZSo7Pr", "original": "wHMrawKNIDN", "number": 3345, "cdate": 1663850191668, "mdate": null, "ddate": null, "tcdate": 1663850191668, "tmdate": 1697935508888, "tddate": null, "forum": "6qeBuZSo7Pr", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Planning Goals for Exploration", "authorids": ["~Edward_S._Hu1", "~Richard_Chang2", "~Oleh_Rybkin1", "~Dinesh_Jayaraman2"], "authors": ["Edward S. Hu", "Richard Chang", "Oleh Rybkin", "Dinesh Jayaraman"], "keywords": ["model-based reinforcement learning", "exploration", "goal-conditioned reinforcement learning", "planning", "intrinsic motivation", "reinforcement learning"], "TL;DR": "We use world models to generate goals for exploration.", "abstract": "Dropped into an unknown environment, what should an agent do to quickly learn about the environment and how to accomplish diverse tasks within it? We address this question within the goal-conditioned reinforcement learning paradigm, by identifying how the agent should set its goals at training time to maximize exploration. We propose \"Planning Exploratory Goals\" (PEG), a method that sets goals for each training episode to directly optimize an intrinsic exploration reward. PEG first chooses goal commands such that the agent's goal-conditioned policy, at its current level of training, will end up in states with high exploration potential. It then launches an exploration policy starting at those promising states. To enable this direct optimization, PEG learns world models and adapts sampling-based planning algorithms to \"plan goal commands\". In challenging simulated robotics environments including a multi-legged ant robot in a maze, and a robot arm on a cluttered tabletop, PEG exploration enables more efficient and effective training of goal-conditioned policies relative to baselines and ablations. Our ant successfully navigates a long maze, and the robot arm successfully builds a stack of three blocks upon command. Website: https://sites.google.com/view/exploratory-goals", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)", "paperhash": "hu|planning_goals_for_exploration", "pdf": "/pdf/b28237bb9e4d96d5f02a9d0639565db68727d08c.pdf", "supplementary_material": "/attachment/0d43ce144b0933fda5695689b53a2e642db4d34e.zip", "_bibtex": "@inproceedings{\nhu2023planning,\ntitle={Planning Goals for Exploration},\nauthor={Edward S. Hu and Richard Chang and Oleh Rybkin and Dinesh Jayaraman},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=6qeBuZSo7Pr}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 2 code implementations](https://www.catalyzex.com/paper/arxiv:2303.13002/code)"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279276061, "odate": 1664468100000, "details": {"replyCount": 32}}, {"id": "Do9MOlwWHu0", "original": "cSLPYJY31FB", "number": 3342, "cdate": 1663850191327, "mdate": null, "ddate": null, "tcdate": 1663850191327, "tmdate": 1677767624333, "tddate": null, "forum": "Do9MOlwWHu0", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Learning Sparse Group Models Through Boolean Relaxation", "authorids": ["~Yijie_Wang2", "~Yuan_Zhou1", "~Xiaoqing_Huang1", "~Kun_Huang2", "~Jie_Zhang20", "~Jianzhu_Ma2"], "authors": ["Yijie Wang", "Yuan Zhou", "Xiaoqing Huang", "Kun Huang", "Jie Zhang", "Jianzhu Ma"], "keywords": ["Structured sparisity", "Convex relaxation", "Cardinality-constrained program", "Small sample size"], "abstract": "We introduce an efficient algorithmic framework for learning sparse group models formulated as the natural convex relaxation of a cardinality-constrained program with Boolean variables. We provide theoretical techniques to characterize the equivalent condition when the relaxation achieves the exact integral optimal solution, as well as a rounding algorithm to produce a feasible integral solution once the optimal relaxation solution is fractional. We demonstrate the power of our equivalent condition by applying it to two ensembles of random problem instances that are challenging and popularly used in literature and prove that our method achieves exactness with overwhelming probability and nearly optimal sample complexity. Empirically, we use synthetic datasets to demonstrate that our proposed method significantly outperforms the state-of-the-art group sparse learning models in terms of individual and group support recovery when the number of samples is small. Furthermore, we show the out-performance of our method in cancer drug response prediction.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "General Machine Learning (ie none of the above)", "paperhash": "wang|learning_sparse_group_models_through_boolean_relaxation", "pdf": "/pdf/0760530295a66fdff783489bb9ee1628a6ed3880.pdf", "_bibtex": "@inproceedings{\nwang2023learning,\ntitle={Learning Sparse Group Models Through Boolean Relaxation},\nauthor={Yijie Wang and Yuan Zhou and Xiaoqing Huang and Kun Huang and Jie Zhang and Jianzhu Ma},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=Do9MOlwWHu0}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279276016, "odate": 1664468100000, "details": {"replyCount": 5}}, {"id": "0cpM2ApF9p6", "original": "bGU6Fk37jyr", "number": 3314, "cdate": 1663850187911, "mdate": null, "ddate": null, "tcdate": 1663850187911, "tmdate": 1697935512540, "tddate": null, "forum": "0cpM2ApF9p6", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "MeshDiffusion: Score-based Generative 3D Mesh Modeling", "authorids": ["~Zhen_Liu6", "~Yao_Feng3", "~Michael_J._Black1", "~Derek_Nowrouzezahrai1", "~Liam_Paull1", "~Weiyang_Liu1"], "authors": ["Zhen Liu", "Yao Feng", "Michael J. Black", "Derek Nowrouzezahrai", "Liam Paull", "Weiyang Liu"], "keywords": ["generative model", "diffusion model", "3D mesh", "shape generation"], "TL;DR": "Diffusion model on 3D meshes of arbitrary topology by direct parametrizing meshes with tetrahedral grids", "abstract": "We consider the task of generating realistic 3D shapes, which is useful for a variety of applications such as automatic scene generation and physical simulation. Compared to other 3D representations like voxels and point clouds, meshes are more desirable in practice, because (1) they enable easy and arbitrary manipulation of shapes for relighting and simulation, and (2) they can fully leverage the power of modern graphics pipelines which are mostly optimized for meshes. Previous scalable methods for generating meshes typically rely on sub-optimal post-processing, and they tend to produce overly-smooth or noisy surfaces without fine-grained geometric details. To overcome these shortcomings, we take advantage of the graph structure of meshes and use a simple yet very effective generative modeling method to generate 3D meshes. Specifically, we represent meshes with deformable tetrahedral grids, and then train a diffusion model on this direct parameterization. We demonstrate the effectiveness of our model on multiple generative tasks.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Generative models", "paperhash": "liu|meshdiffusion_scorebased_generative_3d_mesh_modeling", "pdf": "/pdf/f4b27531cf7771c608830f2a184f9c5ef06eab1c.pdf", "_bibtex": "@inproceedings{\nliu2023meshdiffusion,\ntitle={MeshDiffusion: Score-based Generative 3D Mesh Modeling},\nauthor={Zhen Liu and Yao Feng and Michael J. Black and Derek Nowrouzezahrai and Liam Paull and Weiyang Liu},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=0cpM2ApF9p6}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 3 code implementations](https://www.catalyzex.com/paper/arxiv:2303.08133/code)"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279273751, "odate": 1664468100000, "details": {"replyCount": 16}}, {"id": "n05upKp02kQ", "original": "nhooMxyKh7I", "number": 3290, "cdate": 1663850185035, "mdate": null, "ddate": null, "tcdate": 1663850185035, "tmdate": 1677744722017, "tddate": null, "forum": "n05upKp02kQ", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Partially Observable RL with B-Stability: Unified Structural Condition and Sharp Sample-Efficient Algorithms", "authorids": ["~Fan_Chen4", "~Yu_Bai1", "~Song_Mei1"], "authors": ["Fan Chen", "Yu Bai", "Song Mei"], "keywords": ["reinforcement learning theory", "POMDPs", "predictive state representations", "partially observable reinforcement learning"], "TL;DR": "We propose a unified structural condition for sample-efficient partially observable RL (POMDPs/PSRs), and establish substantially sharper learning results than existing ones.", "abstract": "Partial Observability---where agents can only observe partial information about the true underlying state of the system---is ubiquitous in real-world applications of Reinforcement Learning (RL). Theoretically, learning a near-optimal policy under partial observability is known to be hard in the worst case due to an exponential sample complexity lower bound. Recent work has identified several tractable subclasses that are learnable with polynomial samples, such as Partially Observable Markov Decision Processes (POMDPs) with certain revealing or decodability conditions. However, this line of research is still in its infancy, where (1) unified structural conditions enabling sample-efficient learning are lacking; (2) existing sample complexities for known tractable subclasses are far from sharp; and (3) fewer sample-efficient algorithms are available than in fully observable RL.\n\nThis paper advances all three aspects above for Partially Observable RL in the general setting of Predictive State Representations (PSRs). First, we propose a natural and unified structural condition for PSRs called \\emph{B-stability}. B-stable PSRs encompasses the vast majority of known tractable subclasses such as weakly revealing POMDPs, low-rank future-sufficient POMDPs, decodable POMDPs, and regular PSRs. Next, we show that any B-stable PSR can be learned with polynomial samples in relevant problem parameters. When instantiated in the aforementioned subclasses, our sample complexities improve substantially over the current best ones. Finally, our results are achieved by three algorithms simultaneously: Optimistic Maximum Likelihood Estimation, Estimation-to-Decisions, and Model-Based Optimistic Posterior Sampling. The latter two algorithms are new for sample-efficient learning of POMDPs/PSRs.\nWe additionally design a variant of the Estimation-to-Decisions algorithm to perform sample-efficient \\emph{all-policy model estimation} for B-stable PSRs, which also yields guarantees for reward-free learning as an implication.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Theory (eg, control theory, learning theory, algorithmic game theory)", "paperhash": "chen|partially_observable_rl_with_bstability_unified_structural_condition_and_sharp_sampleefficient_algorithms", "pdf": "/pdf/72aa8e574f037ca63f878f9b771e8fdb68841877.pdf", "_bibtex": "@inproceedings{\nchen2023partially,\ntitle={Partially Observable {RL} with B-Stability: Unified Structural Condition and Sharp Sample-Efficient Algorithms},\nauthor={Fan Chen and Yu Bai and Song Mei},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=n05upKp02kQ}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279272727, "odate": 1664468100000, "details": {"replyCount": 8}}, {"id": "fk7RbGibe1", "original": "fYPS_NXVcEv", "number": 3285, "cdate": 1663850184433, "mdate": null, "ddate": null, "tcdate": 1663850184433, "tmdate": 1677737188144, "tddate": null, "forum": "fk7RbGibe1", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Domain Generalization via Heckman-type Selection Models ", "authorids": ["~Hyungu_Kahng1", "~Hyungrok_Do1", "~Judy_Zhong1"], "authors": ["Hyungu Kahng", "Hyungrok Do", "Judy Zhong"], "keywords": ["Domain Generalization", "Sample Selection", "Bias Correction", "Heckman"], "TL;DR": "A non-random sample selection framework for solving domain generalization, and a set of Heckman-type estimators for various types of outcomes.", "abstract": "The domain generalization (DG) setup considers the problem where models are trained on data sampled from multiple domains and evaluated on test domains unseen during training. In this paper, we formulate DG as a sample selection problem where each domain is sampled from a common underlying population through non-random sampling probabilities that correlate with both the features and the outcome. Under this setting, the fundamental iid assumption of the empirical risk minimization (ERM) is violated, so it often performs worse on test domains whose non-random sampling probabilities differ from the domains in the training dataset. We propose a Selection-Guided DG (SGDG) framework to learn the selection probability of each domain and the joint distribution of the outcome and domain selection variables. The proposed SGDG is domain generalizable as it intends to minimize the risk under the population distribution. We theoretically proved that, under certain regular conditions, SGDG can achieve smaller risk than ERM. Furthermore, we present a class of parametric SGDG (HeckmanDG) estimators applicable to continuous, binary, and multinomial outcomes. We also demonstrated its efficacy empirically through simulations and experiments on a set of benchmark datasets comparing with other well-known DG methods.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "General Machine Learning (ie none of the above)", "paperhash": "kahng|domain_generalization_via_heckmantype_selection_models", "pdf": "/pdf/44f6a3958bfee5b8302b55dd30335b9c8be982eb.pdf", "_bibtex": "@inproceedings{\nkahng2023domain,\ntitle={Domain Generalization via Heckman-type Selection Models },\nauthor={Hyungu Kahng and Hyungrok Do and Judy Zhong},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=fk7RbGibe1}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279272494, "odate": 1664468100000, "details": {"replyCount": 12}}, {"id": "mbxz9Cjehr", "original": "RpNQ6Ffj93D", "number": 3277, "cdate": 1663850183504, "mdate": null, "ddate": null, "tcdate": 1663850183504, "tmdate": 1681421277702, "tddate": null, "forum": "mbxz9Cjehr", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "A CMDP-within-online framework for Meta-Safe Reinforcement Learning", "authorids": ["~Vanshaj_Khattar1", "~Yuhao_Ding2", "~Bilgehan_Sel1", "~Javad_Lavaei1", "~Ming_Jin2"], "authors": ["Vanshaj Khattar", "Yuhao Ding", "Bilgehan Sel", "Javad Lavaei", "Ming Jin"], "keywords": ["Meta-Reinforcement learning", "Constrained MDPs", "online learning", "safe RL", "dynamic regret"], "TL;DR": "We study the problem of meta-reinforcement learning (meta-RL) for constrained Markov decision processes (CMDPs) through the inexact CMDP-within-online framework.", "abstract": "Meta-reinforcement learning has widely been used as a learning-to-learn framework to solve unseen tasks with limited experience. However, the aspect of constraint violations has not been adequately addressed in the existing works, making their application restricted in real-world settings. In this paper, we study the problem of meta-safe reinforcement learning (meta-SRL) through the CMDP-within-online framework. We obtain task-averaged regret guarantees for the reward maximization (optimality gap) and constraint violations using gradient-based meta-learning and show that the task-averaged optimality gap and constraint satisfaction improve with task-similarity in the static environment, or task-relatedness in the changing environment. Several technical challenges arise when making this framework practical while still having strong theoretical guarantees. To address these challenges, we propose a meta-algorithm that performs inexact online learning on the upper bounds of intra-task optimality gap and constraint violations estimated by off-policy stationary distribution corrections. Furthermore, we enable the learning rates to be adapted for every task and extend our approach to settings with the dynamically changing task environments. Finally, experiments are conducted to demonstrate the effectiveness of our approach. The proposed theoretical framework is the first to handle the nonconvexity and stochastic nature of within-task CMDPs, while exploiting inter-task dependency for multi-task safe learning.\n", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)", "paperhash": "khattar|a_cmdpwithinonline_framework_for_metasafe_reinforcement_learning", "pdf": "/pdf/a0814d04508ed834d5ecec6097573946c1f8b619.pdf", "supplementary_material": "/attachment/90e446c318f02963158b6f32b0e84401ef375b2b.zip", "_bibtex": "@inproceedings{\nkhattar2023a,\ntitle={A {CMDP}-within-online framework for Meta-Safe Reinforcement Learning},\nauthor={Vanshaj Khattar and Yuhao Ding and Bilgehan Sel and Javad Lavaei and Ming Jin},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=mbxz9Cjehr}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279271877, "odate": 1664468100000, "details": {"replyCount": 40}}, {"id": "P-73JPgRs0R", "original": "L-8rjAM-Ug7", "number": 3275, "cdate": 1663850183259, "mdate": null, "ddate": null, "tcdate": 1663850183259, "tmdate": 1676906498614, "tddate": null, "forum": "P-73JPgRs0R", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Effects of Graph Convolutions in Multi-layer Networks", "authorids": ["~Aseem_Baranwal1", "~Kimon_Fountoulakis1", "~Aukosh_Jagannath1"], "authors": ["Aseem Baranwal", "Kimon Fountoulakis", "Aukosh Jagannath"], "keywords": ["graph neural networks", "node classification", "classification threshold", "contextual stochastic block model"], "TL;DR": "Theoretical and empirical insights into the performance of graph convolutions in multi-layer networks", "abstract": "Graph Convolutional Networks (GCNs) are one of the most popular architectures that are used to solve classification problems accompanied by graphical information. We present a rigorous theoretical understanding of the effects of graph convolutions in multi-layer networks. We study these effects through the node classification problem of a non-linearly separable Gaussian mixture model coupled with a stochastic block model. First, we show that a single graph convolution expands the regime of the distance between the means where multi-layer networks can classify the data by a factor of at least $1/\\sqrt[4]{\\rm deg}$, where ${\\rm deg}$ denotes the expected degree of a node. Second, we show that with a slightly stronger graph density, two graph convolutions improve this factor to at least $1/\\sqrt[4]{n}$, where $n$ is the number of nodes in the graph. Finally, we provide both theoretical and empirical insights into the performance of graph convolutions placed in different combinations among the layers of a neural network, concluding that the performance is mutually similar for all combinations of the placement. We present extensive experiments on both synthetic and real-world data that illustrate our results.", "pdf": "/pdf/d210fced5bf1ca06dc521b5bd8088e97ffbdc31e.pdf", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "supplementary_material": "/attachment/97f161c63f4457d043ebfe08ecbc7c6d3abcda6b.zip", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Theory (eg, control theory, learning theory, algorithmic game theory)", "paperhash": "baranwal|effects_of_graph_convolutions_in_multilayer_networks", "_bibtex": "@inproceedings{\nbaranwal2023effects,\ntitle={Effects of Graph Convolutions in Multi-layer Networks},\nauthor={Aseem Baranwal and Kimon Fountoulakis and Aukosh Jagannath},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=P-73JPgRs0R}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279271790, "odate": 1664468100000, "details": {"replyCount": 13}}, {"id": "nA5AZ8CEyow", "original": "Jaffs-WwCTP", "number": 3269, "cdate": 1663850182561, "mdate": null, "ddate": null, "tcdate": 1663850182561, "tmdate": 1697935517693, "tddate": null, "forum": "nA5AZ8CEyow", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Post-hoc Concept Bottleneck Models", "authorids": ["~Mert_Yuksekgonul1", "~Maggie_Wang1", "~James_Zou1"], "authors": ["Mert Yuksekgonul", "Maggie Wang", "James Zou"], "keywords": ["concepts", "interpretability", "concept bottleneck models", "model editing"], "TL;DR": "We present a method to turn any neural network into a concept bottleneck model without sacrificing model performance, retaining interpretability benefits along with easy model editing.", "abstract": "Concept Bottleneck Models (CBMs) map the inputs onto a set of interpretable concepts (``the bottleneck'') and use the concepts to make predictions. A concept bottleneck enhances interpretability since it can be investigated to understand what concepts the model \"sees\" in an input and which of these concepts are deemed important. However, CBMs are restrictive in practice as they require dense concept annotations in the training data to learn the bottleneck. Moreover, CBMs often do not match the accuracy of an unrestricted neural network, reducing the incentive to deploy them in practice. In this work, we address these limitations of CBMs by introducing Post-hoc Concept Bottleneck models (PCBMs). We show that we can turn any neural network into a PCBM without sacrificing model performance while still retaining the interpretability benefits. When concept annotations are not available on the training data, we show that PCBM can transfer concepts from other datasets or from natural language descriptions of concepts via multimodal models. A key benefit of PCBM is that it enables users to quickly debug and update the model to reduce spurious correlations and improve generalization to new distributions. PCBM allows for global model edits, which can be more efficient than previous works on local interventions that fix a specific prediction. Through a model-editing user study, we show that editing PCBMs via concept-level feedback can provide significant performance gains without using data from the target domain or model retraining.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)", "paperhash": "yuksekgonul|posthoc_concept_bottleneck_models", "pdf": "/pdf/bd9522b16fb6b3a1e89ec20c6aa411c7a84f0fb3.pdf", "_bibtex": "@inproceedings{\nyuksekgonul2023posthoc,\ntitle={Post-hoc Concept Bottleneck Models},\nauthor={Mert Yuksekgonul and Maggie Wang and James Zou},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=nA5AZ8CEyow}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 2 code implementations](https://www.catalyzex.com/paper/arxiv:2205.15480/code)"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279271101, "odate": 1664468100000, "details": {"replyCount": 9}}, {"id": "u2Pd6x794I", "original": "yNnzv1Awa-P", "number": 3266, "cdate": 1663850182199, "mdate": null, "ddate": null, "tcdate": 1663850182199, "tmdate": 1677079833006, "tddate": null, "forum": "u2Pd6x794I", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "When Source-Free Domain Adaptation Meets Learning with Noisy Labels", "authorids": ["~Li_Yi4", "~Gezheng_Xu2", "~Pengcheng_Xu1", "~Jiaqi_Li2", "~Ruizhi_Pu1", "~Charles_Ling1", "~Ian_McLeod1", "~Boyu_Wang3"], "authors": ["Li Yi", "Gezheng Xu", "Pengcheng Xu", "Jiaqi Li", "Ruizhi Pu", "Charles Ling", "Ian McLeod", "Boyu Wang"], "keywords": ["Source-Free Domain Adaptation", "Unsupervised Domain Adaptation", "Noisy Label Learning"], "abstract": "Recent state-of-the-art source-free domain adaptation (SFDA) methods have focused on learning meaningful cluster structures in the feature space, which have succeeded in adapting the knowledge from source domain to unlabeled target domain without accessing the private source data. However, existing methods rely on the pseudo-labels generated by source models that can be noisy due to domain shift. In this paper, we study SFDA from the perspective of learning with label noise (LLN). Unlike the label noise in the conventional LLN scenario, we prove that the label noise in SFDA follows a different distribution assumption. We also prove that such a difference makes existing LLN methods that rely on their distribution assumptions unable to address the label noise in SFDA. Empirical evidence suggests that only marginal improvements are achieved when applying the existing LLN methods to solve the SFDA problem. On the other hand, although there exists a fundamental difference between the label noise in the two scenarios, we demonstrate theoretically that the early-time training phenomenon (ETP), which has been previously observed in conventional label noise settings, can also be observed in the SFDA problem. Extensive experiments demonstrate significant improvements to existing SFDA algorithms by leveraging ETP to address the label noise in SFDA.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Unsupervised and Self-supervised learning", "paperhash": "yi|when_sourcefree_domain_adaptation_meets_learning_with_noisy_labels", "pdf": "/pdf/3132194ea43e68910cd7e90e9be2141425b45f39.pdf", "supplementary_material": "/attachment/39ca2e6081c452464ec16e3b3009101eaa9d77e4.zip", "_bibtex": "@inproceedings{\nyi2023when,\ntitle={When Source-Free Domain Adaptation Meets Learning with Noisy Labels},\nauthor={Li Yi and Gezheng Xu and Pengcheng Xu and Jiaqi Li and Ruizhi Pu and Charles Ling and Ian McLeod and Boyu Wang},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=u2Pd6x794I}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279270992, "odate": 1664468100000, "details": {"replyCount": 21}}, {"id": "6taykzqcPD", "original": "YAy3OmRWA7", "number": 3258, "cdate": 1663850181252, "mdate": null, "ddate": null, "tcdate": 1663850181252, "tmdate": 1681510144752, "tddate": null, "forum": "6taykzqcPD", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Neural Networks Efficiently Learn Low-Dimensional Representations with SGD", "authorids": ["~Alireza_Mousavi-Hosseini1", "~Sejun_Park1", "~Manuela_Girotti1", "~Ioannis_Mitliagkas1", "~Murat_A_Erdogdu1"], "authors": ["Alireza Mousavi-Hosseini", "Sejun Park", "Manuela Girotti", "Ioannis Mitliagkas", "Murat A Erdogdu"], "keywords": ["feature learning", "generalization", "compressibility", "sgd", "neural networks"], "TL;DR": "We prove that SGD on neural networks can learn low-dimensional features in certain settings, and use this to derive novel generalization and excess risk bounds.", "abstract": "We study the problem of training a two-layer neural network (NN) of arbitrary width using stochastic gradient descent (SGD) where the input $\\boldsymbol{x}\\in \\mathbb{R}^d$ is Gaussian and the target $y \\in \\mathbb{R}$ follows a multiple-index model, i.e., $y=g(\\langle\\boldsymbol{u_1},\\boldsymbol{x}\\rangle,...,\\langle\\boldsymbol{u_k},\\boldsymbol{x}\\rangle)$ with a noisy link function $g$. We prove that the first-layer weights in the NN converge to the $k$-dimensional principal subspace spanned by the vectors $\\boldsymbol{u_1},...,\\boldsymbol{u_k}$ of the true model, when online SGD with weight decay is used for training. This phenomenon has several important consequences when $k \\ll d$. First, by employing uniform convergence on this smaller subspace, we establish a generalization error bound of $\\mathcal{O}(\\sqrt{{kd}/{T}})$ after $T$ iterations of SGD, which is independent of the width of the NN. We further demonstrate that, by recovering the principal direction, SGD-trained ReLU NNs can learn a single-index target of the form $y=f(\\langle\\boldsymbol{u},\\boldsymbol{x}\\rangle) + \\epsilon$ with a sample complexity linear in $d$ (up to log factors), where $f$ is a monotonic function with at most polynomial growth, and $\\epsilon$ is the noise. This is in contrast to the known $d^{\\Omega(p)}$ samples required to learn any degree $p$ polynomial in the kernel regime, and shows that SGD-trained NNs can outperform the Neural Tangent Kernel at initialization. Finally, we establish compressibility guarantees for NNs using that SGD produces an approximately rank-$k$ first-layer weight matrix.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Theory (eg, control theory, learning theory, algorithmic game theory)", "paperhash": "mousavihosseini|neural_networks_efficiently_learn_lowdimensional_representations_with_sgd", "pdf": "/pdf/1240f349d491e95499f0c82e7a0de39047d53f8e.pdf", "_bibtex": "@inproceedings{\nmousavi-hosseini2023neural,\ntitle={Neural Networks Efficiently Learn Low-Dimensional Representations with {SGD}},\nauthor={Alireza Mousavi-Hosseini and Sejun Park and Manuela Girotti and Ioannis Mitliagkas and Murat A Erdogdu},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=6taykzqcPD}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279270362, "odate": 1664468100000, "details": {"replyCount": 9}}, {"id": "MYEap_OcQI", "original": "enFmSxwEkrb", "number": 3252, "cdate": 1663850180531, "mdate": null, "ddate": null, "tcdate": 1663850180531, "tmdate": 1697935519805, "tddate": null, "forum": "MYEap_OcQI", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Does Zero-Shot Reinforcement Learning Exist?", "authorids": ["~Ahmed_Touati1", "~J\u00e9r\u00e9my_Rapin1", "~Yann_Ollivier2"], "authors": ["Ahmed Touati", "J\u00e9r\u00e9my Rapin", "Yann Ollivier"], "keywords": ["controllable agents", "zero-shot RL", "self-supervised representation learning", "successor representation", "offline RL"], "TL;DR": "We revisit zero-shot RL based on successor representations, we introduce improved losses and new models and evaluate them systematically on the unsupervised RL benchmark.", "abstract": "A zero-shot RL agent is an agent that can solve any RL task in a given environment, instantly with no additional planning or learning, after an initial reward-free learning phase. This marks a shift from the reward-centric RL paradigm towards controllable agents that can follow arbitrary instructions in an environment. Current RL agents can solve families of related tasks at best, or require planning anew for each task. Strategies for approximate zero-shot RL have been suggested using successor features (SFs) (Borsa et al., 2018) or forward-backward (FB) representations (Touati & Ollivier, 2021), but testing has been limited. \nAfter clarifying the relationships between these schemes, we introduce improved losses and new SF models, and test the viability of zero-shot RL schemes systematically on tasks from the Unsupervised RL benchmark (Laskin et al., 2021). To disentangle universal representation learning from exploration, we work in an offline setting and repeat the tests on several existing replay buffers.\nSFs appear to suffer from the choice of the elementary state features. SFs with Laplacian eigenfunctions do well, while SFs based on auto-encoders, inverse curiosity, transition models, low-rank transition matrix, contrastive learning, or diversity (APS),  perform unconsistently. In contrast, FB representations jointly learn the elementary and successor features from a single, principled criterion. They perform best and consistently across the board, reaching $85\\%$ of supervised RL performance with a good replay buffer, in a zero-shot manner.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)", "paperhash": "touati|does_zeroshot_reinforcement_learning_exist", "pdf": "/pdf/63a8b5a5af811abc3b027de6cccef1854dbedc3c.pdf", "supplementary_material": "", "_bibtex": "@inproceedings{\ntouati2023does,\ntitle={Does Zero-Shot Reinforcement Learning Exist?},\nauthor={Ahmed Touati and J{\\'e}r{\\'e}my Rapin and Yann Ollivier},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=MYEap_OcQI}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2209.14935/code)"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279270153, "odate": 1664468100000, "details": {"replyCount": 15}}, {"id": "TfBHFLgv77", "original": "QdRa5D1qxw", "number": 3244, "cdate": 1663850179589, "mdate": null, "ddate": null, "tcdate": 1663850179589, "tmdate": 1677693575228, "tddate": null, "forum": "TfBHFLgv77", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Hyperbolic Deep Reinforcement Learning", "authorids": ["~Edoardo_Cetin1", "~Benjamin_Paul_Chamberlain1", "~Michael_M._Bronstein1", "~Jonathan_J_Hunt1"], "authors": ["Edoardo Cetin", "Benjamin Paul Chamberlain", "Michael M. Bronstein", "Jonathan J Hunt"], "keywords": ["Reinforcement learning", "Hyperbolic space", "Representation learning", "Machine learning"], "TL;DR": "We use hyperbolic space to model the latent representations of deep RL algorithms, attaining great performance and generalization benefits.", "abstract": "In deep reinforcement learning (RL), useful information about the state is inherently tied to its possible future successors. Consequently, encoding features that capture the hierarchical relationships between states into the model's latent representations is often conducive to recovering effective policies. In this work, we study a new class of deep RL algorithms that promote encoding such relationships by using hyperbolic space to model latent representations. However, we find that a naive application of existing methodology from the hyperbolic deep learning literature leads to fatal instabilities due to the non-stationarity and variance characterizing common gradient estimators in RL. Hence, we design a new general method that directly addresses such optimization challenges and enables stable end-to-end learning with deep hyperbolic representations. We empirically validate our framework by applying it to popular on-policy and off-policy RL algorithms on the Procgen and Atari 100K benchmarks, attaining near universal performance and generalization benefits. Given its natural fit, we hope this work will inspire future RL research to consider hyperbolic representations as a standard tool.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)", "paperhash": "cetin|hyperbolic_deep_reinforcement_learning", "pdf": "/pdf/9fac2de989afbbe7a7767c39f7d03bdb640f3016.pdf", "supplementary_material": "/attachment/492d8b959e7b487c18e2888458946eca1b5ea6ad.zip", "_bibtex": "@inproceedings{\ncetin2023hyperbolic,\ntitle={Hyperbolic Deep Reinforcement Learning},\nauthor={Edoardo Cetin and Benjamin Paul Chamberlain and Michael M. Bronstein and Jonathan J Hunt},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=TfBHFLgv77}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279269468, "odate": 1664468100000, "details": {"replyCount": 14}}, {"id": "PbfgkZ2HdbE", "original": "ncwjCsq_HD2", "number": 3242, "cdate": 1663850179352, "mdate": null, "ddate": null, "tcdate": 1663850179352, "tmdate": 1677741234513, "tddate": null, "forum": "PbfgkZ2HdbE", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Learning Controllable Adaptive Simulation for Multi-resolution Physics", "authorids": ["~Tailin_Wu1", "~Takashi_Maruyama2", "~Qingqing_Zhao1", "~Gordon_Wetzstein3", "~Jure_Leskovec1"], "authors": ["Tailin Wu", "Takashi Maruyama", "Qingqing Zhao", "Gordon Wetzstein", "Jure Leskovec"], "keywords": ["adaptive", "multi-scale", "error vs. computation", "controllable"], "TL;DR": "We introduce a method jointly learns the surrogate model and dynamically selects appropriate spatial resolutions that devote more compute to the highly dynamic regions", "abstract": "Simulating the time evolution of physical systems is pivotal in many scientific and engineering problems. An open challenge in simulating such systems is their multi-resolution dynamics: a small fraction of the system is extremely dynamic, and requires very fine-grained resolution, while a majority of the system is changing slowly and can be modeled by coarser spatial scales. Typical learning-based surrogate models use a uniform spatial scale, which needs to resolve to the finest required scale and can waste a huge compute to achieve required accuracy. In this work, we introduce Learning controllable Adaptive simulation for Multi-resolution Physics (LAMP) as the first full deep learning-based surrogate model that jointly learns the evolution model and optimizes appropriate spatial resolutions that devote more compute to the highly dynamic regions. LAMP consists of a Graph Neural Network (GNN) for learning the forward evolution, and a GNN-based actor-critic for learning the policy of spatial refinement and coarsening. We introduce learning techniques that optimizes LAMP with weighted sum of error and computational cost as objective, allowing LAMP to adapt to varying relative importance of error vs. computation tradeoff at inference time. We evaluate our method in a 1D benchmark of nonlinear PDEs and a challenging 2D mesh-based simulation. We demonstrate that our LAMP outperforms state-of-the-art deep learning surrogate models, and can adaptively trade-off computation to improve long-term prediction error: it achieves an average of 33.7% error reduction for 1D nonlinear PDEs, and outperforms  MeshGraphNets + classical Adaptive Mesh Refinement (AMR) in 2D mesh-based simulations. Project website with data and code can be found at: http://snap.stanford.edu/lamp.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )", "paperhash": "wu|learning_controllable_adaptive_simulation_for_multiresolution_physics", "pdf": "/pdf/6c5914ffbccd510000a84a0f0aad7cb9fdfbf835.pdf", "supplementary_material": "/attachment/5f94078815937f73bf15a1acee2f32ebf16e1902.zip", "_bibtex": "@inproceedings{\nwu2023learning,\ntitle={Learning Controllable Adaptive Simulation for Multi-resolution Physics},\nauthor={Tailin Wu and Takashi Maruyama and Qingqing Zhao and Gordon Wetzstein and Jure Leskovec},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=PbfgkZ2HdbE}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279269415, "odate": 1664468100000, "details": {"replyCount": 25}}, {"id": "Mpa3tRJFBb", "original": "-kDhZNPVeg", "number": 3204, "cdate": 1663850175013, "mdate": null, "ddate": null, "tcdate": 1663850175013, "tmdate": 1677548353523, "tddate": null, "forum": "Mpa3tRJFBb", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Where to Begin? On the Impact of Pre-Training and Initialization in Federated Learning", "authorids": ["~John_Nguyen1", "~Jianyu_Wang2", "~Kshitiz_Malik2", "~Maziar_Sanjabi1", "~Michael_Rabbat1"], "authors": ["John Nguyen", "Jianyu Wang", "Kshitiz Malik", "Maziar Sanjabi", "Michael Rabbat"], "keywords": ["federated learning", "optimization"], "TL;DR": "Stop worrying about heterogeneity and start from pre-trained weights.", "abstract": "An oft-cited challenge of federated learning is the presence of heterogeneity. \\emph{Data heterogeneity} refers to the fact that data from different clients may follow very different distributions. \\emph{System heterogeneity} refers to client devices having different system capabilities. A considerable number of federated optimization methods address this challenge. In the literature, empirical evaluations usually start federated training from random initialization. However, in many practical applications of federated learning, the server has access to proxy data for the training task that can be used to pre-train a model before starting federated training. Using four standard federated learning benchmark datasets, we empirically study the impact of starting from a pre-trained model in federated learning. Unsurprisingly, starting from a pre-trained model reduces the training time required to reach a target error rate and enables the training of more accurate models (up to 40\\%) than is possible when starting from random initialization. Surprisingly, we also find that starting federated learning from a pre-trained initialization reduces the effect of both data and system heterogeneity. We recommend future work proposing and evaluating federated optimization methods to evaluate the performance when starting from random and pre-trained initializations. This study raises several questions for further work on understanding the role of heterogeneity in federated optimization.", "pdf": "/pdf/270568c6d80daef0fdc3934838d90aba2eb3610c.pdf", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Deep Learning and representational learning", "paperhash": "nguyen|where_to_begin_on_the_impact_of_pretraining_and_initialization_in_federated_learning", "supplementary_material": "/attachment/a5ac0842a4260488fe734ff835266c7882c12307.zip", "_bibtex": "@inproceedings{\nnguyen2023where,\ntitle={Where to Begin? On the Impact of Pre-Training and Initialization in Federated Learning},\nauthor={John Nguyen and Jianyu Wang and Kshitiz Malik and Maziar Sanjabi and Michael Rabbat},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=Mpa3tRJFBb}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279267045, "odate": 1664468100000, "details": {"replyCount": 19}}, {"id": "F_EhNDSamN", "original": "ej2L0-qNWZZ", "number": 3193, "cdate": 1663850173685, "mdate": null, "ddate": null, "tcdate": 1663850173685, "tmdate": 1697935526963, "tddate": null, "forum": "F_EhNDSamN", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Parametrizing Product Shape Manifolds by Composite Networks", "authorids": ["~Josua_Sassen1", "~Klaus_Hildebrandt1", "~Martin_Rumpf1", "~Benedikt_Wirth1"], "authors": ["Josua Sassen", "Klaus Hildebrandt", "Martin Rumpf", "Benedikt Wirth"], "keywords": ["shape spaces", "product manifolds", "nonlinear statistics", "low-dimensional data manifolds"], "abstract": "Parametrizations of data manifolds in shape spaces can be computed using the rich toolbox of Riemannian geometry. This, however, often comes with high computational costs, which raises the question if one can learn an efficient neural network approximation. We show that this is indeed possible for shape spaces with a special product structure, namely those smoothly approximable by a direct sum of low-dimensional manifolds. Our proposed architecture leverages this structure by separately learning approximations for the low-dimensional factors and a subsequent combination. After developing the approach as a general framework, we apply it to a shape space of triangular surfaces. Here, typical examples of data manifolds are given through datasets of articulated models and can be factorized, for example, by a Sparse Principal Geodesic Analysis (SPGA). We demonstrate the effectiveness of our proposed approach with experiments on synthetic data as well as manifolds extracted from data via SPGA.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Deep Learning and representational learning", "paperhash": "sassen|parametrizing_product_shape_manifolds_by_composite_networks", "pdf": "/pdf/2832887c23c3957ac23c919a6f7a43abde5a7ef2.pdf", "_bibtex": "@inproceedings{\nsassen2023parametrizing,\ntitle={Parametrizing Product Shape Manifolds by Composite Networks},\nauthor={Josua Sassen and Klaus Hildebrandt and Martin Rumpf and Benedikt Wirth},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=F_EhNDSamN}\n}", "supplementary_material": "/attachment/53d366369d9788f1052b60d4bfa9c9cc517d2b5d.zip", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2302.14665/code)"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279266034, "odate": 1664468100000, "details": {"replyCount": 8}}, {"id": "zKvm1ETDOq", "original": "iVI0VIOdsA", "number": 3166, "cdate": 1663850170452, "mdate": null, "ddate": null, "tcdate": 1663850170452, "tmdate": 1677774628183, "tddate": null, "forum": "zKvm1ETDOq", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Is Adversarial Training Really a Silver Bullet for Mitigating Data Poisoning?", "authorids": ["~Rui_Wen3", "~Zhengyu_Zhao1", "~Zhuoran_Liu1", "director@cispa.de", "~Tianhao_Wang3", "~Yang_Zhang15"], "authors": ["Rui Wen", "Zhengyu Zhao", "Zhuoran Liu", "Michael Backes", "Tianhao Wang", "Yang Zhang"], "keywords": ["Data poisoning", "adversarial training", "indiscriminative features", "adaptive defenses", "robust vs. non-robust features"], "abstract": "Indiscriminate data poisoning can decrease the clean test accuracy of a deep learning model by slightly perturbing its training samples.\nThere is a consensus that such poisons can hardly harm adversarially-trained (AT) models when the adversarial training budget is no less than the poison budget, i.e., $\\epsilon_\\mathrm{adv}\\geq\\epsilon_\\mathrm{poi}$. This consensus, however, is challenged in this paper based on our new attack strategy that induces \\textit{entangled features} (EntF). The existence of entangled features makes the poisoned data become less useful for training a model, no matter if AT is applied or not. We demonstrate that for attacking a CIFAR-10 AT model under a reasonable setting with $\\epsilon_\\mathrm{adv}=\\epsilon_\\mathrm{poi}=8/255$, our EntF yields an accuracy drop of $13.31\\%$, which is $7\\times$ better than existing methods and equal to discarding $83\\%$ training data. We further show the generalizability of EntF to more challenging settings, e.g., higher AT budgets, partial poisoning, unseen model architectures, and stronger (ensemble or adaptive) defenses. We finally provide new insights into the distinct roles of non-robust vs. robust features in poisoning standard vs. AT models and demonstrate the possibility of using a hybrid attack to poison standard and AT models simultaneously. Our code is available at~\\url{https://github.com/WenRuiUSTC/EntF}.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)", "paperhash": "wen|is_adversarial_training_really_a_silver_bullet_for_mitigating_data_poisoning", "TL;DR": "We propose an indiscriminative feature-based poisoning approach to substantially degrade adversarial training, which was previously considered to be impossible.", "pdf": "/pdf/bcce19ed68bdb0a34957207b9b69cebedeab384c.pdf", "_bibtex": "@inproceedings{\nwen2023is,\ntitle={Is Adversarial Training Really a Silver Bullet for Mitigating Data Poisoning?},\nauthor={Rui Wen and Zhengyu Zhao and Zhuoran Liu and Michael Backes and Tianhao Wang and Yang Zhang},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=zKvm1ETDOq}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279264375, "odate": 1664468100000, "details": {"replyCount": 25}}, {"id": "P3PJokAqGW", "original": "jMWAl-SaSU", "number": 3163, "cdate": 1663850170098, "mdate": null, "ddate": null, "tcdate": 1663850170098, "tmdate": 1697935530881, "tddate": null, "forum": "P3PJokAqGW", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Learning with Stochastic Orders", "authorids": ["~Carles_Domingo-Enrich1", "~Yair_Schiff1", "~Youssef_Mroueh1"], "authors": ["Carles Domingo-Enrich", "Yair Schiff", "Youssef Mroueh"], "keywords": ["optimal transport", "stochastic order", "Choquet order", "convex function", "input convex neural network", "integral probability metric", "image generation", "statistical rates"], "TL;DR": "We propose and study discrepancies and distances between probability measures that arise from the convex or Choquet order, which capture dominance constraints and are useful in applications like image generation.", "abstract": "Learning high-dimensional distributions is often done with explicit likelihood modeling or implicit modeling via minimizing integral probability metrics (IPMs). In this paper, we expand this learning paradigm to stochastic orders, namely, the convex or Choquet order between probability measures. Towards this end, exploiting the relation between convex orders and optimal transport, we introduce the Choquet-Toland distance between probability measures, that can be used as a drop-in replacement for IPMs. We also introduce the Variational Dominance Criterion (VDC) to learn probability measures with dominance constraints, that encode the desired stochastic order between the learned measure and a known baseline. We analyze both quantities and show that they suffer from the curse of dimensionality and propose surrogates via input convex maxout networks (ICMNs), that enjoy parametric rates. We provide a min-max framework for learning with stochastic orders and validate it experimentally on synthetic and high-dimensional image generation, with promising results. Finally, our ICMNs class of convex functions and its derived Rademacher Complexity are of independent interest beyond their application in convex orders. Code to reproduce experimental results is available at https://github.com/yair-schiff/stochastic-orders-ICMN.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Theory (eg, control theory, learning theory, algorithmic game theory)", "paperhash": "domingoenrich|learning_with_stochastic_orders", "pdf": "/pdf/69bf232a5f31365934fcdc570925118eede29e06.pdf", "supplementary_material": "/attachment/981c2a5e7614e0fe73e671c24e61a7b452789845.zip", "_bibtex": "@inproceedings{\ndomingo-enrich2023learning,\ntitle={Learning with Stochastic Orders},\nauthor={Carles Domingo-Enrich and Yair Schiff and Youssef Mroueh},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=P3PJokAqGW}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 4 code implementations](https://www.catalyzex.com/paper/arxiv:2205.13684/code)"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279264247, "odate": 1664468100000, "details": {"replyCount": 5}}, {"id": "6ve2CkeQe5S", "original": "AF0lFQyAox", "number": 3161, "cdate": 1663850169863, "mdate": null, "ddate": null, "tcdate": 1663850169863, "tmdate": 1697935531310, "tddate": null, "forum": "6ve2CkeQe5S", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "MEDFAIR: Benchmarking Fairness for Medical Imaging", "authorids": ["~Yongshuo_Zong1", "~Yongxin_Yang1", "~Timothy_Hospedales1"], "authors": ["Yongshuo Zong", "Yongxin Yang", "Timothy Hospedales"], "keywords": ["Fairness", "Bias Mitigation", "Medical Imaging", "Benchmark"], "TL;DR": "We develop a fairness benchmark for medical imaging and find that the state-of-the-art bias mitigation algorithm does not significantly outperform ERM.", "abstract": "A multitude of work has shown that machine learning-based medical diagnosis systems can be biased against certain subgroups of people. This has motivated a growing number of bias mitigation algorithms that aim to address fairness issues in machine learning. However, it is difficult to compare their effectiveness in medical imaging for two reasons. First, there is little consensus on the criteria to assess fairness. Second, existing bias mitigation algorithms are developed under different settings, e.g., datasets, model selection strategies, backbones, and fairness metrics, making a direct comparison and evaluation based on existing results impossible. In this work, we introduce MEDFAIR, a framework to benchmark the fairness of machine learning models for medical imaging. MEDFAIR covers eleven algorithms from various categories, ten datasets from different imaging modalities, and three model selection criteria. Through extensive experiments, we find that the under-studied issue of model selection criterion can have a significant impact on fairness outcomes; while in contrast, state-of-the-art bias mitigation algorithms do not significantly improve fairness outcomes over empirical risk minimization (ERM) in both in-distribution and out-of-distribution settings. We evaluate fairness from various perspectives and make recommendations for different medical application scenarios that require different ethical principles. Our framework provides a reproducible and easy-to-use entry point for the development and evaluation of future bias mitigation algorithms in deep learning. Code is available at https://github.com/ys-zong/MEDFAIR.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)", "paperhash": "zong|medfair_benchmarking_fairness_for_medical_imaging", "pdf": "/pdf/75dab3d31898ee627528af860910801000bfc9c1.pdf", "supplementary_material": "/attachment/ec90176413847af39ce2ee80f1a7df4702f58aa3.zip", "_bibtex": "@inproceedings{\nzong2023medfair,\ntitle={{MEDFAIR}: Benchmarking Fairness for Medical Imaging},\nauthor={Yongshuo Zong and Yongxin Yang and Timothy Hospedales},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=6ve2CkeQe5S}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 3 code implementations](https://www.catalyzex.com/paper/arxiv:2210.01725/code)"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279264142, "odate": 1664468100000, "details": {"replyCount": 16}}, {"id": "TUBpc5rqGA", "original": "KGNp7UorsC", "number": 3145, "cdate": 1663850167967, "mdate": null, "ddate": null, "tcdate": 1663850167967, "tmdate": 1697935533703, "tddate": null, "forum": "TUBpc5rqGA", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Neural Design for Genetic Perturbation Experiments", "authorids": ["~Aldo_Pacchiano1", "~Drausin_Wulsin1", "~Robert_A_Barton1", "luis@immunai.com"], "authors": ["Aldo Pacchiano", "Drausin Wulsin", "Robert A Barton", "Luis Voloch"], "keywords": ["genetiic perturbation experiments", "gene disco", "optimism", "neural optimism"], "TL;DR": "We introduce and analyze many tractable methods for noiseless optimistic arm elimination with applications in genetic perturbation experiments.", "abstract": "The problem of how to genetically modify cells in order to maximize a certain cellular phenotype has taken center stage in drug development over the last few years (with, for example, genetically edited CAR-T, CAR-NK, and CAR-NKT cells entering cancer clinical trials). Exhausting the search space for all possible genetic edits (perturbations) or combinations thereof is infeasible due to cost and experimental limitations. This work provides a theoretically sound framework for iteratively exploring the space of perturbations in pooled batches in order to maximize a target phenotype under an experimental budget. Inspired by this application domain, we study the problem of batch query bandit optimization and introduce the Optimistic Arm Elimination ($\\mathrm{OAE}$) principle designed to find an almost optimal arm under different functional relationships between the queries (arms) and the outputs (rewards). We analyze the convergence properties of $\\mathrm{OAE}$ by relating it to the Eluder dimension of the algorithm's function class and validate that $\\mathrm{OAE}$ outperforms other strategies in finding optimal actions in experiments on simulated problems, public datasets well-studied in bandit contexts, and in genetic perturbation datasets when the regression model is a deep neural network. OAE also outperforms the benchmark algorithms in 3 of 4 datasets in the GeneDisco experimental planning challenge. ", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )", "paperhash": "pacchiano|neural_design_for_genetic_perturbation_experiments", "pdf": "/pdf/f56ee4a8d1d86d0f8b8aba389f8502186aeab60b.pdf", "supplementary_material": "/attachment/ffb6f99135593550230f2491700fb42284a2917c.zip", "_bibtex": "@inproceedings{\npacchiano2023neural,\ntitle={Neural Design for Genetic Perturbation Experiments},\nauthor={Aldo Pacchiano and Drausin Wulsin and Robert A Barton and Luis Voloch},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=TUBpc5rqGA}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2207.12805/code)"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279262918, "odate": 1664468100000, "details": {"replyCount": 25}}, {"id": "R98ZfMt-jE", "original": "Ljs2hNYzfp", "number": 3131, "cdate": 1663850166272, "mdate": null, "ddate": null, "tcdate": 1663850166272, "tmdate": 1677733949592, "tddate": null, "forum": "R98ZfMt-jE", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Efficient Discrete Multi Marginal Optimal Transport Regularization", "authorids": ["~Ronak_Mehta1", "~Jeffery_Kline1", "~Vishnu_Suresh_Lokhande1", "~Glenn_Fung2", "~Vikas_Singh1"], "authors": ["Ronak Mehta", "Jeffery Kline", "Vishnu Suresh Lokhande", "Glenn Fung", "Vikas Singh"], "keywords": ["optimal transport", "multi-marginal", "earth mover's distance", "fairness"], "TL;DR": "Using a fast algorithm for computing generalized earth mover's distances, we solve practical discrete multi-marginal optimal transport problems in neural network learning applications.", "abstract": "Optimal transport has emerged as a powerful tool for a variety of problems in machine learning, and it is frequently used to enforce distributional constraints. In this context, existing methods often use either a Wasserstein metric, or else they apply concurrent barycenter approaches when more than two distributions are considered. In this paper, we  leverage multi-marginal optimal transport (MMOT), where we take advantage of a procedure that computes a generalized earth mover's distance as a sub-routine. We show that not only is our algorithm computationally more efficient compared to other barycentric-based distance methods, but it has the additional advantage that gradients used for backpropagation can be efficiently computed during the forward pass computation itself, which leads to substantially faster model training. We provide technical details about this new regularization term and its properties, and we present experimental demonstrations of faster runtimes when compared to standard Wasserstein-style methods. Finally, on a range of experiments designed to assess effectiveness at enforcing fairness, we demonstrate our method compares well with alternatives.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Optimization (eg, convex and non-convex optimization)", "paperhash": "mehta|efficient_discrete_multi_marginal_optimal_transport_regularization", "pdf": "/pdf/751b7f72b933e8842e1162601b80445c8fa2b7c7.pdf", "supplementary_material": "/attachment/b9427c84e18c7e95294487c9726e240d99ca5c59.zip", "_bibtex": "@inproceedings{\nmehta2023efficient,\ntitle={Efficient Discrete Multi Marginal Optimal Transport Regularization},\nauthor={Ronak Mehta and Jeffery Kline and Vishnu Suresh Lokhande and Glenn Fung and Vikas Singh},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=R98ZfMt-jE}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279262180, "odate": 1664468100000, "details": {"replyCount": 14}}, {"id": "xSsW2Am-ukZ", "original": "NY3nDyH4Qxw", "number": 3123, "cdate": 1663850165322, "mdate": null, "ddate": null, "tcdate": 1663850165322, "tmdate": 1681504786975, "tddate": null, "forum": "xSsW2Am-ukZ", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Unmasking the Lottery Ticket Hypothesis: What's Encoded in a Winning Ticket's Mask?", "authorids": ["~Mansheej_Paul1", "~Feng_Chen13", "~Brett_W._Larsen1", "~Jonathan_Frankle1", "~Surya_Ganguli1", "~Gintare_Karolina_Dziugaite1"], "authors": ["Mansheej Paul", "Feng Chen", "Brett W. Larsen", "Jonathan Frankle", "Surya Ganguli", "Gintare Karolina Dziugaite"], "keywords": ["linear mode connectivity", "iterative magnitude pruning", "loss landscape geometry", "lottery ticket hypothesis", "sparsity"], "abstract": "As neural networks get larger and costlier, it is important to find sparse networks that require less compute and memory but can be trained to the same accuracy as the full network (i.e. matching). Iterative magnitude pruning (IMP) is a state of the art algorithm that can find such highly sparse matching subnetworks, known as winning tickets. IMP iterates through cycles of training, pruning a fraction of smallest magnitude weights, rewinding unpruned weights back to an early training point, and repeating. Despite its simplicity, the principles underlying when and how IMP finds winning tickets remain elusive. In particular, what useful information does an IMP mask found at the end of training convey to a rewound network near the beginning of training? How does SGD allow the network to extract this information? And why is iterative pruning needed, i.e. why can't we prune to very high sparsities in one shot? We investigate these questions through the lens of the geometry of the error landscape. First, we find that\u2014at higher sparsities\u2014pairs of pruned networks at successive pruning iterations are connected by a linear path with zero error barrier if and only if they are matching. This indicates that masks found at the end of training convey to the rewind point the identity of an axial subspace that intersects a desired linearly connected mode of a matching sublevel set. Second, we show SGD can exploit this information due to a strong form of robustness: it can return to this mode despite strong perturbations early in training. Third, we show how the flatness of the error landscape at the end of training limits the fraction of weights that can be pruned at each iteration of IMP. This analysis yields a new quantitative link between IMP performance and the Hessian eigenspectrum. Finally, we show that the role of retraining in IMP is to find a network with new small weights to prune. Overall, these results make progress toward demystifying the existence of winning tickets by revealing the fundamental role of error landscape geometry in the algorithms used to find them.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Deep Learning and representational learning", "paperhash": "paul|unmasking_the_lottery_ticket_hypothesis_whats_encoded_in_a_winning_tickets_mask", "TL;DR": "We provide an error landscape perspective on what information is encoded in a winning ticket's mask and how Iterative Magnitude Pruning finds matching subnetworks.", "pdf": "/pdf/4dbbc1d35dfd048e01a703f7058ecec7d030cfea.pdf", "_bibtex": "@inproceedings{\npaul2023unmasking,\ntitle={Unmasking the Lottery Ticket Hypothesis: What's Encoded in a Winning Ticket's Mask?},\nauthor={Mansheej Paul and Feng Chen and Brett W. Larsen and Jonathan Frankle and Surya Ganguli and Gintare Karolina Dziugaite},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=xSsW2Am-ukZ}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279261475, "odate": 1664468100000, "details": {"replyCount": 13}}, {"id": "TatRHT_1cK", "original": "aXGy9O1LgqO", "number": 3116, "cdate": 1663850164469, "mdate": null, "ddate": null, "tcdate": 1663850164469, "tmdate": 1697935537908, "tddate": null, "forum": "TatRHT_1cK", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Quantifying Memorization Across Neural Language Models", "authorids": ["~Nicholas_Carlini1", "~Daphne_Ippolito1", "~Matthew_Jagielski1", "~Katherine_Lee1", "~Florian_Tramer1", "~Chiyuan_Zhang1"], "authors": ["Nicholas Carlini", "Daphne Ippolito", "Matthew Jagielski", "Katherine Lee", "Florian Tramer", "Chiyuan Zhang"], "keywords": ["memorization", "large language models", "duplication"], "TL;DR": "Model size, duplication, and context length all impact how easy it is to extract training data from large language models.", "abstract": "Large language models (LMs) have been shown to memorize parts of their training data, and when prompted appropriately, they will emit the memorized training data verbatim. This is undesirable because memorization violates privacy (exposing user data), degrades utility (repeated easy-to-memorize text is often low quality), and hurts fairness (some texts are memorized over others).\nWe describe three log-linear relationships that quantify the degree to which LMs emit memorized training data. Memorization significantly grows as we increase (1) the capacity of a model, (2) the number of times an example has been duplicated, and (3) the number of tokens of context used to prompt the model. Surprisingly, we find the situation becomes complicated when generalizing these results across model families. On the whole, we find that memorization in LMs is more prevalent than previously believed and will likely get worse as models continues to scale, at least without active mitigations.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)", "paperhash": "carlini|quantifying_memorization_across_neural_language_models", "pdf": "/pdf/6b4201e769d9dc79c8462750821d94951ee50a84.pdf", "_bibtex": "@inproceedings{\ncarlini2023quantifying,\ntitle={Quantifying Memorization Across Neural Language Models},\nauthor={Nicholas Carlini and Daphne Ippolito and Matthew Jagielski and Katherine Lee and Florian Tramer and Chiyuan Zhang},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=TatRHT_1cK}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 2 code implementations](https://www.catalyzex.com/paper/arxiv:2202.07646/code)"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279261273, "odate": 1664468100000, "details": {"replyCount": 18}}, {"id": "AWZgXGmsbA", "original": "3cnCwMWXM9q", "number": 3114, "cdate": 1663850164240, "mdate": null, "ddate": null, "tcdate": 1663850164240, "tmdate": 1677717320684, "tddate": null, "forum": "AWZgXGmsbA", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Powderworld: A Platform for Understanding Generalization via Rich Task Distributions", "authorids": ["~Kevin_Frans1", "~Phillip_Isola1"], "authors": ["Kevin Frans", "Phillip Isola"], "keywords": ["reinforcement learning", "environment", "generalization", "out-of-distribution", "multi-task"], "abstract": "One of the grand challenges of reinforcement learning is the ability to generalize to new tasks. However, general agents require a set of rich, diverse tasks to train on. Designing a `foundation environment' for such tasks is tricky -- the ideal environment would support a range of emergent phenomena, an expressive task space, and fast runtime. To take a step towards addressing this research bottleneck, this work presents Powderworld, a lightweight yet expressive simulation environment running directly on the GPU. Within Powderworld, two motivating task distributions are presented, one for world-modelling and one for reinforcement learning. Each contains hand-designed test tasks to examine generalization. Experiments indicate that increasing the environment's complexity improves generalization for world models, yet causes reinforcement learning agents to struggle. Powderworld aims to support the study of generalization by providing a source of diverse tasks arising from the same core rules.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)", "paperhash": "frans|powderworld_a_platform_for_understanding_generalization_via_rich_task_distributions", "TL;DR": "Powderworld is an environment supporting the study of generalization by providing diverse tasks arising from the same core rules.", "pdf": "/pdf/2fadf0fbbebe9f361cc99785d5c8977657738d68.pdf", "supplementary_material": "/attachment/910a9af121317edc7a43ab973d613003673e2fda.zip", "_bibtex": "@inproceedings{\nfrans2023powderworld,\ntitle={Powderworld: A Platform for Understanding Generalization via Rich Task Distributions},\nauthor={Kevin Frans and Phillip Isola},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=AWZgXGmsbA}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279261128, "odate": 1664468100000, "details": {"replyCount": 15}}, {"id": "kJUS5nD0vPB", "original": "Ek5WYtd-k6B", "number": 3086, "cdate": 1663850160820, "mdate": null, "ddate": null, "tcdate": 1663850160820, "tmdate": 1677542452843, "tddate": null, "forum": "kJUS5nD0vPB", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Out-of-Distribution Detection and Selective Generation for Conditional Language Models", "authorids": ["~Jie_Ren2", "~Jiaming_Luo2", "~Yao_Zhao5", "~Kundan_Krishna1", "~Mohammad_Saleh1", "~Balaji_Lakshminarayanan1", "~Peter_J_Liu1"], "authors": ["Jie Ren", "Jiaming Luo", "Yao Zhao", "Kundan Krishna", "Mohammad Saleh", "Balaji Lakshminarayanan", "Peter J Liu"], "keywords": ["Out-of-distribution Detection", "Natural Language Generation", "Selective Generation", "Uncertainty"], "abstract": "Machine learning algorithms typically assume independent and identically distributed samples in training and at test time (IID). Much work has shown that high-performing ML classifiers can degrade significantly and provide overly-confident, wrong classification predictions,  particularly for out-of-distribution (OOD) inputs. Conditional language models (CLMs) are predominantly trained to classify the next token in an output sequence, and may suffer even worse degradation on OOD inputs as the prediction is done auto-regressively over many steps. Furthermore, the space of potential low-quality outputs is larger as arbitrary text can be generated and it is important to know when to trust the generated output. We present a highly accurate and lightweight OOD detection method for CLMs, and demonstrate its effectiveness on abstractive summarization and translation. We also show how our method can be used under the common and realistic setting of distribution shift for selective generation (analogous to selective prediction for classification) of high-quality outputs, while  automatically abstaining from low-quality ones, enabling safer deployment of generative language models.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Applications (eg, speech processing, computer vision, NLP)", "paperhash": "ren|outofdistribution_detection_and_selective_generation_for_conditional_language_models", "TL;DR": "A simple, fast, effective method for out-of-distribution detection and selective generation for conditional language models.", "pdf": "/pdf/f47874745e38526618ae5e9fd6012d1584ed30a1.pdf", "_bibtex": "@inproceedings{\nren2023outofdistribution,\ntitle={Out-of-Distribution Detection and Selective Generation for Conditional Language Models},\nauthor={Jie Ren and Jiaming Luo and Yao Zhao and Kundan Krishna and Mohammad Saleh and Balaji Lakshminarayanan and Peter J Liu},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=kJUS5nD0vPB}\n}", "supplementary_material": "/attachment/b29b9d7b823527747e08f0cc059261a8f7b0cf1e.zip", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279259506, "odate": 1664468100000, "details": {"replyCount": 15}}, {"id": "3UHoYrglYkG", "original": "KTTJuNTYbFy", "number": 3066, "cdate": 1663850158355, "mdate": null, "ddate": null, "tcdate": 1663850158355, "tmdate": 1677230524325, "tddate": null, "forum": "3UHoYrglYkG", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Differentially Private $L_2$-Heavy Hitters in the Sliding Window Model", "authorids": ["~Jeremiah_Blocki2", "~Seunghoon_Lee1", "~Tamalika_Mukherjee1", "~Samson_Zhou1"], "authors": ["Jeremiah Blocki", "Seunghoon Lee", "Tamalika Mukherjee", "Samson Zhou"], "keywords": ["differential privacy", "heavy hitters", "streaming algorithms", "sliding window model"], "abstract": "The data management of large companies often prioritize more recent data, as a source of higher accuracy prediction than outdated data. For example, the Facebook data policy retains user search histories for $6$ months while the Google data retention policy states that browser information may be stored for up to $9$ months. These policies are captured by the sliding window model, in which only the most recent $W$ statistics form the underlying dataset. In this paper, we consider the problem of privately releasing the $L_2$-heavy hitters in the sliding window model, which include $L_p$-heavy hitters for $p\\le 2$ and in some sense are the strongest possible guarantees that can be achieved using polylogarithmic space, but cannot be handled by existing techniques due to the sub-additivity of the $L_2$ norm. Moreover, existing non-private sliding window algorithms use the smooth histogram framework, which has high sensitivity. To overcome these barriers, we introduce the first differentially private algorithm for $L_2$-heavy hitters in the sliding window model by initiating a number of $L_2$-heavy hitter algorithms across the stream with significantly lower threshold. Similarly, we augment the algorithms with an approximate frequency tracking algorithm with significantly higher accuracy. We then use smooth sensitivity and statistical distance arguments to show that we can add noise proportional to an estimation of the $L_2$ norm. To the best of our knowledge, our techniques are the first to privately release statistics that are related to a sub-additive function in the sliding window model, and may be of independent interest to future differentially private algorithmic design in the sliding window model.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)", "paperhash": "blocki|differentially_private_l_2heavy_hitters_in_the_sliding_window_model", "pdf": "/pdf/7a0d8905677bac47b853d1dfdaa37542861101da.pdf", "supplementary_material": "/attachment/6c52be204a7750587c5a87de660b9d496c52f4e5.zip", "_bibtex": "@inproceedings{\nblocki2023differentially,\ntitle={Differentially Private \\$L\\_2\\$-Heavy Hitters in the Sliding Window Model},\nauthor={Jeremiah Blocki and Seunghoon Lee and Tamalika Mukherjee and Samson Zhou},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=3UHoYrglYkG}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279258140, "odate": 1664468100000, "details": {"replyCount": 11}}, {"id": "ApF0dmi1_9K", "original": "MMlDm3b3nGa", "number": 2999, "cdate": 1663850150324, "mdate": null, "ddate": null, "tcdate": 1663850150324, "tmdate": 1697935555382, "tddate": null, "forum": "ApF0dmi1_9K", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "NTFields: Neural Time Fields for Physics-Informed Robot Motion Planning", "authorids": ["~Ruiqi_Ni1", "~Ahmed_H_Qureshi1"], "authors": ["Ruiqi Ni", "Ahmed H Qureshi"], "keywords": ["Robotics", "Motion Planning", "Neural Fields", "Implicit Neural Representation", "Physics Informed Deep Learning"], "abstract": "Neural Motion Planners (NMPs) have emerged as a promising tool for solving robot navigation tasks in complex environments. However, these methods often require expert data for learning, which limits their application to scenarios where data generation is time-consuming. Recent developments have also led to physics-informed deep neural models capable of representing complex dynamical Partial Differential Equations (PDEs). Inspired by these developments, we propose Neural Time Fields (NTFields) for robot motion planning in cluttered scenarios. Our framework represents a wave propagation model generating continuous arrival time to find path solutions informed by a nonlinear first-order PDE called Eikonal Equation. We evaluate our method in various cluttered 3D environments, including the Gibson dataset, and demonstrate its ability to solve motion planning problems for 4-DOF and 6-DOF robot manipulators where the traditional grid-based Eikonal planners often face the curse of dimensionality. Furthermore, the results show that our method exhibits high success rates and significantly lower computational times than the state-of-the-art methods, including NMPs that require training data from classical planners.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Applications (eg, speech processing, computer vision, NLP)", "paperhash": "ni|ntfields_neural_time_fields_for_physicsinformed_robot_motion_planning", "TL;DR": "A physics-informed neural time fields model for robot motion planning.", "pdf": "/pdf/483cf04b31ae0d71d5a838b5ba85e6273a018d60.pdf", "supplementary_material": "/attachment/ff843c8e24c9e90980c923c5c464f3637f87e4ef.zip", "_bibtex": "@inproceedings{\nni2023ntfields,\ntitle={{NTF}ields: Neural Time Fields for Physics-Informed Robot Motion Planning},\nauthor={Ruiqi Ni and Ahmed H Qureshi},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=ApF0dmi1_9K}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2210.00120/code)"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279253904, "odate": 1664468100000, "details": {"replyCount": 23}}, {"id": "rwo-ls5GqGn", "original": "kcTvikDsvAs", "number": 2989, "cdate": 1663850149139, "mdate": null, "ddate": null, "tcdate": 1663850149139, "tmdate": 1697935556499, "tddate": null, "forum": "rwo-ls5GqGn", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "ZiCo: Zero-shot NAS via inverse Coefficient of Variation on Gradients", "authorids": ["~Guihong_Li1", "~Yuedong_Yang2", "~Kartikeya_Bhardwaj1", "~Radu_Marculescu2"], "authors": ["Guihong Li", "Yuedong Yang", "Kartikeya Bhardwaj", "Radu Marculescu"], "keywords": ["Neural Architecture Search", "Zero-shot NAS", "Gradient Analysis", "Training Convergence"], "abstract": "Neural Architecture Search (NAS) is widely used to automatically obtain the neural network with the best performance among a large number of candidate architectures. To reduce the search time, zero-shot NAS aims at designing training-free proxies that can predict the test performance of a given architecture. However, as shown recently, none of the zero-shot proxies proposed to date can actually work consistently better than a naive proxy, namely, the number of network parameters (#Params). To improve this state of affairs, as the main theoretical contribution, we first reveal how some specific gradient properties across different samples impact the convergence rate and generalization capacity of neural networks. Based on this theoretical analysis, we propose a new zero-shot proxy, ZiCo, the first proxy that works consistently better than #Params. We demonstrate that ZiCo works better than State-Of-The-Art (SOTA) proxies on several popular NAS-Benchmarks (NASBench101, NATSBench-SSS/TSS, TransNASBench-101) for multiple applications (e.g., image classification/reconstruction and pixel-level prediction). Finally, we demonstrate that the optimal architectures found via ZiCo are as competitive as the ones found by one-shot and multi-shot NAS methods, but with much less search time. For example, ZiCo-based NAS can find optimal architectures with 78.1%, 79.4%, and 80.4% test accuracy under inference budgets of 450M, 600M, and 1000M FLOPs, respectively, on ImageNet within 0.4 GPU days. Our code is available at https://github.com/SLDGroup/ZiCo.\n\n", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Deep Learning and representational learning", "paperhash": "li|zico_zeroshot_nas_via_inverse_coefficient_of_variation_on_gradients", "TL;DR": "A theoretically grounded SOTA proxy for zero-shot NAS under various inference budgets.", "pdf": "/pdf/0ed7119196bfabbdc248d6add738ac67510f7662.pdf", "supplementary_material": "", "_bibtex": "@inproceedings{\nli2023zico,\ntitle={ZiCo: Zero-shot {NAS} via inverse Coefficient of Variation on Gradients},\nauthor={Guihong Li and Yuedong Yang and Kartikeya Bhardwaj and Radu Marculescu},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=rwo-ls5GqGn}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 2 code implementations](https://www.catalyzex.com/paper/arxiv:2301.11300/code)"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279253502, "odate": 1664468100000, "details": {"replyCount": 28}}, {"id": "hQ9V5QN27eS", "original": "wGZXrcETyG", "number": 2975, "cdate": 1663850147428, "mdate": null, "ddate": null, "tcdate": 1663850147428, "tmdate": 1676905609818, "tddate": null, "forum": "hQ9V5QN27eS", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Pink Noise Is All You Need: Colored Noise Exploration in Deep Reinforcement Learning", "authorids": ["~Onno_Eberhard1", "~Jakob_Hollenstein1", "~Cristina_Pinneri1", "~Georg_Martius1"], "authors": ["Onno Eberhard", "Jakob Hollenstein", "Cristina Pinneri", "Georg Martius"], "keywords": ["reinforcement learning", "exploration", "action noise", "continuous control"], "abstract": "In off-policy deep reinforcement learning with continuous action spaces, exploration is often implemented by injecting action noise into the action selection process. Popular algorithms based on stochastic policies, such as SAC or MPO, inject white noise by sampling actions from uncorrelated Gaussian distributions. In many tasks, however, white noise does not provide sufficient exploration, and temporally correlated noise is used instead. A common choice is Ornstein-Uhlenbeck (OU) noise, which is closely related to Brownian motion (red noise). Both red noise and white noise belong to the broad family of colored noise. In this work, we perform a comprehensive experimental evaluation on MPO and SAC to explore the effectiveness of other colors of noise as action noise. We find that pink noise, which is halfway between white and red noise, significantly outperforms white noise, OU noise, and other alternatives on a wide range of environments. Thus, we recommend it as the default choice for action noise in continuous control.\n", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)", "paperhash": "eberhard|pink_noise_is_all_you_need_colored_noise_exploration_in_deep_reinforcement_learning", "TL;DR": "Pink noise, a temporally correlated noise type, outperforms other action noise types on standard continuous control benchmarks.", "pdf": "/pdf/9eb6698653898299e855964e9b4950f0e56ab28c.pdf", "supplementary_material": "/attachment/d9ba60151cc44374e1793ca3c2fb62260ef512f1.zip", "_bibtex": "@inproceedings{\neberhard2023pink,\ntitle={Pink Noise Is All You Need: Colored Noise Exploration in Deep Reinforcement Learning},\nauthor={Onno Eberhard and Jakob Hollenstein and Cristina Pinneri and Georg Martius},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=hQ9V5QN27eS}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279252206, "odate": 1664468100000, "details": {"replyCount": 14}}, {"id": "1mNssCWt_v", "original": "581U4QsSxZZ", "number": 2968, "cdate": 1663850146611, "mdate": null, "ddate": null, "tcdate": 1663850146611, "tmdate": 1697935559545, "tddate": null, "forum": "1mNssCWt_v", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "STaSy: Score-based Tabular data Synthesis", "authorids": ["~Jayoung_Kim1", "~Chaejeong_Lee1", "~Noseong_Park1"], "authors": ["Jayoung Kim", "Chaejeong Lee", "Noseong Park"], "keywords": ["Score-based generative model", "Tabular data", "Self-paced learning"], "abstract": "Tabular data synthesis is a long-standing research topic in machine learning. Many different methods have been proposed over the past decades, ranging from statistical methods to deep generative methods. However, it has not always been successful due to the complicated nature of real-world tabular data. In this paper, we present a new model named $\\textbf{S}$core-based $\\textbf{Ta}$bular data $\\textbf{Sy}$nthesis ($\\texttt{STaSy}$) and its training strategy based on the paradigm of score-based generative modeling. Despite the fact that score-based generative models have resolved many issues in generative models, there still exists room for improvement in tabular data synthesis. Our proposed training strategy includes a self-paced learning technique and a fine-tuning strategy, which further increases the sampling quality and diversity by stabilizing the denoising score matching training. Furthermore, we also conduct rigorous experimental studies in terms of the generative task trilemma: sampling quality, diversity, and time. In our experiments with 15 benchmark tabular datasets and 7 baselines, our method outperforms existing methods in terms of task-dependant evaluations and diversity.\n", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Generative models", "paperhash": "kim|stasy_scorebased_tabular_data_synthesis", "TL;DR": "We design a score-based generative model for tabular data and apply two training strategies, including the self-paced learning and the proposed fine-tuning method, to stabilize the denoising score matching training.", "pdf": "/pdf/7cc08c44de490f3e79794b5827aa36b84f99c4c3.pdf", "supplementary_material": "/attachment/842fa5c040f64f1e8d59e24d0d67919abc7fc0af.zip", "_bibtex": "@inproceedings{\nkim2023stasy,\ntitle={{ST}aSy: Score-based Tabular data Synthesis},\nauthor={Jayoung Kim and Chaejeong Lee and Noseong Park},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=1mNssCWt_v}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 5 code implementations](https://www.catalyzex.com/paper/arxiv:2210.04018/code)"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279251952, "odate": 1664468100000, "details": {"replyCount": 6}}, {"id": "k71IGLC8cfc", "original": "66fbucnmg1", "number": 2945, "cdate": 1663850144589, "mdate": null, "ddate": null, "tcdate": 1663850144589, "tmdate": 1697935562504, "tddate": null, "forum": "k71IGLC8cfc", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "A Unified Algebraic Perspective on Lipschitz Neural Networks", "authorids": ["~Alexandre_Araujo3", "~Aaron_J_Havens1", "~Blaise_Delattre1", "~Alexandre_Allauzen1", "~Bin_Hu2"], "authors": ["Alexandre Araujo", "Aaron J Havens", "Blaise Delattre", "Alexandre Allauzen", "Bin Hu"], "keywords": ["Deep Learning", "Lipschitz neural networks", "Robustness"], "TL;DR": "We present a novel algebraic perspective unifying various types of 1-Lipschitz neural networks, and show that AOL and CPL can be re-derived and generalized using exactly the same semidefinite programming (SDP) condition.", "abstract": "Important research efforts have focused on the design and training of neural networks with a controlled Lipschitz constant. The goal is to increase and sometimes guarantee the robustness against adversarial attacks. Recent promising techniques draw inspirations from different backgrounds to design 1-Lipschitz neural networks, just to name a few: convex potential layers derive from the discretization of continuous dynamical systems, Almost-Orthogonal-Layer proposes a tailored method for matrix rescaling. However, it is today important to consider the recent and promising contributions in the field under a common theoretical lens to better design new and improved layers. This paper introduces a novel algebraic perspective unifying various types of 1-Lipschitz neural networks, including the ones previously mentioned, along with methods based on orthogonality and spectral methods. Interestingly, we show that many existing techniques can be derived and generalized via finding analytical solutions of a common semidefinite programming (SDP) condition.  We also prove that AOL biases the scaled weight to the ones which are close to the set of orthogonal matrices in a certain mathematical manner. Moreover, our algebraic condition, combined with the Gershgorin circle theorem, readily leads to new and diverse parameterizations for 1-Lipschitz network layers. Our approach, called SDP-based Lipschitz Layers (SLL), allows us to design non-trivial yet efficient generalization of convex potential layers.  Finally, the comprehensive set of experiments on image classification shows that SLLs outperform previous approaches on certified robust accuracy. Code is available at https://github.com/araujoalexandre/Lipschitz-SLL-Networks.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Deep Learning and representational learning", "paperhash": "araujo|a_unified_algebraic_perspective_on_lipschitz_neural_networks", "pdf": "/pdf/0db46e14af869da0146f16c3a0b546c42c16ac4a.pdf", "supplementary_material": "/attachment/8bc8042b86d7e29324114845fb51b28c0f6e84eb.zip", "_bibtex": "@inproceedings{\naraujo2023a,\ntitle={A Unified Algebraic Perspective on Lipschitz Neural Networks},\nauthor={Alexandre Araujo and Aaron J Havens and Blaise Delattre and Alexandre Allauzen and Bin Hu},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=k71IGLC8cfc}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2303.03169/code)"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279250589, "odate": 1664468100000, "details": {"replyCount": 13}}, {"id": "nZ2NtpolC5-", "original": "Wqf3EiN-K8", "number": 2936, "cdate": 1663850143503, "mdate": null, "ddate": null, "tcdate": 1663850143503, "tmdate": 1676487933255, "tddate": null, "forum": "nZ2NtpolC5-", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "The Influence of Learning Rule on Representation Dynamics in Wide Neural Networks", "authorids": ["~Blake_Bordelon1", "~Cengiz_Pehlevan2"], "authors": ["Blake Bordelon", "Cengiz Pehlevan"], "keywords": ["Deep Learning Theory", "Learning Rules", "Representations"], "TL;DR": "A theoretical analysis of deep networks and their representations when trained with a variety of learning rules.", "abstract": "It is unclear how changing the learning rule of a deep neural network alters its learning dynamics and representations. To gain insight into the relationship between learned features, function approximation, and the learning rule, we analyze infinite-width deep networks trained with gradient descent (GD) and biologically-plausible alternatives including feedback alignment (FA), direct feedback alignment (DFA), and error modulated Hebbian learning (Hebb), as well as gated linear networks (GLN). We show that, for each of these learning rules, the evolution of the output function at infinite width is governed by a time varying effective neural tangent kernel (eNTK). In the lazy training limit, this eNTK is static and does not evolve, while in the rich mean-field regime this kernel's evolution can be determined self-consistently with dynamical mean field theory (DMFT). This DMFT enables comparisons of the feature and prediction dynamics induced by each of these learning rules. In the lazy limit, we find that DFA and Hebb can only learn using the last layer features, while full FA can utilize earlier layers with a scale determined by the initial correlation between feedforward and feedback weight matrices. In the rich regime, DFA and FA utilize a temporally evolving and depth-dependent NTK. Counterintuitively, we find that FA networks trained in the rich regime exhibit more feature learning if initialized with smaller correlation between the forward and backward pass weights. GLNs admit a very simple formula for their lazy limit kernel and preserve conditional Gaussianity of their preactivations under gating functions. Error modulated Hebb rules show very small task-relevant alignment of their kernels and perform most task relevant learning in the last layer.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Deep Learning and representational learning", "paperhash": "bordelon|the_influence_of_learning_rule_on_representation_dynamics_in_wide_neural_networks", "pdf": "/pdf/48d0ec8e5e188584424c803e8b24556739d8fa4d.pdf", "supplementary_material": "/attachment/eca2cd8607b84c8f6909000ba0a083d2ef19165f.zip", "_bibtex": "@inproceedings{\nbordelon2023the,\ntitle={The Influence of Learning Rule on Representation Dynamics in Wide Neural Networks},\nauthor={Blake Bordelon and Cengiz Pehlevan},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=nZ2NtpolC5-}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279249989, "odate": 1664468100000, "details": {"replyCount": 18}}, {"id": "sCYXJr3QJM8", "original": "DyrWgh9KzY9", "number": 2914, "cdate": 1663850140572, "mdate": null, "ddate": null, "tcdate": 1663850140572, "tmdate": 1677383090393, "tddate": null, "forum": "sCYXJr3QJM8", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Few-shot Cross-domain Image Generation via Inference-time Latent-code Learning", "authorids": ["~Arnab_Kumar_Mondal2", "~Piyush_Tiwary1", "~Parag_Singla1", "~Prathosh_AP1"], "authors": ["Arnab Kumar Mondal", "Piyush Tiwary", "Parag Singla", "Prathosh AP"], "keywords": ["generative domain adaptation", "generative adversarial network"], "TL;DR": "Adapt a GAN trained on a single large-scale source dataset to multiple target domains containing very few examples without re-training the pretrained source generator.", "abstract": "In this work, our objective is to adapt a Deep generative model trained on a large-scale source dataset to multiple target domains with scarce data. Specifically, we focus on adapting a pre-trained Generative Adversarial Network (GAN) to a target domain without re-training the generator. Our method draws the motivation from the fact that out-of-distribution samples can be `embedded' onto the latent space of a pre-trained source-GAN. We propose to train a small latent-generation network during the inference stage, each time a  batch of target samples is to be generated. These target latent codes are fed to the source-generator to obtain  novel target samples. Despite using the same small set of target samples and the source generator, multiple independent training episodes of the latent-generation network results in the diversity of the generated target samples. Our method, albeit simple, can be used to generate data from multiple target distributions using a generator trained on a single source distribution. We demonstrate the efficacy of our surprisingly simple method in generating multiple target datasets with only a single source generator and a few target samples.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Generative models", "paperhash": "mondal|fewshot_crossdomain_image_generation_via_inferencetime_latentcode_learning", "pdf": "/pdf/acc5eab2f3488d4a16e1e9bdc1b8836b5ebccdfe.pdf", "supplementary_material": "/attachment/027c80aacbb5a3cfe5ab88e96681a0e3cd95998d.zip", "_bibtex": "@inproceedings{\nmondal2023fewshot,\ntitle={Few-shot Cross-domain Image Generation via Inference-time Latent-code Learning},\nauthor={Arnab Kumar Mondal and Piyush Tiwary and Parag Singla and Prathosh AP},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=sCYXJr3QJM8}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279248797, "odate": 1664468100000, "details": {"replyCount": 11}}, {"id": "DJEEqoAq7to", "original": "elY0proMp9Q", "number": 2913, "cdate": 1663850140451, "mdate": null, "ddate": null, "tcdate": 1663850140451, "tmdate": 1697935566467, "tddate": null, "forum": "DJEEqoAq7to", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "RLx2: Training a Sparse Deep Reinforcement Learning Model from Scratch", "authorids": ["~Yiqin_Tan1", "~Pihe_Hu1", "~Ling_Pan1", "~Jiatai_Huang1", "~Longbo_Huang2"], "authors": ["Yiqin Tan", "Pihe Hu", "Ling Pan", "Jiatai Huang", "Longbo Huang"], "keywords": ["Deep Reinforcement Learning", "Lottery Ticket Hypothesis", "Model Compression", "Value Learning"], "TL;DR": "We propose a new framework for training an efficient DRL agent from scratch with an ultra-sparse network with strong performanc without performance degradation.", "abstract": "Training deep reinforcement learning (DRL) models usually requires high computation costs. Therefore, compressing DRL models possesses immense potential for training acceleration and model deployment. However, existing methods that generate small models mainly adopt the knowledge distillation-based approach by iteratively training a dense network. As a result, the training process still demands massive computing resources. Indeed, sparse training from scratch in DRL has not been well explored and is particularly challenging due to non-stationarity in bootstrap training. In this work, we propose a novel sparse DRL training framework, \u201cthe Rigged Reinforcement Learning Lottery\u201d (RLx2), which builds upon gradient-based topology evolution and is capable of training a sparse DRL model based entirely on a sparse network. Specifically, RLx2 introduces a novel multi-step TD target mechanism with a dynamic-capacity replay buffer to achieve robust value learning and efficient topology exploration in sparse models. It also reaches state-of-the-art sparse training performance in several tasks, showing $7.5\\times$-$20\\times$ model compression with less than $3\\%$ performance degradation and up to $20\\times$ and $50\\times$ FLOPs reduction for training and inference, respectively.", "pdf": "/pdf/095bd7aea3382d53f48388a8b9051db4f9ed8f31.pdf", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "supplementary_material": "/attachment/eedd483a7a1d6b37739f9e7b0cdfed676dea2867.zip", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)", "paperhash": "tan|rlx2_training_a_sparse_deep_reinforcement_learning_model_from_scratch", "_bibtex": "@inproceedings{\ntan2023rlx,\ntitle={{RL}x2: Training a Sparse Deep Reinforcement Learning Model from Scratch},\nauthor={Yiqin Tan and Pihe Hu and Ling Pan and Jiatai Huang and Longbo Huang},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=DJEEqoAq7to}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2205.15043/code)"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279248681, "odate": 1664468100000, "details": {"replyCount": 17}}, {"id": "J6F3lLg4Kdp", "original": "EOxn9TwMW8k", "number": 2905, "cdate": 1663850139490, "mdate": null, "ddate": null, "tcdate": 1663850139490, "tmdate": 1697935567502, "tddate": null, "forum": "J6F3lLg4Kdp", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Sparsity May Cry: Let Us Fail (Current) Sparse Neural Networks Together!", "authorids": ["~Shiwei_Liu2", "~Tianlong_Chen1", "~Zhenyu_Zhang4", "~Xuxi_Chen1", "~Tianjin_Huang1", "~AJAY_KUMAR_JAISWAL1", "~Zhangyang_Wang1"], "authors": ["Shiwei Liu", "Tianlong Chen", "Zhenyu Zhang", "Xuxi Chen", "Tianjin Huang", "AJAY KUMAR JAISWAL", "Zhangyang Wang"], "keywords": ["Sparse Neural Networks", "Benchmark", "Sparsity", "Neural Network Pruning"], "TL;DR": "In this work, we assemble a large-scale, difficult and diverse benchmark for sparse neural networks, on which current SOTA sparse networks are actually prone to significant performance degradation, sometimes even at trivial sparsity levels, e.g., 5%.", "abstract": "Sparse Neural Networks (SNNs) have received voluminous attention predominantly due to growing computational and memory footprints of consistently exploding parameter count in large-scale models. Similar to their dense counterparts, recent SNNs generalize just as well and are equipped with numerous favorable benefits (e.g., low complexity, high scalability, and robustness), sometimes even better than the original dense networks. As research effort is focused on developing increasingly sophisticated sparse algorithms, it is startling that a comprehensive benchmark to evaluate the effectiveness of these algorithms has been highly overlooked. In absence of a carefully crafted evaluation benchmark, most if not all, sparse algorithms are evaluated against fairly simple and naive tasks (eg. CIFAR-10/100, ImageNet, GLUE, etc.), which can potentially camouflage many advantages as well unexpected predicaments of SNNs. In pursuit of a more general evaluation and unveiling the true potential of sparse algorithms, we introduce \u201cSparsity May Cry\u201d Benchmark (SMC-Bench), a collection of carefully-curated 4 diverse tasks with 10 datasets, that accounts for capturing a wide range of domain-specific and sophisticated knowledge. Our systemic evaluation of the most representative sparse algorithms reveals an important obscured observation: the state-of-the-art magnitude- and/or gradient-based sparse algorithms seemingly fail to perform on SMC-Bench when applied out-of-the-box, sometimes at significantly trivial sparsity as low as 5%. The observations seek the immediate attention of the sparsity research community to reconsider the highly proclaimed benefits of SNNs. We further conduct a thorough investigation into the reasons for the failure of common SNNs. Our analysis points out that such failure is intimately related to the \u201clazy regime\u201d of large model training, which hints us with stronger pruning recipes that alleviate the failure on SMC-Bench (though still more or less suffering). By incorporating these well-thought and diverse tasks, SMC-Bench is designed to favor and encourage the development of more scalable and generalizable sparse algorithms. We open-source SMC-Bench to assist researchers in building next-generation sparse algorithms that scale and generalize: https://github.com/VITA-Group/SMC-Bench.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Deep Learning and representational learning", "paperhash": "liu|sparsity_may_cry_let_us_fail_current_sparse_neural_networks_together", "pdf": "/pdf/60f68324a3ec40c50412c32d7f1d7ee813d44b35.pdf", "_bibtex": "@inproceedings{\nliu2023sparsity,\ntitle={Sparsity May Cry: Let Us Fail (Current) Sparse Neural Networks Together!},\nauthor={Shiwei Liu and Tianlong Chen and Zhenyu Zhang and Xuxi Chen and Tianjin Huang and AJAY KUMAR JAISWAL and Zhangyang Wang},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=J6F3lLg4Kdp}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 2 code implementations](https://www.catalyzex.com/paper/arxiv:2303.02141/code)"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279248222, "odate": 1664468100000, "details": {"replyCount": 26}}, {"id": "w1hwFUb_81", "original": "W2iY_qvH35z", "number": 2877, "cdate": 1663850136178, "mdate": null, "ddate": null, "tcdate": 1663850136178, "tmdate": 1697935570929, "tddate": null, "forum": "w1hwFUb_81", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Sparse MoE as the New Dropout: Scaling Dense and Self-Slimmable Transformers", "authorids": ["~Tianlong_Chen1", "~Zhenyu_Zhang4", "~AJAY_KUMAR_JAISWAL1", "~Shiwei_Liu2", "~Zhangyang_Wang1"], "authors": ["Tianlong Chen", "Zhenyu Zhang", "AJAY KUMAR JAISWAL", "Shiwei Liu", "Zhangyang Wang"], "keywords": ["Sparse Mixture-of-Experts", "Random Routing", "Transformer Training", "Dropout"], "TL;DR": "A new plug-and-paly strategy for training over-parameterized transformer models, leverages SMoEs with random routings to empower scaling transformers to better performance in the full capacity settings without collapse.", "abstract": "Despite their remarkable achievement, gigantic transformers encounter significant drawbacks, including exorbitant computational and memory footprints during training, as well as severe collapse evidenced by a high degree of parameter redundancy. Sparsely-activated Mixture-of-Experts (SMoEs) have shown promise to mitigate the issue of training efficiency, yet they are prone to (1) $\\textit{redundant experts}$ due to representational collapse; and (2) $\\textit{poor expert scalability for inference and downstream fine-tuning}$, primarily due to overfitting of the learned routing policy to the number of activated experts during training. As recent research efforts are predominantly focused on improving routing policies to encourage expert specializations, this work focuses on $\\textit{exploring the overlooked scalability bottleneck of SMoEs}$ and leveraging it to effectively $\\textbf{scale dense transformers}$. To this end, we propose a new plug-and-play training framework, $\\textbf{SMoE-Dropout}$, to enable scaling transformers to better accuracy in their full capacity without collapse. Specifically, SMoE-Dropout consists of a $\\textit{randomly initialized and fixed}$ router network to activate experts and gradually increases the activated expert number as training progresses over time. Transformers trained by SMoE-Dropout naturally exhibit a $\\textbf{``self-slimmable\u201d}$ property subject to resource availability, offering smooth and consistent performance boosts with an increase in activated experts during inference or fine-tuning. Our extensive experiments across diverse transformer architectures on a variety of tasks demonstrate the superior performance and substantial computation savings of SMoE-Dropout, compared to dense training baselines with equivalent parameter counts. In particular, our trained BERT outperforms its densely trained counterpart with consistent improvements of {$1.03\\%$, $0.78\\%$, $1.09\\%$} on challenging reasoning tasks {$\\texttt{ASDiv-A}$, $\\texttt{MAWPS}$, $\\texttt{SVAMP}$}, respectively. Codes and models are available in https://github.com/VITA-Group/Random-MoE-as-Dropout.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Deep Learning and representational learning", "paperhash": "chen|sparse_moe_as_the_new_dropout_scaling_dense_and_selfslimmable_transformers", "pdf": "/pdf/9a22d737856844ae4058be999052c67e4e975671.pdf", "_bibtex": "@inproceedings{\nchen2023sparse,\ntitle={Sparse MoE as the New Dropout: Scaling Dense and Self-Slimmable Transformers},\nauthor={Tianlong Chen and Zhenyu Zhang and AJAY KUMAR JAISWAL and Shiwei Liu and Zhangyang Wang},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=w1hwFUb_81}\n}", "supplementary_material": "/attachment/ffe36e33acdd73c0cd1a886a172d4d1b699f5fee.zip", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2303.01610/code)"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279246245, "odate": 1664468100000, "details": {"replyCount": 22}}, {"id": "LfdEuhjR5GV", "original": "w2_4ZXb5lW9", "number": 2847, "cdate": 1663850132611, "mdate": null, "ddate": null, "tcdate": 1663850132611, "tmdate": 1676781274157, "tddate": null, "forum": "LfdEuhjR5GV", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Adversarial Training of Self-supervised Monocular Depth Estimation against Physical-World Attacks", "authorids": ["~Zhiyuan_Cheng2", "~James_Chenhao_Liang1", "~Guanhong_Tao1", "~Dongfang_Liu1", "~Xiangyu_Zhang3"], "authors": ["Zhiyuan Cheng", "James Chenhao Liang", "Guanhong Tao", "Dongfang Liu", "Xiangyu Zhang"], "keywords": ["Adversarial Training", "Monocular Depth Estimation", "Adversarial Attack", "Self-supervised Learning."], "TL;DR": "Use self-supervised adversarial training to harden monocular depth estimation models against physical-world adversarial attacks.", "abstract": "Monocular Depth Estimation (MDE) is a critical component in applications such as autonomous driving. There are various attacks against MDE networks. These attacks, especially the physical ones, pose a great threat to the security of such systems.  Traditional adversarial training method requires ground-truth labels and hence cannot be directly applied to self-supervised MDE that does not have depth ground truth. Some self-supervised model hardening technique (e.g., contrastive learning) ignores the domain knowledge of MDE and can hardly achieve optimal performance. In this work, we propose a novel adversarial training method for self-supervised MDE models based on view synthesis without using the depth ground truth. We improve adversarial robustness against physical-world attacks using $L_0$-norm-bounded perturbation in training. We compare our method with supervised learning-based and contrastive learning-based methods that are tailored for MDE. Results on two representative MDE networks show that we achieve better robustness against various adversarial attacks with nearly no benign performance degradation.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Unsupervised and Self-supervised learning", "paperhash": "cheng|adversarial_training_of_selfsupervised_monocular_depth_estimation_against_physicalworld_attacks", "pdf": "/pdf/2adac83c94d065c20230762eac3aad072f2424ef.pdf", "supplementary_material": "/attachment/8a8b0a0b1d26ff1f3e8db33b4688f49b73cb7124.zip", "_bibtex": "@inproceedings{\ncheng2023adversarial,\ntitle={Adversarial Training of Self-supervised Monocular Depth Estimation against Physical-World Attacks},\nauthor={Zhiyuan Cheng and James Chenhao Liang and Guanhong Tao and Dongfang Liu and Xiangyu Zhang},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=LfdEuhjR5GV}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279244583, "odate": 1664468100000, "details": {"replyCount": 22}}, {"id": "yHY9NbQJ5BP", "original": "BDhAr-gPrQr", "number": 2846, "cdate": 1663850132489, "mdate": null, "ddate": null, "tcdate": 1663850132489, "tmdate": 1681488899735, "tddate": null, "forum": "yHY9NbQJ5BP", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Sparsity-Constrained Optimal Transport", "authorids": ["~Tianlin_Liu2", "~Joan_Puigcerver1", "~Mathieu_Blondel1"], "authors": ["Tianlin Liu", "Joan Puigcerver", "Mathieu Blondel"], "keywords": ["optimal transport", "sparsity"], "TL;DR": "We propose formulations for optimal transport with cardinality constraints and apply them to sparse mixture of experts.", "abstract": "Regularized optimal transport (OT) is now increasingly used as a loss or as a matching layer in neural networks. Entropy-regularized OT can be computed using the Sinkhorn algorithm but it leads to fully-dense transportation plans, meaning that all sources are (fractionally) matched with all targets. To address this issue, several works have investigated quadratic regularization instead. This regularization preserves sparsity and leads to unconstrained and smooth (semi) dual objectives, that can be solved with off-the-shelf gradient methods. Unfortunately, quadratic regularization does not give direct control over the cardinality (number of nonzeros) of the transportation plan. We propose in this paper a new approach for OT with explicit cardinality constraints on the transportation plan. Our work is motivated by an application to sparse mixture of experts, where OT can be used to match input tokens such as image patches with expert models such as neural networks. Cardinality constraints ensure that at most $k$ tokens are matched with an expert, which is crucial for computational performance reasons. Despite the nonconvexity of cardinality constraints, we show that the corresponding (semi) dual problems are tractable and can be solved with first-order gradient methods. Our method can be thought as a middle ground between unregularized OT (recovered in the limit case $k=1$) and quadratically-regularized OT (recovered when $k$ is large enough). The smoothness of the objectives increases as $k$ increases, giving rise to a trade-off between convergence speed and sparsity of the optimal plan.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Optimization (eg, convex and non-convex optimization)", "paperhash": "liu|sparsityconstrained_optimal_transport", "pdf": "/pdf/01b19a43fd4282f5a55738b35ee52c3bb7236a0d.pdf", "_bibtex": "@inproceedings{\nliu2023sparsityconstrained,\ntitle={Sparsity-Constrained Optimal Transport},\nauthor={Tianlin Liu and Joan Puigcerver and Mathieu Blondel},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=yHY9NbQJ5BP}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279244563, "odate": 1664468100000, "details": {"replyCount": 17}}, {"id": "mMNimwRb7Gr", "original": "2DV697kpSUu", "number": 2839, "cdate": 1663850131651, "mdate": null, "ddate": null, "tcdate": 1663850131651, "tmdate": 1677519909274, "tddate": null, "forum": "mMNimwRb7Gr", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Turning the Curse of Heterogeneity in Federated Learning into a Blessing for Out-of-Distribution Detection", "authorids": ["~Shuyang_Yu1", "~Junyuan_Hong1", "~Haotao_Wang1", "~Zhangyang_Wang1", "~Jiayu_Zhou1"], "authors": ["Shuyang Yu", "Junyuan Hong", "Haotao Wang", "Zhangyang Wang", "Jiayu Zhou"], "keywords": ["out-of-distribution detection", "federated learning", "heterogeneity"], "abstract": "Deep neural networks have witnessed huge successes in many challenging prediction tasks and yet they often suffer from out-of-distribution (OoD) samples, misclassifying them with high confidence. Recent advances show promising OoD detection performance for centralized training, and however, OoD detection in federated learning (FL) is largely overlooked, even though many security sensitive applications such as autonomous driving and voice recognition authorization are commonly trained using FL for data privacy concerns. The main challenge that prevents previous state-of-the-art OoD detection methods from being incorporated to FL is that they require large amount of real OoD samples. However, in real-world scenarios, such large-scale OoD training data can be costly or even infeasible to obtain, especially for resource-limited local devices. On the other hand, a notorious challenge in FL is data heterogeneity where each client collects non-identically and independently distributed (non-iid) data. We propose to take advantage of such heterogeneity and turn the curse into a blessing that facilitates OoD detection in FL. The key is that for each client, non-iid data from other clients (unseen external classes) can serve as an alternative to real OoD samples. Specifically, we propose a novel Federated Out-of-Distribution Synthesizer (FOSTER), which learns a class-conditional generator to synthesize virtual external-class OoD samples, and maintains data confidentiality and communication efficiency required by FL. Experimental results show that our method outperforms the state-of-the-art by 2.49%, 2.88%, 1.42% AUROC, and 0.01%, 0.89%, 1.74% ID accuracy, on CIFAR-10, CIFAR-100, and STL10, respectively.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Deep Learning and representational learning", "paperhash": "yu|turning_the_curse_of_heterogeneity_in_federated_learning_into_a_blessing_for_outofdistribution_detection", "pdf": "/pdf/3943d2638f2adc77b54de624c3d14c17ee8615f8.pdf", "supplementary_material": "/attachment/fdd55350776baba45f461e2c60deddfd22cdc403.zip", "_bibtex": "@inproceedings{\nyu2023turning,\ntitle={Turning the Curse of Heterogeneity in Federated Learning into a Blessing for Out-of-Distribution Detection},\nauthor={Shuyang Yu and Junyuan Hong and Haotao Wang and Zhangyang Wang and Jiayu Zhou},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=mMNimwRb7Gr}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279244124, "odate": 1664468100000, "details": {"replyCount": 19}}, {"id": "j6zUzrapY3L", "original": "Bwr66W4jx1D", "number": 2827, "cdate": 1663850130241, "mdate": null, "ddate": null, "tcdate": 1663850130241, "tmdate": 1678076273593, "tddate": null, "forum": "j6zUzrapY3L", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "DIFFormer: Scalable (Graph) Transformers Induced by Energy Constrained Diffusion", "authorids": ["~Qitian_Wu1", "~Chenxiao_Yang1", "~Wentao_Zhao1", "~Yixuan_He2", "~David_Wipf1", "~Junchi_Yan2"], "authors": ["Qitian Wu", "Chenxiao Yang", "Wentao Zhao", "Yixuan He", "David Wipf", "Junchi Yan"], "keywords": ["structured representation learning", "diffusion model", "optimization-induced model", "node prediction"], "abstract": "Real-world data generation often involves complex inter-dependencies among instances, violating the IID-data hypothesis of standard learning paradigms and posing a challenge for uncovering the geometric structures for learning desired instance representations. To this end, we introduce an energy constrained diffusion model which encodes a batch of instances from a dataset into evolutionary states that progressively incorporate other instances' information by their interactions. The diffusion process is constrained by descent criteria w.r.t. a principled energy function that characterizes the global consistency of instance representations over latent structures. We provide rigorous theory that implies closed-form optimal estimates for the pairwise diffusion strength among arbitrary instance pairs, which gives rise to a new class of neural encoders, dubbed as DIFFormer (diffusion-based Transformers), with two instantiations: a simple version with linear complexity for prohibitive instance numbers, and an advanced version for learning complex structures. Experiments highlight the wide applicability of our model as a general-purpose encoder backbone with superior performance in various tasks, such as node classification on large graphs, semi-supervised image/text classification, and spatial-temporal dynamics prediction. The codes are available at https://github.com/qitianwu/DIFFormer.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Deep Learning and representational learning", "paperhash": "wu|difformer_scalable_graph_transformers_induced_by_energy_constrained_diffusion", "TL;DR": "We introduce an energy constrained diffusion model for semi-supervised representation learning, based on which a new class of nerual encoders is derived for efficiently and effectively learning inter-instance latent graphs", "pdf": "/pdf/2c274286ca9d89f558de1d9abc67d9b0a429bc4d.pdf", "_bibtex": "@inproceedings{\nwu2023difformer,\ntitle={{DIFF}ormer: Scalable (Graph) Transformers Induced by Energy Constrained Diffusion},\nauthor={Qitian Wu and Chenxiao Yang and Wentao Zhao and Yixuan He and David Wipf and Junchi Yan},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=j6zUzrapY3L}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279243469, "odate": 1664468100000, "details": {"replyCount": 9}}, {"id": "d3QNWD_pcFv", "original": "mFEB7Jvx7_", "number": 2826, "cdate": 1663850130126, "mdate": null, "ddate": null, "tcdate": 1663850130126, "tmdate": 1677461653971, "tddate": null, "forum": "d3QNWD_pcFv", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Neural Lagrangian Schr\\\"{o}dinger Bridge: Diffusion Modeling for Population Dynamics", "authorids": ["~Takeshi_Koshizuka1", "isseis@gmail.com"], "authors": ["Takeshi Koshizuka", "Issei Sato"], "keywords": ["Population Dynamics", "Trajectory Inference", "Neural SDEs", "Stochastic Optimal Transport", "Schr\u00f6dinger Bridge"], "abstract": "Population dynamics is the study of temporal and spatial variation in the size of populations of organisms and is a major part of population ecology. One of the main difficulties in analyzing population dynamics is that we can only obtain observation data with coarse time intervals from fixed-point observations due to experimental costs or measurement constraints. Recently, modeling population dynamics by using continuous normalizing flows (CNFs) and dynamic optimal transport has been proposed to infer the sample trajectories from a fixed-point observed population. While the sample behavior in CNFs is deterministic, the actual sample in biological systems moves in an essentially random yet directional manner. Moreover, when a sample moves from point A to point B in dynamical systems, its trajectory typically follows the principle of least action in which the corresponding action has the smallest possible value. To satisfy these requirements of the sample trajectories, we formulate the Lagrangian Schr\u00f6dinger bridge (LSB) problem and propose to solve it approximately by modeling the advection-diffusion process with regularized neural SDE. We also develop a model architecture that enables faster computation of the loss function. Experimental results show that the proposed method can efficiently approximate the population-level dynamics even for high-dimensional data and that using the prior knowledge introduced by the Lagrangian enables us to estimate the sample-level dynamics with stochastic behavior.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )", "paperhash": "koshizuka|neural_lagrangian_schr\\odinger_bridge_diffusion_modeling_for_population_dynamics", "pdf": "/pdf/4f5dfd7d5e9825029e736d0ace01eda002efdcb8.pdf", "supplementary_material": "/attachment/7ffcd82ee8a93609f1e9f7c16aefd4deba3df980.zip", "_bibtex": "@inproceedings{\nkoshizuka2023neural,\ntitle={Neural Lagrangian Schr{\\textbackslash}''\\{o\\}dinger Bridge: Diffusion Modeling for Population Dynamics},\nauthor={Takeshi Koshizuka and Issei Sato},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=d3QNWD_pcFv}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279243330, "odate": 1664468100000, "details": {"replyCount": 30}}, {"id": "QC10RmRbZy9", "original": "GcOaxDyQv1R", "number": 2812, "cdate": 1663850128424, "mdate": null, "ddate": null, "tcdate": 1663850128424, "tmdate": 1677724072709, "tddate": null, "forum": "QC10RmRbZy9", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Loss Landscapes are All You Need: Neural Network Generalization Can Be Explained Without the Implicit Bias of Gradient Descent", "authorids": ["~Ping-yeh_Chiang1", "~Renkun_Ni1", "~David_Yu_Miller1", "~Arpit_Bansal1", "~Jonas_Geiping1", "~Micah_Goldblum1", "~Tom_Goldstein1"], "authors": ["Ping-yeh Chiang", "Renkun Ni", "David Yu Miller", "Arpit Bansal", "Jonas Geiping", "Micah Goldblum", "Tom Goldstein"], "keywords": ["generalization", "regularization"], "TL;DR": "We empirically showed that a random optimizer performs just as well as SGD", "abstract": "It is commonly believed that the implicit regularization of optimizers is needed for neural networks to generalize in the overparameterized regime. In this paper, we observe experimentally that this implicit regularization behavior is {\\em generic}, i.e. it does not depend strongly on the choice of optimizer. We demonstrate this by training neural networks using several gradient-free optimizers, which do not benefit from properties that are often attributed to gradient-based optimizers.   This includes a guess-and-check optimizer that generates uniformly random parameter vectors until finding one that happens to achieve perfect train accuracy, and a zeroth-order Pattern Search optimizer that uses no gradient computations. In the low sample and few-shot regimes, where zeroth order optimizers are most computationally tractable, we find that these non-gradient optimizers achieve test accuracy comparable to SGD. The code to reproduce results can be found at https://github.com/Ping-C/optimizer .", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "General Machine Learning (ie none of the above)", "paperhash": "chiang|loss_landscapes_are_all_you_need_neural_network_generalization_can_be_explained_without_the_implicit_bias_of_gradient_descent", "pdf": "/pdf/2a88b78329da070f92f565b0cde765a1fb20d3d9.pdf", "_bibtex": "@inproceedings{\nchiang2023loss,\ntitle={Loss Landscapes are All You Need: Neural Network Generalization Can Be Explained Without the Implicit Bias of Gradient Descent},\nauthor={Ping-yeh Chiang and Renkun Ni and David Yu Miller and Arpit Bansal and Jonas Geiping and Micah Goldblum and Tom Goldstein},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=QC10RmRbZy9}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279242787, "odate": 1664468100000, "details": {"replyCount": 10}}, {"id": "h5OpjGd_lo6", "original": "hUQSvyscLL", "number": 2800, "cdate": 1663850127018, "mdate": null, "ddate": null, "tcdate": 1663850127018, "tmdate": 1677394539347, "tddate": null, "forum": "h5OpjGd_lo6", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Self-Guided Noise-Free Data Generation for Efficient Zero-Shot Learning", "authorids": ["~Jiahui_Gao2", "~Renjie_Pi1", "~LIN_Yong1", "~Hang_Xu1", "~Jiacheng_Ye2", "~Zhiyong_Wu3", "~WEIZHONG_ZHANG2", "~Xiaodan_Liang2", "~Zhenguo_Li1", "~Lingpeng_Kong1"], "authors": ["Jiahui Gao", "Renjie Pi", "LIN Yong", "Hang Xu", "Jiacheng Ye", "Zhiyong Wu", "WEIZHONG ZHANG", "Xiaodan Liang", "Zhenguo Li", "Lingpeng Kong"], "keywords": ["Pre-Trained Language Model", "Prompt-Based Learning", "Efficient Zero-Shot Learning"], "abstract": "There is a rising interest in further exploring the zero-shot learning potential of large pre-trained language models (PLMs). A new paradigm called data-generation-based zero-shot learning has achieved impressive success. In this paradigm, the synthesized data from the PLM acts as the carrier of knowledge, which is used to train a task-specific model with orders of magnitude fewer parameters than the PLM, achieving both higher performance and efficiency than prompt-based zero-shot learning methods on PLMs. The main hurdle of this approach is that the synthesized data from PLM usually contains a significant portion of low-quality samples. Fitting on such data will greatly hamper the performance of the task-specific model, making it unreliable for deployment. Previous methods remedy this issue mainly by filtering synthetic data using heuristic metrics(e.g., output confidence), or refining the data with the help of a human expert, which comes with excessive manual tuning or expensive costs. In this paper, we propose a novel noise-robust re-weighting framework SunGen to automatically construct high-quality data for zero-shot classification problems. Our framework features the ability to learn the sample weights indicating data quality without requiring any human annotation. We theoretically and empirically verify the ability of our method to help construct good-quality synthetic datasets. Notably, SunGen-LSTM yields a 9.8% relative improvement than the baseline on average accuracy across eight different established text classification tasks.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Applications (eg, speech processing, computer vision, NLP)", "paperhash": "gao|selfguided_noisefree_data_generation_for_efficient_zeroshot_learning", "TL;DR": "This paper proposes a framework to automatically enhance the quality of PLM-generated data for efficient zero-shot learning, without relying on any human annotation.", "pdf": "/pdf/82812310fbf1dff5ce1f72fe99e2d46523ca8d5a.pdf", "supplementary_material": "/attachment/f82759f1b8cb0b546e73c154952848cfebc42e90.zip", "_bibtex": "@inproceedings{\ngao2023selfguided,\ntitle={Self-Guided Noise-Free Data Generation for Efficient Zero-Shot Learning},\nauthor={Jiahui Gao and Renjie Pi and LIN Yong and Hang Xu and Jiacheng Ye and Zhiyong Wu and WEIZHONG ZHANG and Xiaodan Liang and Zhenguo Li and Lingpeng Kong},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=h5OpjGd_lo6}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279242038, "odate": 1664468100000, "details": {"replyCount": 20}}, {"id": "aBWnqqsuot7", "original": "Jtw0aXUnNCk", "number": 2745, "cdate": 1663850120440, "mdate": null, "ddate": null, "tcdate": 1663850120440, "tmdate": 1697935585408, "tddate": null, "forum": "aBWnqqsuot7", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "D4FT: A Deep Learning Approach to Kohn-Sham Density Functional Theory", "authorids": ["~Tianbo_Li1", "~Min_Lin1", "~Zheyuan_Hu1", "~Kunhao_Zheng1", "~Giovanni_Vignale1", "~Kenji_Kawaguchi1", "c2dhead@nus.edu.sg", "kostya@nus.edu.sg", "~Shuicheng_YAN3"], "authors": ["Tianbo Li", "Min Lin", "Zheyuan Hu", "Kunhao Zheng", "Giovanni Vignale", "Kenji Kawaguchi", "A.H. Castro Neto", "Kostya S. Novoselov", "Shuicheng YAN"], "keywords": ["AI for Science", "Quantum Chemisty", "Density Functional Theory", "Deep Learning", "Kohn-Sham Equation."], "TL;DR": "This paper propose a deep learning approch to solving Kohn-Sham Density Functional Theory.", "abstract": "Kohn-Sham Density Functional Theory (KS-DFT) has been traditionally solved by the Self-Consistent Field (SCF) method. Behind the SCF loop is the physics intuition of solving a system of non-interactive single-electron wave functions under an effective potential. In this work, we propose a deep learning approach to KS-DFT. First, in contrast to the conventional SCF loop, we propose to directly minimize the total energy by reparameterizing the orthogonal constraint as a feed-forward computation. We prove that such an approach has the same expressivity as the SCF method, yet reduces the computational complexity from O(N^4) to O(N^3). Second, the numerical integration which involves a summation over the quadrature grids can be amortized to the optimization steps. At each step, stochastic gradient descent (SGD) is performed with a sampled minibatch of the grids. Extensive experiments are carried out to demonstrate the advantage of our approach in terms of efficiency and stability. In addition, we show that our approach enables us to explore more complex neural-based wave functions. ", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )", "paperhash": "li|d4ft_a_deep_learning_approach_to_kohnsham_density_functional_theory", "pdf": "/pdf/2224ef90a640f03ebd92a397a2ffd6bc277a8b16.pdf", "_bibtex": "@inproceedings{\nli2023dft,\ntitle={D4{FT}: A Deep Learning Approach to Kohn-Sham Density Functional Theory},\nauthor={Tianbo Li and Min Lin and Zheyuan Hu and Kunhao Zheng and Giovanni Vignale and Kenji Kawaguchi and A.H. Castro Neto and Kostya S. Novoselov and Shuicheng YAN},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=aBWnqqsuot7}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2303.00399/code)"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279238971, "odate": 1664468100000, "details": {"replyCount": 9}}, {"id": "kPLzOfPfA2l", "original": "cfF48Nc9zhD", "number": 2743, "cdate": 1663850120208, "mdate": null, "ddate": null, "tcdate": 1663850120208, "tmdate": 1677808827887, "tddate": null, "forum": "kPLzOfPfA2l", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Warping the Space: Weight Space Rotation for Class-Incremental Few-Shot Learning", "authorids": ["~Do-Yeon_Kim1", "~Dong-Jun_Han1", "~Jun_Seo1", "~Jaekyun_Moon2"], "authors": ["Do-Yeon Kim", "Dong-Jun Han", "Jun Seo", "Jaekyun Moon"], "keywords": ["incremental few-shot learning", "catastrophic forgetting", "parameter space", "weight space rotation"], "TL;DR": "This paper introduced a concept of weight space rotation which makes changes to parameter space itself for solving incremental few-shot learning problem.", "abstract": "Class-incremental few-shot learning, where new sets of classes are provided sequentially with only a few training samples, presents a great challenge due to catastrophic forgetting of old knowledge and overfitting caused by lack of data. During finetuning on new classes, the performance on previous classes deteriorates quickly even when only a small fraction of parameters are updated, since the previous knowledge is broadly associated with most of the model parameters in the original parameter space. In this paper, we introduce WaRP, the \\textit{weight space rotation process}, which transforms the original parameter space into a new space so that we can push most of the previous knowledge compactly into only a few important parameters. By properly identifying and freezing these key parameters in the new weight space, we can finetune the remaining parameters without affecting the knowledge of previous classes. As a result, WaRP provides an additional room for the model to effectively learn new classes in future incremental sessions. Experimental results confirm the effectiveness of our solution and show the improved performance over the state-of-the-art methods.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Deep Learning and representational learning", "paperhash": "kim|warping_the_space_weight_space_rotation_for_classincremental_fewshot_learning", "pdf": "/pdf/36973a131d3dce27cb038d510a98686e3e24a480.pdf", "supplementary_material": "/attachment/694eb8660beb5c084a198cd976d5cb8142f71961.zip", "_bibtex": "@inproceedings{\nkim2023warping,\ntitle={Warping the Space: Weight Space Rotation for Class-Incremental Few-Shot Learning},\nauthor={Do-Yeon Kim and Dong-Jun Han and Jun Seo and Jaekyun Moon},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=kPLzOfPfA2l}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279238919, "odate": 1664468100000, "details": {"replyCount": 23}}, {"id": "tYIMtogyee", "original": "zSoIKddqa1v", "number": 2731, "cdate": 1663850118786, "mdate": null, "ddate": null, "tcdate": 1663850118786, "tmdate": 1697935586892, "tddate": null, "forum": "tYIMtogyee", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Pre-training via Denoising for Molecular Property Prediction", "authorids": ["~Sheheryar_Zaidi1", "~Michael_Schaarschmidt1", "~James_Martens1", "~Hyunjik_Kim1", "~Yee_Whye_Teh2", "~Alvaro_Sanchez-Gonzalez1", "~Peter_Battaglia1", "~Razvan_Pascanu1", "~Jonathan_Godwin1"], "authors": ["Sheheryar Zaidi", "Michael Schaarschmidt", "James Martens", "Hyunjik Kim", "Yee Whye Teh", "Alvaro Sanchez-Gonzalez", "Peter Battaglia", "Razvan Pascanu", "Jonathan Godwin"], "keywords": ["Molecular Property Prediction", "Pre-training", "Graph Neural Networks", "Denoising", "Molecules"], "TL;DR": "We describe a technique for pre-training models for molecular property prediction from 3D structures based on denoising and show that it achieves SOTA results for various tasks.", "abstract": "Many important problems involving molecular property prediction from 3D structures have limited data, posing a generalization challenge for neural networks. In this paper, we describe a pre-training technique based on denoising that achieves a new state-of-the-art in molecular property prediction by utilizing large datasets of 3D molecular structures at equilibrium to learn meaningful representations for downstream tasks. Relying on the well-known link between denoising autoencoders and score-matching, we show that the denoising objective corresponds to learning a molecular force field -- arising from approximating the Boltzmann distribution with a mixture of Gaussians -- directly from equilibrium structures. Our experiments demonstrate that using this pre-training objective significantly improves performance on multiple benchmarks, achieving a new state-of-the-art on the majority of targets in the widely used QM9 dataset. Our analysis then provides practical insights into the effects of different factors -- dataset sizes, model size and architecture, and the choice of upstream and downstream datasets -- on pre-training.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )", "paperhash": "zaidi|pretraining_via_denoising_for_molecular_property_prediction", "pdf": "/pdf/5124e3ed078b69949b650fc3e97fcc328fafe4ff.pdf", "supplementary_material": "/attachment/4453cb1345a2e730a49e27256eb5c73e2328a508.zip", "_bibtex": "@inproceedings{\nzaidi2023pretraining,\ntitle={Pre-training via Denoising for Molecular Property Prediction},\nauthor={Sheheryar Zaidi and Michael Schaarschmidt and James Martens and Hyunjik Kim and Yee Whye Teh and Alvaro Sanchez-Gonzalez and Peter Battaglia and Razvan Pascanu and Jonathan Godwin},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=tYIMtogyee}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 2 code implementations](https://www.catalyzex.com/paper/arxiv:2206.00133/code)"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279238139, "odate": 1664468100000, "details": {"replyCount": 10}}, {"id": "-9PVqZ-IR_", "original": "sAGqfbrdVsX", "number": 2705, "cdate": 1663850115835, "mdate": null, "ddate": null, "tcdate": 1663850115835, "tmdate": 1697935589879, "tddate": null, "forum": "-9PVqZ-IR_", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Martingale Posterior Neural Processes", "authorids": ["~Hyungi_Lee1", "~Eunggu_Yun1", "~Giung_Nam1", "~Edwin_Fong1", "~Juho_Lee2"], "authors": ["Hyungi Lee", "Eunggu Yun", "Giung Nam", "Edwin Fong", "Juho Lee"], "keywords": [], "TL;DR": "Martingale Posterior Distribution, Neural Processes", "abstract": "A Neural Process (NP) estimates a stochastic process implicitly defined with neural networks given a stream of data, rather than pre-specifying priors already known, such as Gaussian processes. An ideal NP would learn everything from data without any inductive biases, but in practice, we often restrict the class of stochastic processes for the ease of estimation. One such restriction is the use of a finite-dimensional latent variable accounting for the uncertainty in the functions drawn from NPs. Some recent works show that this can be improved with more \u201cdata-driven\u201d source of uncertainty such as bootstrapping. In this work, we take a different approach based on the martingale posterior, a recently developed alternative to Bayesian inference. For the martingale posterior, instead of specifying prior-likelihood pairs, a predictive distribution for future data is specified. Under specific conditions on the predictive distribution, it can be shown that the uncertainty in the generated future data actually corresponds to the uncertainty of the implicitly defined Bayesian posteriors. Based on this result, instead of assuming any form of the latent variables, we equip a NP with a predictive distribution implicitly defined with neural networks and use the corresponding martingale posteriors as the source of uncertainty. The resulting model, which we name as Martingale Posterior Neural Process (MPNP), is demonstrated to outperform baselines on various tasks.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Probabilistic Methods (eg, variational inference, causal inference, Gaussian processes)", "paperhash": "lee|martingale_posterior_neural_processes", "pdf": "/pdf/5806c8aefe1a560e8eb99dbcad6143cd7e30f31d.pdf", "supplementary_material": "/attachment/46f2ab3ae1c88cca2222c0937d1c9d4a1f3f9876.zip", "_bibtex": "@inproceedings{\nlee2023martingale,\ntitle={Martingale Posterior Neural Processes},\nauthor={Hyungi Lee and Eunggu Yun and Giung Nam and Edwin Fong and Juho Lee},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=-9PVqZ-IR_}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 3 code implementations](https://www.catalyzex.com/paper/arxiv:2304.09431/code)"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279236599, "odate": 1664468100000, "details": {"replyCount": 9}}, {"id": "bvpkw7UIRdU", "original": "jysrPv5TzBB", "number": 2641, "cdate": 1663850108220, "mdate": null, "ddate": null, "tcdate": 1663850108220, "tmdate": 1677665148759, "tddate": null, "forum": "bvpkw7UIRdU", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "On the Usefulness of Embeddings, Clusters and Strings for Text Generation Evaluation", "authorids": ["~Tiago_Pimentel1", "~Clara_Isabel_Meister1", "~Ryan_Cotterell1"], "authors": ["Tiago Pimentel", "Clara Isabel Meister", "Ryan Cotterell"], "keywords": ["language generation", "automatic evaluation", "contextual embeddings"], "TL;DR": "We provide a theoretical and empirical analysis of why a recently-proposed automatic evaluation metric for language generators correlates well with human judgments. We identify its use of embeddings from pretrained language models as the main reason.", "abstract": "A good automatic evaluation metric for language generation ideally correlates highly with human judgements of text quality.  Yet, there is a dearth of such metrics, which inhibits the rapid and efficient progress of language generators. One exception is  the recently proposed Mauve. In theory, Mauve measures an information-theoretic divergence between two probability distributions over strings: one representing the language generator under evaluation; the other representing the true natural language distribution. Mauve's authors argue that its success comes from the qualitative properties of their proposed divergence.  Yet in practice, as this divergence is uncomputable, Mauve approximates it by measuring the divergence between multinomial distributions over clusters instead, where cluster assignments are attained by grouping strings based on a pretrained language model's embeddings. As we show, however, this is not a tight approximation---in either theory or practice. This begs the question: why does Mauve work so well? In this work, we show that \\mauve was right for the wrong reasons, and that its newly proposed divergence is not necessary for its high performance. In fact, classical divergences paired with its proposed cluster-based approximation may actually serve as better evaluation metrics. We finish the paper with a probing analysis; this analysis leads us to conclude that---by encoding syntactic- and coherence-level features of text, while ignoring surface-level features---such cluster-based approximations to string distributions may simply be better for evaluating state-of-the-art language generators.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Applications (eg, speech processing, computer vision, NLP)", "paperhash": "pimentel|on_the_usefulness_of_embeddings_clusters_and_strings_for_text_generation_evaluation", "pdf": "/pdf/ecbd3cf3099fb64e9d4d2614aa66862f601c3328.pdf", "_bibtex": "@inproceedings{\npimentel2023on,\ntitle={On the Usefulness of Embeddings, Clusters and Strings for Text Generation Evaluation},\nauthor={Tiago Pimentel and Clara Isabel Meister and Ryan Cotterell},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=bvpkw7UIRdU}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279233248, "odate": 1664468100000, "details": {"replyCount": 14}}, {"id": "C-xa_D3oTj6", "original": "gf6ra6aurT", "number": 2595, "cdate": 1663850102776, "mdate": null, "ddate": null, "tcdate": 1663850102776, "tmdate": 1677168132268, "tddate": null, "forum": "C-xa_D3oTj6", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "DEP-RL: Embodied Exploration for Reinforcement Learning in Overactuated and Musculoskeletal Systems", "authorids": ["~Pierre_Schumacher1", "~Daniel_Haeufle1", "~Dieter_B\u00fcchler1", "~Syn_Schmitt1", "~Georg_Martius1"], "authors": ["Pierre Schumacher", "Daniel Haeufle", "Dieter B\u00fcchler", "Syn Schmitt", "Georg Martius"], "keywords": ["reinforcement learning", "musculoskeletal", "correlated exploration"], "TL;DR": "A technique from the self-organization literature is used to improve performance of RL agents on overactuated systems with up to 120 muscle actuators.", "abstract": "Muscle-actuated organisms are capable of learning an unparalleled diversity of dexterous movements despite their vast amount of muscles. \nReinforcement learning (RL) on large musculoskeletal models, however, has not been able to show similar performance.  \nWe conjecture that ineffective exploration in large overactuated action spaces is a key problem.\nThis is supported by the finding that common exploration noise strategies are inadequate in synthetic examples of overactuated systems. \nWe identify differential extrinsic plasticity (DEP), a method from the domain of self-organization, as being able to induce state-space covering exploration within seconds of interaction. \nBy integrating DEP into RL, we achieve fast learning of reaching and locomotion in musculoskeletal systems, outperforming current approaches in all considered tasks in sample efficiency and robustness.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)", "paperhash": "schumacher|deprl_embodied_exploration_for_reinforcement_learning_in_overactuated_and_musculoskeletal_systems", "pdf": "/pdf/e3ebc4afb3c3051ac2670b1f21a54881897fe728.pdf", "supplementary_material": "/attachment/a3a1b5fc1575aa780e3e4c170fbec643e764a4e9.zip", "_bibtex": "@inproceedings{\nschumacher2023deprl,\ntitle={{DEP}-{RL}: Embodied Exploration for Reinforcement Learning in Overactuated and Musculoskeletal Systems},\nauthor={Pierre Schumacher and Daniel Haeufle and Dieter B{\\\"u}chler and Syn Schmitt and Georg Martius},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=C-xa_D3oTj6}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279230788, "odate": 1664468100000, "details": {"replyCount": 13}}, {"id": "PEgBEB74JjB", "original": "r8B3AVUDVAJ", "number": 2592, "cdate": 1663850102395, "mdate": null, "ddate": null, "tcdate": 1663850102395, "tmdate": 1676555250963, "tddate": null, "forum": "PEgBEB74JjB", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "The Symmetric Generalized Eigenvalue Problem as a Nash Equilibrium", "authorids": ["~Ian_Gemp1", "~Charlie_Chen2", "~Brian_McWilliams2"], "authors": ["Ian Gemp", "Charlie Chen", "Brian McWilliams"], "keywords": ["generalized eigenvalue problem", "nash", "riemannian optimization", "canonical correlation analysis", "independent component analysis", "distributed computing"], "TL;DR": "We formulate the solution to the generalized eigenvalue problem as the Nash of a game, design an unbiased streaming-style algorithm to solve it, and analyze neural representations 1000x larger than before.", "abstract": "The symmetric generalized eigenvalue problem (SGEP) is a fundamental concept in numerical linear algebra. It captures the solution of many classical machine learning problems such as canonical correlation analysis, independent components analysis, partial least squares, linear discriminant analysis, principal components and others. Despite this, most general solvers are prohibitively expensive when dealing with *streaming data sets* (i.e., minibatches) and research has instead concentrated on finding efficient solutions to specific problem instances. In this work, we develop a game-theoretic formulation of the top-$k$ SGEP whose Nash equilibrium is the set of generalized eigenvectors. We also present a parallelizable algorithm with guaranteed asymptotic convergence to the Nash. Current state-of-the-art methods require $\\mathcal{O}(d^2k)$ runtime complexity per iteration which is prohibitively expensive when the number of dimensions ($d$) is large. We show how to modify this parallel approach to achieve $\\mathcal{O}(dk)$ runtime complexity. Empirically we demonstrate that this resulting algorithm is able to solve a variety of SGEP problem instances including a large-scale analysis of neural network activations.", "pdf": "/pdf/fa439d55119aeee9e8abbf9fc9998c806d8d9320.pdf", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "supplementary_material": "/attachment/5175e65352b48b17631ec3ecacf44f115e404b19.zip", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "General Machine Learning (ie none of the above)", "paperhash": "gemp|the_symmetric_generalized_eigenvalue_problem_as_a_nash_equilibrium", "_bibtex": "@inproceedings{\ngemp2023the,\ntitle={The Symmetric Generalized Eigenvalue Problem as a Nash Equilibrium},\nauthor={Ian Gemp and Charlie Chen and Brian McWilliams},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=PEgBEB74JjB}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279230500, "odate": 1664468100000, "details": {"replyCount": 11}}, {"id": "n-bvaLSCC78", "original": "naWru4gHay", "number": 2573, "cdate": 1663850100118, "mdate": null, "ddate": null, "tcdate": 1663850100118, "tmdate": 1677218371833, "tddate": null, "forum": "n-bvaLSCC78", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "EA-HAS-Bench: Energy-aware Hyperparameter and Architecture Search Benchmark", "authorids": ["~Shuguang_Dou1", "~XINYANG_JIANG2", "~Cai_Rong_Zhao1", "~Dongsheng_Li2"], "authors": ["Shuguang Dou", "XINYANG JIANG", "Cai Rong Zhao", "Dongsheng Li"], "keywords": [], "TL;DR": "We provide the first HAS dataset aware of the overall search energy cost", "abstract": "The energy consumption for training deep learning models is increasing at an alarming rate due to the growth of training data and model scale, resulting in a negative impact on carbon neutrality. Energy consumption is an especially pressing issue for AutoML algorithms because it usually requires repeatedly training large numbers of computationally intensive deep models to search for optimal configurations. This paper takes one of the most essential steps in developing energy-aware (EA) NAS methods, by providing a benchmark that makes EA-NAS research more reproducible and accessible. Specifically, we present the first large-scale energy-aware benchmark that allows studying AutoML methods to achieve better trade-offs between performance and search energy consumption, named EA-HAS-Bench. EA-HAS-Bench provides a large-scale architecture/hyperparameter joint search space, covering diversified configurations related to energy consumption. Furthermore, we propose a novel surrogate model specially designed for large joint search space, which proposes a Bezier curve-based model to predict learning curves with unlimited shape and length. Based on the proposed dataset, we new energy-aware AutoML method that arms existing AutoML algorithms to consider the search energy consumption, and our experiments show that the modified energy-aware AutoML methods achieve a better trade-off between energy consumption and model performance.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Infrastructure (eg, datasets, competitions, implementations, libraries)", "paperhash": "dou|eahasbench_energyaware_hyperparameter_and_architecture_search_benchmark", "pdf": "/pdf/9106b5730cee2cbeca225886e09cd6befa802419.pdf", "_bibtex": "@inproceedings{\ndou2023eahasbench,\ntitle={{EA}-{HAS}-Bench: Energy-aware Hyperparameter and Architecture Search Benchmark},\nauthor={Shuguang Dou and XINYANG JIANG and Cai Rong Zhao and Dongsheng Li},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=n-bvaLSCC78}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279229817, "odate": 1664468100000, "details": {"replyCount": 20}}, {"id": "WAgXmT8BeRj", "original": "EoRO5P8Ii0z", "number": 2557, "cdate": 1663850098197, "mdate": null, "ddate": null, "tcdate": 1663850098197, "tmdate": 1697935605458, "tddate": null, "forum": "WAgXmT8BeRj", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "MARS: Meta-learning as Score Matching in the Function Space", "authorids": ["~Krunoslav_Lehman_Pavasovic1", "~Jonas_Rothfuss1", "~Andreas_Krause1"], "authors": ["Krunoslav Lehman Pavasovic", "Jonas Rothfuss", "Andreas Krause"], "keywords": ["score estimation", "meta-learning", "bayesian neural networks"], "TL;DR": "Meta-learning in the function space by estimating the score function of the data-generating process marginals.", "abstract": "Meta-learning aims to extract useful inductive biases from a set of related datasets. In Bayesian meta-learning, this is typically achieved by constructing a prior distribution over neural network parameters. However, specifying families of computationally viable prior distributions over the high-dimensional neural network parameters is difficult. As a result, existing approaches resort to meta-learning restrictive diagonal Gaussian priors, severely limiting their expressiveness and performance. To circumvent these issues, we approach meta-learning through the lens of functional Bayesian neural network inference which views the prior as a stochastic process and performs inference in the function space. Specifically, we view the meta-training tasks as samples from the data-generating process and formalize meta-learning as empirically estimating the law of this stochastic process. Our approach can seamlessly acquire and represent complex prior knowledge by meta-learning the score function of the data-generating process marginals instead of parameter space priors. In a comprehensive benchmark, we demonstrate that our method achieves state-of-the-art performance in terms of predictive accuracy and substantial improvements in the quality of uncertainty estimates.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Probabilistic Methods (eg, variational inference, causal inference, Gaussian processes)", "paperhash": "pavasovic|mars_metalearning_as_score_matching_in_the_function_space", "pdf": "/pdf/1844049a3a5915d7c96f3e7a03be2fe5f82a0e4b.pdf", "supplementary_material": "", "_bibtex": "@inproceedings{\npavasovic2023mars,\ntitle={{MARS}: Meta-learning as Score Matching in the Function Space},\nauthor={Krunoslav Lehman Pavasovic and Jonas Rothfuss and Andreas Krause},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=WAgXmT8BeRj}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2210.13319/code)"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279228518, "odate": 1664468100000, "details": {"replyCount": 10}}, {"id": "KDhFkA6MQsW", "original": "9eisUiNX7bh", "number": 2555, "cdate": 1663850097931, "mdate": null, "ddate": null, "tcdate": 1663850097931, "tmdate": 1677300441720, "tddate": null, "forum": "KDhFkA6MQsW", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Faster Gradient-Free Methods for Escaping Saddle Points", "authorids": ["~Hualin_Zhang1", "~Bin_Gu1"], "authors": ["Hualin Zhang", "Bin Gu"], "keywords": [], "abstract": "Escaping from saddle points has become an important research topic in non-convex optimization. In this paper, we study the case when calculations of explicit gradients are expensive or even infeasible, and only function values are accessible. \nCurrently, there have  two types of gradient-free (zeroth-order) methods based on  random perturbation and negative curvature finding  proposed to escape saddle points  efficiently and converge to an $\\epsilon$-approximate second-order stationary point. \nNesterov's accelerated gradient descent (AGD) method can escape saddle points faster than gradient descent (GD) which have been verified in first-order algorithms. However, whether  AGD could accelerate the gradient-free methods is still unstudied. To  unfold this mystery, in this paper, we propose two accelerated  variants for the two types of gradient-free methods of escaping saddle points. We show that our algorithms can find an $\\epsilon$-approximate second-order stationary point with $\\tilde{\\mathcal{O}}(1/\\epsilon^{1.75})$ iteration complexity and $\\tilde{\\mathcal{O}}(d/\\epsilon^{1.75})$ oracle complexity, where $d$ is the problem dimension. Thus, our methods achieve a comparable convergence rate to their first-order counterparts and have fewer oracle complexity compared to prior derivative-free methods for finding second-order stationary points.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Optimization (eg, convex and non-convex optimization)", "paperhash": "zhang|faster_gradientfree_methods_for_escaping_saddle_points", "pdf": "/pdf/98601f415eedff1073917a2b7eeacd6ce9a0031f.pdf", "supplementary_material": "/attachment/6605c218da865de303c0bd714b53282fef6827fd.zip", "_bibtex": "@inproceedings{\nzhang2023faster,\ntitle={Faster Gradient-Free Methods for Escaping Saddle Points},\nauthor={Hualin Zhang and Bin Gu},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=KDhFkA6MQsW}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279228402, "odate": 1664468100000, "details": {"replyCount": 11}}, {"id": "xjxUjHa_Wpa", "original": "Q87uEJ7B4K", "number": 2470, "cdate": 1663850087545, "mdate": null, "ddate": null, "tcdate": 1663850087545, "tmdate": 1697935613116, "tddate": null, "forum": "xjxUjHa_Wpa", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "VA-DepthNet: A Variational Approach to Single Image Depth Prediction", "authorids": ["~Ce_Liu3", "~Suryansh_Kumar1", "~Shuhang_Gu3", "~Radu_Timofte1", "~Luc_Van_Gool1"], "authors": ["Ce Liu", "Suryansh Kumar", "Shuhang Gu", "Radu Timofte", "Luc Van Gool"], "keywords": ["Single Image Depth Estimation", "Variational Approach."], "abstract": "We introduce VA-DepthNet, a simple, effective, and accurate deep neural network approach for the single-image depth prediction (SIDP) problem. The proposed approach advocates using classical first-order variational constraints for this problem. While state-of-the-art deep neural network methods for SIDP learn the scene depth from images in a supervised setting, they often overlook the invaluable invariances and priors in the rigid scene space, such as the regularity of the scene. The paper's main contribution is to reveal the benefit of classical and well-founded variational constraints in the neural network design for the SIDP task. It is shown that imposing first-order variational constraints in the scene space together with popular encoder-decoder-based network architecture design provides excellent results for the supervised SIDP task. The imposed first-order variational constraint makes the network aware of the depth gradient in the scene space, i.e., regularity. The paper demonstrates the usefulness of the proposed approach via extensive evaluation and ablation analysis over several benchmark datasets, such as KITTI, NYU Depth V2, and SUN RGB-D. The VA-DepthNet at test time shows considerable improvements in depth prediction accuracy compared to the prior art and is accurate also at high-frequency regions in the scene space.  At the time of writing this paper, our method---labeled as VA-DepthNet, when tested on the KITTI depth-prediction evaluation set benchmarks, shows state-of-the-art results, and is the top-performing published approach.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Applications (eg, speech processing, computer vision, NLP)", "paperhash": "liu|vadepthnet_a_variational_approach_to_single_image_depth_prediction", "pdf": "/pdf/583bb302f77492085cedcf40f241f19b02f4e775.pdf", "supplementary_material": "/attachment/c5e1d8a85a6763c36f64cd1417552d7fa3d213fd.zip", "_bibtex": "@inproceedings{\nliu2023vadepthnet,\ntitle={{VA}-DepthNet: A Variational Approach to Single Image Depth Prediction},\nauthor={Ce Liu and Suryansh Kumar and Shuhang Gu and Radu Timofte and Luc Van Gool},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=xjxUjHa_Wpa}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2302.06556/code)"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279224104, "odate": 1664468100000, "details": {"replyCount": 10}}, {"id": "_CDixzkzeyb", "original": "iKfzVroZd51", "number": 2469, "cdate": 1663850087423, "mdate": null, "ddate": null, "tcdate": 1663850087423, "tmdate": 1676913562483, "tddate": null, "forum": "_CDixzkzeyb", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Prompt-to-Prompt Image Editing with Cross-Attention Control", "authorids": ["~Amir_Hertz1", "~Ron_Mokady1", "~Jay_Tenenbaum1", "~Kfir_Aberman1", "~Yael_Pritch1", "~Daniel_Cohen-or2"], "authors": ["Amir Hertz", "Ron Mokady", "Jay Tenenbaum", "Kfir Aberman", "Yael Pritch", "Daniel Cohen-or"], "keywords": ["Image generation", "Image editing", "Diffusion models", "Attention layer", "Computer vision", "Machine learning"], "abstract": "Recent large-scale text-driven synthesis diffusion models have attracted much attention thanks to their remarkable capabilities of generating highly diverse images that follow given text prompts. Therefore, it is only natural to build upon these synthesis models to provide text-driven image editing capabilities. However, Editing is challenging for these generative models, since an innate property of an editing technique is to preserve some content from the original image, while in the text-based models, even a small modification of the text prompt often leads to a completely different outcome. State-of-the-art methods mitigate this by requiring the users to provide a spatial mask to localize the edit, hence, ignoring the original structure and content within the masked region. In this paper, we pursue an intuitive prompt-to-prompt editing framework, where the edits are controlled by text only. We analyze a text-conditioned model in depth and observe that the cross-attention layers are the key to controlling the relation between the spatial layout of the image to each word in the prompt. With this observation, we propose to control the attention maps along the diffusion process. Our approach enables us to monitor the synthesis process by editing the textual prompt only, paving the way to a myriad of caption-based editing applications such as localized editing by replacing a word, global editing by adding a specification, and even controlling the extent to which a word is reflected in the image. We present our results over diverse images and prompts with different text-to-image models, demonstrating high-quality synthesis and fidelity to the edited prompts.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Generative models", "paperhash": "hertz|prompttoprompt_image_editing_with_crossattention_control", "pdf": "/pdf/a6e78444f28f4790c2b8eb24364ced3ce736feb0.pdf", "_bibtex": "@inproceedings{\nhertz2023prompttoprompt,\ntitle={Prompt-to-Prompt Image Editing with Cross-Attention Control},\nauthor={Amir Hertz and Ron Mokady and Jay Tenenbaum and Kfir Aberman and Yael Pritch and Daniel Cohen-or},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=_CDixzkzeyb}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279224168, "odate": 1664468100000, "details": {"replyCount": 11}}, {"id": "3lge0p5o-M-", "original": "huXIkSI5BW", "number": 2464, "cdate": 1663850086816, "mdate": null, "ddate": null, "tcdate": 1663850086816, "tmdate": 1697935613781, "tddate": null, "forum": "3lge0p5o-M-", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "DiffEdit: Diffusion-based semantic image editing with mask guidance", "authorids": ["~Guillaume_Couairon1", "~Jakob_Verbeek1", "~Holger_Schwenk1", "~Matthieu_Cord1"], "authors": ["Guillaume Couairon", "Jakob Verbeek", "Holger Schwenk", "Matthieu Cord"], "keywords": ["computer vision", "image editing", "diffusion models"], "abstract": "Image generation has recently seen tremendous advances, with diffusion models allowing to synthesize convincing images for a large variety of text prompts. In this article, we propose DiffEdit, a method to take advantage of text-conditioned diffusion models for the task of semantic image editing, where the goal is to edit an image based on a text query. Semantic image editing is an extension of image generation, with the additional constraint that the generated image should be as similar as possible to a given input image. \nCurrent editing methods based on diffusion models usually require to provide a mask, making the task much easier by treating it as a conditional inpainting task. In contrast, our main contribution is able to automatically generate a mask highlighting regions of the input image that need to be edited, by contrasting predictions of a diffusion model conditioned on different text prompts. Moreover, we rely on latent inference to preserve content in those regions of interest and show excellent synergies with mask-based diffusion. \nDiffEdit achieves state-of-the-art editing performance on ImageNet. In addition, we evaluate semantic image editing in more challenging settings, using images from the COCO dataset as well as text-based generated images.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Generative models", "paperhash": "couairon|diffedit_diffusionbased_semantic_image_editing_with_mask_guidance", "pdf": "/pdf/3d837329e3740d349726e77482e1be2f69278a1b.pdf", "_bibtex": "@inproceedings{\ncouairon2023diffedit,\ntitle={DiffEdit: Diffusion-based semantic image editing with mask guidance},\nauthor={Guillaume Couairon and Jakob Verbeek and Holger Schwenk and Matthieu Cord},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=3lge0p5o-M-}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 2 code implementations](https://www.catalyzex.com/paper/arxiv:2210.11427/code)"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279223946, "odate": 1664468100000, "details": {"replyCount": 10}}, {"id": "JTGimap_-F", "original": "uBzN68d6qOG", "number": 2371, "cdate": 1663850074758, "mdate": null, "ddate": null, "tcdate": 1663850074758, "tmdate": 1677753925213, "tddate": null, "forum": "JTGimap_-F", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Rarity Score : A New Metric to Evaluate the Uncommonness of Synthesized Images", "authorids": ["~Jiyeon_Han1", "~Hwanil_Choi1", "~Yunjey_Choi3", "~Junho_Kim3", "~Jung-Woo_Ha1", "~Jaesik_Choi1"], "authors": ["Jiyeon Han", "Hwanil Choi", "Yunjey Choi", "Junho Kim", "Jung-Woo Ha", "Jaesik Choi"], "keywords": [], "abstract": "Evaluation metrics in image synthesis play a key role to measure performances of generative models. However, most metrics mainly focus on image fidelity. Existing diversity metrics are derived by comparing distributions, and thus they cannot quantify the diversity or rarity degree of each generated image. In this work, we propose a new evaluation metric, called `rarity score', to measure both image-wise uncommonness and model-wise diversified generation performance.   \nWe first show empirical observation that typical samples are close to each other and distinctive samples are far from each other in nearest-neighbor distances on latent spaces represented by feature extractor networks such as VGG16. We then show that one can effectively filter typical or distinctive samples with the proposed metric. We also use our metric to demonstrate that the extent to which different generative models produce rare images can be effectively compared. Further, our metric can be used to compare rarities between datasets that share the same concept such as CelebA-HQ and FFHQ. Finally, we analyze the use of metrics in different designs of feature extractors to better understand the relationship between feature spaces and resulting high-rarity images. Code will be publicly available for the research community.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Generative models", "paperhash": "han|rarity_score_a_new_metric_to_evaluate_the_uncommonness_of_synthesized_images", "pdf": "/pdf/dfcead3ef1a1fcc3a124e59886764e4d93b824a7.pdf", "_bibtex": "@inproceedings{\nhan2023rarity,\ntitle={Rarity Score : A New Metric to Evaluate the Uncommonness of Synthesized Images},\nauthor={Jiyeon Han and Hwanil Choi and Yunjey Choi and Junho Kim and Jung-Woo Ha and Jaesik Choi},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=JTGimap_-F}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279800000, "odate": 1664468100000, "details": {"replyCount": 26}}, {"id": "09hVcSDkea", "original": "nOZGFTmmnj6", "number": 2355, "cdate": 1663850072897, "mdate": null, "ddate": null, "tcdate": 1663850072897, "tmdate": 1697935623702, "tddate": null, "forum": "09hVcSDkea", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Corrupted Image Modeling for Self-Supervised Visual Pre-Training", "authorids": ["~Yuxin_Fang1", "~Li_Dong1", "~Hangbo_Bao1", "~Xinggang_Wang1", "~Furu_Wei1"], "authors": ["Yuxin Fang", "Li Dong", "Hangbo Bao", "Xinggang Wang", "Furu Wei"], "keywords": ["Self-supervised Learning", "Representation Learning", "Vision Transformer"], "abstract": "We introduce Corrupted Image Modeling (CIM) for self-supervised visual pre-training. CIM uses an auxiliary generator with a small trainable BEiT to corrupt the input image instead of using artificial [MASK] tokens, where some patches are randomly selected and replaced with plausible alternatives sampled from the BEiT output distribution. Given this corrupted image, an enhancer network learns to either recover all the original image pixels, or predict whether each visual token is replaced by a generator sample or not. The generator and the enhancer are simultaneously trained and synergistically updated. After pre-training, the enhancer can be used as a high-capacity visual encoder for downstream tasks. CIM is a general and flexible visual pre-training framework that is suitable for various network architectures. For the first time, CIM demonstrates that both ViT and CNN can learn rich visual representations using a unified, non-Siamese framework. Experimental results show that our approach achieves compelling results in vision benchmarks, such as ImageNet classification and ADE20K semantic segmentation.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Unsupervised and Self-supervised learning", "paperhash": "fang|corrupted_image_modeling_for_selfsupervised_visual_pretraining", "pdf": "/pdf/4f86e1c43a4f5b420e19c75c8be820279b0b46a9.pdf", "supplementary_material": "/attachment/223016db6b0eaaed98424b1bd4deb2ca6bce43dc.zip", "_bibtex": "@inproceedings{\nfang2023corrupted,\ntitle={Corrupted Image Modeling for Self-Supervised Visual Pre-Training},\nauthor={Yuxin Fang and Li Dong and Hangbo Bao and Xinggang Wang and Furu Wei},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=09hVcSDkea}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 2 code implementations](https://www.catalyzex.com/paper/arxiv:2202.03382/code)"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279218772, "odate": 1664468100000, "details": {"replyCount": 24}}, {"id": "sd90a2ytrt", "original": "DAGikLLD47", "number": 2352, "cdate": 1663850072483, "mdate": null, "ddate": null, "tcdate": 1663850072483, "tmdate": 1697935623735, "tddate": null, "forum": "sd90a2ytrt", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Semi-Implicit Variational Inference via Score Matching", "authorids": ["~Longlin_Yu1", "~Cheng_Zhang3"], "authors": ["Longlin Yu", "Cheng Zhang"], "keywords": ["Semi-implicit variational inference", "denoising score matching", "minimax optimization"], "abstract": "Semi-implicit variational inference (SIVI) greatly enriches the expressiveness of variational families by considering implicit variational distributions defined in a hierarchical manner. However, due to the intractable densities of variational distributions, current SIVI approaches often use surrogate evidence lower bounds (ELBOs) or employ expensive inner-loop MCMC runs for unbiased ELBOs for training. In this paper, we propose SIVI-SM, a new method for SIVI based on an alternative training objective via score matching. Leveraging the hierarchical structure of semi-implicit variational families, the score matching objective allows a minimax formulation where the intractable variational densities can be naturally handled with denoising score matching.  We show that SIVI-SM closely matches the accuracy of MCMC and outperforms ELBO-based SIVI methods in a variety of Bayesian inference tasks. ", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Probabilistic Methods (eg, variational inference, causal inference, Gaussian processes)", "paperhash": "yu|semiimplicit_variational_inference_via_score_matching", "TL;DR": "A new semi-implict variational inference method using a score matching training objective", "pdf": "/pdf/0d0ccdad3898dc31ee34f2593f76a3a9d2a77512.pdf", "_bibtex": "@inproceedings{\nyu2023semiimplicit,\ntitle={Semi-Implicit Variational Inference via Score Matching},\nauthor={Longlin Yu and Cheng Zhang},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=sd90a2ytrt}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2308.10014/code)"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279218745, "odate": 1664468100000, "details": {"replyCount": 13}}, {"id": "fxjzKOdw9wb", "original": "wwyTsjZiif", "number": 2322, "cdate": 1663850068731, "mdate": null, "ddate": null, "tcdate": 1663850068731, "tmdate": 1677572375057, "tddate": null, "forum": "fxjzKOdw9wb", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Exploring Temporally Dynamic Data Augmentation for Video Recognition", "authorids": ["~Taeoh_Kim2", "~Jinhyung_Kim1", "~Minho_Shim1", "~Sangdoo_Yun1", "~Myunggu_Kang2", "~Dongyoon_Wee1", "~Sangyoun_Lee1"], "authors": ["Taeoh Kim", "Jinhyung Kim", "Minho Shim", "Sangdoo Yun", "Myunggu Kang", "Dongyoon Wee", "Sangyoun Lee"], "keywords": ["Video Recognition", "Data Augmentation"], "TL;DR": "We propose a novel data augmentation framework for video recognition that extends the static nature of image augmentations into temporally dynamic.", "abstract": "Data augmentation has recently emerged as an essential component of modern training recipes for visual recognition tasks.\nHowever, data augmentation for video recognition has been rarely explored despite its effectiveness.\nFew existing augmentation recipes for video recognition naively extend the image augmentation methods by applying the same operations to the whole video frames.\nOur main idea is that the magnitude of augmentation operations for each frame needs to be changed over time to capture the real-world video's temporal variations.\nThese variations should be generated as diverse as possible using fewer additional hyper-parameters during training.\nThrough this motivation, we propose a simple yet effective video data augmentation framework, DynaAugment.\nThe magnitude of augmentation operations on each frame is changed by an effective mechanism, Fourier Sampling that parameterizes diverse, smooth, and realistic temporal variations.\nDynaAugment also includes an extended search space suitable for video for automatic data augmentation methods.\nDynaAugment experimentally demonstrates that there are additional performance rooms to be improved from static augmentations on diverse video models.\nSpecifically, we show the effectiveness of DynaAugment on various video datasets and tasks: large-scale video recognition (Kinetics-400 and Something-Something-v2), small-scale video recognition (UCF-101 and HMDB-51), fine-grained video recognition (Diving-48 and FineGym), video action segmentation on Breakfast, video action localization on THUMOS'14, and video object detection on MOT17Det.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Applications (eg, speech processing, computer vision, NLP)", "paperhash": "kim|exploring_temporally_dynamic_data_augmentation_for_video_recognition", "pdf": "/pdf/0c7e421612ae6fa1ce1a6ff3fc3b73e0fef95830.pdf", "supplementary_material": "", "_bibtex": "@inproceedings{\nkim2023exploring,\ntitle={Exploring Temporally Dynamic Data Augmentation for Video Recognition},\nauthor={Taeoh Kim and Jinhyung Kim and Minho Shim and Sangdoo Yun and Myunggu Kang and Dongyoon Wee and Sangyoun Lee},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=fxjzKOdw9wb}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279217042, "odate": 1664468100000, "details": {"replyCount": 10}}, {"id": "dqITIpZ5Z4b", "original": "lpAtsdCraQ", "number": 2264, "cdate": 1663850061807, "mdate": null, "ddate": null, "tcdate": 1663850061807, "tmdate": 1677709825249, "tddate": null, "forum": "dqITIpZ5Z4b", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "A General Framework for Sample-Efficient Function Approximation in Reinforcement Learning", "authorids": ["~Zixiang_Chen1", "~Chris_Junchi_Li1", "~Huizhuo_Yuan1", "~Quanquan_Gu1", "~Michael_Jordan1"], "authors": ["Zixiang Chen", "Chris Junchi Li", "Huizhuo Yuan", "Quanquan Gu", "Michael Jordan"], "keywords": ["general function approximation", "sample-efficient RL", "optimization-based exploration", "Eluder dimension", "Bellman rank", "witness rank", "complexity measure", "hypothesis class"], "TL;DR": "We provide a unified framework that nearly includes all model-free and model-based RL classes while maintaining sharp sample efficiency.", "abstract": "With the increasing need for handling large state and action spaces, general function approximation has become a key technique in reinforcement learning (RL). In this paper, we propose a general framework that unifies model-based and model-free RL, and an  Admissible Bellman Characterization (ABC) class that subsumes nearly all Markov decision process (MDP) models in the literature for tractable RL. We propose a novel estimation function with decomposable structural properties for optimization-based exploration and the functional Eluder dimension as a complexity measure of the ABC class. Under our framework, a new sample-efficient algorithm namely OPtimization-based ExploRation with Approximation (OPERA) is proposed, achieving regret bounds that match or improve over the best-known results for a variety of MDP models. In particular, for MDPs with low Witness rank, under a slightly stronger assumption, OPERA improves the state-of-the-art sample complexity results by a factor of $dH$. Our framework provides a generic interface to design and analyze new RL models and algorithms.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Theory (eg, control theory, learning theory, algorithmic game theory)", "paperhash": "chen|a_general_framework_for_sampleefficient_function_approximation_in_reinforcement_learning", "pdf": "/pdf/78f90f35e722c4fb344bd1556ce84379181cd92a.pdf", "_bibtex": "@inproceedings{\nchen2023a,\ntitle={A General Framework for Sample-Efficient Function Approximation in Reinforcement Learning},\nauthor={Zixiang Chen and Chris Junchi Li and Huizhuo Yuan and Quanquan Gu and Michael Jordan},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=dqITIpZ5Z4b}\n}", "supplementary_material": "/attachment/dbb6766c533b4641dad338419feb507b4fbff977.zip", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279213338, "odate": 1664468100000, "details": {"replyCount": 8}}, {"id": "bBpT6dEjeRG", "original": "a0UuHurfBex", "number": 2208, "cdate": 1663850055113, "mdate": null, "ddate": null, "tcdate": 1663850055113, "tmdate": 1677646604025, "tddate": null, "forum": "bBpT6dEjeRG", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Adversarial Attacks on Adversarial Bandits", "authorids": ["~Yuzhe_Ma1", "~Zhijin_Zhou1"], "authors": ["Yuzhe Ma", "Zhijin Zhou"], "keywords": ["adversarial attacks", "adversarial bandits", "target action", "sublinear cumulative attack cost"], "abstract": "We study a security threat to adversarial multi-armed bandit, in which an attacker perturbs the loss or reward signal to control the behavior of the victim bandit player. We show that the attacker is able to mislead any no-regret adversarial bandit algorithm into selecting a suboptimal target action in every but sublinear (T\u2212o(T )) number of rounds, while incurring only sublinear (o(T)) cumulative attack cost. This result implies critical security concern in real-world bandit-based systems, e.g., in online recommendation, an attacker might be able to hijack the recommender system and promote a desired product. Our proposed attack algorithms require knowledge of only the regret rate, thus are agnostic to the concrete bandit algorithm employed by the victim player. We also derived a theoretical lower bound on the cumulative attack cost that any victim-agnostic attack algorithm must incur. The lower bound matches the upper bound achieved by our attack, which shows that our attack is asymptotically optimal.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)", "paperhash": "ma|adversarial_attacks_on_adversarial_bandits", "pdf": "/pdf/082ae9856f805df99b2abe0f422e94e79c2f5733.pdf", "supplementary_material": "/attachment/d3febcd5aee23b3cbe85a01cb7c000eaf90baf0d.zip", "_bibtex": "@inproceedings{\nma2023adversarial,\ntitle={Adversarial Attacks on Adversarial Bandits},\nauthor={Yuzhe Ma and Zhijin Zhou},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=bBpT6dEjeRG}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279209293, "odate": 1664468100000, "details": {"replyCount": 7}}, {"id": "QVcDQJdFTG", "original": "vncwnjvmQsN", "number": 2175, "cdate": 1663850051015, "mdate": null, "ddate": null, "tcdate": 1663850051015, "tmdate": 1677514346603, "tddate": null, "forum": "QVcDQJdFTG", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Ensuring DNN Solution Feasibility for Optimization Problems with Linear Constraints", "authorids": ["~Tianyu_Zhao2", "~Xiang_Pan4", "~Minghua_Chen1", "~Steven_Low1"], "authors": ["Tianyu Zhao", "Xiang Pan", "Minghua Chen", "Steven Low"], "keywords": ["Deep learning", "Deep neural network", "Constrained optimization", "Solution feasibility guarantee", "Optimal power flow"], "TL;DR": "This paper proposes a preventive learning framework to ensure DNN solution feasibility for optimization problems with linear constraints without post-processing.", "abstract": "We propose preventive learning as the first framework to guarantee Deep Neural Network (DNN) solution feasibility for optimization problems with linear constraints without post-processing, upon satisfying a mild condition on constraint calibration. Without loss of generality, we focus on problems with only inequality constraints. We systematically calibrate the inequality constraints used in training, thereby anticipating DNN prediction errors and ensuring the obtained solutions remain feasible. We characterize the calibration rate and a critical DNN size, based on which we can directly construct a DNN with provable solution feasibility guarantee. We further propose an Adversarial-Sample Aware training algorithm to improve its optimality performance. We apply the framework to develop DeepOPF+ for solving essential DC optimal power flow problems in grid operation. Simulation results over IEEE test cases show that it outperforms existing strong DNN baselines in ensuring 100\\% feasibility and attaining consistent optimality loss (<0.19%) and speedup (up to x228) in both light-load and heavy-load regimes, as compared to a state-of-the-art solver. We also apply our framework to a non-convex problem and show its performance advantage over existing schemes.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Deep Learning and representational learning", "paperhash": "zhao|ensuring_dnn_solution_feasibility_for_optimization_problems_with_linear_constraints", "pdf": "/pdf/e48b4b7a07d7810a1f1175bb20762f88e7436ae8.pdf", "supplementary_material": "/attachment/8fc74f0bfa54e58735080e79ae43d252e6186422.zip", "_bibtex": "@inproceedings{\nzhao2023ensuring,\ntitle={Ensuring {DNN} Solution Feasibility for Optimization Problems with Linear Constraints},\nauthor={Tianyu Zhao and Xiang Pan and Minghua Chen and Steven Low},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=QVcDQJdFTG}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279207186, "odate": 1664468100000, "details": {"replyCount": 30}}, {"id": "FKXVK9dyMM", "original": "0Sbpk13kbV", "number": 2153, "cdate": 1663850048431, "mdate": null, "ddate": null, "tcdate": 1663850048431, "tmdate": 1697935646038, "tddate": null, "forum": "FKXVK9dyMM", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "LightGCL: Simple Yet Effective Graph Contrastive Learning for Recommendation", "authorids": ["~Xuheng_Cai1", "~Chao_Huang7", "~Lianghao_Xia1", "~Xubin_Ren1"], "authors": ["Xuheng Cai", "Chao Huang", "Lianghao Xia", "Xubin Ren"], "keywords": ["recommender systems", "graph neural networks", "contrastive learning"], "TL;DR": "A new lightweight graph contrastive learning approach to enhance recommender systems", "abstract": "Graph neural network (GNN) is a powerful learning approach for graph-based recommender systems. Recently, GNNs integrated with contrastive learning have shown superior performance in recommendation with their data augmentation schemes, aiming at dealing with highly sparse data. Despite their success, most existing graph contrastive learning methods either perform stochastic augmentation (e.g., node/edge perturbation) on the user-item interaction graph, or rely on the heuristic-based augmentation techniques (e.g., user clustering) for generating contrastive views. We argue that these methods cannot well preserve the intrinsic semantic structures and are easily biased by the noise perturbation. In this paper, we propose a simple yet effective graph contrastive learning paradigm LightGCL that mitigates these issues impairing the generality and robustness of CL-based recommenders. Our model exclusively utilizes singular value decomposition for contrastive augmentation, which enables the unconstrained structural refinement with global collaborative relation modeling. Experiments conducted on several benchmark datasets demonstrate the significant improvement in performance of our model over the state-of-the-arts. Further analyses demonstrate the superiority of LightGCL's robustness against data sparsity and popularity bias. The source code of our model is available at https://github.com/HKUDS/LightGCL.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Applications (eg, speech processing, computer vision, NLP)", "paperhash": "cai|lightgcl_simple_yet_effective_graph_contrastive_learning_for_recommendation", "pdf": "/pdf/83b56b5d44ab3126d8b47ac750cd92cb0c6475dc.pdf", "supplementary_material": "/attachment/2cdd627a52cb87e9e61ea6ae23276ee476450fbb.zip", "_bibtex": "@inproceedings{\ncai2023lightgcl,\ntitle={Light{GCL}: Simple Yet Effective Graph Contrastive Learning for Recommendation},\nauthor={Xuheng Cai and Chao Huang and Lianghao Xia and Xubin Ren},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=FKXVK9dyMM}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2302.08191/code)"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279205990, "odate": 1664468100000, "details": {"replyCount": 14}}, {"id": "j9m-mVnndbm", "original": "qo3QUetwGS", "number": 2124, "cdate": 1663850044951, "mdate": null, "ddate": null, "tcdate": 1663850044951, "tmdate": 1676441604740, "tddate": null, "forum": "j9m-mVnndbm", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "MIMT: Masked Image Modeling Transformer for Video Compression", "authorids": ["~Jinxi_Xiang1", "~Kuan_Tian1", "~Jun_Zhang17"], "authors": ["Jinxi Xiang", "Kuan Tian", "Jun Zhang"], "keywords": ["video compression", "masked image modeling", "transformer", "entropy model"], "TL;DR": "draft", "abstract": "Deep learning video compression outperforms its hand-craft counterparts with enhanced flexibility and capacity. One key component of the learned video codec is the autoregressive entropy model conditioned on spatial and temporal priors. Operating autoregressive on raster scanning order naively treats the context as unidirectional. This is neither efficient nor optimal, considering that conditional information probably locates at the end of the sequence. We thus introduce an entropy model based on a masked image modeling transformer (MIMT) to learn the spatial-temporal dependencies. Video frames are first encoded into sequences of tokens and then processed with the transformer encoder as priors.   The transformer decoder learns the probability mass functions (PMFs) \\emph{conditioned} on the  priors and masked inputs. Then it is capable of selecting optimal decoding orders without a fixed direction.  During training, MIMT aims to predict the PMFs of randomly masked tokens by attending to tokens in all directions. This allows MIMT to capture the temporal dependencies from encoded priors and the spatial dependencies from the unmasked tokens, i.e., decoded tokens. At inference time, the model begins with generating  PMFs of all masked tokens in parallel and then decodes the frame iteratively from the previously-selected decoded tokens (i.e., with high confidence). In addition, we improve the overall performance with more techniques, e.g.,  manifold conditional priors accumulating a long range of information,  shifted window attention to reduce complexity. Extensive experiments demonstrate the proposed MIMT framework equipped with the new transformer entropy model achieves state-of-the-art performance on HEVC, UVG, and MCL-JCV datasets, generally outperforming the VVC in terms of PSNR and SSIM. ", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Applications (eg, speech processing, computer vision, NLP)", "paperhash": "xiang|mimt_masked_image_modeling_transformer_for_video_compression", "pdf": "/pdf/77a1b3484f4a2e2c214313bd3f9964508a65d42a.pdf", "_bibtex": "@inproceedings{\nxiang2023mimt,\ntitle={{MIMT}: Masked Image Modeling Transformer for Video Compression},\nauthor={Jinxi Xiang and Kuan Tian and Jun Zhang},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=j9m-mVnndbm}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279204428, "odate": 1664468100000, "details": {"replyCount": 33}}, {"id": "COZDy0WYGg", "original": "gTaFhItpnsC", "number": 2110, "cdate": 1663850043387, "mdate": null, "ddate": null, "tcdate": 1663850043387, "tmdate": 1697935650765, "tddate": null, "forum": "COZDy0WYGg", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Hungry Hungry Hippos: Towards Language Modeling with State Space Models", "authorids": ["~Daniel_Y_Fu1", "~Tri_Dao1", "~Khaled_Kamal_Saab1", "~Armin_W_Thomas1", "~Atri_Rudra1", "~Christopher_Re1"], "authors": ["Daniel Y Fu", "Tri Dao", "Khaled Kamal Saab", "Armin W Thomas", "Atri Rudra", "Christopher Re"], "keywords": ["language modeling", "state space models", "efficiency"], "abstract": "State space models (SSMs) have demonstrated state-of-the-art sequence modeling performance in some modalities, but underperform attention in language modeling. Moreover, despite scaling nearly linearly in sequence length instead of quadratically, SSMs are still slower than Transformers due to poor hardware utilization. In this paper, we make progress on understanding the expressivity gap between SSMs and attention in language modeling, and on reducing the hardware barrier between SSMs and attention. First, we use synthetic language modeling tasks to understand the gap between SSMs and attention. We find that existing SSMs struggle with two capabilities: recalling earlier tokens in the sequence and comparing tokens across the sequence. To understand the impact on language modeling, we propose a new SSM layer, H3, that is explicitly designed for these abilities. H3 matches attention on the synthetic languages and comes within 0.4 PPL of Transformers on OpenWebText. Furthermore, a hybrid 125M-parameter H3-attention model that retains two attention layers surprisingly outperforms Transformers on OpenWebText by 1.0 PPL. Next, to improve the efficiency of training SSMs on modern hardware, we propose FlashConv. FlashConv uses a fused block FFT algorithm to improve efficiency on sequences up to 8K, and introduces a novel state passing algorithm that exploits the recurrent properties of SSMs to scale to longer sequences. FlashConv yields 2$\\times$ speedup on the long-range arena benchmark and allows hybrid language models to generate text 2.4$\\times$ faster than Transformers. Using FlashConv, we scale hybrid H3-attention language models up to 2.7B parameters on the Pile and find promising initial results, achieving lower perplexity than Transformers and outperforming Transformers in zero- and few-shot learning on a majority of tasks in the SuperGLUE benchmark.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Deep Learning and representational learning", "paperhash": "fu|hungry_hungry_hippos_towards_language_modeling_with_state_space_models", "TL;DR": "We study the expressivity gap between state space models (SSMs) and attention on language modeling and reduce the hardware barrier between SSMs and attention.", "pdf": "/pdf/b3774a7e6b7bda0783528bf1dc8e2600707d797f.pdf", "supplementary_material": "/attachment/4c012ef368f3eaa6ff0ecd823df3989e121a78f0.zip", "_bibtex": "@inproceedings{\nfu2023hungry,\ntitle={Hungry Hungry Hippos: Towards Language Modeling with State Space Models},\nauthor={Daniel Y Fu and Tri Dao and Khaled Kamal Saab and Armin W Thomas and Atri Rudra and Christopher Re},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=COZDy0WYGg}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2212.14052/code)"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279203685, "odate": 1664468100000, "details": {"replyCount": 12}}, {"id": "4fZc_79Lrqs", "original": "EZgqp9OuA1", "number": 2102, "cdate": 1663850042406, "mdate": null, "ddate": null, "tcdate": 1663850042406, "tmdate": 1681520964199, "tddate": null, "forum": "4fZc_79Lrqs", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "ACMP: Allen-Cahn Message Passing with Attractive and Repulsive Forces for Graph Neural Networks", "authorids": ["~Yuelin_Wang2", "~Kai_Yi2", "~Xinliang_Liu1", "~Yu_Guang_Wang1", "~Shi_Jin1"], "authors": ["Yuelin Wang", "Kai Yi", "Xinliang Liu", "Yu Guang Wang", "Shi Jin"], "keywords": [], "abstract": "Neural message passing is a basic feature extraction unit for graph-structured data considering neighboring node features in network propagation from one layer to the next. We model such process by an interacting particle system with attractive and repulsive forces and the Allen-Cahn force arising in the modeling of phase transition. The dynamics of the system is a reaction-diffusion process which can separate particles without blowing up. This induces an Allen-Cahn message passing (ACMP) for graph neural networks where the numerical iteration for the particle system solution constitutes the message passing propagation. ACMP which has a simple implementation with a neural ODE solver can propel the network depth up to one hundred of layers with theoretically proven strictly positive lower bound of the Dirichlet energy. It thus provides a deep model of GNNs circumventing the common GNN problem of oversmoothing. GNNs with ACMP achieve state of the art performance for real-world node classification tasks on both homophilic and heterophilic datasets. Codes are available at https://github.com/ykiiiiii/ACMP", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Deep Learning and representational learning", "paperhash": "wang|acmp_allencahn_message_passing_with_attractive_and_repulsive_forces_for_graph_neural_networks", "pdf": "/pdf/d58ae8ad07cd24feb44b22279a901a3b7fbf5279.pdf", "supplementary_material": "", "_bibtex": "@inproceedings{\nwang2023acmp,\ntitle={{ACMP}: Allen-Cahn Message Passing with Attractive and Repulsive Forces for Graph Neural Networks},\nauthor={Yuelin Wang and Kai Yi and Xinliang Liu and Yu Guang Wang and Shi Jin},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=4fZc_79Lrqs}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279203082, "odate": 1664468100000, "details": {"replyCount": 13}}, {"id": "cFuMmbWiN6", "original": "Qmrfu65bG-", "number": 2095, "cdate": 1663850041569, "mdate": null, "ddate": null, "tcdate": 1663850041569, "tmdate": 1677598868441, "tddate": null, "forum": "cFuMmbWiN6", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Relational Attention: Generalizing Transformers for Graph-Structured Tasks", "authorids": ["~Cameron_Diao1", "~Ricky_Loynd1"], "authors": ["Cameron Diao", "Ricky Loynd"], "keywords": ["Graph Neural Networks", "Transformers", "Graph Representation Learning", "Neural Algorithmic Reasoning"], "TL;DR": "We generalize transformer attention to include edge vectors, which are then updated along with the standard node vectors in each layer of a transformer's computation.", "abstract": "Transformers flexibly operate over sets of real-valued vectors representing task-specific entities and their attributes, where each vector might encode one word-piece token and its position in a sequence, or some piece of information that carries no position at all. As set processors, transformers are at a disadvantage in reasoning over more general graph-structured data where nodes represent entities and edges represent relations between entities. To address this shortcoming, we generalize transformer attention to consider and update edge vectors in each transformer layer. We evaluate this relational transformer on a diverse array of graph-structured tasks, including the large and challenging CLRS Algorithmic Reasoning Benchmark. There, it dramatically outperforms state-of-the-art graph neural networks expressly designed to reason over graph-structured data. Our analysis demonstrates that these gains are attributable to relational attention's inherent ability to leverage the greater expressivity of graphs over sets.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Deep Learning and representational learning", "paperhash": "diao|relational_attention_generalizing_transformers_for_graphstructured_tasks", "pdf": "/pdf/49232cd55923175bab0a33ca81d281c76edcfaad.pdf", "supplementary_material": "/attachment/0ded88bcf3debf1216eed96055932324f3450686.zip", "_bibtex": "@inproceedings{\ndiao2023relational,\ntitle={Relational Attention: Generalizing Transformers for Graph-Structured Tasks},\nauthor={Cameron Diao and Ricky Loynd},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=cFuMmbWiN6}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279202699, "odate": 1664468100000, "details": {"replyCount": 7}}, {"id": "99RpBVpLiX", "original": "KpAXTig3bT1", "number": 2092, "cdate": 1663850041203, "mdate": null, "ddate": null, "tcdate": 1663850041203, "tmdate": 1697935652674, "tddate": null, "forum": "99RpBVpLiX", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Distilling Model Failures as Directions in Latent Space", "authorids": ["~Saachi_Jain1", "~Hannah_Lawrence1", "~Ankur_Moitra1", "~Aleksander_Madry1"], "authors": ["Saachi Jain", "Hannah Lawrence", "Ankur Moitra", "Aleksander Madry"], "keywords": ["datasets", "biases", "subpopulations"], "TL;DR": "We present a scalable method for automatically distilling and captioning a model's failure modes as directions in a latent space.", "abstract": "Existing methods for isolating hard subpopulations and spurious correlations in datasets often require human intervention. This can make these methods labor-intensive and dataset-specific. To address these shortcomings, we present a scalable method for automatically distilling a model's failure modes. Specifically, we harness linear classifiers to identify consistent error patterns, and, in turn, induce a natural representation of these failure modes as directions within the feature space. We demonstrate that this framework allows us to discover and automatically caption challenging subpopulations within the training dataset. Moreover, by combining our framework with off-the-shelf diffusion models, we can generate images that are especially challenging for the analyzed model, and thus can be used to perform synthetic data augmentation that helps remedy the model's failure modes.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Deep Learning and representational learning", "paperhash": "jain|distilling_model_failures_as_directions_in_latent_space", "pdf": "/pdf/c9daa261ea96d95a6dee52da157a59e14333cf07.pdf", "supplementary_material": "/attachment/cf68800d62e70258a55e3370c07c56e0ad7cd3e2.zip", "_bibtex": "@inproceedings{\njain2023distilling,\ntitle={Distilling Model Failures as Directions in Latent Space},\nauthor={Saachi Jain and Hannah Lawrence and Ankur Moitra and Aleksander Madry},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=99RpBVpLiX}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2206.14754/code)"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279202550, "odate": 1664468100000, "details": {"replyCount": 12}}, {"id": "8qjSA5QACb40", "original": "55SpmVx7tSW", "number": 2072, "cdate": 1663850039043, "mdate": null, "ddate": null, "tcdate": 1663850039043, "tmdate": 1676652324207, "tddate": null, "forum": "8qjSA5QACb40", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Combinatorial-Probabilistic Trade-Off: P-Values of Community Properties Test in the Stochastic Block Models", "authorids": ["~Shuting_Shen1", "~Junwei_Lu1"], "authors": ["Shuting Shen", "Junwei Lu"], "keywords": ["combinatorial inference", "stochastic block models", "community properties", "minimax lower bound"], "TL;DR": "We propose an inferential framework testing the general community combinatorial properties of the stochastic block model and prove the minimax lower bound of the general community property test.", "abstract": "We propose an inferential framework testing the general community combinatorial properties of the stochastic block model.  We aim to test the hypothesis on whether a certain community property is satisfied, e.g., whether a given set of nodes belong to the same community, and provide p-values for uncertainty quantification. Our framework is applicable to all symmetric community properties. To ease the challenges caused by the combinatorial nature of community properties, we develop a novel shadowing bootstrap method.  Utilizing the symmetry, our method can find a shadowing representative of the true assignment and the number of tested assignments in the alternative is largely reduced.  In theory, we introduce a combinatorial distance between two community classes and show a combinatorial-probabilistic trade-off phenomenon. Our test is honest as long as the product of the combinatorial distance between two communities and the probabilistic distance between two connection probabilities is sufficiently large.  Besides, we show that such trade-off also exists in the information-theoretic lower bound.  We also implement numerical experiments to show the validity of our method.", "pdf": "/pdf/5c689940c93924b24ea5f66a7b1ea95007134c04.pdf", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "supplementary_material": "/attachment/5a6903c26aa7292675c23a901d0c7befb8990c28.zip", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Theory (eg, control theory, learning theory, algorithmic game theory)", "paperhash": "shen|combinatorialprobabilistic_tradeoff_pvalues_of_community_properties_test_in_the_stochastic_block_models", "_bibtex": "@inproceedings{\nshen2023combinatorialprobabilistic,\ntitle={Combinatorial-Probabilistic Trade-Off: P-Values of Community Properties Test in the Stochastic Block Models},\nauthor={Shuting Shen and Junwei Lu},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=8qjSA5QACb40}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279201527, "odate": 1664468100000, "details": {"replyCount": 13}}, {"id": "yYbhKqdi7Hz", "original": "Ns5SYFr4Md", "number": 2055, "cdate": 1663850037073, "mdate": null, "ddate": null, "tcdate": 1663850037073, "tmdate": 1676399881505, "tddate": null, "forum": "yYbhKqdi7Hz", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Continuized Acceleration for Quasar Convex Functions  in Non-Convex Optimization", "authorids": ["~Jun-Kun_Wang1", "~Andre_Wibisono1"], "authors": ["Jun-Kun Wang", "Andre Wibisono"], "keywords": [], "abstract": "Quasar convexity is a condition that allows some first-order methods to efficiently minimize a function even when the optimization landscape is non-convex. Previous works develop near-optimal accelerated algorithms for minimizing this class of functions, however, they require a subroutine of binary search which results in multiple calls to gradient evaluations in each iteration, and consequently the total number of gradient evaluations does not match a known lower bound. In this work, we show that a recently proposed continuized Nesterov acceleration can be applied to minimizing quasar convex functions and achieves the optimal bound with a high probability. Furthermore, we find that the objective functions of training generalized linear models (GLMs) satisfy quasar convexity, which broadens the applicability of the relevant algorithms, while known practical examples of quasar convexity in non-convex learning are sparse in the literature. We also show that if a smooth and one-point strongly convex, Polyak-Lojasiewicz, or quadratic-growth function satisfies quasar convexity, then attaining an accelerated linear rate for minimizing the function is possible under certain conditions, while acceleration is not known in general for these classes of functions.\n", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Optimization (eg, convex and non-convex optimization)", "paperhash": "wang|continuized_acceleration_for_quasar_convex_functions_in_nonconvex_optimization", "pdf": "/pdf/1c5f7418978dd32dfc6351a734e73fa6cc98583e.pdf", "supplementary_material": "/attachment/51863c5ed77136dfae4cf92908c28b9440f0d974.zip", "_bibtex": "@inproceedings{\nwang2023continuized,\ntitle={Continuized Acceleration for Quasar Convex Functions  in Non-Convex Optimization},\nauthor={Jun-Kun Wang and Andre Wibisono},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=yYbhKqdi7Hz}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279200324, "odate": 1664468100000, "details": {"replyCount": 13}}, {"id": "8sSnD78NqTN", "original": "UbsIE9NoS6J", "number": 2052, "cdate": 1663850036695, "mdate": null, "ddate": null, "tcdate": 1663850036695, "tmdate": 1697935657835, "tddate": null, "forum": "8sSnD78NqTN", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Learning Soft Constraints From Constrained Expert Demonstrations", "authorids": ["~Ashish_Gaurav1", "~Kasra_Rezaee1", "~Guiliang_Liu1", "~Pascal_Poupart2"], "authors": ["Ashish Gaurav", "Kasra Rezaee", "Guiliang Liu", "Pascal Poupart"], "keywords": ["inverse reinforcement learning", "constraint learning"], "abstract": "Inverse reinforcement learning (IRL) methods assume that the expert data is generated by an agent optimizing some reward function. However, in many settings, the agent may optimize a reward function subject to some constraints, where the constraints induce behaviors that may be otherwise difficult to express with just a reward function. We consider the setting where the reward function is given, and the constraints are unknown, and propose a method that is able to recover these constraints satisfactorily from the expert data. While previous work has focused on recovering hard constraints, our method can recover cumulative soft constraints that the agent satisfies on average per episode. In IRL fashion, our method solves this problem by adjusting the constraint function iteratively through a constrained optimization procedure, until the agent behavior matches the expert behavior. We demonstrate our approach on synthetic environments, robotics environments and real world highway driving scenarios.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)", "paperhash": "gaurav|learning_soft_constraints_from_constrained_expert_demonstrations", "pdf": "/pdf/8fcf77a080574ee36abb6525663524292f7b5217.pdf", "supplementary_material": "/attachment/ecf58c5e058aaae3db43179a16bfda43e4e006cf.zip", "_bibtex": "@inproceedings{\ngaurav2023learning,\ntitle={Learning Soft Constraints From Constrained Expert Demonstrations},\nauthor={Ashish Gaurav and Kasra Rezaee and Guiliang Liu and Pascal Poupart},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=8sSnD78NqTN}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2206.01311/code)"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279200200, "odate": 1664468100000, "details": {"replyCount": 18}}, {"id": "cDYRS5iZ16f", "original": "rYuUzYbPat2", "number": 2031, "cdate": 1663850033911, "mdate": null, "ddate": null, "tcdate": 1663850033911, "tmdate": 1697935660105, "tddate": null, "forum": "cDYRS5iZ16f", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Learning to Grow Pretrained Models for Efficient Transformer Training", "authorids": ["~Peihao_Wang1", "~Rameswar_Panda1", "~Lucas_Torroba_Hennigen1", "~Philip_Greengard1", "~Leonid_Karlinsky3", "~Rogerio_Feris1", "~David_Daniel_Cox1", "~Zhangyang_Wang1", "~Yoon_Kim1"], "authors": ["Peihao Wang", "Rameswar Panda", "Lucas Torroba Hennigen", "Philip Greengard", "Leonid Karlinsky", "Rogerio Feris", "David Daniel Cox", "Zhangyang Wang", "Yoon Kim"], "keywords": ["Transformer", "Efficient Training", "Model Reuse"], "TL;DR": "Learning to grow smaller, extant models to enable faster training of newer, larger transformers.", "abstract": "Scaling transformers has led to significant breakthroughs in many domains, leading to a paradigm in which larger versions of existing models are trained and released on a periodic basis. New instances of such models are typically trained completely from scratch, despite the fact that they are often just scaled-up versions of their smaller counterparts. How can we use the implicit knowledge in the parameters of smaller, extant models to enable faster training of newer, larger models? This paper describes an approach for accelerating transformer training by learning to grow pretrained transformers, where we learn to linearly map  the parameters of the smaller model to initialize the larger model. For tractable learning, we factorize the linear transformation as a composition of  (linear) width- and  depth-growth operators, and further employ a  Kronecker factorization of these growth operators to encode architectural knowledge. Extensive experiments across both language and vision transformers demonstrate that our learned Linear Growth Operator (LiGO)  can save up to 50% computational cost of training from scratch, while also consistently outperforming strong baselines that also reuse smaller pretrained models to initialize larger models.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Applications (eg, speech processing, computer vision, NLP)", "paperhash": "wang|learning_to_grow_pretrained_models_for_efficient_transformer_training", "pdf": "/pdf/043fba8d0ed8251ba2eb757665721e7fc496d839.pdf", "_bibtex": "@inproceedings{\nwang2023learning,\ntitle={Learning to Grow Pretrained Models for Efficient Transformer Training},\nauthor={Peihao Wang and Rameswar Panda and Lucas Torroba Hennigen and Philip Greengard and Leonid Karlinsky and Rogerio Feris and David Daniel Cox and Zhangyang Wang and Yoon Kim},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=cDYRS5iZ16f}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2303.00980/code)"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279199018, "odate": 1664468100000, "details": {"replyCount": 12}}, {"id": "hQwb-lbM6EL", "original": "xvTJamxdKzO", "number": 2022, "cdate": 1663850032788, "mdate": null, "ddate": null, "tcdate": 1663850032788, "tmdate": 1697935661868, "tddate": null, "forum": "hQwb-lbM6EL", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "InCoder: A Generative Model for Code Infilling and Synthesis", "authorids": ["~Daniel_Fried1", "~Armen_Aghajanyan1", "~Jessy_Lin1", "~Sida_Wang2", "~Eric_Wallace1", "~Freda_Shi1", "~Ruiqi_Zhong1", "~Scott_Yih1", "~Luke_Zettlemoyer1", "~Mike_Lewis1"], "authors": ["Daniel Fried", "Armen Aghajanyan", "Jessy Lin", "Sida Wang", "Eric Wallace", "Freda Shi", "Ruiqi Zhong", "Scott Yih", "Luke Zettlemoyer", "Mike Lewis"], "keywords": ["code generation", "program synthesis", "language to code"], "TL;DR": "An infilling-capable code completion model, evaluated on tasks including language-to-code, type inference, and comment generation.", "abstract": "Code is seldom written in a single left-to-right pass and is instead repeatedly edited and refined. We introduce InCoder, a unified generative model that can perform program synthesis (via left-to-right generation) as well as editing (via masking and infilling). InCoder is trained to generate code files from a large corpus of permissively licensed code, where regions of code have been randomly masked and moved to the end of each file, allowing code infilling with bidirectional context. Our model is the first large generative code model that is able to infill arbitrary regions of code, which we evaluate in a zero-shot setting on challenging tasks such as type inference, comment generation, and variable re-naming. We find that the ability to condition on bidirectional context substantially improves performance on these tasks, while still performing comparably on standard program synthesis benchmarks in comparison to left-to-right only models pretrained at similar scale. Our models and code will be publicly released.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Applications (eg, speech processing, computer vision, NLP)", "paperhash": "fried|incoder_a_generative_model_for_code_infilling_and_synthesis", "pdf": "/pdf/be45f53a1cdce7b55fea4d2ed6ba734f27dea87f.pdf", "_bibtex": "@inproceedings{\nfried2023incoder,\ntitle={InCoder: A Generative Model for Code Infilling and Synthesis},\nauthor={Daniel Fried and Armen Aghajanyan and Jessy Lin and Sida Wang and Eric Wallace and Freda Shi and Ruiqi Zhong and Scott Yih and Luke Zettlemoyer and Mike Lewis},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=hQwb-lbM6EL}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2204.05999/code)"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279198223, "odate": 1664468100000, "details": {"replyCount": 12}}, {"id": "E01k9048soZ", "original": "byAjS5RFzIY", "number": 1996, "cdate": 1663850028979, "mdate": null, "ddate": null, "tcdate": 1663850028979, "tmdate": 1677810039517, "tddate": null, "forum": "E01k9048soZ", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "UNIFIED-IO: A Unified Model for Vision, Language, and Multi-modal Tasks", "authorids": ["~Jiasen_Lu2", "~Christopher_Clark1", "~Rowan_Zellers1", "~Roozbeh_Mottaghi1", "~Aniruddha_Kembhavi1"], "authors": ["Jiasen Lu", "Christopher Clark", "Rowan Zellers", "Roozbeh Mottaghi", "Aniruddha Kembhavi"], "keywords": [], "abstract": "We propose Unified-IO, a model that performs a large variety of AI tasks spanning classical computer vision tasks, including pose estimation, object detection, depth estimation and image generation, vision-and-language tasks such as region captioning and referring expression, to natural language processing tasks such as question answering and paraphrasing. Developing a single unified model for such a large variety of tasks poses unique challenges due to the heterogeneous inputs and outputs pertaining to each task, including RGB images, per-pixel maps, binary masks, bounding boxes, and language. We achieve this unification by homogenizing every supported input and output into a sequence of discrete vocabulary tokens. This common representation across all tasks allows us to train a single transformer-based architecture, jointly on over 90 diverse datasets in the vision and language fields. Unified-IO is the first model capable of performing all 7 tasks on the GRIT benchmark and produces strong results across 16 diverse benchmarks like NYUv2-Depth, ImageNet, VQA2.0, OK-VQA, Swig, VizWizGround, BoolQ, and SciTail, with no task-specific fine-tuning. Code and pre-trained models will be made publicly available.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Applications (eg, speech processing, computer vision, NLP)", "paperhash": "lu|unifiedio_a_unified_model_for_vision_language_and_multimodal_tasks", "pdf": "/pdf/4f576a5041215d0298e9540a8c23041533da1724.pdf", "supplementary_material": "/attachment/f20b20659f2134138240091060a33b38914ef019.zip", "_bibtex": "@inproceedings{\nlu2023unifiedio,\ntitle={{UNIFIED}-{IO}: A Unified Model for Vision, Language, and Multi-modal Tasks},\nauthor={Jiasen Lu and Christopher Clark and Rowan Zellers and Roozbeh Mottaghi and Aniruddha Kembhavi},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=E01k9048soZ}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279197031, "odate": 1664468100000, "details": {"replyCount": 14}}, {"id": "3k5CUGDLNdd", "original": "QAd3kbbp_O", "number": 1995, "cdate": 1663850028857, "mdate": null, "ddate": null, "tcdate": 1663850028857, "tmdate": 1697935664889, "tddate": null, "forum": "3k5CUGDLNdd", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Benchmarking Offline Reinforcement Learning on Real-Robot Hardware", "authorids": ["~Nico_G\u00fcrtler1", "~Sebastian_Blaes1", "~Pavel_Kolev1", "~Felix_Widmaier1", "~Manuel_Wuthrich1", "~Stefan_Bauer1", "~Bernhard_Sch\u00f6lkopf1", "~Georg_Martius1"], "authors": ["Nico G\u00fcrtler", "Sebastian Blaes", "Pavel Kolev", "Felix Widmaier", "Manuel Wuthrich", "Stefan Bauer", "Bernhard Sch\u00f6lkopf", "Georg Martius"], "keywords": ["offline reinforcement learning", "robotic manipulation", "dexterous manipulation", "TriFinger platform"], "TL;DR": "We propose new robotics datasets for dexterous manipulation and benchmark offline RL algorithms on them.", "abstract": "Learning policies from previously recorded data is a promising direction for real-world robotics tasks, as online learning is often infeasible. Dexterous manipulation in particular remains an open problem in its general form. The combination of offline reinforcement learning with large diverse datasets, however, has the potential to lead to a breakthrough in this challenging domain analogously to the rapid progress made in supervised learning in recent years. To coordinate the efforts of the research community toward tackling this problem, we propose a benchmark including: i) a large collection of data for offline learning from a dexterous manipulation platform on two tasks, obtained with capable RL agents trained in simulation; ii) the option to execute learned policies on a real-world robotic system and a simulation for efficient debugging. We evaluate prominent open-sourced offline reinforcement learning algorithms on the datasets and provide a reproducible experimental setup for offline reinforcement learning on real systems.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)", "paperhash": "g\u00fcrtler|benchmarking_offline_reinforcement_learning_on_realrobot_hardware", "pdf": "/pdf/67dcc1b0cfc87e5d6aeaf0391094380da9c1897b.pdf", "_bibtex": "@inproceedings{\ng{\\\"u}rtler2023benchmarking,\ntitle={Benchmarking Offline Reinforcement Learning on Real-Robot Hardware},\nauthor={Nico G{\\\"u}rtler and Sebastian Blaes and Pavel Kolev and Felix Widmaier and Manuel Wuthrich and Stefan Bauer and Bernhard Sch{\\\"o}lkopf and Georg Martius},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=3k5CUGDLNdd}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 4 code implementations](https://www.catalyzex.com/paper/arxiv:2307.15690/code)"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279196914, "odate": 1664468100000, "details": {"replyCount": 9}}, {"id": "RgUPdudkWlN", "original": "kCwjkHgq5yz", "number": 1994, "cdate": 1663850028733, "mdate": null, "ddate": null, "tcdate": 1663850028733, "tmdate": 1697935664862, "tddate": null, "forum": "RgUPdudkWlN", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "CUDA: Curriculum of Data Augmentation for Long-tailed Recognition", "authorids": ["~Sumyeong_Ahn1", "~Jongwoo_Ko1", "~Se-Young_Yun1"], "authors": ["Sumyeong Ahn", "Jongwoo Ko", "Se-Young Yun"], "keywords": ["Long-tailed recognition", "class imbalance"], "abstract": "Class imbalance problems frequently occur in real-world tasks, and conventional deep learning algorithms are well known for performance degradation on imbalanced training datasets. To mitigate this problem, many approaches have aimed to balance among given classes by re-weighting or re-sampling training samples. These re-balancing methods increase the impact of minority classes and reduce the influence of majority classes on the output of models. However, the extracted representations may be of poor quality owing to the limited number of minority samples. To handle this restriction, several methods have been developed that increase the representations of minority samples by leveraging the features of the majority samples. Despite extensive recent studies, no deep analysis has been conducted on determination of classes to be augmented and strength of augmentation has been conducted. In this study, we first investigate the correlation between the degree of augmentation and class-wise performance, and find that the proper degree of augmentation must be allocated for each class to mitigate class imbalance problems. Motivated by this finding, we propose a simple and efficient novel curriculum, which is designed to find the appropriate per-class strength of data augmentation, called CUDA: CUrriculum of Data Augmentation for long-tailed recognition. CUDA can simply be integrated into existing long-tailed recognition methods. We present the results of experiments showing that CUDA effectively achieves better generalization performance compared to the state-of-the-art method on various imbalanced datasets such as CIFAR-100-LT, ImageNet-LT, and iNaturalist 2018. \n", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Deep Learning and representational learning", "paperhash": "ahn|cuda_curriculum_of_data_augmentation_for_longtailed_recognition", "TL;DR": "We propose a class-wise data augmentation method by designing the curriculum of data augmentation, which is based on our findings that stronger augmentation on major classes improves the performance on long-tailed recognition.", "pdf": "/pdf/653fc91920f2396c3eec7c4aab421dc95ba6ccf5.pdf", "supplementary_material": "", "_bibtex": "@inproceedings{\nahn2023cuda,\ntitle={{CUDA}: Curriculum of Data Augmentation for Long-tailed Recognition},\nauthor={Sumyeong Ahn and Jongwoo Ko and Se-Young Yun},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=RgUPdudkWlN}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 4 code implementations](https://www.catalyzex.com/paper/arxiv:2302.05499/code)"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279196787, "odate": 1664468100000, "details": {"replyCount": 35}}, {"id": "5ktFNz_pJLK", "original": "_dU3RUTsy-F", "number": 1982, "cdate": 1663850027186, "mdate": null, "ddate": null, "tcdate": 1663850027186, "tmdate": 1697935667270, "tddate": null, "forum": "5ktFNz_pJLK", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Learning to Estimate Shapley Values with Vision Transformers", "authorids": ["~Ian_Connick_Covert1", "~Chanwoo_Kim3", "~Su-In_Lee2"], "authors": ["Ian Connick Covert", "Chanwoo Kim", "Su-In Lee"], "keywords": ["ViTs", "Shapley values", "amortization", "explainability"], "TL;DR": "A learning-based approach to efficiently calculate Shapley values for ViTs", "abstract": "Transformers have become a default architecture in computer vision, but understanding what drives their predictions remains a challenging problem. Current explanation approaches rely on attention values or input gradients, but these provide a limited view of a model\u2019s dependencies. Shapley values offer a theoretically sound alternative, but their computational cost makes them impractical for large, high-dimensional models. In this work, we aim to make Shapley values practical for vision transformers (ViTs). To do so, we first leverage an attention masking approach to evaluate ViTs with partial information, and we then develop a procedure to generate Shapley value explanations via a separate, learned explainer model. Our experiments compare Shapley values to many baseline methods (e.g., attention rollout, GradCAM, LRP), and we find that our approach provides more accurate explanations than existing methods for ViTs.", "pdf": "/pdf/63a91ca98681923ceee596aa7d3254f49445c743.pdf", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)", "paperhash": "covert|learning_to_estimate_shapley_values_with_vision_transformers", "supplementary_material": "/attachment/cc200e79c97b312761ec59f9c0b11831c5ed8c95.zip", "_bibtex": "@inproceedings{\ncovert2023learning,\ntitle={Learning to Estimate Shapley Values with Vision Transformers},\nauthor={Ian Connick Covert and Chanwoo Kim and Su-In Lee},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=5ktFNz_pJLK}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 2 code implementations](https://www.catalyzex.com/paper/arxiv:2206.05282/code)"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279195931, "odate": 1664468100000, "details": {"replyCount": 21}}, {"id": "Iuubb9W6Jtk", "original": "DDAvJkmJuAz", "number": 1977, "cdate": 1663850026560, "mdate": null, "ddate": null, "tcdate": 1663850026560, "tmdate": 1697935667879, "tddate": null, "forum": "Iuubb9W6Jtk", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "A framework for benchmarking Class-out-of-distribution detection and its application to ImageNet", "authorids": ["~Ido_Galil1", "~Mohammed_Dabbah1", "~Ran_El-Yaniv1"], "authors": ["Ido Galil", "Mohammed Dabbah", "Ran El-Yaniv"], "keywords": ["benchmarking", "out of distribution", "class out of distribution", "OOD", "OOD detection"], "TL;DR": "We present a framework for benchmarking the performance of image classifiers in detecting OOD. We apply it to benchmark 525 pretrained ImageNet classifiers, and analyze their performance resulting in interesting conclusions", "abstract": "When deployed for risk-sensitive tasks, deep neural networks must be able to detect instances with labels from outside the distribution for which they were trained.\nIn this paper we present a novel framework to benchmark the ability of image classifiers to detect class-out-of-distribution instances\n(i.e., instances whose true labels do not appear in the training distribution) at various levels of detection difficulty.\nWe apply this technique to ImageNet, and benchmark 525 pretrained, publicly available, ImageNet-1k classifiers. \nThe code for generating a benchmark for any ImageNet-1k classifier, along with the benchmarks prepared for the above-mentioned 525 models is available at https://github.com/mdabbah/COOD_benchmarking.\n\nThe usefulness of the proposed framework and its advantage over alternative existing benchmarks is demonstrated by analyzing the results obtained for these models, which reveals numerous novel observations including:\n(1) knowledge distillation consistently improves class-out-of-distribution (C-OOD) detection performance; (2) a subset of ViTs performs better C-OOD detection than any other model; (3) the language\u2013-vision CLIP model achieves good zero-shot detection performance, with its best instance outperforming 96% of all other models evaluated; (4) accuracy and in-distribution ranking are positively correlated to C-OOD detection; and \n(5) we compare various confidence functions for C-OOD detection.\nOur companion paper, also published in ICLR 2023 (What Can We Learn From The Selective Prediction And Uncertainty Estimation Performance Of 523 Imagenet Classifiers), examines the uncertainty estimation performance (ranking, calibration, and selective prediction performance) of these classifiers in an in-distribution setting.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Deep Learning and representational learning", "paperhash": "galil|a_framework_for_benchmarking_classoutofdistribution_detection_and_its_application_to_imagenet", "pdf": "/pdf/973b16b739dacc7aaa862e3a74f9469f31742eb0.pdf", "_bibtex": "@inproceedings{\ngalil2023a,\ntitle={A framework for benchmarking Class-out-of-distribution detection and its application to ImageNet},\nauthor={Ido Galil and Mohammed Dabbah and Ran El-Yaniv},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=Iuubb9W6Jtk}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2302.11893/code)"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279195666, "odate": 1664468100000, "details": {"replyCount": 11}}, {"id": "vDFA1tpuLvk", "original": "Sqdmg0NegCH", "number": 1971, "cdate": 1663850025821, "mdate": null, "ddate": null, "tcdate": 1663850025821, "tmdate": 1697935668885, "tddate": null, "forum": "vDFA1tpuLvk", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Retrieval-based Controllable Molecule Generation", "authorids": ["~Zichao_Wang1", "~Weili_Nie1", "~Zhuoran_Qiao1", "~Chaowei_Xiao2", "~Richard_Baraniuk1", "~Anima_Anandkumar1"], "authors": ["Zichao Wang", "Weili Nie", "Zhuoran Qiao", "Chaowei Xiao", "Richard Baraniuk", "Anima Anandkumar"], "keywords": ["controllable molecule generation", "retrieval mechanism", "exemplar molecules", "drug discovery"], "TL;DR": "We propose a first-of-its-kind retrieval-based framework for controllable molecule generation which can effectively extrapolate beyond the retrieval database and achieves state-of-the-art performance on various benchmarks.", "abstract": "Generating new molecules with specified chemical and biological properties via generative models has emerged as a promising direction for drug discovery. However, existing methods require extensive training/fine-tuning with a large dataset, often unavailable in real-world generation tasks. In this work, we propose a new retrieval-based framework for controllable molecule generation. We use a small set of exemplar molecules,  i.e., those that (partially) satisfy the design criteria, to steer the pre-trained generative model towards synthesizing molecules that satisfy the given design criteria. We design a retrieval mechanism that retrieves and fuses the exemplar molecules with the input molecule, which is trained by a new self-supervised objective that predicts the nearest neighbor of the input molecule. We also propose an iterative refinement process to dynamically update the generated molecules and retrieval database for better generalization. Our approach is agnostic to the choice of generative models and requires no task-specific fine-tuning. On various tasks ranging from simple design criteria to a challenging real-world scenario for designing lead compounds that bind to the SARS-CoV-2 main protease, we demonstrate our approach extrapolates well beyond the retrieval database, and achieves better performance and wider applicability than previous methods.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )", "paperhash": "wang|retrievalbased_controllable_molecule_generation", "pdf": "/pdf/22616ca08340c5ed2e05df70269bcf7e3ebf5592.pdf", "_bibtex": "@inproceedings{\nwang2023retrievalbased,\ntitle={Retrieval-based Controllable Molecule Generation},\nauthor={Zichao Wang and Weili Nie and Zhuoran Qiao and Chaowei Xiao and Richard Baraniuk and Anima Anandkumar},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=vDFA1tpuLvk}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 8 code implementations](https://www.catalyzex.com/paper/arxiv:2208.11126/code)"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279195154, "odate": 1664468100000, "details": {"replyCount": 27}}, {"id": "_s1N-DnxdyT", "original": "DFvJpD92xB9", "number": 1927, "cdate": 1663850020505, "mdate": null, "ddate": null, "tcdate": 1663850020505, "tmdate": 1697935675469, "tddate": null, "forum": "_s1N-DnxdyT", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Stochastic Multi-Person 3D Motion Forecasting", "authorids": ["~Sirui_Xu1", "~Yu-Xiong_Wang1", "~Liangyan_Gui1"], "authors": ["Sirui Xu", "Yu-Xiong Wang", "Liangyan Gui"], "keywords": ["stochastic forecasting", "multi-person 3D motion", "dual-level generative modeling"], "TL;DR": "We introduce a new task of stochastic multi-person 3D motion forecasting, and propose a dual-level generative modeling framework to address this task.", "abstract": "This paper aims to deal with the ignored real-world complexities in prior work on human motion forecasting, emphasizing the social properties of multi-person motion, the diversity of motion and social interactions, and the complexity of articulated motion. To this end, we introduce a novel task of stochastic multi-person 3D motion forecasting. We propose a dual-level generative modeling framework that separately models independent individual motion at the local level and social interactions at the global level. Notably, this dual-level modeling mechanism can be achieved within a shared generative model, through introducing learnable latent codes that represent intents of future motion and switching the codes' modes of operation at different levels. Our framework is general; we instantiate it with different generative models, including generative adversarial networks and diffusion models, and various multi-person forecasting models. Extensive experiments on CMU-Mocap, MuPoTS-3D, and SoMoF benchmarks show that our approach produces diverse and accurate multi-person predictions, significantly outperforming the state of the art. ", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Applications (eg, speech processing, computer vision, NLP)", "paperhash": "xu|stochastic_multiperson_3d_motion_forecasting", "pdf": "/pdf/cd1fe46c26063b4d564a5f4fa721d062014dd432.pdf", "supplementary_material": "/attachment/f67d89736da202eec3e50bded8ba23aaed544395.zip", "_bibtex": "@inproceedings{\nxu2023stochastic,\ntitle={Stochastic Multi-Person 3D Motion Forecasting},\nauthor={Sirui Xu and Yu-Xiong Wang and Liangyan Gui},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=_s1N-DnxdyT}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 2 code implementations](https://www.catalyzex.com/paper/arxiv:2306.05421/code)"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279192527, "odate": 1664468100000, "details": {"replyCount": 17}}, {"id": "Q-UHqMorzil", "original": "t5DTJZ3K-vD", "number": 1915, "cdate": 1663850019071, "mdate": null, "ddate": null, "tcdate": 1663850019071, "tmdate": 1677734927046, "tddate": null, "forum": "Q-UHqMorzil", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Sign and Basis Invariant Networks for Spectral Graph Representation Learning", "authorids": ["~Derek_Lim1", "~Joshua_David_Robinson1", "~Lingxiao_Zhao1", "~Tess_Smidt1", "~Suvrit_Sra1", "~Haggai_Maron1", "~Stefanie_Jegelka3"], "authors": ["Derek Lim", "Joshua David Robinson", "Lingxiao Zhao", "Tess Smidt", "Suvrit Sra", "Haggai Maron", "Stefanie Jegelka"], "keywords": ["Invariance", "Equivariance", "Eigenvectors", "Spectral", "Neural Networks"], "TL;DR": "We develop neural networks invariant to the symmetries of eigenvectors, which are theoretically expressive and empirically improve performance in geometric learning tasks.", "abstract": "We introduce SignNet and BasisNet---new neural architectures that are invariant to two key symmetries displayed by eigenvectors: (i) sign flips, since if v is an eigenvector then so is -v; and (ii) more general basis symmetries, which occur in higher dimensional eigenspaces with infinitely many choices of basis eigenvectors. We prove that under certain conditions our networks are universal, i.e., they can approximate any continuous function of eigenvectors with the desired invariances. When used with Laplacian eigenvectors, our networks are provably more expressive than existing spectral methods on graphs; for instance, they subsume all spectral graph convolutions, certain spectral graph invariants, and previously proposed graph positional encodings as special cases. Experiments show that our networks significantly outperform existing baselines on molecular graph regression, learning expressive graph representations, and learning neural fields on triangle meshes. Our code is available at https://github.com/cptq/SignNet-BasisNet.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Deep Learning and representational learning", "paperhash": "lim|sign_and_basis_invariant_networks_for_spectral_graph_representation_learning", "pdf": "/pdf/dcdf0914e050b658395e5e8f1bafe2c5d8f6dffc.pdf", "supplementary_material": "/attachment/3bb05ffaf6de6b62042e3e858646679f5cb7e2af.zip", "_bibtex": "@inproceedings{\nlim2023sign,\ntitle={Sign and Basis Invariant Networks for Spectral Graph Representation Learning},\nauthor={Derek Lim and Joshua David Robinson and Lingxiao Zhao and Tess Smidt and Suvrit Sra and Haggai Maron and Stefanie Jegelka},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=Q-UHqMorzil}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279191774, "odate": 1664468100000, "details": {"replyCount": 9}}, {"id": "7C9aRX2nBf2", "original": "rZf3dGsl-3v", "number": 1912, "cdate": 1663850018723, "mdate": null, "ddate": null, "tcdate": 1663850018723, "tmdate": 1676330929229, "tddate": null, "forum": "7C9aRX2nBf2", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Sequential Latent Variable Models for Few-Shot High-Dimensional Time-Series Forecasting", "authorids": ["~Xiajun_Jiang1", "~Ryan_Missel1", "~Zhiyuan_Li5", "~Linwei_Wang1"], "authors": ["Xiajun Jiang", "Ryan Missel", "Zhiyuan Li", "Linwei Wang"], "keywords": ["Time series", "generative models", "Bayesian meta-learning"], "TL;DR": "We present the very first step toward few-shot high-dimensional sequence forecasting by a Bayesian meta-learning model that learns the process of learning latent dynamics that changes with the small number of observations that are available.", "abstract": "Modern applications increasingly require learning and forecasting latent dynamics from high-dimensional time-series. Compared to univariate time-series forecasting, this adds a new challenge of reasoning about the latent dynamics of an unobserved abstract state. Sequential latent variable models (LVMs) present an attractive solution, although existing works either struggle with long-term forecasting or have difficulty learning across diverse dynamics. In this paper, we first present a conceptual framework of sequential LVMs to unify existing works, contrast their fundamental limitations, and identify an intuitive solution to long-term forecasting for diverse dynamics via meta-learning. We then present the first framework of few-shot forecasting for high-dimensional time-series: instead of learning a single dynamic function, we leverage data of diverse dynamics and learn to adapt latent dynamic functions to few-shot support series. This is realized via Bayesian meta-learning underpinned by: 1) a latent dynamic function conditioned on knowledge derived from few-shot support series, and 2) a meta-model that learns to extract such dynamic-specific knowledge via feed-forward embedding of support set. We compared the presented framework with a comprehensive set of baseline models trained 1) globally on the large meta-training set with diverse dynamics, and 2) individually on single dynamics, both with and without fine-tuning to k-shot support series used by the meta-models. We demonstrated that the presented framework is agnostic to the latent dynamic function of choice and, at meta-test time, is able to forecast for new dynamics given variable-shot of support series.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Generative models", "paperhash": "jiang|sequential_latent_variable_models_for_fewshot_highdimensional_timeseries_forecasting", "pdf": "/pdf/2a624e3ea737a57633593e32152635c30eaf25d6.pdf", "_bibtex": "@inproceedings{\njiang2023sequential,\ntitle={Sequential Latent Variable Models for Few-Shot High-Dimensional Time-Series Forecasting},\nauthor={Xiajun Jiang and Ryan Missel and Zhiyuan Li and Linwei Wang},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=7C9aRX2nBf2}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279191409, "odate": 1664468100000, "details": {"replyCount": 15}}, {"id": "XomEU3eNeSQ", "original": "Qp3xQRcuPyI", "number": 1911, "cdate": 1663850018600, "mdate": null, "ddate": null, "tcdate": 1663850018600, "tmdate": 1697935677369, "tddate": null, "forum": "XomEU3eNeSQ", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Code Translation with Compiler Representations", "authorids": ["~Marc_Szafraniec1", "~Baptiste_Roziere1", "~Hugh_James_Leather1", "~Patrick_Labatut1", "~Francois_Charton1", "~Gabriel_Synnaeve1"], "authors": ["Marc Szafraniec", "Baptiste Roziere", "Hugh James Leather", "Patrick Labatut", "Francois Charton", "Gabriel Synnaeve"], "keywords": ["Neural Machine Translation", "Unsupervised Learning", "Programming Languages", "LLVM", "Decompilation", "Deep Learning", "Program Translation"], "TL;DR": "We leverage compiler intermediate representations (IR) for the unsupervised neural machine translation of programming languages and get state-of-the-art results", "abstract": "In this paper, we leverage low-level compiler intermediate representations (IR) code translation. Traditional transpilers rely on syntactic information and handcrafted rules, which limits their applicability and produces unnatural-looking code. Applying neural machine translation (NMT) approaches to code has successfully broadened the set of programs on which one can get a natural-looking translation. However, they treat the code as sequences of text tokens, and still do not differentiate well enough between similar pieces of code which have different semantics in different languages. The consequence is low quality translation, reducing the practicality of NMT, and stressing the need for an approach significantly increasing its accuracy. Here we propose to augment code translation with IRs, specifically LLVM IR, with results on the C++, Java, Rust, and Go languages. Our method improves upon the state of the art for unsupervised code translation, increasing the number of correct translations by 11% on average, and up to 79% for the Java \u2192 Rust pair with greedy decoding. With beam search, it increases the number of correct translations by 5.5% in average. We extend previous test sets for code translation, by adding hundreds of Go and Rust functions. Additionally, we train models with high performance on the problem of IR decompilation, generating programming source code from IR, and study using IRs as intermediary pivot for translation.", "pdf": "/pdf/e6271eb661d7f4d7cff1993ad01d1e6dcaa983e0.pdf", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Applications (eg, speech processing, computer vision, NLP)", "paperhash": "szafraniec|code_translation_with_compiler_representations", "_bibtex": "@inproceedings{\nszafraniec2023code,\ntitle={Code Translation with Compiler Representations},\nauthor={Marc Szafraniec and Baptiste Roziere and Hugh James Leather and Patrick Labatut and Francois Charton and Gabriel Synnaeve},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=XomEU3eNeSQ}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 3 code implementations](https://www.catalyzex.com/paper/arxiv:2207.03578/code)"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279191248, "odate": 1664468100000, "details": {"replyCount": 16}}, {"id": "zDiHoIWa0q1", "original": "VztOToP0RMe", "number": 1906, "cdate": 1663850018015, "mdate": null, "ddate": null, "tcdate": 1663850018015, "tmdate": 1697935678144, "tddate": null, "forum": "zDiHoIWa0q1", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Omnigrok: Grokking Beyond Algorithmic Data", "authorids": ["~Ziming_Liu2", "~Eric_J_Michaud1", "~Max_Tegmark1"], "authors": ["Ziming Liu", "Eric J Michaud", "Max Tegmark"], "keywords": ["grokking", "loss landscape", "neural dynamics", "representation learning", "initialization"], "TL;DR": "We aim to understand grokking through the lens of neural loss landscapes, and show grokking can occur for various datasets beyond algorithmic datasets.", "abstract": "Grokking, the unusual phenomenon for algorithmic datasets where generalization happens long after overfitting the training data, has remained elusive. We aim to understand grokking by analyzing the loss landscapes of neural networks, identifying the mismatch between training and test losses as the cause for grokking. We refer to this as the \"LU mechanism\" because training and test losses (against model weight norm) typically resemble \"L\" and \"U\", respectively. This simple mechanism can nicely explain many aspects of grokking: data size dependence, weight decay dependence, the emergence of representations, etc. Guided by the intuitive picture, we are able to induce grokking on tasks involving images, language and molecules, although the grokking signals are sometimes less dramatic. We attribute the dramatic nature of grokking for algorithmic datasets to representation learning.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Deep Learning and representational learning", "paperhash": "liu|omnigrok_grokking_beyond_algorithmic_data", "pdf": "/pdf/4f07c7b6fea42534db8640c840402f6d066a8bd5.pdf", "_bibtex": "@inproceedings{\nliu2023omnigrok,\ntitle={Omnigrok: Grokking Beyond Algorithmic Data},\nauthor={Ziming Liu and Eric J Michaud and Max Tegmark},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=zDiHoIWa0q1}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2210.01117/code)"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279190952, "odate": 1664468100000, "details": {"replyCount": 14}}, {"id": "XCTVFJwS9LJ", "original": "8fwT8Vpe_0", "number": 1902, "cdate": 1663850017532, "mdate": null, "ddate": null, "tcdate": 1663850017532, "tmdate": 1697935678815, "tddate": null, "forum": "XCTVFJwS9LJ", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Flow Annealed Importance Sampling Bootstrap", "authorids": ["~Laurence_Illing_Midgley1", "~Vincent_Stimper1", "~Gregor_N._C._Simm1", "~Bernhard_Sch\u00f6lkopf1", "~Jos\u00e9_Miguel_Hern\u00e1ndez-Lobato1"], "authors": ["Laurence Illing Midgley", "Vincent Stimper", "Gregor N. C. Simm", "Bernhard Sch\u00f6lkopf", "Jos\u00e9 Miguel Hern\u00e1ndez-Lobato"], "keywords": ["Normalizing flow", "Boltzmann distribution", "Boltzmann generator", "Annealed Importance Sampling", "Approximate Inference"], "TL;DR": "We train normalizing flows to fit multi-modal target distributions by generating samples where the flow is a poor approximation of the target using an annealed importance sampling bootstrap procedure.", "abstract": "Normalizing flows are tractable density models that can approximate complicated target distributions, e.g. Boltzmann distributions of physical systems. However, current methods for training flows either suffer from mode-seeking behavior, use samples from the target generated beforehand by expensive MCMC methods, or use stochastic losses that have high variance. To avoid these problems, we augment flows with annealed importance sampling (AIS) and minimize the mass-covering $\\alpha$-divergence with $\\alpha=2$, which minimizes importance weight variance. Our method, Flow AIS Bootstrap (FAB), uses AIS to generate samples in regions where the flow is a poor approximation of the target, facilitating the discovery of new modes. We apply FAB to multimodal targets and show that we can approximate them very accurately where previous methods fail. To the best of our knowledge, we are the first to learn the Boltzmann distribution of the alanine dipeptide molecule using only the unnormalized target density, without access to samples generated via Molecular Dynamics (MD) simulations: FAB produces better results than training via maximum likelihood on MD samples while using 100 times fewer target evaluations. After reweighting the samples, we obtain unbiased histograms of dihedral angles that are almost identical to the ground truth.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )", "paperhash": "midgley|flow_annealed_importance_sampling_bootstrap", "pdf": "/pdf/b982ed337b6c3ff43fb3fa4e63f9492b31f03e06.pdf", "supplementary_material": "", "_bibtex": "@inproceedings{\nmidgley2023flow,\ntitle={Flow Annealed Importance Sampling Bootstrap},\nauthor={Laurence Illing Midgley and Vincent Stimper and Gregor N. C. Simm and Bernhard Sch{\\\"o}lkopf and Jos{\\'e} Miguel Hern{\\'a}ndez-Lobato},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=XCTVFJwS9LJ}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2208.01893/code)"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279190528, "odate": 1664468100000, "details": {"replyCount": 19}}, {"id": "ih0uFRFhaZZ", "original": "5mjWX4oZjT1", "number": 1891, "cdate": 1663850016185, "mdate": null, "ddate": null, "tcdate": 1663850016185, "tmdate": 1681319470469, "tddate": null, "forum": "ih0uFRFhaZZ", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Continual Unsupervised Disentangling of Self-Organizing Representations", "authorids": ["~Zhiyuan_Li5", "~Xiajun_Jiang1", "~Ryan_Missel1", "~Prashnna_Kumar_Gyawali1", "~Nilesh_Kumar1", "~Linwei_Wang1"], "authors": ["Zhiyuan Li", "Xiajun Jiang", "Ryan Missel", "Prashnna Kumar Gyawali", "Nilesh Kumar", "Linwei Wang"], "keywords": ["continual disentanglment", "generative model", "VAE", "SOM"], "TL;DR": "We proposed a novel generative model describing a topologically-connected mixture of spike-and-slab distributions in the latent space for continual unsupervised learning and disentangling representations.", "abstract": "Limited progress has been made in continual unsupervised learning of representations, especially in reusing, expanding, and continually disentangling learned semantic factors across data environments. We argue that this is because existing approaches treat continually-arrived data independently, without considering how they are related based on the underlying semantic factors. We address this by a new generative model describing a topologically-connected mixture of spike-and-slab distributions in the latent space, learned end-to-end in a continual fashion via principled variational inference. The learned mixture is able to automatically discover the active semantic factors underlying each data environment and to accumulate their relational structure based on that. This distilled knowledge of different data environments can further be used for generative replay and guiding continual disentangling of new semantic factors. We tested the presented method on a split version of 3DShapes to provide the first quantitative disentanglement evaluation of continually learned representations, and further demonstrated its ability to continually disentangle new representations in benchmark datasets.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Deep Learning and representational learning", "paperhash": "li|continual_unsupervised_disentangling_of_selforganizing_representations", "pdf": "/pdf/fdb507165ec3efc7233824c93b345e73bef5cd31.pdf", "_bibtex": "@inproceedings{\nli2023continual,\ntitle={Continual Unsupervised Disentangling of Self-Organizing Representations},\nauthor={Zhiyuan Li and Xiajun Jiang and Ryan Missel and Prashnna Kumar Gyawali and Nilesh Kumar and Linwei Wang},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=ih0uFRFhaZZ}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279190084, "odate": 1664468100000, "details": {"replyCount": 14}}, {"id": "5VBBA91N6n", "original": "TkO0jwcEXT0", "number": 1871, "cdate": 1663850013747, "mdate": null, "ddate": null, "tcdate": 1663850013747, "tmdate": 1677490380555, "tddate": null, "forum": "5VBBA91N6n", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "LMC: Fast Training of GNNs via Subgraph Sampling with Provable Convergence", "authorids": ["~Zhihao_Shi3", "~Xize_Liang1", "~Jie_Wang1"], "authors": ["Zhihao Shi", "Xize Liang", "Jie Wang"], "keywords": ["Graph Nerual Networks", "Scalable Training", "Provable Convergence", "Local Message Compensation"], "abstract": "The message passing-based graph neural networks (GNNs) have achieved great success in many real-world applications.\nHowever, training GNNs on large-scale graphs suffers from the well-known neighbor explosion problem, i.e., the exponentially increasing dependencies of nodes with the number of message passing layers. Subgraph-wise sampling methods---a promising class of mini-batch training techniques---discard messages outside the mini-batches in backward passes to avoid the neighbor explosion problem at the expense of gradient estimation accuracy. This poses significant challenges to their convergence analysis and convergence speeds, which seriously limits their reliable real-world applications. To address this challenge, we propose a novel subgraph-wise sampling method with a convergence guarantee, namely Local Message Compensation (LMC). To the best of our knowledge, LMC is the {\\it first} subgraph-wise sampling method with provable convergence. The key idea of LMC is to retrieve the discarded messages in backward passes based on a message passing formulation of backward passes. By efficient and effective compensations for the discarded messages in both forward and backward passes, LMC computes accurate mini-batch gradients and thus accelerates convergence. We further show that LMC converges to first-order stationary points of GNNs. Experiments on large-scale benchmark tasks demonstrate that LMC significantly outperforms state-of-the-art subgraph-wise sampling methods in terms of efficiency.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Optimization (eg, convex and non-convex optimization)", "paperhash": "shi|lmc_fast_training_of_gnns_via_subgraph_sampling_with_provable_convergence", "TL;DR": "We propose a novel and efficient subgraph-wise sampling method with a convergence guarantee by Local Message Compensation (LMC).", "pdf": "/pdf/afdfd7b6a07fae9bc742768d872aaea1ea7526a3.pdf", "_bibtex": "@inproceedings{\nshi2023lmc,\ntitle={{LMC}: Fast Training of {GNN}s via Subgraph Sampling with Provable Convergence},\nauthor={Zhihao Shi and Xize Liang and Jie Wang},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=5VBBA91N6n}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279188640, "odate": 1664468100000, "details": {"replyCount": 18}}, {"id": "rZ-wylY5VI", "original": "zkHShZAE2D", "number": 1817, "cdate": 1663850007590, "mdate": null, "ddate": null, "tcdate": 1663850007590, "tmdate": 1697935688142, "tddate": null, "forum": "rZ-wylY5VI", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Programmatically Grounded, Compositionally Generalizable Robotic Manipulation", "authorids": ["~Renhao_Wang1", "~Jiayuan_Mao1", "~Joy_Hsu2", "~Hang_Zhao1", "~Jiajun_Wu1", "~Yang_Gao1"], "authors": ["Renhao Wang", "Jiayuan Mao", "Joy Hsu", "Hang Zhao", "Jiajun Wu", "Yang Gao"], "keywords": ["Vision-Language-Action Grounding", "Zero-Shot Generalization", "Compositional Generalization", "Neurosymbolic Learning"], "TL;DR": "We parse and execute semantically grounded neural programs for robotic manipulation, enabling better zero-shot and compositional generalizable to new manipulation behaviors.", "abstract": "Robots operating in the real world require both rich manipulation skills as well as the ability to semantically reason about when to apply those skills. Towards this goal, recent works have integrated semantic representations from large-scale pretrained vision-language (VL) models into manipulation models, imparting them with more general reasoning capabilities. However, we show that the conventional {\\it pretraining-finetuning} pipeline for integrating such representations entangles the learning of domain-specific action information and domain-general visual information, leading to less data-efficient training and poor generalization to unseen objects and tasks. To this end, we propose \\ours, a {\\it modular} approach to better leverage pretrained VL models by exploiting the syntactic and semantic structures of language instructions. Our framework uses a semantic parser to recover an executable program, composed of functional modules grounded on vision and action across different modalities. Each functional module is realized as a combination of deterministic computation and learnable neural networks. Program execution produces parameters to general manipulation primitives for a robotic end-effector. The entire modular network can be trained with end-to-end imitation learning objectives. Experiments show that our model successfully disentangles action and perception, translating to improved zero-shot and compositional generalization in a variety of manipulation behaviors. Project webpage at: \\url{https://progport.github.io}.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)", "paperhash": "wang|programmatically_grounded_compositionally_generalizable_robotic_manipulation", "pdf": "/pdf/3f955a8cf103d552d11f9329dde46d6173f574aa.pdf", "_bibtex": "@inproceedings{\nwang2023programmatically,\ntitle={Programmatically Grounded, Compositionally Generalizable Robotic Manipulation},\nauthor={Renhao Wang and Jiayuan Mao and Joy Hsu and Hang Zhao and Jiajun Wu and Yang Gao},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=rZ-wylY5VI}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2304.13826/code)"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279186177, "odate": 1664468100000, "details": {"replyCount": 5}}, {"id": "4eJ43EN2g6l", "original": "sUuOIzHZGWo", "number": 1783, "cdate": 1663850003531, "mdate": null, "ddate": null, "tcdate": 1663850003531, "tmdate": 1677632877994, "tddate": null, "forum": "4eJ43EN2g6l", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "SketchKnitter: Vectorized Sketch Generation with Diffusion Models", "authorids": ["wanqqiang@bupt.edu.cn", "denghaoge@bupt.edu.cn", "~Yonggang_Qi2", "~Da_Li3", "~Yi-Zhe_Song2"], "authors": ["Qiang Wang", "Haoge Deng", "Yonggang Qi", "Da Li", "Yi-Zhe Song"], "keywords": [], "abstract": "We show vectorized sketch generation can be identified as a reversal of the stroke deformation process. This relationship was established by means of a diffusion model that learns data distributions over the stroke-point locations and pen states of real human sketches. Given randomly scattered stroke-points, sketch generation becomes a process of deformation-based denoising, where the generator rectifies positions of stroke points at each timestep to converge at a recognizable sketch. A key innovation was to embed recognizability into the reverse time diffusion process. It was observed that the estimated noise during the reversal process is strongly correlated with sketch classification accuracy. An auxiliary recurrent neural network (RNN) was consequently used to quantify recognizability during data sampling. It follows that, based on the recognizability scores, a sampling shortcut function can also be devised that renders better quality sketches with fewer sampling steps. Finally it is shown that the model can be easily extended to a conditional generation framework, where given incomplete and unfaithful sketches, it yields one that is more visually appealing and with higher recognizability.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Generative models", "paperhash": "wang|sketchknitter_vectorized_sketch_generation_with_diffusion_models", "pdf": "/pdf/aa51f28767b5d95ceced7af0c79780b06d2fd1e0.pdf", "_bibtex": "@inproceedings{\nwang2023sketchknitter,\ntitle={SketchKnitter: Vectorized Sketch Generation with Diffusion Models},\nauthor={Qiang Wang and Haoge Deng and Yonggang Qi and Da Li and Yi-Zhe Song},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=4eJ43EN2g6l}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279184605, "odate": 1664468100000, "details": {"replyCount": 10}}, {"id": "S07feAlQHgM", "original": "J75E_YoloIy", "number": 1762, "cdate": 1663850000929, "mdate": null, "ddate": null, "tcdate": 1663850000929, "tmdate": 1676530573922, "tddate": null, "forum": "S07feAlQHgM", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "A Model or 603 Exemplars: Towards Memory-Efficient Class-Incremental Learning", "authorids": ["~Da-Wei_Zhou1", "~Qi-Wei_Wang1", "~Han-Jia_Ye1", "~De-Chuan_Zhan1"], "authors": ["Da-Wei Zhou", "Qi-Wei Wang", "Han-Jia Ye", "De-Chuan Zhan"], "keywords": ["class-incremental learning"], "abstract": "Real-world applications require the classification model to adapt to new classes without forgetting old ones. Correspondingly, Class-Incremental Learning (CIL) aims to train a model with limited memory size to meet this requirement. Typical CIL methods tend to save representative exemplars from former classes to resist forgetting, while recent works find that storing models from history can substantially boost the performance. However, the stored models are not counted into the memory budget, which implicitly results in unfair comparisons. We find that when counting the model size into the total budget and comparing methods with aligned memory size, saving models do not consistently work, especially for the case with limited memory budgets. As a result, we need to holistically evaluate different CIL methods at different memory scales and simultaneously consider accuracy and memory size for measurement. On the other hand, we dive deeply into the construction of the memory buffer for memory efficiency. By analyzing the effect of different layers in the network, we find that shallow and deep layers have different characteristics in CIL. Motivated by this, we propose a simple yet effective baseline, denoted as MEMO for Memory-efficient Expandable MOdel. MEMO extends specialized layers based on the shared generalized representations, efficiently extracting diverse representations with modest cost and maintaining representative exemplars. Extensive experiments on benchmark datasets validate MEMO's competitive performance. Code is available at: https://github.com/wangkiw/ICLR23-MEMO", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Deep Learning and representational learning", "paperhash": "zhou|a_model_or_603_exemplars_towards_memoryefficient_classincremental_learning", "pdf": "/pdf/1b652f4ee2aba1681f8d0e268557ff8ce743d37d.pdf", "_bibtex": "@inproceedings{\nzhou2023a,\ntitle={A Model or 603 Exemplars: Towards Memory-Efficient Class-Incremental Learning},\nauthor={Da-Wei Zhou and Qi-Wei Wang and Han-Jia Ye and De-Chuan Zhan},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=S07feAlQHgM}\n}", "supplementary_material": "", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279183192, "odate": 1664468100000, "details": {"replyCount": 19}}, {"id": "IxmWsm4xrua", "original": "eV5XZpzAlO0", "number": 1740, "cdate": 1663849997232, "mdate": null, "ddate": null, "tcdate": 1663849997232, "tmdate": 1697935696153, "tddate": null, "forum": "IxmWsm4xrua", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Toeplitz Neural Network for Sequence Modeling", "authorids": ["~Zhen_Qin6", "~Xiaodong_Han3", "~Weixuan_Sun1", "~Bowen_He3", "~Dong_Li11", "~Dongxu_Li2", "~Yuchao_Dai1", "~Lingpeng_Kong1", "~Yiran_Zhong1"], "authors": ["Zhen Qin", "Xiaodong Han", "Weixuan Sun", "Bowen He", "Dong Li", "Dongxu Li", "Yuchao Dai", "Lingpeng Kong", "Yiran Zhong"], "keywords": ["Toeplitz Matrix", "Sequence Modeling", "Relative position"], "abstract": "Sequence modeling has important applications in natural language processing and computer vision. Recently, the transformer-based models have shown strong performance on various sequence modeling tasks, which rely on attention to capture pairwise token relations, and position embedding to inject positional information. While showing good performance, the transformer models are inefficient to scale to long input sequences, mainly due to the quadratic space-time complexity of attention. To overcome this inefficiency, we propose to model sequences with a relative position encoded Toeplitz matrix and use a Toeplitz matrix-vector production trick to reduce the space-time complexity of the sequence modeling to log linear. A lightweight sub-network called relative position encoder is proposed to generate relative position coefficients with a fixed budget of parameters, enabling the proposed Toeplitz neural network to deal with varying sequence lengths. In addition, despite being trained on 512-token sequences, our model can extrapolate input sequence length up to 14K tokens in inference with consistent performance. Extensive experiments on autoregressive and bidirectional language modeling, image modeling, and the challenging Long-range Arena Benchmark show that our method achieves better performance than its competitors in most downstream tasks while being significantly faster.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Deep Learning and representational learning", "paperhash": "qin|toeplitz_neural_network_for_sequence_modeling", "TL;DR": "An efficient method that uses Toeplitz matrices to model sequences.", "pdf": "/pdf/2a7e1fcbcfe67f92df33295ecde966d4a9095dda.pdf", "_bibtex": "@inproceedings{\nqin2023toeplitz,\ntitle={Toeplitz Neural Network for Sequence Modeling},\nauthor={Zhen Qin and Xiaodong Han and Weixuan Sun and Bowen He and Dong Li and Dongxu Li and Yuchao Dai and Lingpeng Kong and Yiran Zhong},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=IxmWsm4xrua}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2305.04749/code)"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279182048, "odate": 1664468100000, "details": {"replyCount": 19}}, {"id": "isiQ5KIXbjj", "original": "bmsgPWA3S5O", "number": 1686, "cdate": 1663849990736, "mdate": null, "ddate": null, "tcdate": 1663849990736, "tmdate": 1697935701314, "tddate": null, "forum": "isiQ5KIXbjj", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "QuAnt: Quantum Annealing with Learnt Couplings", "authorids": ["~Marcel_Seelbach_Benkner1", "~Maximilian_Krahn1", "~Edith_Tretschk1", "~Zorah_L\u00e4hner1", "~Michael_Moeller1", "~Vladislav_Golyanik1"], "authors": ["Marcel Seelbach Benkner", "Maximilian Krahn", "Edith Tretschk", "Zorah L\u00e4hner", "Michael Moeller", "Vladislav Golyanik"], "keywords": [], "abstract": "Modern quantum annealers can find high-quality solutions to combinatorial optimisation objectives given as quadratic unconstrained binary optimisation (QUBO) problems. Unfortunately, obtaining suitable QUBO forms in computer vision remains challenging and currently requires problem-specific analytical derivations. Moreover, such explicit formulations impose tangible constraints on solution encodings. In stark contrast to prior work, this paper proposes to learn QUBO forms from data through gradient backpropagation instead of deriving them. As a result, the solution encodings can be  chosen flexibly and compactly. Furthermore, our methodology is general and virtually independent of the specifics of the target problem type. We demonstrate the advantages of learnt  QUBOs on the diverse problem types of graph matching, 2D point cloud alignment and 3D rotation estimation. Our results are competitive with the previous quantum state of the art while requiring much fewer logical and physical qubits, enabling our method to scale to larger problems. The code and the new dataset are available at https://4dqv.mpi-inf.mpg.de/QuAnt/.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Deep Learning and representational learning", "paperhash": "benkner|quant_quantum_annealing_with_learnt_couplings", "pdf": "/pdf/abe676c41d571977f05ff1eee049ec4fb86d0301.pdf", "supplementary_material": "/attachment/69bcf435d6d94f220c81aabae3488d501d198582.zip", "_bibtex": "@inproceedings{\nbenkner2023quant,\ntitle={QuAnt: Quantum Annealing with Learnt Couplings},\nauthor={Marcel Seelbach Benkner and Maximilian Krahn and Edith Tretschk and Zorah L{\\\"a}hner and Michael Moeller and Vladislav Golyanik},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=isiQ5KIXbjj}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2210.08114/code)"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279179046, "odate": 1664468100000, "details": {"replyCount": 9}}, {"id": "q3F0UBAruO", "original": "DkDf19WLnBt", "number": 1657, "cdate": 1663849987191, "mdate": null, "ddate": null, "tcdate": 1663849987191, "tmdate": 1677603044714, "tddate": null, "forum": "q3F0UBAruO", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Towards Effective and Interpretable Human-Agent Collaboration in MOBA Games: A Communication Perspective", "authorids": ["~Yiming_Gao4", "~Feiyu_Liu1", "~Liang_Wang10", "~Zhenjie_Lian1", "~Weixuan_Wang1", "~Siqin_Li1", "~Xianliang_Wang1", "~Xianhan_Zeng1", "~Rundong_Wang1", "~jiawei_wang2", "~QIANG_FU8", "~Yang_Wei2", "~Lanxiao_Huang1", "~Wei_Liu3"], "authors": ["Yiming Gao", "Feiyu Liu", "Liang Wang", "Zhenjie Lian", "Weixuan Wang", "Siqin Li", "Xianliang Wang", "Xianhan Zeng", "Rundong Wang", "jiawei wang", "QIANG FU", "Yang Wei", "Lanxiao Huang", "Wei Liu"], "keywords": ["game playing", "multi-agent", "human-ai communication", "human-ai collaboration", "deep reinforcement learning"], "TL;DR": "We propose an efficient and interpretable Meta-Command Communication-based (MCC) framework for accomplishing effective human-AI collaboration in MOBA games. ", "abstract": "MOBA games, e.g., Dota2 and Honor of Kings, have been actively used as the testbed for the recent AI research on games, and various AI systems have been developed at the human level so far. However, these AI systems mainly focus on how to compete with humans, less on exploring how to collaborate with humans. To this end, this paper makes the first attempt to investigate human-agent collaboration in MOBA games. In this paper, we propose to enable humans and agents to collaborate through explicit communication by designing an efficient and interpretable Meta-Command Communication-based framework, dubbed MCC, for accomplishing effective human-agent collaboration in MOBA games. The MCC framework consists of two pivotal modules: 1) an interpretable communication protocol, i.e., the Meta-Command, to bridge the communication gap between humans and agents; 2) a meta-command value estimator, i.e., the Meta-Command Selector, to select a valuable meta-command for each agent to achieve effective human-agent collaboration. Experimental results in Honor of Kings demonstrate that MCC agents can collaborate reasonably well with human teammates and even generalize to collaborate with different levels and numbers of human teammates. Videos are available at https://sites.google.com/view/mcc-demo.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)", "paperhash": "gao|towards_effective_and_interpretable_humanagent_collaboration_in_moba_games_a_communication_perspective", "pdf": "/pdf/05be94f6c3da0d1f97a06aaecf42515ddc07d159.pdf", "_bibtex": "@inproceedings{\ngao2023towards,\ntitle={Towards Effective and Interpretable Human-Agent Collaboration in {MOBA} Games: A Communication Perspective},\nauthor={Yiming Gao and Feiyu Liu and Liang Wang and Zhenjie Lian and Weixuan Wang and Siqin Li and Xianliang Wang and Xianhan Zeng and Rundong Wang and jiawei wang and QIANG FU and Yang Wei and Lanxiao Huang and Wei Liu},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=q3F0UBAruO}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279177418, "odate": 1664468100000, "details": {"replyCount": 19}}, {"id": "uqg3FhRZaq", "original": "nWTT9d7BsJq", "number": 1640, "cdate": 1663849985181, "mdate": null, "ddate": null, "tcdate": 1663849985181, "tmdate": 1676716570412, "tddate": null, "forum": "uqg3FhRZaq", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "On the complexity of nonsmooth automatic differentiation", "authorids": ["~Jerome_Bolte1", "~Ryan_Boustany1", "~Edouard_Pauwels1", "~B\u00e9atrice_Pesquet-Popescu1"], "authors": ["Jerome Bolte", "Ryan Boustany", "Edouard Pauwels", "B\u00e9atrice Pesquet-Popescu"], "keywords": ["Automatic differentiation", "nonsmooth derivatives", "computational complexity", "cheap derivatives", "conservative gradients"], "TL;DR": "Backpropagation of nonsmooth  gradients is proved to be a fast/cheap process for the vast class of locally Lipschitz semi-algebraic functions.", "abstract": "Using the notion of conservative gradient, we provide a simple model to estimate the computational costs of the backward and forward modes of algorithmic differentiation for a wide class of nonsmooth programs. The complexity overhead of the backward mode turns out to be independent of the dimension when using programs with locally Lipschitz semi-algebraic or definable elementary functions. This extends considerably the Baur-Strassen's smooth cheap gradient principle. We illustrate our results by establishing fast backpropagation results of conservative gradients through feedforward neural networks with standard activation and  loss functions. Nonsmooth backpropagation's cheapness contrasts with concurrent forward approaches, which have, to this day, dimensional-dependent worst case  overhead estimates. We provide further results suggesting the superiority of backward propagation of conservative gradients. Indeed, we relate the complexity of computing a large number of directional derivatives to that of matrix multiplication, and we show that finding two subgradients in the Clarke subdifferential of a function is a NP-hard problem.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Optimization (eg, convex and non-convex optimization)", "paperhash": "bolte|on_the_complexity_of_nonsmooth_automatic_differentiation", "pdf": "/pdf/81b5f1858aeb447b1d248391272b9e30a7ceb511.pdf", "supplementary_material": "", "_bibtex": "@inproceedings{\nbolte2023on,\ntitle={On the complexity of nonsmooth automatic differentiation},\nauthor={Jerome Bolte and Ryan Boustany and Edouard Pauwels and B{\\'e}atrice Pesquet-Popescu},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=uqg3FhRZaq}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279176463, "odate": 1664468100000, "details": {"replyCount": 11}}, {"id": "OnD9zGAGT0k", "original": "GSfD7XLZNy", "number": 1619, "cdate": 1663849982650, "mdate": null, "ddate": null, "tcdate": 1663849982650, "tmdate": 1697935708793, "tddate": null, "forum": "OnD9zGAGT0k", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Diffusion Posterior Sampling for General Noisy Inverse Problems", "authorids": ["~Hyungjin_Chung1", "~Jeongsol_Kim1", "mccann@lanl.gov", "mklasky@lanl.gov", "~Jong_Chul_Ye1"], "authors": ["Hyungjin Chung", "Jeongsol Kim", "Michael Thompson Mccann", "Marc Louis Klasky", "Jong Chul Ye"], "keywords": ["Diffusion model", "Inverse problem", "Posterior sampling"], "TL;DR": "We propose a diffusion model-based general inverse problem solver that scales to nonlinear problems and different noise statistics.", "abstract": "Diffusion models have been recently studied as powerful generative inverse problem solvers, owing to their high quality reconstructions and the ease of combining existing iterative solvers. However, most works focus on solving simple linear inverse problems in noiseless settings, which significantly under-represents the complexity of real-world problems. In this work, we extend diffusion solvers to efficiently handle general noisy (non)linear inverse problems via the Laplace approximation of the posterior sampling. Interestingly, the resulting posterior sampling scheme is a blended version of diffusion sampling with the manifold constrained gradient without a strict measurement consistency projection step, yielding a more desirable generative path in noisy settings compared to the previous studies. Our method demonstrates that diffusion models can incorporate various measurement noise statistics such as Gaussian and Poisson, and also efficiently handle noisy nonlinear inverse problems such as Fourier phase retrieval and non-uniform deblurring.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Generative models", "paperhash": "chung|diffusion_posterior_sampling_for_general_noisy_inverse_problems", "pdf": "/pdf/dd7f2e1f5581d91eb4c1ff34fec78b93d3dfa599.pdf", "_bibtex": "@inproceedings{\nchung2023diffusion,\ntitle={Diffusion Posterior Sampling for General Noisy Inverse Problems},\nauthor={Hyungjin Chung and Jeongsol Kim and Michael Thompson Mccann and Marc Louis Klasky and Jong Chul Ye},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=OnD9zGAGT0k}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 4 code implementations](https://www.catalyzex.com/paper/arxiv:2209.14687/code)"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279175050, "odate": 1664468100000, "details": {"replyCount": 18}}, {"id": "MkbcAHIYgyS", "original": "0yFdYtru4h6", "number": 1606, "cdate": 1663849981048, "mdate": null, "ddate": null, "tcdate": 1663849981048, "tmdate": 1697935710478, "tddate": null, "forum": "MkbcAHIYgyS", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Mass-Editing Memory in a Transformer", "authorids": ["~Kevin_Meng1", "~Arnab_Sen_Sharma1", "~Alex_J_Andonian1", "~Yonatan_Belinkov1", "~David_Bau1"], "authors": ["Kevin Meng", "Arnab Sen Sharma", "Alex J Andonian", "Yonatan Belinkov", "David Bau"], "keywords": ["language models", "GPT", "transformers", "model editing", "factual associations", "memory"], "TL;DR": "An algorithm that can make tens of thousands of edits to an autoregressive transformer's memory.", "abstract": "Recent work has shown exciting promise in updating large language models with new memories, so as to replace obsolete information or add specialized knowledge. However, this line of work is predominantly limited to updating single associations. We develop MEMIT, a method for directly updating a language model with many memories, demonstrating experimentally that it can scale up to thousands of associations for GPT-J (6B) and GPT-NeoX (20B), exceeding prior work by an order of magnitude. Our code and data will be open-sourced upon publication.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Applications (eg, speech processing, computer vision, NLP)", "paperhash": "meng|massediting_memory_in_a_transformer", "pdf": "/pdf/5d2ff18d2f074c0f0b7bda40d118bb08e13bcd43.pdf", "supplementary_material": "/attachment/7163bba87b77b7773eaac5f74f70dcb09ed7097d.zip", "_bibtex": "@inproceedings{\nmeng2023massediting,\ntitle={Mass-Editing Memory in a Transformer},\nauthor={Kevin Meng and Arnab Sen Sharma and Alex J Andonian and Yonatan Belinkov and David Bau},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=MkbcAHIYgyS}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2210.07229/code)"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279174094, "odate": 1664468100000, "details": {"replyCount": 11}}, {"id": "iV9Cs8s8keU", "original": "GSoWegHc0C7", "number": 1599, "cdate": 1663849980160, "mdate": null, "ddate": null, "tcdate": 1663849980160, "tmdate": 1681537396719, "tddate": null, "forum": "iV9Cs8s8keU", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Learning the Positions in CountSketch", "authorids": ["~Yi_Li8", "~Honghao_Lin1", "~Simin_Liu1", "~Ali_Vakilian1", "~David_Woodruff1"], "authors": ["Yi Li", "Honghao Lin", "Simin Liu", "Ali Vakilian", "David Woodruff"], "keywords": ["learning-augmented sketches", "count-sketch", "low-rank approximation", "iterative Hessian sketch"], "abstract": "We consider sketching algorithms which first compress data by multiplication with a random sketch matrix, and then apply the sketch to quickly solve an optimization problem, e.g., low-rank approximation and regression. In the learning-based sketching paradigm proposed by Indyk et al., the sketch matrix is found by choosing a random sparse matrix, e.g., CountSketch, and then the values of its non-zero entries are updated by running gradient descent on a training data set. Despite the growing body of work on this paradigm, a noticeable omission is that the locations of the non-zero entries of previous algorithms were fixed, and only their values were learned.\nIn this work, we propose the first learning-based algorithms that also optimize the locations of the non-zero entries. Our first proposed algorithm is based on a greedy algorithm. However, one drawback of the greedy algorithm is its slower training time. We fix this issue and propose approaches for learning a sketching matrix for both low-rank approximation and Hessian approximation for second-order optimization. The latter is helpful for a range of constrained optimization problems, such as LASSO and matrix estimation with a nuclear norm constraint. Both approaches achieve good accuracy with a fast running time.  Moreover, our experiments suggest that our algorithm can still reduce the error significantly even if we only have a very limited number of training matrices.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Optimization (eg, convex and non-convex optimization)", "paperhash": "li|learning_the_positions_in_countsketch", "TL;DR": "We propose the first learning-based algorithms that also optimize the locations of the non-zero entries of CountSketch matrix.", "pdf": "/pdf/cc22b9e7a5b739383f6f17c1c3f51a0cf1f79b66.pdf", "supplementary_material": "/attachment/054d7b89f7670546fb466c2b0237b83d4349eaae.zip", "_bibtex": "@inproceedings{\nli2023learning,\ntitle={Learning the Positions in CountSketch},\nauthor={Yi Li and Honghao Lin and Simin Liu and Ali Vakilian and David Woodruff},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=iV9Cs8s8keU}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279173874, "odate": 1664468100000, "details": {"replyCount": 10}}, {"id": "v69itrHLEu", "original": "KwqcuZAnBM", "number": 1563, "cdate": 1663849975927, "mdate": null, "ddate": null, "tcdate": 1663849975927, "tmdate": 1676878453412, "tddate": null, "forum": "v69itrHLEu", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Outcome-directed Reinforcement Learning by Uncertainty \\& Temporal Distance-Aware Curriculum Goal Generation", "authorids": ["~Daesol_Cho1", "~Seungjae_Lee2", "~H._Jin_Kim1"], "authors": ["Daesol Cho", "Seungjae Lee", "H. Jin Kim"], "keywords": ["Curriculum Learning", "Outcome-directed RL", "Goal-conditioned RL"], "abstract": "Current reinforcement learning (RL) often suffers when solving a challenging exploration problem where the desired outcomes or high rewards are rarely observed. Even though curriculum RL, a framework that solves complex tasks by proposing a sequence of surrogate tasks, shows reasonable results, most of the previous works still have difficulty in proposing curriculum due to the absence of a mechanism for obtaining calibrated guidance to the desired outcome state without any prior domain knowledge. To alleviate it, we propose an uncertainty \\& temporal distance-aware curriculum goal generation method for the outcome-directed RL via solving a bipartite matching problem. It could not only provide precisely calibrated guidance of the curriculum to the desired outcome states but also bring much better sample efficiency and geometry-agnostic curriculum goal proposal capability compared to previous curriculum RL methods. We demonstrate that our algorithm significantly outperforms these prior methods in a variety of challenging navigation tasks and robotic manipulation tasks in a quantitative and qualitative way.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)", "paperhash": "cho|outcomedirected_reinforcement_learning_by_uncertainty_\\_temporal_distanceaware_curriculum_goal_generation", "pdf": "/pdf/2c6db8a4ff69ca681456fe5e686ec86f942d3e12.pdf", "supplementary_material": "/attachment/623faec2c3c315c0e2a00bb104f6674515b2fd74.zip", "_bibtex": "@inproceedings{\ncho2023outcomedirected,\ntitle={Outcome-directed Reinforcement Learning by Uncertainty {\\textbackslash}\\& Temporal Distance-Aware Curriculum Goal Generation},\nauthor={Daesol Cho and Seungjae Lee and H. Jin Kim},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=v69itrHLEu}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279171782, "odate": 1664468100000, "details": {"replyCount": 13}}, {"id": "Mvetq8DO05O", "original": "MDxIbhXgKCw", "number": 1532, "cdate": 1663849972249, "mdate": null, "ddate": null, "tcdate": 1663849972249, "tmdate": 1697935718704, "tddate": null, "forum": "Mvetq8DO05O", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "A Laplace-inspired Distribution on SO(3) for Probabilistic Rotation Estimation", "authorids": ["~Yingda_Yin1", "~Yang_Wang34", "~He_Wang5", "~Baoquan_Chen1"], "authors": ["Yingda Yin", "Yang Wang", "He Wang", "Baoquan Chen"], "keywords": [], "abstract": "Estimating the 3DoF rotation from a single RGB image is an important yet challenging problem. Probabilistic rotation regression has raised more and more attention with the benefit of expressing uncertainty information along with the prediction. Though modeling noise using Gaussian-resembling Bingham distribution and matrix Fisher distribution is natural, they are shown to be sensitive to outliers for the nature of quadratic punishment to deviations. In this paper, we draw inspiration from multivariate Laplace distribution and propose a novel Rotation Laplace distribution on SO(3). Rotation Laplace distribution is robust to the disturbance of outliers and enforces much gradient to the low-error region, resulting in a better convergence. Our extensive experiments show that our proposed distribution achieves state-of-the-art performance for rotation regression tasks over both probabilistic and non-probabilistic baselines. Our project page is at pku-epic.github.io/RotationLaplace.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Probabilistic Methods (eg, variational inference, causal inference, Gaussian processes)", "paperhash": "yin|a_laplaceinspired_distribution_on_so3_for_probabilistic_rotation_estimation", "pdf": "/pdf/40fe2e0a65fc37b47b6e6110a4872759e47e20f0.pdf", "supplementary_material": "", "_bibtex": "@inproceedings{\nyin2023a,\ntitle={A Laplace-inspired Distribution on {SO}(3) for Probabilistic Rotation Estimation},\nauthor={Yingda Yin and Yang Wang and He Wang and Baoquan Chen},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=Mvetq8DO05O}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2303.01743/code)"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279169657, "odate": 1664468100000, "details": {"replyCount": 15}}, {"id": "3F6I-0-57SC", "original": "vOSA1haxs3y", "number": 1520, "cdate": 1663849970677, "mdate": null, "ddate": null, "tcdate": 1663849970677, "tmdate": 1677664533625, "tddate": null, "forum": "3F6I-0-57SC", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "HiViT: A Simpler and More Efficient Design of Hierarchical Vision Transformer", "authorids": ["~Xiaosong_Zhang2", "~Yunjie_Tian1", "~Lingxi_Xie1", "~Wei_Huang11", "~Qi_Dai2", "~Qixiang_Ye1", "~Qi_Tian3"], "authors": ["Xiaosong Zhang", "Yunjie Tian", "Lingxi Xie", "Wei Huang", "Qi Dai", "Qixiang Ye", "Qi Tian"], "keywords": ["Hierarchical vision transformers", "self-supervised learning", "masked image modeling"], "TL;DR": "A novel hierarchical vision transformer that is stronger and faster when applied to masked image modeling", "abstract": "There has been a debate on the choice of plain vs. hierarchical vision transformers, where researchers often believe that the former (e.g., ViT) has a simpler design but the latter (e.g., Swin) enjoys higher recognition accuracy. Recently, the emerge of masked image modeling (MIM), a self-supervised visual pre-training method, raised a new challenge to vision transformers in terms of flexibility, i.e., part of image patches or tokens are to be discarded, which seems to claim the advantages of plain vision transformers. In this paper, we delve deep into the comparison between ViT and Swin, revealing that (i) the performance gain of Swin is mainly brought by a deepened backbone and relative positional encoding, (ii) the hierarchical design of Swin can be simplified into hierarchical patch embedding (proposed in this work), and (iii) other designs such as shifted-window attentions can be removed. By removing the unnecessary operations, we come up with a new architecture named HiViT (short for hierarchical ViT), which is simpler and more efficient than Swin yet further improves its performance on fully-supervised and self-supervised visual representation learning. In particular, after pre-trained using masked autoencoder (MAE) on ImageNet-1K, HiViT-B reports a 84.6% accuracy on ImageNet-1K classification, a 53.3% box AP on COCO detection, and a 52.8% mIoU on ADE20K segmentation, significantly surpassing the baseline. Code is available at https://github.com/zhangxiaosong18/hivit.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Unsupervised and Self-supervised learning", "paperhash": "zhang|hivit_a_simpler_and_more_efficient_design_of_hierarchical_vision_transformer", "pdf": "/pdf/7835ef364a3e5f77397911e7f2f90b3aa3630f8b.pdf", "supplementary_material": "/attachment/1f35accd3be082244c68fb391909ec922537ad4a.zip", "_bibtex": "@inproceedings{\nzhang2023hivit,\ntitle={HiViT: A Simpler and More Efficient Design of Hierarchical Vision Transformer},\nauthor={Xiaosong Zhang and Yunjie Tian and Lingxi Xie and Wei Huang and Qi Dai and Qixiang Ye and Qi Tian},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=3F6I-0-57SC}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279169262, "odate": 1664468100000, "details": {"replyCount": 12}}, {"id": "kIPyTuEZuAK", "original": "fJYUUsypGi", "number": 1496, "cdate": 1663849968020, "mdate": null, "ddate": null, "tcdate": 1663849968020, "tmdate": 1677552947007, "tddate": null, "forum": "kIPyTuEZuAK", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "A Minimalist Dataset for Systematic Generalization of Perception, Syntax, and Semantics", "authorids": ["~Qing_Li1", "~Siyuan_Huang2", "~Yining_Hong1", "~Yixin_Zhu1", "~Ying_Nian_Wu1", "~Song-Chun_Zhu1"], "authors": ["Qing Li", "Siyuan Huang", "Yining Hong", "Yixin Zhu", "Ying Nian Wu", "Song-Chun Zhu"], "keywords": ["Systematic Generalization", "Concept Learning"], "abstract": "Inspired by humans' exceptional ability to master arithmetic and generalize to new problems, we present a new dataset, HINT, to examine machines' capability of learning generalizable concepts at three levels: perception, syntax, and semantics. In HINT, machines are tasked with learning how concepts are perceived from raw signals such as images (i.e., perception), how multiple concepts are structurally combined to form a valid expression (i.e., syntax), and how concepts are realized to afford various reasoning tasks (i.e., semantics), all in a weakly supervised manner. Focusing on systematic generalization, we carefully design a five-fold test set to evaluate both the interpolation and the extrapolation of learned concepts w.r.t the three levels. Further, we design a few-shot learning split to determine whether or not models can rapidly learn new concepts and generalize them to more complex scenarios. To comprehend existing models' limitations, we undertake extensive experiments with various sequence-to-sequence models, including RNNs, Transformers, and GPT-3 (with the chain of thought prompting). The results indicate that current models struggle to extrapolate to long-range syntactic dependency and semantics. Models exhibit a considerable gap toward human-level generalization when evaluated with new concepts in a few-shot setting. Moreover, we discover that it is infeasible to solve HINT by merely scaling up the dataset and the model size; this strategy contributes little to the extrapolation of syntax and semantics. Finally, in zero-shot GPT-3 experiments, the chain of thought prompting exhibits impressive results and significantly boosts the test accuracy. We believe the HINT dataset and the experimental findings are of great interest to the learning community on systematic generalization.%", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Infrastructure (eg, datasets, competitions, implementations, libraries)", "paperhash": "li|a_minimalist_dataset_for_systematic_generalization_of_perception_syntax_and_semantics", "TL;DR": "We take inspiration from arithmetic and present a new benchmark for studying systematic generalization of perception, syntax, and semantics.", "pdf": "/pdf/09b973c9c84fd934195e0c087cb7af065e9c6829.pdf", "_bibtex": "@inproceedings{\nli2023a,\ntitle={A Minimalist Dataset for Systematic Generalization of Perception, Syntax, and Semantics},\nauthor={Qing Li and Siyuan Huang and Yining Hong and Yixin Zhu and Ying Nian Wu and Song-Chun Zhu},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=kIPyTuEZuAK}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279167923, "odate": 1664468100000, "details": {"replyCount": 10}}, {"id": "gOZ_pKANaPW", "original": "EZCg7ngdhM", "number": 1478, "cdate": 1663849966126, "mdate": null, "ddate": null, "tcdate": 1663849966126, "tmdate": 1677639284530, "tddate": null, "forum": "gOZ_pKANaPW", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Unsupervised Model Selection for Time Series Anomaly Detection", "authorids": ["~Mononito_Goswami1", "~Cristian_Ignacio_Challu1", "~Laurent_Callot1", "~Lenon_Minorics1", "~Andrey_Kan1"], "authors": ["Mononito Goswami", "Cristian Ignacio Challu", "Laurent Callot", "Lenon Minorics", "Andrey Kan"], "keywords": ["Time Series", "Anomaly Detection", "Model Selection", "Unsupervised Learning", "Rank Aggregation"], "TL;DR": "This paper answers the question-- Given an unlabeled dataset and a set of candidate time series anomaly detectors, how can we select the most accurate model?", "abstract": "Anomaly detection in time-series has a wide range of practical applications. While numerous anomaly detection methods have been proposed in the literature, a recent survey concluded that no single method is the most accurate across various datasets. To make matters worse, anomaly labels are scarce and rarely available in practice. The practical problem of selecting the most accurate model for a given dataset without labels has received little attention in the literature. This paper answers this question \\textit{i.e.} Given an unlabeled dataset and a set of candidate anomaly detectors, how can we select the most accurate model? To this end, we identify three classes of surrogate (unsupervised) metrics, namely, \\textit{prediction error}, \\textit{model centrality}, and \\textit{performance on injected synthetic anomalies}, and show that some metrics are highly correlated with standard supervised anomaly detection performance metrics such as the $F_1$ score, but to varying degrees. We formulate metric combination with multiple imperfect surrogate metrics as a robust rank aggregation problem. We then provide theoretical justification behind the proposed approach. Large-scale experiments on multiple real-world datasets demonstrate that our proposed unsupervised approach is as effective as selecting the most accurate model based on partially labeled data.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "General Machine Learning (ie none of the above)", "paperhash": "goswami|unsupervised_model_selection_for_time_series_anomaly_detection", "pdf": "/pdf/b9338f8e0cd4d78c188aa60e26ced6737232b2a8.pdf", "_bibtex": "@inproceedings{\ngoswami2023unsupervised,\ntitle={Unsupervised Model Selection for Time Series Anomaly Detection},\nauthor={Mononito Goswami and Cristian Ignacio Challu and Laurent Callot and Lenon Minorics and Andrey Kan},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=gOZ_pKANaPW}\n}", "supplementary_material": "", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279167194, "odate": 1664468100000, "details": {"replyCount": 20}}, {"id": "vtVDI3w_BLL", "original": "IdHiCciuM7", "number": 1430, "cdate": 1663849960506, "mdate": null, "ddate": null, "tcdate": 1663849960506, "tmdate": 1677522553524, "tddate": null, "forum": "vtVDI3w_BLL", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "AANG : Automating Auxiliary Learning", "authorids": ["~Lucio_M._Dery1", "~Paul_Michel1", "~Mikhail_Khodak1", "~Graham_Neubig1", "~Ameet_Talwalkar1"], "authors": ["Lucio M. Dery", "Paul Michel", "Mikhail Khodak", "Graham Neubig", "Ameet Talwalkar"], "keywords": ["auxiliary learning", "automl", "natural language processing", "meta-learning", "algorithmic stability", "multitask learning"], "TL;DR": "We automatically generate a suite of auxiliary objectives and give a theoretically informed, efficient algorithm for searching the space of generated objectives to find those most useful to a specified end-task.", "abstract": "Auxiliary objectives, supplementary learning signals that are introduced to help aid learning on data-starved or highly complex end-tasks, are commonplace in machine learning. Whilst much work has been done to formulate useful auxiliary objectives, their construction is still an art which proceeds by slow and tedious hand-design. Intuition for how and when these objectives improve end-task performance has also had limited theoretical backing. In this work, we present an approach for automatically generating a suite of auxiliary objectives. We achieve this by deconstructing existing objectives within a novel unified taxonomy, identifying connections between them, and generating new ones based on the uncovered structure. Next, we theoretically formalize widely-held intuitions about how auxiliary learning improves generalization on the end-task. This leads us to a principled and efficient algorithm for searching the space of generated objectives to find those most useful to a specified end-task.\nWith natural language processing (NLP) as our domain of study, we demonstrate that our automated auxiliary learning pipeline leads to strong improvements over competitive baselines across continued training experiments on a pre-trained model on 5 NLP end-tasks.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Unsupervised and Self-supervised learning", "paperhash": "dery|aang_automating_auxiliary_learning", "pdf": "/pdf/89801dac56ce056d438ce9105f85d897747fa081.pdf", "supplementary_material": "/attachment/63c1d8036f53ddb644881cc07ab785dbb7cdbd59.zip", "_bibtex": "@inproceedings{\ndery2023aang,\ntitle={{AANG} : Automating Auxiliary Learning},\nauthor={Lucio M. Dery and Paul Michel and Mikhail Khodak and Graham Neubig and Ameet Talwalkar},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=vtVDI3w_BLL}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279164610, "odate": 1664468100000, "details": {"replyCount": 19}}, {"id": "9gfir3fSy3J", "original": "fjgRKCPSx_b", "number": 1421, "cdate": 1663849959556, "mdate": null, "ddate": null, "tcdate": 1663849959556, "tmdate": 1681490983461, "tddate": null, "forum": "9gfir3fSy3J", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "NeRN: Learning Neural Representations for Neural Networks", "authorids": ["~Maor_Ashkenazi1", "~Zohar_Rimon1", "~Ron_Vainshtein1", "~Shir_Levi1", "~Elad_Richardson2", "~Pinchas_Mintz1", "~Eran_Treister1"], "authors": ["Maor Ashkenazi", "Zohar Rimon", "Ron Vainshtein", "Shir Levi", "Elad Richardson", "Pinchas Mintz", "Eran Treister"], "keywords": ["Convolutional Neural Networks", "Neural Representations", "Implicit Representations"], "TL;DR": "In this paper we present NerN: a neural representation for the weights of a pretrained neural network, which is obtained by applying smoothness over the reconstructed weights and various knowledge distillation techniques", "abstract": "Neural Representations have recently been shown to effectively reconstruct a wide range of signals from 3D meshes and shapes to images and videos. We show that, when adapted correctly, neural representations can be used to directly represent the weights of a pre-trained convolutional neural network, resulting in a Neural Representation for Neural Networks (NeRN). Inspired by coordinate inputs of previous neural representation methods, we assign a coordinate to each convolutional kernel in our network based on its position in the architecture, and optimize a predictor network to map coordinates to their corresponding weights. Similarly to the spatial smoothness of visual scenes, we show that incorporating a smoothness constraint over the original network's weights aids NeRN towards a better reconstruction. In addition, since slight perturbations in pre-trained model weights can result in a considerable accuracy loss, we employ techniques from the field of knowledge distillation to stabilize the learning process. We demonstrate the effectiveness of NeRN in reconstructing widely used architectures on CIFAR-10, CIFAR-100, and ImageNet. Finally, we present two applications using NeRN, demonstrating the capabilities of the learned representations.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Deep Learning and representational learning", "paperhash": "ashkenazi|nern_learning_neural_representations_for_neural_networks", "pdf": "/pdf/7a5e2aeccac1ea354d122a24d739db89c51f2599.pdf", "supplementary_material": "/attachment/bcf5ec7864fde8d72756ed6f516572a3a518615e.zip", "_bibtex": "@inproceedings{\nashkenazi2023nern,\ntitle={Ne{RN}: Learning Neural Representations for Neural Networks},\nauthor={Maor Ashkenazi and Zohar Rimon and Ron Vainshtein and Shir Levi and Elad Richardson and Pinchas Mintz and Eran Treister},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=9gfir3fSy3J}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279163861, "odate": 1664468100000, "details": {"replyCount": 10}}, {"id": "-P7G-8dmSh4", "original": "ytGLntB8NU", "number": 1405, "cdate": 1663849957851, "mdate": null, "ddate": null, "tcdate": 1663849957851, "tmdate": 1697935731041, "tddate": null, "forum": "-P7G-8dmSh4", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Formal Mathematics Statement Curriculum Learning", "authorids": ["spolu@protonmail.com", "~Jesse_Michael_Han1", "~Kunhao_Zheng1", "~Mantas_Baksys1", "~Igor_Babuschkin1", "~Ilya_Sutskever1"], "authors": ["Stanislas Polu", "Jesse Michael Han", "Kunhao Zheng", "Mantas Baksys", "Igor Babuschkin", "Ilya Sutskever"], "keywords": ["neural theorem proving", "formal mathematics", "language modeling", "expert iteration"], "abstract": "We explore the use of expert iteration in the context of language modeling applied to formal mathematics. We show that at same compute budget, expert iteration, by which we mean proof search interleaved with learning, dramatically outperforms proof search only. We also observe that when applied to a collection of formal statements of sufficiently varied difficulty, expert iteration is capable of finding and solving a curriculum of increasingly difficult problems, without the need for associated ground-truth proofs. Finally, by applying this expert iteration to a manually curated set of problem statements, we surpass previous state-of-the-art on the miniF2F benchmark, automatically solving multiple challenging problems drawn from high school olympiads.", "pdf": "/pdf/f13db9db8ab1cc1e6f7db9c1754c276c7c7601ed.pdf", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )", "paperhash": "polu|formal_mathematics_statement_curriculum_learning", "_bibtex": "@inproceedings{\npolu2023formal,\ntitle={Formal Mathematics Statement Curriculum Learning},\nauthor={Stanislas Polu and Jesse Michael Han and Kunhao Zheng and Mantas Baksys and Igor Babuschkin and Ilya Sutskever},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=-P7G-8dmSh4}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 3 code implementations](https://www.catalyzex.com/paper/arxiv:2202.01344/code)"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279162955, "odate": 1664468100000, "details": {"replyCount": 8}}, {"id": "6fuPIe9tbnC", "original": "8cP4Pn6KD3", "number": 1367, "cdate": 1663849953518, "mdate": null, "ddate": null, "tcdate": 1663849953518, "tmdate": 1697935734687, "tddate": null, "forum": "6fuPIe9tbnC", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Multifactor Sequential Disentanglement via Structured Koopman Autoencoders", "authorids": ["~Nimrod_Berman1", "~Ilan_Naiman1", "~Omri_Azencot1"], "authors": ["Nimrod Berman", "Ilan Naiman", "Omri Azencot"], "keywords": ["Koopman methods", "Sequential Disentanglement"], "TL;DR": "A new method for learning multifactor disentangled representations of sequential data", "abstract": "Disentangling complex data to its latent factors of variation is a fundamental task in representation learning. Existing work on sequential disentanglement mostly provides two factor representations, i.e., it separates the data to time-varying and time-invariant factors. In contrast, we consider multifactor disentanglement in which multiple (more than two) semantic disentangled components are generated. Key to our approach is a strong inductive bias where we assume that the underlying dynamics can be represented linearly in the latent space. Under this assumption, it becomes natural to exploit the recently introduced Koopman autoencoder models. However, disentangled representations are not guaranteed in Koopman approaches, and thus we propose a novel spectral loss term which leads to structured Koopman matrices and disentanglement. Overall, we propose a simple and easy to code new deep model that is fully unsupervised and it supports multifactor disentanglement. We showcase new disentangling abilities such as swapping of individual static factors between characters, and an incremental swap of disentangled factors from the source to the target. Moreover, we evaluate our method extensively on two factor standard benchmark tasks where we significantly improve over competing unsupervised approaches, and we perform competitively in comparison to weakly- and self-supervised state-of-the-art approaches. The code is available at https://github.com/azencot-group/SKD.", "pdf": "/pdf/80996ea72234008065b9f90cd4275bc159fa8565.pdf", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "supplementary_material": "/attachment/bfff9d538e012f5bab63814d7173609342bcb3fe.zip", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Deep Learning and representational learning", "paperhash": "berman|multifactor_sequential_disentanglement_via_structured_koopman_autoencoders", "_bibtex": "@inproceedings{\nberman2023multifactor,\ntitle={Multifactor Sequential Disentanglement via Structured Koopman Autoencoders},\nauthor={Nimrod Berman and Ilan Naiman and Omri Azencot},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=6fuPIe9tbnC}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2303.17264/code)"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279161117, "odate": 1664468100000, "details": {"replyCount": 11}}, {"id": "XXTyv1zD9zD", "original": "kSA7z89kCx", "number": 1362, "cdate": 1663849952926, "mdate": null, "ddate": null, "tcdate": 1663849952926, "tmdate": 1677753790905, "tddate": null, "forum": "XXTyv1zD9zD", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Packed Ensembles for efficient uncertainty estimation", "authorids": ["~Olivier_Laurent1", "~Adrien_Lafage1", "~Enzo_Tartaglione1", "~Geoffrey_Daniel1", "~Jean-marc_Martinez1", "~Andrei_Bursuc1", "~Gianni_Franchi1"], "authors": ["Olivier Laurent", "Adrien Lafage", "Enzo Tartaglione", "Geoffrey Daniel", "Jean-marc Martinez", "Andrei Bursuc", "Gianni Franchi"], "keywords": ["Efficient Ensembling", "Uncertainty Quantification", "OOD Detection"], "abstract": "Deep Ensembles (DE) are a prominent approach for achieving excellent performance on key metrics such as accuracy, calibration, uncertainty estimation, and out-of-distribution detection. However, hardware limitations of real-world systems constrain to smaller ensembles and lower-capacity networks, significantly deteriorating their performance and properties. We introduce Packed-Ensembles (PE), a strategy to design and train lightweight structured ensembles by carefully modulating the dimension of their encoding space. We leverage grouped convolutions to parallelize the ensemble into a single shared backbone and forward pass to improve training and inference speeds. PE is designed to operate within the memory limits of a standard neural network. Our extensive research indicates that PE accurately preserves the properties of DE, such as diversity, and performs equally well in terms of accuracy, calibration, out-of-distribution detection, and robustness to distribution shift. We make our code available at https://github.com/ENSTA-U2IS/torch-uncertainty.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "General Machine Learning (ie none of the above)", "paperhash": "laurent|packed_ensembles_for_efficient_uncertainty_estimation", "TL;DR": "Packed-Ensembles leverage the width of DNNs and grouped convolutions to train subnetworks in parallel and form an efficient ensemble.", "pdf": "/pdf/ca8af472cc5062b34c4e52f4fcb5b8591d4474c9.pdf", "supplementary_material": "/attachment/2fd42b3fc4774c1f8ab80bab361e1c560c55e2ac.zip", "_bibtex": "@inproceedings{\nlaurent2023packed,\ntitle={Packed Ensembles for efficient uncertainty estimation},\nauthor={Olivier Laurent and Adrien Lafage and Enzo Tartaglione and Geoffrey Daniel and Jean-marc Martinez and Andrei Bursuc and Gianni Franchi},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=XXTyv1zD9zD}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279160605, "odate": 1664468100000, "details": {"replyCount": 12}}, {"id": "9y0HFvaAYD6", "original": "SIn27Ds_mYc", "number": 1335, "cdate": 1663849949266, "mdate": null, "ddate": null, "tcdate": 1663849949266, "tmdate": 1697935738983, "tddate": null, "forum": "9y0HFvaAYD6", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Hidden Markov Transformer for Simultaneous Machine Translation", "authorids": ["~Shaolei_Zhang1", "~Yang_Feng4"], "authors": ["Shaolei Zhang", "Yang Feng"], "keywords": ["Simultaneous machine translation", "Machine translation", "Natural language processing", "Transformer"], "abstract": "Simultaneous machine translation (SiMT) outputs the target sequence while receiving the source sequence, and hence learning when to start translating each target token is the core challenge for SiMT task. However, it is non-trivial to learn the optimal moment among many possible moments of starting translating, as the moments of starting translating always hide inside the model and can only be supervised with the observed target sequence. In this paper, we propose a Hidden Markov Transformer (HMT), which treats the moments of starting translating as hidden events and the target sequence as the corresponding observed events, thereby organizing them as a hidden Markov model. HMT explicitly models multiple moments of starting translating as the candidate hidden events, and then selects one to generate the target token. During training, by maximizing the marginal likelihood of the target sequence over multiple moments of starting translating, HMT learns to start translating at the moments that target tokens can be generated more accurately. Experiments on multiple SiMT benchmarks show that HMT outperforms strong baselines and achieves state-of-the-art performance.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Applications (eg, speech processing, computer vision, NLP)", "paperhash": "zhang|hidden_markov_transformer_for_simultaneous_machine_translation", "pdf": "/pdf/fcf9747a3df24a2f10acd861765126ce790b5424.pdf", "_bibtex": "@inproceedings{\nzhang2023hidden,\ntitle={Hidden Markov Transformer for Simultaneous Machine Translation},\nauthor={Shaolei Zhang and Yang Feng},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=9y0HFvaAYD6}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 4 code implementations](https://www.catalyzex.com/paper/arxiv:2303.00257/code)"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279159208, "odate": 1664468100000, "details": {"replyCount": 12}}, {"id": "U2g8OGONA_V", "original": "tcuVrRZshTT", "number": 1305, "cdate": 1663849945737, "mdate": null, "ddate": null, "tcdate": 1663849945737, "tmdate": 1677731596522, "tddate": null, "forum": "U2g8OGONA_V", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Multi-domain image generation and translation with identifiability guarantees", "authorids": ["~Shaoan_Xie4", "~Lingjing_Kong1", "~Mingming_Gong1", "~Kun_Zhang1"], "authors": ["Shaoan Xie", "Lingjing Kong", "Mingming Gong", "Kun Zhang"], "keywords": ["multi-domain image generation", "image translation", "identifiability", "Nonlinear ICA"], "abstract": "Multi-domain image generation and unpaired image-to-to-image translation are two important and related computer vision problems. The common technique for the two tasks is the learning of a joint distribution from multiple marginal distributions. However, it is well known that there can be infinitely many joint distributions that can derive the same marginals. Hence, it is necessary to formulate suitable constraints to address this highly ill-posed problem. Inspired by the recent advances in nonlinear Independent Component Analysis (ICA) theory, we propose a new method to learn the joint distribution from the marginals by enforcing a specific type of minimal change across domains. We report one of the first results connecting multi-domain generative models to identifiability and shows why identifiability is essential and how to achieve it theoretically and practically. We apply our method to five multi-domain image generation and six image-to-image translation tasks. The superior performance of our model supports our theory and demonstrates the effectiveness of our method. The training code are available at https://github.com/Mid-Push/i-stylegan.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Generative models", "paperhash": "xie|multidomain_image_generation_and_translation_with_identifiability_guarantees", "TL;DR": "We propose a way to learn the pairing information from unpaired data with theoretial guarantees, with direct applications in learning tasks such as image-to-image translation", "pdf": "/pdf/51f8278f376fd961504ae802f4d2f35deeb936d7.pdf", "supplementary_material": "/attachment/627c2a1e20901494783c437e41e440c81b7dbde3.zip", "_bibtex": "@inproceedings{\nxie2023multidomain,\ntitle={Multi-domain image generation and translation with identifiability guarantees},\nauthor={Shaoan Xie and Lingjing Kong and Mingming Gong and Kun Zhang},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=U2g8OGONA_V}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279157742, "odate": 1664468100000, "details": {"replyCount": 18}}, {"id": "Zy350cRstc6", "original": "d_Bstd5nR_", "number": 1293, "cdate": 1663849944424, "mdate": null, "ddate": null, "tcdate": 1663849944424, "tmdate": 1677679524488, "tddate": null, "forum": "Zy350cRstc6", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Continual evaluation for lifelong learning: Identifying the stability gap", "authorids": ["~Matthias_De_Lange1", "~Gido_M_van_de_Ven1", "~Tinne_Tuytelaars1"], "authors": ["Matthias De Lange", "Gido M van de Ven", "Tinne Tuytelaars"], "keywords": ["Continual learning", "lifelong learning", "incremental learning", "evaluation metrics"], "TL;DR": "Proposing an iteration-based continual evaluation framework for CL, we discover, quantify, and analyse the \"stability gap\", a phenomenon where upon learning new tasks, past tasks exhibit substantial but transient performance loss for SOTA CL methods.", "abstract": "Time-dependent data-generating distributions have proven to be difficult for gradient-based training of neural networks, as the greedy updates result in catastrophic forgetting of previously learned knowledge. Despite the progress in the field of continual learning to overcome this forgetting, we show that a set of common state-of-the-art methods still suffers from substantial forgetting upon starting to learn new tasks, except that this forgetting is temporary and followed by a phase of performance recovery. We refer to this intriguing but potentially problematic phenomenon as the stability gap. The stability gap had likely remained under the radar due to standard practice in the field of evaluating continual learning models only after each task. Instead, we establish a framework for continual evaluation that uses per-iteration evaluation and we define a new set of metrics to quantify worst-case performance. Empirically we show that experience replay, constraint-based replay, knowledge-distillation, and parameter regularization methods are all prone to the stability gap; and that the stability gap can be observed in class-, task-, and domain-incremental learning benchmarks. Additionally, a controlled experiment shows that the stability gap increases when tasks are more dissimilar. Finally, by disentangling gradients into plasticity and stability components, we propose a conceptual explanation for the stability gap.", "pdf": "/pdf/913d2396e313fdd690c50b875b3c31efaa2e05a5.pdf", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Deep Learning and representational learning", "paperhash": "lange|continual_evaluation_for_lifelong_learning_identifying_the_stability_gap", "_bibtex": "@inproceedings{\nlange2023continual,\ntitle={Continual evaluation for lifelong learning: Identifying the stability gap},\nauthor={Matthias De Lange and Gido M van de Ven and Tinne Tuytelaars},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=Zy350cRstc6}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279156754, "odate": 1664468100000, "details": {"replyCount": 19}}, {"id": "pxStyaf2oJ5", "original": "3rEm76j1Ru", "number": 1287, "cdate": 1663849943710, "mdate": null, "ddate": null, "tcdate": 1663849943710, "tmdate": 1677711632077, "tddate": null, "forum": "pxStyaf2oJ5", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Domain-Indexing Variational Bayes: Interpretable Domain Index for Domain Adaptation", "authorids": ["~Zihao_Xu2", "~Guang-Yuan_Hao1", "~Hao_He1", "~Hao_Wang3"], "authors": ["Zihao Xu", "Guang-Yuan Hao", "Hao He", "Hao Wang"], "keywords": [], "abstract": "Previous studies have shown that leveraging \"domain index\" can significantly boost domain adaptation performance (Wang et al., 2020; Xu et al., 2022). However, such domain indices are not always available. To address this challenge, we first provide a formal definition of domain index from the probabilistic perspective, and then propose an adversarial variational Bayesian framework that infers domain indices from multi-domain data, thereby providing additional insight on domain relations and improving domain adaptation performance. Our theoretical analysis shows that our adversarial variational Bayesian framework finds the optimal domain index at equilibrium. Empirical results on both synthetic and real data verify that our model can produce interpretable domain indices which enable us to achieve superior performance compared to state-of-the-art domain adaptation methods. Code is available at https://github.com/Wang-ML-Lab/VDI.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Probabilistic Methods (eg, variational inference, causal inference, Gaussian processes)", "paperhash": "xu|domainindexing_variational_bayes_interpretable_domain_index_for_domain_adaptation", "pdf": "/pdf/4340ecd2eb1d6cddf23d0257a4ab36cd01fba41e.pdf", "_bibtex": "@inproceedings{\nxu2023domainindexing,\ntitle={Domain-Indexing Variational Bayes: Interpretable Domain Index for Domain Adaptation},\nauthor={Zihao Xu and Guang-Yuan Hao and Hao He and Hao Wang},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=pxStyaf2oJ5}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279156015, "odate": 1664468100000, "details": {"replyCount": 19}}, {"id": "p7G8t5FVn2h", "original": "qsbQUn8THL", "number": 1277, "cdate": 1663849942645, "mdate": null, "ddate": null, "tcdate": 1663849942645, "tmdate": 1697935745136, "tddate": null, "forum": "p7G8t5FVn2h", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "One-Pixel Shortcut: On the Learning Preference of Deep Neural Networks", "authorids": ["~Shutong_Wu1", "~Sizhe_Chen1", "~Cihang_Xie3", "~Xiaolin_Huang1"], "authors": ["Shutong Wu", "Sizhe Chen", "Cihang Xie", "Xiaolin Huang"], "keywords": ["unlearnable examples", "shortcut learning", "one-pixel feature", "deep neural network"], "TL;DR": "We propose a model-free method to craft unlearnable example by perturbing only one pixel, and construct a benchmark containing images that are unlearnable by various existing methods to avoid shortcut learning.", "abstract": "Unlearnable examples (ULEs) aim to protect data from unauthorized usage for training DNNs. Existing work adds $\\ell_\\infty$-bounded perturbations to the original sample so that the trained model generalizes poorly. Such perturbations, however, are easy to eliminate by adversarial training and data augmentations. In this paper, we resolve this problem from a novel perspective by perturbing only one pixel in each image. Interestingly, such a small modification could effectively degrade model accuracy to almost an untrained counterpart. Moreover, our produced \\emph{One-Pixel Shortcut (OPS)} could not be erased by adversarial training and strong augmentations. To generate OPS, we perturb in-class images at the same position to the same target value that could mostly and stably deviate from all the original images. Since such generation is only based on images, OPS needs significantly less computation cost than the previous methods using DNN generators. Based on OPS, we introduce an unlearnable dataset called CIFAR-10-S, which is indistinguishable from CIFAR-10 by humans but induces the trained model to extremely low accuracy. Even under adversarial training, a ResNet-18 trained on CIFAR-10-S has only 10.61% accuracy, compared to 83.02% by the existing error-minimizing method.", "pdf": "/pdf/b69561625d5ce4388db999c205fdb5a8b988725e.pdf", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "supplementary_material": "/attachment/da6c321999c823b721cfa616459f879e63ee4d82.zip", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Deep Learning and representational learning", "paperhash": "wu|onepixel_shortcut_on_the_learning_preference_of_deep_neural_networks", "_bibtex": "@inproceedings{\nwu2023onepixel,\ntitle={One-Pixel Shortcut: On the Learning Preference of Deep Neural Networks},\nauthor={Shutong Wu and Sizhe Chen and Cihang Xie and Xiaolin Huang},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=p7G8t5FVn2h}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2205.12141/code)"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279155225, "odate": 1664468100000, "details": {"replyCount": 16}}, {"id": "g8wBdhnstYz", "original": "mzDGLW1pWEB", "number": 1227, "cdate": 1663849936758, "mdate": null, "ddate": null, "tcdate": 1663849936758, "tmdate": 1677764255842, "tddate": null, "forum": "g8wBdhnstYz", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Deterministic training of generative autoencoders using invertible layers", "authorids": ["~Gianluigi_Silvestri1", "~Daan_Roos1", "~Luca_Ambrogioni1"], "authors": ["Gianluigi Silvestri", "Daan Roos", "Luca Ambrogioni"], "keywords": [], "abstract": "In this work, we provide a deterministic alternative to the stochastic variational training of generative autoencoders. We refer to these new generative autoencoders as AutoEncoders within Flows (AEF), since the encoder and decoder are defined as affine layers of an overall invertible architecture. This results in a deterministic encoding of the data, as opposed to the stochastic encoding of VAEs. The paper introduces two related families of AEFs. The first family relies on a partition of the ambient space and is trained by exact maximum-likelihood. The second family exploits a deterministic expansion of the ambient space and is trained by maximizing the log-probability in this extended space. This latter case leaves complete freedom in the choice of encoder, decoder and prior architectures, making it a drop-in replacement for the training of existing VAEs and VAE-style models. We show that these AEFs can have strikingly higher performance than architecturally identical VAEs in terms of log-likelihood and sample quality, especially for low dimensional latent spaces. Importantly, we show that AEF samples are substantially sharper than VAE samples. ", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Generative models", "paperhash": "silvestri|deterministic_training_of_generative_autoencoders_using_invertible_layers", "pdf": "/pdf/78c7fb939078a784f02006f7272c92a758e1e9c7.pdf", "_bibtex": "@inproceedings{\nsilvestri2023deterministic,\ntitle={Deterministic training of generative autoencoders using invertible layers},\nauthor={Gianluigi Silvestri and Daan Roos and Luca Ambrogioni},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=g8wBdhnstYz}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279152514, "odate": 1664468100000, "details": {"replyCount": 19}}, {"id": "aFzaXRImWE", "original": "lZ17YKzBwN", "number": 1154, "cdate": 1663849928508, "mdate": null, "ddate": null, "tcdate": 1663849928508, "tmdate": 1677543810223, "tddate": null, "forum": "aFzaXRImWE", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "A Holistic View of Label Noise Transition Matrix in Deep Learning and Beyond", "authorids": ["~LIN_Yong1", "~Renjie_Pi1", "~WEIZHONG_ZHANG2", "~Xiaobo_Xia1", "~Jiahui_Gao2", "~Xiao_Zhou4", "~Tongliang_Liu1", "~Bo_Han1"], "authors": ["LIN Yong", "Renjie Pi", "WEIZHONG ZHANG", "Xiaobo Xia", "Jiahui Gao", "Xiao Zhou", "Tongliang Liu", "Bo Han"], "keywords": [], "abstract": "In this paper, we explore learning statistically consistent classifiers under label noise by estimating the noise transition matrix T. We first provide a holistic view of existing T-estimation methods including those with or without anchor point assumptions.  We unified them into the Minimum Geometric Envelope Operator (MGEO) framework, which tries to find the smallest T (in terms of a certain metric) that elicits a convex hull to enclose the posteriors of all the training data. Although MGEO methods show appealing theoretical properties and empirical results, we find them prone to failing when the noisy posterior estimation is imperfect, which is inevitable in practice. Specifically, we show that MGEO methods are in-consistent even with infinite samples if the noisy posterior is not estimated accurately. In view of this, we make the first effort to address this issue by proposing a novel T-estimation framework via the lens of bilevel optimization, and term it RObust Bilevel OpTimzation (ROBOT). ROBOT paves a new road beyond MGEO framework, which enjoys strong theoretical properties: identifibility, consistency and finite-sample generalization guarantees. Notably, ROBOT neither requires the perfect posterior estimation nor assumes the existence of anchor points. We further theoretically demonstrate that ROBOT is more robust in the case where MGEO methods fail. Experimentally, our framework also shows superior performance across multiple benchmarks.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "General Machine Learning (ie none of the above)", "paperhash": "yong|a_holistic_view_of_label_noise_transition_matrix_in_deep_learning_and_beyond", "pdf": "/pdf/405fab9c74f731a957a6e9ee24c23a06a6809b77.pdf", "supplementary_material": "/attachment/429434df65546c46f62904b772e5fa83c55ce987.zip", "_bibtex": "@inproceedings{\nyong2023a,\ntitle={A Holistic View of Label Noise Transition Matrix in Deep Learning and Beyond},\nauthor={LIN Yong and Renjie Pi and WEIZHONG ZHANG and Xiaobo Xia and Jiahui Gao and Xiao Zhou and Tongliang Liu and Bo Han},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=aFzaXRImWE}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279148397, "odate": 1664468100000, "details": {"replyCount": 19}}, {"id": "ZTMuZ68B1g", "original": "34-cHcBKsS", "number": 1153, "cdate": 1663849928388, "mdate": null, "ddate": null, "tcdate": 1663849928388, "tmdate": 1677571983416, "tddate": null, "forum": "ZTMuZ68B1g", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Active Learning in Bayesian Neural Networks with Balanced Entropy Learning Principle", "authorids": ["~Jae_Oh_Woo1"], "authors": ["Jae Oh Woo"], "keywords": ["bayesian neural network", "bayesian active learning", "balanced entropy learning", "uncertainty quantification"], "TL;DR": "We propose a new bayesian active learning principle.", "abstract": "Acquiring labeled data is challenging in many machine learning applications with limited budgets. Active learning gives a procedure to select the most informative data points and improve data efficiency by reducing the cost of labeling. The info-max learning principle maximizing mutual information such as BALD has been successful and widely adapted in various active learning applications. However, this pool-based specific objective inherently introduces a redundant selection and further requires a high computational cost for batch selection. In this paper, we design and propose a new uncertainty measure, Balanced Entropy Acquisition (BalEntAcq), which captures the information balance between the uncertainty of underlying softmax probability and the label variable. To do this, we approximate each marginal distribution by Beta distribution. Beta approximation enables us to formulate BalEntAcq as a ratio between an augmented entropy and the marginalized joint entropy. The closed-form expression of BalEntAcq facilitates parallelization by estimating two parameters in each marginal Beta distribution. BalEntAcq is a purely standalone measure without requiring any relational computations with other data points. Nevertheless, BalEntAcq captures a well-diversified selection near the decision boundary with a margin, unlike other existing uncertainty measures such as BALD, Entropy, or Mean Standard Deviation (MeanSD). Finally, we demonstrate that our balanced entropy learning principle with BalEntAcq consistently outperforms well-known linearly scalable active learning methods, including a recently proposed PowerBALD, a simple but diversified version of BALD, by showing experimental results obtained from MNIST, CIFAR-100, SVHN, and TinyImageNet datasets.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Probabilistic Methods (eg, variational inference, causal inference, Gaussian processes)", "paperhash": "woo|active_learning_in_bayesian_neural_networks_with_balanced_entropy_learning_principle", "pdf": "/pdf/4919425fc00a999aa99ff64ba1e275ca945e9f6f.pdf", "supplementary_material": "/attachment/1ade9c8d935be2c53f27740c0e3c579a5b953a99.zip", "_bibtex": "@inproceedings{\nwoo2023active,\ntitle={Active Learning in Bayesian Neural Networks with Balanced Entropy Learning Principle},\nauthor={Jae Oh Woo},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=ZTMuZ68B1g}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279148355, "odate": 1664468100000, "details": {"replyCount": 14}}, {"id": "i9ogGQHYbkY", "original": "qU6u28Nr5FA", "number": 1152, "cdate": 1663849928268, "mdate": null, "ddate": null, "tcdate": 1663849928268, "tmdate": 1677449010078, "tddate": null, "forum": "i9ogGQHYbkY", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Near-Optimal Adversarial Reinforcement Learning with Switching Costs", "authorids": ["~Ming_Shi1", "~Yingbin_Liang1", "~Ness_Shroff1"], "authors": ["Ming Shi", "Yingbin Liang", "Ness Shroff"], "keywords": ["adversarial reinforcement learning", "switching costs", "regret analysis", "lower bound"], "TL;DR": "This paper provides the first algorithms with near-optimal regrets for adversarial reinforcement learning with switching costs, and a matching lower bound on the regret.", "abstract": "Switching costs, which capture the costs for changing policies, are regarded as a critical metric in reinforcement learning (RL), in addition to the standard metric of losses (or rewards). However, existing studies on switching costs (with a coefficient that is strictly positive and is independent of the time horizon) have mainly focused on static RL, where the loss distribution is assumed to be fixed during the learning process, and thus practical scenarios where the loss distribution could be non-stationary or even adversarial are not considered. While adversarial RL better models this type of practical scenarios, an open problem remains: how to develop a provably efficient algorithm for adversarial RL with switching costs? This paper makes the first effort towards solving this problem. First, we provide a regret lower-bound that shows that the regret of any algorithm must be larger than $\\tilde{\\Omega}( ( H S A )^{1/3} T^{2/3} )$, where $T$, $S$, $A$ and $H$ are the number of episodes, states, actions and layers in each episode, respectively. Our lower bound indicates that, due to the fundamental challenge of switching costs in adversarial RL, the best achieved regret (whose dependency on $T$ is $\\tilde{O}(\\sqrt{T})$) in static RL with switching costs (as well as adversarial RL without switching costs) is no longer achievable. Moreover, we propose two novel switching-reduced algorithms with regrets that match our lower bound when the transition function is known, and match our lower bound within a small factor of $\\tilde{O}( H^{1/3} )$ when the transition function is unknown. Our regret analysis demonstrates the near-optimal performance of them.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Theory (eg, control theory, learning theory, algorithmic game theory)", "paperhash": "shi|nearoptimal_adversarial_reinforcement_learning_with_switching_costs", "pdf": "/pdf/c49c1d1fb9288fba31814bc7cccd62fe483bf469.pdf", "_bibtex": "@inproceedings{\nshi2023nearoptimal,\ntitle={Near-Optimal Adversarial Reinforcement Learning with Switching Costs},\nauthor={Ming Shi and Yingbin Liang and Ness Shroff},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=i9ogGQHYbkY}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279148332, "odate": 1664468100000, "details": {"replyCount": 20}}, {"id": "IowKt5rYWsK", "original": "lPdhke-_sdE", "number": 1136, "cdate": 1663849926314, "mdate": null, "ddate": null, "tcdate": 1663849926314, "tmdate": 1697935760157, "tddate": null, "forum": "IowKt5rYWsK", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "GPViT: A High Resolution Non-Hierarchical Vision Transformer with Group Propagation", "authorids": ["~Chenhongyi_Yang3", "~Jiarui_Xu1", "~Shalini_De_Mello1", "~Elliot_J._Crowley1", "~Xiaolong_Wang3"], "authors": ["Chenhongyi Yang", "Jiarui Xu", "Shalini De Mello", "Elliot J. Crowley", "Xiaolong Wang"], "keywords": ["Visual Recognition", "Vision transformer architecture"], "TL;DR": "A high-resolution vision transformer architecture based on a new efficient global information exchange mechanism for general visual recognition.", "abstract": "We present the Group Propagation Vision Transformer (GPViT): a novel non- hierarchical (i.e. non-pyramidal) transformer model designed for general visual recognition with high-resolution features. High-resolution features (or tokens) are a natural fit for tasks that involve perceiving fine-grained details such as detection and segmentation, but exchanging global information between these features is expensive in memory and computation because of the way self-attention scales. We provide a highly efficient alternative Group Propagation Block (GP Block) to exchange global information. In each GP Block, features are first grouped to- gether by a fixed number of learnable group tokens; we then perform Group Propagation where global information is exchanged between the grouped fea- tures; finally, global information in the updated grouped features is returned back to the image features through a transformer decoder. We evaluate GPViT on a variety of visual recognition tasks including image classification, semantic seg- mentation, object detection, and instance segmentation. Our method achieves significant performance gains over previous works across all tasks, especially on tasks that require high-resolution outputs, for example, our GPViT-L3 out- performs Swin Transformer-B by 2.0 mIoU on ADE20K semantic segmentation with only half as many parameters. Code and pre-trained models are available at https://github.com/ChenhongyiYang/GPViT.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Applications (eg, speech processing, computer vision, NLP)", "paperhash": "yang|gpvit_a_high_resolution_nonhierarchical_vision_transformer_with_group_propagation", "pdf": "/pdf/9542365fc4380de76797ec856ed324fe9acf8f79.pdf", "_bibtex": "@inproceedings{\nyang2023gpvit,\ntitle={{GPV}iT: A High Resolution Non-Hierarchical Vision Transformer with Group Propagation},\nauthor={Chenhongyi Yang and Jiarui Xu and Shalini De Mello and Elliot J. Crowley and Xiaolong Wang},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=IowKt5rYWsK}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2212.06795/code)"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279147400, "odate": 1664468100000, "details": {"replyCount": 11}}, {"id": "d8CBRlWNkqH", "original": "qkE1m1aotAB", "number": 1111, "cdate": 1663849923456, "mdate": null, "ddate": null, "tcdate": 1663849923456, "tmdate": 1697935763533, "tddate": null, "forum": "d8CBRlWNkqH", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Neural Optimal Transport", "authorids": ["~Alexander_Korotin2", "~Daniil_Selikhanovych1", "~Evgeny_Burnaev1"], "authors": ["Alexander Korotin", "Daniil Selikhanovych", "Evgeny Burnaev"], "keywords": ["weak optimal transport", "neural networks"], "TL;DR": "We present a novel neural-networks-based algorithm to compute optimal transport maps and plans for strong and weak transport costs.", "abstract": "We present a novel neural-networks-based algorithm to compute optimal transport maps and plans for strong and weak transport costs. To justify the usage of neural networks, we prove that they are universal approximators of transport plans between probability distributions. We evaluate the performance of our optimal transport algorithm on toy examples and on the unpaired image-to-image translation.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Generative models", "paperhash": "korotin|neural_optimal_transport", "pdf": "/pdf/b137a1ea32ff2b3c00faafef118b83c3223bc3eb.pdf", "supplementary_material": "", "_bibtex": "@inproceedings{\nkorotin2023neural,\ntitle={Neural Optimal Transport},\nauthor={Alexander Korotin and Daniil Selikhanovych and Evgeny Burnaev},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=d8CBRlWNkqH}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 5 code implementations](https://www.catalyzex.com/paper/arxiv:2201.12220/code)"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279145368, "odate": 1664468100000, "details": {"replyCount": 9}}, {"id": "4WM4cy42B81", "original": "evxixEar4h7", "number": 1068, "cdate": 1663849918179, "mdate": null, "ddate": null, "tcdate": 1663849918179, "tmdate": 1697935768433, "tddate": null, "forum": "4WM4cy42B81", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Dirichlet-based Uncertainty Calibration for Active Domain Adaptation", "authorids": ["~Mixue_Xie2", "~Shuang_Li6", "~Rui_Zhang20", "~Chi_Harold_Liu1"], "authors": ["Mixue Xie", "Shuang Li", "Rui Zhang", "Chi Harold Liu"], "keywords": ["domain adaptation", "active learning", "uncertainty", "Dirichlet"], "abstract": "Active domain adaptation (DA) aims to maximally boost the model adaptation on a new target domain by actively selecting limited target data to annotate, whereas traditional active learning methods may be less effective since they do not consider the domain shift issue. Despite active DA methods address this by further proposing targetness to measure the representativeness of target domain characteristics, their predictive uncertainty is usually based on the prediction of deterministic models, which can easily be miscalibrated on data with distribution shift. Considering this, we propose a Dirichlet-based Uncertainty Calibration (DUC) approach for active DA, which simultaneously achieves the mitigation of miscalibration and the selection of informative target samples. Specifically, we place a Dirichlet prior on the prediction and interpret the prediction as a distribution on the probability simplex, rather than a point estimate like deterministic models. This manner enables us to consider all possible predictions, mitigating the miscalibration of unilateral prediction. Then a two-round selection strategy based on different uncertainty origins is designed to select target samples that are both representative of target domain and conducive to discriminability. Extensive experiments on cross-domain image classification and semantic segmentation validate the superiority of DUC.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "General Machine Learning (ie none of the above)", "paperhash": "xie|dirichletbased_uncertainty_calibration_for_active_domain_adaptation", "pdf": "/pdf/d263b9c4283973a09247e2e1effd05f8d9bd7652.pdf", "supplementary_material": "/attachment/3ad1fa04da718b44a4e6b2f80fdd578220f9854c.zip", "_bibtex": "@inproceedings{\nxie2023dirichletbased,\ntitle={Dirichlet-based Uncertainty Calibration for Active Domain Adaptation},\nauthor={Mixue Xie and Shuang Li and Rui Zhang and Chi Harold Liu},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=4WM4cy42B81}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2302.13824/code)"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279142577, "odate": 1664468100000, "details": {"replyCount": 4}}, {"id": "IloMJ5rqfnt", "original": "VIUjKncihJ1", "number": 1067, "cdate": 1663849918023, "mdate": null, "ddate": null, "tcdate": 1663849918023, "tmdate": 1697935768691, "tddate": null, "forum": "IloMJ5rqfnt", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Accurate Image Restoration with Attention Retractable Transformer", "authorids": ["~Jiale_Zhang3", "~Yulun_Zhang1", "~Jinjin_Gu1", "~Yongbing_Zhang1", "~Linghe_Kong1", "~Xin_Yuan4"], "authors": ["Jiale Zhang", "Yulun Zhang", "Jinjin Gu", "Yongbing Zhang", "Linghe Kong", "Xin Yuan"], "keywords": ["Image restoration", "Dense and sparse attention"], "TL;DR": "A new SOTA image restoration method attention retractable Transformer.", "abstract": "Recently, Transformer-based image restoration networks have achieved promising improvements over convolutional neural networks due to parameter-independent global interactions. To lower computational cost, existing works generally limit self-attention computation within non-overlapping windows. However, each group of tokens are always from a dense area of the image. This is considered as a dense attention strategy since the interactions of tokens are restrained in dense regions. Obviously, this strategy could result in restricted receptive fields. To address this issue, we propose \\textbf{A}ttention \\textbf{R}etractable \\textbf{T}ransformer (ART) for image restoration, which presents both dense and sparse attention modules in the network. The sparse attention module allows tokens from sparse areas to interact and thus provides a wider receptive field. Furthermore, the alternating application of dense and sparse attention modules greatly enhances representation ability of Transformer while providing retractable attention on the input image.We conduct extensive experiments on image super-resolution, denoising, and JPEG compression artifact reduction tasks. Experimental results validate that our proposed ART outperforms state-of-the-art methods on various benchmark datasets both quantitatively and visually. We also provide code and models at~\\url{https://github.com/gladzhang/ART}.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Applications (eg, speech processing, computer vision, NLP)", "paperhash": "zhang|accurate_image_restoration_with_attention_retractable_transformer", "pdf": "/pdf/aa567c400b76e1249b3186bd548cfc118ad0f339.pdf", "supplementary_material": "/attachment/77fe90ca1af98ee50e60942c3068310e2c0a3ee8.zip", "_bibtex": "@inproceedings{\nzhang2023accurate,\ntitle={Accurate Image Restoration with Attention Retractable Transformer},\nauthor={Jiale Zhang and Yulun Zhang and Jinjin Gu and Yongbing Zhang and Linghe Kong and Xin Yuan},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=IloMJ5rqfnt}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2210.01427/code)"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279142511, "odate": 1664468100000, "details": {"replyCount": 12}}, {"id": "C2fsSj3ZGiU", "original": "mafnXpVl39", "number": 1059, "cdate": 1663849917003, "mdate": null, "ddate": null, "tcdate": 1663849917003, "tmdate": 1676880373708, "tddate": null, "forum": "C2fsSj3ZGiU", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Neural Episodic Control with State Abstraction", "authorids": ["~Zhuo_Li6", "~Derui_Zhu2", "~Yujing_Hu2", "~Xiaofei_Xie2", "~Lei_Ma1", "~YAN_ZHENG1", "~Yan_Song4", "~Yingfeng_Chen2", "~Jianjun_Zhao1"], "authors": ["Zhuo Li", "Derui Zhu", "Yujing Hu", "Xiaofei Xie", "Lei Ma", "YAN ZHENG", "Yan Song", "Yingfeng Chen", "Jianjun Zhao"], "keywords": ["Deep reinforcement learning", "episodic control", "sample efficiency", "state abstraction"], "TL;DR": "We propose NECSA, a simple and effective state abstraction-based episodic control containing a more comprehensive episodic memory, a novel state measurement, and a multi-step state analysis.", "abstract": "Existing Deep Reinforcement Learning (DRL) algorithms suffer from sample inefficiency. Generally, episodic control-based approaches are solutions that leverage highly rewarded past experiences to improve sample efficiency of DRL algorithms. However, previous episodic control-based approaches fail to utilize the latent information from the historical behaviors (\\eg, state transitions, topological similarities, \\etc) and lack scalability during DRL training. This work introduces Neural Episodic Control with State Abstraction (NECSA), a simple but effective state abstraction-based episodic control containing a more comprehensive episodic memory, a novel state evaluation, and a multi-step state analysis. We evaluate our approach to the MuJoCo and Atari tasks in OpenAI gym domains. The experimental results indicate that NECSA achieves higher sample efficiency than the state-of-the-art episodic control-based approaches. Our data and code are available at the project website\\footnote{\\url{https://sites.google.com/view/drl-necsa}}. ", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)", "paperhash": "li|neural_episodic_control_with_state_abstraction", "pdf": "/pdf/48c93f23de2f99bd3c38419a3f4bf1aba384c134.pdf", "supplementary_material": "/attachment/8c7ba7297579f446b825beb84765b7950c5a6a4b.zip", "_bibtex": "@inproceedings{\nli2023neural,\ntitle={Neural Episodic Control with State Abstraction},\nauthor={Zhuo Li and Derui Zhu and Yujing Hu and Xiaofei Xie and Lei Ma and YAN ZHENG and Yan Song and Yingfeng Chen and Jianjun Zhao},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=C2fsSj3ZGiU}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279142201, "odate": 1664468100000, "details": {"replyCount": 25}}, {"id": "4oXTQ6m_ws8", "original": "6ZOQRwGi4CL", "number": 1033, "cdate": 1663849914270, "mdate": null, "ddate": null, "tcdate": 1663849914270, "tmdate": 1697935772963, "tddate": null, "forum": "4oXTQ6m_ws8", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "The Role of ImageNet Classes in Fr\u00e9chet Inception Distance", "authorids": ["~Tuomas_Kynk\u00e4\u00e4nniemi1", "~Tero_Karras1", "~Miika_Aittala2", "~Timo_Aila1", "~Jaakko_Lehtinen1"], "authors": ["Tuomas Kynk\u00e4\u00e4nniemi", "Tero Karras", "Miika Aittala", "Timo Aila", "Jaakko Lehtinen"], "keywords": ["generative models", "evaluation", "Fr\u00e9chet Inception Distance"], "TL;DR": "We elucidate why using ImageNet pre-trained Inception features in FID can cause discrepancies with human judgement.", "abstract": "Fr\u00e9chet Inception Distance (FID) is the primary metric for ranking models in data-driven generative modeling. While remarkably successful, the metric is known to sometimes disagree with human judgement. We investigate a root cause of these discrepancies, and visualize what FID \"looks at\" in generated images. We show that the feature space that FID is (typically) computed in is so close to the ImageNet classifications that aligning the histograms of Top-$N$ classifications between sets of generated and real images can reduce FID substantially \u2014 without actually improving the quality of results. Thus, we conclude that FID is prone to intentional or accidental distortions. As a practical example of an accidental distortion, we discuss a case where an ImageNet pre-trained FastGAN achieves a FID comparable to StyleGAN2, while being worse in terms of human evaluation.", "pdf": "/pdf/0e0f4c80c56d0d57f3f758fa07e6f2226ddefea8.pdf", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Generative models", "paperhash": "kynk\u00e4\u00e4nniemi|the_role_of_imagenet_classes_in_fr\u00e9chet_inception_distance", "_bibtex": "@inproceedings{\nkynk{\\\"a}{\\\"a}nniemi2023the,\ntitle={The Role of ImageNet Classes in Fr\\'echet Inception Distance},\nauthor={Tuomas Kynk{\\\"a}{\\\"a}nniemi and Tero Karras and Miika Aittala and Timo Aila and Jaakko Lehtinen},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=4oXTQ6m_ws8}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 4 code implementations](https://www.catalyzex.com/paper/arxiv:2203.06026/code)"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279140580, "odate": 1664468100000, "details": {"replyCount": 10}}, {"id": "pd1P2eUBVfq", "original": "9JiBBeby9s", "number": 1031, "cdate": 1663849914030, "mdate": null, "ddate": null, "tcdate": 1663849914030, "tmdate": 1677665105467, "tddate": null, "forum": "pd1P2eUBVfq", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Diffusion Models Already Have A Semantic Latent Space", "authorids": ["~Mingi_Kwon1", "~Jaeseok_Jeong2", "~Youngjung_Uh2"], "authors": ["Mingi Kwon", "Jaeseok Jeong", "Youngjung Uh"], "keywords": ["diffusion models", "semantic image editing"], "abstract": "Diffusion models achieve outstanding generative performance in various domains. Despite their great success, they lack semantic latent space which is essential for controlling the generative process. To address the problem, we propose asymmetric reverse process (Asyrp) which discovers the semantic latent space in frozen pretrained diffusion models. Our semantic latent space, named h-space, has nice properties for accommodating semantic image manipulation: homogeneity, linearity, robustness, and consistency across timesteps. In addition, we measure editing strength and quality deficiency of a generative process at timesteps to provide a principled design of the process for versatility and quality improvements. Our method is applicable to various architectures (DDPM++, iDDPM, and ADM) and datasets (CelebA-HQ, AFHQ-dog, LSUN-church, LSUN-bedroom, and METFACES).", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Generative models", "paperhash": "kwon|diffusion_models_already_have_a_semantic_latent_space", "TL;DR": "We discover the semantic latent space of pretrained diffusion models by introducing asymmetric reverse process.", "pdf": "/pdf/0d48a82a332a9c1fbc68f65e41a9b16eb9efa537.pdf", "supplementary_material": "/attachment/62942df08ed6f6aaf1899bf56970b1e3ddefc9ae.zip", "_bibtex": "@inproceedings{\nkwon2023diffusion,\ntitle={Diffusion Models Already Have A Semantic Latent Space},\nauthor={Mingi Kwon and Jaeseok Jeong and Youngjung Uh},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=pd1P2eUBVfq}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279140425, "odate": 1664468100000, "details": {"replyCount": 22}}, {"id": "mRieQgMtNTQ", "original": "IadhHxexONB", "number": 1026, "cdate": 1663849913437, "mdate": null, "ddate": null, "tcdate": 1663849913437, "tmdate": 1697935773532, "tddate": null, "forum": "mRieQgMtNTQ", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Zero-Shot Image Restoration Using Denoising Diffusion Null-Space Model", "authorids": ["~Yinhuai_Wang1", "~Jiwen_Yu1", "~Jian_Zhang22"], "authors": ["Yinhuai Wang", "Jiwen Yu", "Jian Zhang"], "keywords": ["Zero-Shot", "Inverse Problems", "Super-Resolution", "Diffusion Models", "Range-Null Space", "Image Restoration", "Colorization", "Compressed Sensing", "Inpainting", "Deblur", "Old Photo Restoration", "Blind Restoration"], "abstract": "Most existing Image Restoration (IR) models are task-specific, which can not be generalized to different degradation operators. In this work, we propose the Denoising Diffusion Null-Space Model (DDNM), a novel zero-shot framework for arbitrary linear IR problems, including but not limited to image super-resolution, colorization, inpainting, compressed sensing, and deblurring. DDNM only needs a pre-trained off-the-shelf diffusion model as the generative prior, without any extra training or network modifications. By refining only the null-space contents during the reverse diffusion process, we can yield diverse results satisfying both data consistency and realness. We further propose an enhanced and robust version, dubbed DDNM+, to support noisy restoration and improve restoration quality for hard tasks. Our experiments on several IR tasks reveal that DDNM outperforms other state-of-the-art zero-shot IR methods. We also demonstrate that DDNM+ can solve complex real-world applications, e.g., old photo restoration. ", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Applications (eg, speech processing, computer vision, NLP)", "paperhash": "wang|zeroshot_image_restoration_using_denoising_diffusion_nullspace_model", "TL;DR": "We present a novel zero-shot image restoration framework, achieving state-of-the-art performance.", "pdf": "/pdf/e31de23cacc50c8cddef5c6e559520cdd3a62b0c.pdf", "_bibtex": "@inproceedings{\nwang2023zeroshot,\ntitle={Zero-Shot Image Restoration Using Denoising Diffusion Null-Space Model},\nauthor={Yinhuai Wang and Jiwen Yu and Jian Zhang},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=mRieQgMtNTQ}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2212.00490/code)"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279139998, "odate": 1664468100000, "details": {"replyCount": 18}}, {"id": "CrfhZAsJDsZ", "original": "N5Tc3cC5Kc", "number": 969, "cdate": 1663849906812, "mdate": null, "ddate": null, "tcdate": 1663849906812, "tmdate": 1677616196442, "tddate": null, "forum": "CrfhZAsJDsZ", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Nonlinear Reconstruction for Operator Learning of PDEs with Discontinuities", "authorids": ["~Samuel_Lanthaler1", "~Roberto_Molinaro1", "~Patrik_Hadorn1", "~Siddhartha_Mishra1"], "authors": ["Samuel Lanthaler", "Roberto Molinaro", "Patrik Hadorn", "Siddhartha Mishra"], "keywords": [], "TL;DR": "Operator learning based on non-linear reconstruction (FNOs, shift-DeepONets) outperform methods based on linear reconstruction (DeepONets, PCA-Net) for PDEs with discontinuities.", "abstract": "Discontinuous solutions arise in a large class of hyperbolic and advection-dominated PDEs. This paper investigates, both theoretically and empirically, the operator learning of PDEs with discontinuous solutions. We rigorously prove, in terms of lower approximation bounds, that methods which entail a linear reconstruction step (e.g. DeepONets or PCA-Nets) fail to efficiently approximate the solution operator of such PDEs. In contrast, we show that certain methods employing a non-linear reconstruction mechanism can overcome these fundamental lower bounds and approximate the underlying operator efficiently. The latter class includes Fourier Neural Operators and a novel extension of DeepONets termed shift-DeepONets. Our theoretical findings are confirmed by empirical results for advection equations, inviscid Burgers\u2019 equation and the compressible Euler equations of gas dynamics.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Theory (eg, control theory, learning theory, algorithmic game theory)", "paperhash": "lanthaler|nonlinear_reconstruction_for_operator_learning_of_pdes_with_discontinuities", "pdf": "/pdf/995dfba9492244e0ce9642782af6ec9a55816279.pdf", "supplementary_material": "/attachment/80383641b8f1818bc2f501b8ac3c27c6add6c1da.zip", "_bibtex": "@inproceedings{\nlanthaler2023nonlinear,\ntitle={Nonlinear Reconstruction for Operator Learning of {PDE}s with Discontinuities},\nauthor={Samuel Lanthaler and Roberto Molinaro and Patrik Hadorn and Siddhartha Mishra},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=CrfhZAsJDsZ}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279137435, "odate": 1664468100000, "details": {"replyCount": 20}}, {"id": "k60XE_b0Ix6", "original": "CTOqXJH-nN", "number": 952, "cdate": 1663849904831, "mdate": null, "ddate": null, "tcdate": 1663849904831, "tmdate": 1697935780512, "tddate": null, "forum": "k60XE_b0Ix6", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Learning Label Encodings for Deep Regression", "authorids": ["~Deval_Shah1", "~Tor_M._Aamodt1"], "authors": ["Deval Shah", "Tor M. Aamodt"], "keywords": ["Regression", "Label Encoding"], "TL;DR": "We propose an end-to-end automated approach to learn label encodings for deep regression.", "abstract": "Deep regression networks are widely used to tackle the problem of predicting a continuous value for a given input. Task-specialized approaches for training regression networks have shown significant improvement over generic approaches, such as direct regression. More recently, a generic approach based on regression by binary classification using binary-encoded labels has shown significant improvement over direct regression. The space of label encodings for regression is large. Lacking heretofore have been automated approaches to find a good label encoding for a given application. This paper introduces Regularized Label Encoding Learning (RLEL) for end-to-end training of an entire network and its label encoding. RLEL provides a generic approach for tackling regression. Underlying RLEL is our observation that the search space of label encodings can be constrained and efficiently explored by using a continuous search space of real-valued label encodings combined with a regularization function designed to encourage encodings with certain properties. These properties balance the probability of classification error in individual bits against error correction capability. Label encodings found by RLEL result in lower or comparable errors to manually designed label encodings. Applying RLEL results in $10.9\\%$ and $12.4\\%$ improvement in Mean Absolute Error (MAE) over direct regression and multiclass classification, respectively. Our evaluation demonstrates that RLEL can be combined with off-the-shelf feature extractors and is suitable across different architectures, datasets, and tasks. Code is available at \\url{https://github.com/ubc-aamodt-group/RLEL_regression}. ", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Deep Learning and representational learning", "paperhash": "shah|learning_label_encodings_for_deep_regression", "pdf": "/pdf/3af8d03ffcf4536fc86a2416e751d3d4282af4d0.pdf", "supplementary_material": "/attachment/f4a8a40bcac831cf270f18d3ca41399c79ad652c.zip", "_bibtex": "@inproceedings{\nshah2023learning,\ntitle={Learning Label Encodings for Deep Regression},\nauthor={Deval Shah and Tor M. Aamodt},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=k60XE_b0Ix6}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2303.02273/code)"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279136291, "odate": 1664468100000, "details": {"replyCount": 15}}, {"id": "Z3IClM_bzvP", "original": "tAEllYARIG", "number": 940, "cdate": 1663849903374, "mdate": null, "ddate": null, "tcdate": 1663849903374, "tmdate": 1697935782151, "tddate": null, "forum": "Z3IClM_bzvP", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Multi-skill Mobile Manipulation for Object Rearrangement", "authorids": ["~Jiayuan_Gu1", "~Devendra_Singh_Chaplot2", "~Hao_Su1", "~Jitendra_Malik2"], "authors": ["Jiayuan Gu", "Devendra Singh Chaplot", "Hao Su", "Jitendra Malik"], "keywords": ["mobile manipulation", "reinforcement learning"], "abstract": "We study a modular approach to tackle long-horizon mobile manipulation tasks for object rearrangement, which decomposes a full task into a sequence of subtasks. To tackle the entire task, prior work chains multiple stationary manipulation skills with a point-goal navigation skill, which are learned individually on subtasks. Although more effective than monolithic end-to-end RL policies, this framework suffers from compounding errors in skill chaining, e.g., navigating to a bad location where a stationary manipulation skill can not reach its target to manipulate. To this end, we propose that the manipulation skills should include mobility to have flexibility in interacting with the target object from multiple locations and at the same time the navigation skill could have multiple end points which lead to successful manipulation. We operationalize these ideas by implementing mobile manipulation skills rather than stationary ones and training a navigation skill trained with region goal instead of point goal. We evaluate our multi-skill mobile manipulation method M3 on 3 challenging long-horizon mobile manipulation tasks in the Home Assistant Benchmark (HAB), and show superior performance as compared to the baselines.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)", "paperhash": "gu|multiskill_mobile_manipulation_for_object_rearrangement", "pdf": "/pdf/826efb580419b89e9ce1db3a7c676c7010ebe04b.pdf", "_bibtex": "@inproceedings{\ngu2023multiskill,\ntitle={Multi-skill Mobile Manipulation for Object Rearrangement},\nauthor={Jiayuan Gu and Devendra Singh Chaplot and Hao Su and Jitendra Malik},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=Z3IClM_bzvP}\n}", "supplementary_material": "/attachment/e84ece0b5844f41a84a6060f27810f198b678e5d.zip", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 3 code implementations](https://www.catalyzex.com/paper/arxiv:2209.02778/code)"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279135314, "odate": 1664468100000, "details": {"replyCount": 11}}, {"id": "3RhuF8foyPW", "original": "Q-_MJS_Cvxv", "number": 935, "cdate": 1663849902765, "mdate": null, "ddate": null, "tcdate": 1663849902765, "tmdate": 1677524834451, "tddate": null, "forum": "3RhuF8foyPW", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Single-shot General Hyper-parameter Optimization for Federated Learning", "authorids": ["~Yi_Zhou13", "~Parikshit_Ram1", "~Theodoros_Salonidis1", "~Nathalie_Baracaldo1", "~Horst_Samulowitz1", "~Heiko_Ludwig1"], "authors": ["Yi Zhou", "Parikshit Ram", "Theodoros Salonidis", "Nathalie Baracaldo", "Horst Samulowitz", "Heiko Ludwig"], "keywords": ["Federated Learning", "Hyperparameter Optimization", "Optimality Gap Analysis"], "TL;DR": "We propose a single-shot hyperparameter optimization scheme for Federated Learning systems with theoretical performance guarantees and strong empirical performance against baselines.", "abstract": "We address the problem of hyper-parameter optimization (HPO) for federated learning (FL-HPO). We introduce Federated Loss SuRface Aggregation (FLoRA), a general FL-HPO solution framework that can address use cases of tabular data and any Machine Learning (ML) model including gradient boosting training algorithms, SVMs, neural networks, among others and thereby further expands the scope of FL-HPO. FLoRA enables single-shot FL-HPO: identifying a single set of good hyper-parameters that are subsequently used in a single FL training. Thus, it enables FL-HPO solutions with minimal additional communication overhead compared to FL training without HPO. Utilizing standard smoothness assumptions, we theoretically characterize the optimality gap of FLoRA for any convex and non-convex loss functions, which explicitly accounts for the heterogeneous nature of the parties' local data distributions, a dominant characteristic of FL systems. Our empirical evaluation of FLoRA for multiple FL algorithms on seven OpenML datasets demonstrates significant model accuracy improvements over the baselines, and robustness to increasing number of parties involved in FL-HPO training.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Optimization (eg, convex and non-convex optimization)", "paperhash": "zhou|singleshot_general_hyperparameter_optimization_for_federated_learning", "pdf": "/pdf/05e0c917ee8caab80ea9a21a831a3c9589442e99.pdf", "supplementary_material": "/attachment/e75b7dd85264fb7266bd4c321a2ba2763a681f59.zip", "_bibtex": "@inproceedings{\nzhou2023singleshot,\ntitle={Single-shot General Hyper-parameter Optimization for Federated Learning},\nauthor={Yi Zhou and Parikshit Ram and Theodoros Salonidis and Nathalie Baracaldo and Horst Samulowitz and Heiko Ludwig},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=3RhuF8foyPW}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279135449, "odate": 1664468100000, "details": {"replyCount": 13}}, {"id": "RWtGreRpovS", "original": "WEzcz-Xx5FN", "number": 926, "cdate": 1663849901667, "mdate": null, "ddate": null, "tcdate": 1663849901667, "tmdate": 1677761077532, "tddate": null, "forum": "RWtGreRpovS", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Simplicial Embeddings in Self-Supervised Learning and Downstream Classification", "authorids": ["~Samuel_Lavoie1", "~Christos_Tsirigotis1", "~Max_Schwarzer1", "~Ankit_Vani1", "~Michael_Noukhovitch1", "~Kenji_Kawaguchi1", "~Aaron_Courville3"], "authors": ["Samuel Lavoie", "Christos Tsirigotis", "Max Schwarzer", "Ankit Vani", "Michael Noukhovitch", "Kenji Kawaguchi", "Aaron Courville"], "keywords": ["Self-Supervised learning", "Representation learning", "Pre-training"], "TL;DR": "We use softmax to embed representations in a collection of simplices in SSL models, which offers improved generalization properties for downstream classification.", "abstract": "Simplicial Embeddings (SEM) are representations learned through self-supervised learning (SSL), wherein a representation is projected into $L$ simplices of $V$ dimensions each using a \\texttt{softmax} operation. This procedure conditions the representation onto a constrained space during pretraining and imparts an inductive bias for group sparsity. For downstream classification, we formally prove that the SEM representation leads to better generalization than an unnormalized representation.\nFurthermore, we empirically demonstrate that SSL methods trained with SEMs have improved generalization on natural image datasets such as CIFAR-100 and ImageNet. Finally, when used in a downstream classification task, we show that SEM features exhibit emergent semantic coherence where small groups of learned features are distinctly predictive of semantically-relevant classes.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Unsupervised and Self-supervised learning", "paperhash": "lavoie|simplicial_embeddings_in_selfsupervised_learning_and_downstream_classification", "pdf": "/pdf/fadb3c6b6bc3ec01fc5bf271cf08a4eb1e0f6fc1.pdf", "supplementary_material": "/attachment/4fd5f9371de7715e85d215337cea506dcb997227.zip", "_bibtex": "@inproceedings{\nlavoie2023simplicial,\ntitle={Simplicial Embeddings in Self-Supervised Learning and Downstream Classification},\nauthor={Samuel Lavoie and Christos Tsirigotis and Max Schwarzer and Ankit Vani and Michael Noukhovitch and Kenji Kawaguchi and Aaron Courville},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=RWtGreRpovS}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279134686, "odate": 1664468100000, "details": {"replyCount": 18}}, {"id": "plKu2GByCNW", "original": "07on_mgdwQ5", "number": 924, "cdate": 1663849901422, "mdate": null, "ddate": null, "tcdate": 1663849901422, "tmdate": 1697935784137, "tddate": null, "forum": "plKu2GByCNW", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Vision Transformer Adapter for Dense Predictions", "authorids": ["~Zhe_Chen10", "~Yuchen_Duan1", "~Wenhai_Wang2", "~Junjun_He2", "~Tong_Lu1", "~Jifeng_Dai1", "~Yu_Qiao1"], "authors": ["Zhe Chen", "Yuchen Duan", "Wenhai Wang", "Junjun He", "Tong Lu", "Jifeng Dai", "Yu Qiao"], "keywords": ["Plain Vision Transformer", "Adapter", "Dense Prediction"], "abstract": "This work investigates a simple yet powerful dense prediction task adapter for Vision Transformer (ViT). Unlike recently advanced variants that incorporate vision-specific inductive biases into their architectures, the plain ViT suffers inferior performance on dense predictions due to weak prior assumptions. To address this issue, we propose the ViT-Adapter, which allows plain ViT to achieve comparable performance to vision-specific transformers. Specifically, the backbone in our framework is a plain ViT that can learn powerful representations from large-scale multi-modal data. When transferring to downstream tasks, a pre-training-free adapter is used to introduce the image-related inductive biases into the model, making it suitable for these tasks. We verify ViT-Adapter on multiple dense prediction tasks, including object detection, instance segmentation, and semantic segmentation. Notably, without using extra detection data, our ViT-Adapter-L yields state-of-the-art 60.9 box AP and 53.0 mask AP on COCO test-dev. We hope that the ViT-Adapter could serve as an alternative for vision-specific transformers and facilitate future research. Code and models will be released at https://github.com/czczup/ViT-Adapter.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Applications (eg, speech processing, computer vision, NLP)", "paperhash": "chen|vision_transformer_adapter_for_dense_predictions", "TL;DR": "This work investigates a simple yet powerful dense prediction task adapter for Vision Transformer (ViT).", "pdf": "/pdf/a1a7cac48a3e0fa0d2a12b5a46c5b2463fe22a38.pdf", "_bibtex": "@inproceedings{\nchen2023vision,\ntitle={Vision Transformer Adapter for Dense Predictions},\nauthor={Zhe Chen and Yuchen Duan and Wenhai Wang and Junjun He and Tong Lu and Jifeng Dai and Yu Qiao},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=plKu2GByCNW}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2205.08534/code)"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279134513, "odate": 1664468100000, "details": {"replyCount": 15}}, {"id": "hVrXUps3LFA", "original": "uaq3ga1aEl", "number": 912, "cdate": 1663849899983, "mdate": null, "ddate": null, "tcdate": 1663849899983, "tmdate": 1677031321212, "tddate": null, "forum": "hVrXUps3LFA", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Divide to Adapt: Mitigating Confirmation Bias for Domain Adaptation of Black-Box Predictors", "authorids": ["~Jianfei_Yang4", "~Xiangyu_Peng2", "~Kai_Wang8", "~Zheng_Zhu1", "~Jiashi_Feng1", "~Lihua_Xie2", "~Yang_You1"], "authors": ["Jianfei Yang", "Xiangyu Peng", "Kai Wang", "Zheng Zhu", "Jiashi Feng", "Lihua Xie", "Yang You"], "keywords": ["model adaptation", "black-box predictors", "transfer learning"], "TL;DR": "A black-box model adaptation approach that purifies the pseudo labels for knowledge distillation.", "abstract": "Domain Adaptation of Black-box Predictors (DABP) aims to learn a model on an unlabeled target domain supervised by a black-box predictor trained on a source domain. It does not require access to both the source-domain data and the predictor parameters, thus addressing the data privacy and portability issues of standard domain adaptation methods. Existing DABP approaches mostly rely on knowledge distillation (KD) from the black-box predictor, i.e., training the model with its noisy target-domain predictions, which however inevitably introduces the confirmation bias accumulated from the prediction noises and leads to degrading performance. To mitigate such bias, we propose a new strategy, \\textit{divide-to-adapt}, that purifies cross-domain knowledge distillation by proper domain division. This is inspired by an observation we make for the first time in domain adaptation: the target domain usually contains easy-to-adapt and hard-to-adapt samples that have different levels of domain discrepancy w.r.t. the source domain, and deep models tend to fit easy-to-adapt samples first. Leveraging easy-to-adapt samples with less noise can help KD alleviate the negative effect of prediction noises from black-box predictors. In this sense, the target domain can be divided into an easy-to-adapt subdomain with less noise and a hard-to-adapt subdomain at the early stage of training. Then the adaptation is achieved by semi-supervised learning. We further reduce distribution discrepancy between subdomains and develop weak-strong augmentation strategy to filter the predictor errors progressively. As such, our method is a simple yet effective solution to reduce error accumulation in cross-domain knowledge distillation for DABP. Moreover, we prove that the target error of DABP is bounded by the noise ratio of two subdomains, i.e., the confirmation bias, which provides the theoretical justifications for our method. Extensive experiments demonstrate our method achieves state of the art on all DABP benchmarks, outperforming the existing best approach by 7.0\\% on VisDA-17, and is even comparable with the standard domain adaptation methods that use the source-domain data.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "paperhash": "yang|divide_to_adapt_mitigating_confirmation_bias_for_domain_adaptation_of_blackbox_predictors", "pdf": "/pdf/f6acdba3a448c8c49b38089c9fcca2175f862634.pdf", "supplementary_material": "/attachment/5e2c58a42b7cd96818cde67ffea5a10b8cbac49a.zip", "Please_choose_the_closest_area_that_your_submission_falls_into": "Deep Learning and representational learning", "_bibtex": "@inproceedings{\nyang2023divide,\ntitle={Divide to Adapt: Mitigating Confirmation Bias for Domain Adaptation of Black-Box Predictors},\nauthor={Jianfei Yang and Xiangyu Peng and Kai Wang and Zheng Zhu and Jiashi Feng and Lihua Xie and Yang You},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=hVrXUps3LFA}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279133888, "odate": 1664468100000, "details": {"replyCount": 22}}, {"id": "zqwryBoXYnh", "original": "7Ig7hrzuvh6", "number": 898, "cdate": 1663849898560, "mdate": null, "ddate": null, "tcdate": 1663849898560, "tmdate": 1677620361027, "tddate": null, "forum": "zqwryBoXYnh", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "PLOT: Prompt Learning with Optimal Transport for Vision-Language Models", "authorids": ["~Guangyi_Chen1", "~Weiran_Yao1", "~Xiangchen_Song1", "~Xinyue_Li3", "~Yongming_Rao1", "~Kun_Zhang1"], "authors": ["Guangyi Chen", "Weiran Yao", "Xiangchen Song", "Xinyue Li", "Yongming Rao", "Kun Zhang"], "keywords": [], "abstract": "With the increasing attention to large vision-language models such as CLIP, there has been a significant amount of effort dedicated to building efficient prompts. Unlike conventional methods of only learning one single prompt, we propose to learn multiple comprehensive prompts to describe diverse characteristics of categories such as intrinsic attributes or extrinsic contexts. However, directly matching each prompt to the same visual feature is problematic, as it pushes the prompts to converge to one point. To solve this problem, we propose to apply optimal transport to match the vision and text modalities. Specifically, we first model images and the categories with visual and textual feature sets. Then, we apply a two-stage optimization strategy to learn the prompts. In the inner loop, we optimize the optimal transport distance to align visual features and prompts by the Sinkhorn algorithm, while in the outer loop, we learn the prompts by this distance from the supervised data. Extensive experiments are conducted on the few-shot recognition task and the improvement demonstrates the superiority of our method. The code is available at https://github.com/CHENGY12/PLOT.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Deep Learning and representational learning", "paperhash": "chen|plot_prompt_learning_with_optimal_transport_for_visionlanguage_models", "pdf": "/pdf/ddf150416bd1ce46f5512042c2aaa162c8ad10b7.pdf", "supplementary_material": "/attachment/b6b86d575bfaf4304159426709ae9861059451c7.zip", "_bibtex": "@inproceedings{\nchen2023plot,\ntitle={{PLOT}: Prompt Learning with Optimal Transport for Vision-Language Models},\nauthor={Guangyi Chen and Weiran Yao and Xiangchen Song and Xinyue Li and Yongming Rao and Kun Zhang},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=zqwryBoXYnh}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279133034, "odate": 1664468100000, "details": {"replyCount": 15}}, {"id": "VA1YpcNr7ul", "original": "RQ8wV0gx_MA", "number": 886, "cdate": 1663849897269, "mdate": null, "ddate": null, "tcdate": 1663849897269, "tmdate": 1677610139400, "tddate": null, "forum": "VA1YpcNr7ul", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "DASHA: Distributed Nonconvex Optimization with Communication Compression and Optimal Oracle Complexity", "authorids": ["~Alexander_Tyurin1", "~Peter_Richt\u00e1rik1"], "authors": ["Alexander Tyurin", "Peter Richt\u00e1rik"], "keywords": ["Nonconvex Optimization", "Variance Reduction", "Compressed Communication", "Distributed Optimization"], "TL;DR": "We provide a new method that improves the state-of-the-art theoretical complexity of distributed optimization methods with compressed communication in the nonconvex regime.", "abstract": "We develop and analyze  DASHA: a new family of methods for nonconvex distributed optimization problems. When the local functions at the nodes have a finite-sum or an expectation form, our new methods, DASHA-PAGE, DASHA-MVR and DASHA-SYNC-MVR, improve the theoretical oracle and communication complexity of the previous state-of-the-art method MARINA by Gorbunov et al. (2020). In particular, to achieve an $\\varepsilon$-stationary point, and considering the random sparsifier Rand$K$ as an example, our methods compute the optimal number of gradients $\\mathcal{O}\\left(\\frac{\\sqrt{m}}{\\varepsilon\\sqrt{n}}\\right)$ and $\\mathcal{O}\\left(\\frac{\\sigma}{\\varepsilon^{3/2}n}\\right)$ in finite-sum and expectation form cases, respectively, while maintaining the SOTA communication complexity $\\mathcal{O}\\left(\\frac{d}{\\varepsilon \\sqrt{n}}\\right)$. Furthermore, unlike MARINA, the new methods DASHA, DASHA-PAGE and DASHA-MVR send compressed vectors only, which makes them more practical for federated learning. We extend our results to the case when the functions satisfy the Polyak-Lojasiewicz condition. Finally, our theory is corroborated in practice: we see a significant improvement in experiments with nonconvex classification and training of deep learning models.", "pdf": "/pdf/b48aa1d65ec14a3d0d8248dd7e332ea750bdee69.pdf", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Optimization (eg, convex and non-convex optimization)", "paperhash": "tyurin|dasha_distributed_nonconvex_optimization_with_communication_compression_and_optimal_oracle_complexity", "_bibtex": "@inproceedings{\ntyurin2023dasha,\ntitle={{DASHA}: Distributed Nonconvex Optimization with Communication Compression and Optimal Oracle Complexity},\nauthor={Alexander Tyurin and Peter Richt{\\'a}rik},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=VA1YpcNr7ul}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279132679, "odate": 1664468100000, "details": {"replyCount": 11}}, {"id": "JJuP86nBl4q", "original": "Or-_zfLE84S", "number": 857, "cdate": 1663849893887, "mdate": null, "ddate": null, "tcdate": 1663849893887, "tmdate": 1697935790363, "tddate": null, "forum": "JJuP86nBl4q", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "LAVA: Data Valuation without Pre-Specified Learning Algorithms", "authorids": ["~Hoang_Anh_Just1", "~Feiyang_Kang1", "~Tianhao_Wang2", "~Yi_Zeng3", "~Myeongseob_Ko1", "~Ming_Jin2", "~Ruoxi_Jia1"], "authors": ["Hoang Anh Just", "Feiyang Kang", "Tianhao Wang", "Yi Zeng", "Myeongseob Ko", "Ming Jin", "Ruoxi Jia"], "keywords": ["data valuation", "optimal transport", "model agnostic", "data-driven"], "TL;DR": "We propose LAVA: a novel model-agnostic approach to data valuation using a non-conventional, class-wise Wasserstein discrepancy.", "abstract": "Traditionally, data valuation is posed as a problem of equitably splitting the validation performance of a learning algorithm among the training data. As a result, the calculated data values depend on many design choices of the underlying learning algorithm. However, this dependence is undesirable for many use cases of data valuation, such as setting priorities over different data sources in a data acquisition process and informing pricing mechanisms in a data marketplace. In these scenarios, data needs to be valued before the actual analysis and the choice of the learning algorithm is still undetermined then. Another side-effect of the dependence is that to assess the value of individual points, one needs to re-run the learning algorithm with and without a point, which incurs a large computation burden. \n\nThis work leapfrogs over the current limits of data valuation methods by introducing a new framework that can value training data in a way that is oblivious to the downstream learning algorithm. Our main results are as follows. $\\textbf{(1)}$ We develop a proxy for the validation performance associated with a training set based on a non-conventional $\\textit{class-wise}$ $\\textit{Wasserstein distance}$ between the training and the validation set. We show that the distance characterizes the upper bound of the validation performance for any given model under certain Lipschitz conditions. $\\textbf{(2)}$ We develop a novel method to value individual data based on the sensitivity analysis of the $\\textit{class-wise}$ Wasserstein distance. Importantly, these values can be directly obtained $\\textit{for free}$ from the output of off-the-shelf optimization solvers once the Wasserstein distance is computed. $\\textbf{(3) }$We evaluate our new data valuation framework over various use cases related to detecting low-quality data\nand show that, surprisingly, the learning-agnostic feature of our framework enables a $\\textit{significant improvement}$ over the state-of-the-art performance while being $\\textit{orders of magnitude faster.}$ ", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "General Machine Learning (ie none of the above)", "paperhash": "just|lava_data_valuation_without_prespecified_learning_algorithms", "pdf": "/pdf/8a4a49f404d172df902842781f95ef52ed70433e.pdf", "supplementary_material": "", "_bibtex": "@inproceedings{\njust2023lava,\ntitle={{LAVA}: Data Valuation without Pre-Specified Learning Algorithms},\nauthor={Hoang Anh Just and Feiyang Kang and Tianhao Wang and Yi Zeng and Myeongseob Ko and Ming Jin and Ruoxi Jia},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=JJuP86nBl4q}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2305.00054/code)"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279131324, "odate": 1664468100000, "details": {"replyCount": 48}}, {"id": "SEh5SfEQtqB", "original": "PxkX_rlwmlp", "number": 851, "cdate": 1663849893184, "mdate": null, "ddate": null, "tcdate": 1663849893184, "tmdate": 1697935790761, "tddate": null, "forum": "SEh5SfEQtqB", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Meta-prediction Model for Distillation-Aware NAS on Unseen Datasets", "authorids": ["~Hayeon_Lee1", "~Sohyun_An1", "~Minseon_Kim1", "~Sung_Ju_Hwang1"], "authors": ["Hayeon Lee", "Sohyun An", "Minseon Kim", "Sung Ju Hwang"], "keywords": ["Neural Architecture Search", "Meta Learning"], "TL;DR": "We propose a one-shot meta accuracy prediction model which can predict a given architecture's final performances on a dataset when performing KD with a given teacher, without having to actually train it on the target task. ", "abstract": "Distillation-aware Neural Architecture Search (DaNAS) aims to search for an optimal student architecture that obtains the best performance and/or efficiency when distilling the knowledge from a given teacher model. Previous DaNAS methods have mostly tackled the search for the neural architecture for fixed datasets and the teacher, which are not generalized well on a new task consisting of an unseen dataset and an unseen teacher, thus need to perform a costly search for any new combination of the datasets and the teachers. For standard NAS tasks without KD, meta-learning-based computationally efficient NAS methods have been proposed, which learn the generalized search process over multiple tasks (datasets) and transfer the knowledge obtained over those tasks to a new task. However, since they assume learning from scratch without KD from a teacher, they might not be ideal for DaNAS scenarios. To eliminate the excessive computational cost of DaNAS methods and the sub-optimality of rapid NAS methods, we propose a distillation-aware meta-accuracy prediction model, DaSS (Distillation-aware Student Search), which can predict a given architecture's final performances on a dataset when performing KD with a given teacher, without having actually to train it on the target task. The experimental results demonstrate that our proposed meta-prediction model successfully generalizes to multiple unseen datasets for DaNAS tasks, largely outperforming existing meta-NAS methods and rapid NAS baselines. Code is available at https://github.com/CownowAn/DaSS.", "pdf": "/pdf/80703f68458650e155bc0dd7dd6c988a91fbc1be.pdf", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Deep Learning and representational learning", "paperhash": "lee|metaprediction_model_for_distillationaware_nas_on_unseen_datasets", "supplementary_material": "/attachment/de76a4c3147835acec72f50759fee58ce808d98c.zip", "_bibtex": "@inproceedings{\nlee2023metaprediction,\ntitle={Meta-prediction Model for Distillation-Aware {NAS} on Unseen Datasets},\nauthor={Hayeon Lee and Sohyun An and Minseon Kim and Sung Ju Hwang},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=SEh5SfEQtqB}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2305.16948/code)"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279131010, "odate": 1664468100000, "details": {"replyCount": 32}}, {"id": "rLwC0_MG-4w", "original": "gU1tuuNAXbZ", "number": 841, "cdate": 1663849892094, "mdate": null, "ddate": null, "tcdate": 1663849892094, "tmdate": 1677503518703, "tddate": null, "forum": "rLwC0_MG-4w", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Denoising Diffusion Error Correction Codes", "authorids": ["~Yoni_Choukroun1", "~Lior_Wolf1"], "authors": ["Yoni Choukroun", "Lior Wolf"], "keywords": ["ECC", "Deep Learning", "Diffusion Models"], "TL;DR": "We propose a novel SOTA Neural error correction decoder based on a new diffusion model.", "abstract": "Error correction code (ECC) is an integral part of the physical communication layer, ensuring reliable data transfer over noisy channels. \nRecently, neural decoders have demonstrated their advantage over classical decoding techniques. \nHowever, recent state-of-the-art neural decoders suffer from high complexity and lack the important iterative scheme characteristic of many legacy decoders. \nIn this work, we propose to employ denoising diffusion models for the soft decoding of linear codes at arbitrary block lengths. \nOur framework models the forward channel corruption as a series of diffusion steps that can be reversed iteratively. \nThree contributions are made: (i) a diffusion process suitable for the decoding setting is introduced, (ii) the neural diffusion decoder is conditioned on the number of parity errors, which indicates the level of corruption at a given step, (iii) a line search procedure based on the code's syndrome obtains the optimal reverse diffusion step size. \nThe proposed approach demonstrates the power of diffusion models for ECC and is able to achieve state-of-the-art accuracy, outperforming the other neural decoders by sizable margins, even for a single reverse diffusion step. ", "pdf": "/pdf/1ba7d8f5e235d93b8db4a40b633bb42c9494223e.pdf", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "supplementary_material": "/attachment/260b97939babf582c7fc3633869663f03bf8c3da.zip", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Deep Learning and representational learning", "paperhash": "choukroun|denoising_diffusion_error_correction_codes", "_bibtex": "@inproceedings{\nchoukroun2023denoising,\ntitle={Denoising Diffusion Error Correction Codes},\nauthor={Yoni Choukroun and Lior Wolf},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=rLwC0_MG-4w}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279130741, "odate": 1664468100000, "details": {"replyCount": 17}}, {"id": "2RwXVje1rAh", "original": "J7kgohxuWga", "number": 831, "cdate": 1663849890858, "mdate": null, "ddate": null, "tcdate": 1663849890858, "tmdate": 1697935792008, "tddate": null, "forum": "2RwXVje1rAh", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Exploring Active 3D Object Detection from a Generalization Perspective", "authorids": ["~Yadan_Luo1", "~Zhuoxiao_Chen1", "~Zijian_Wang2", "~Xin_Yu1", "~Zi_Huang1", "~Mahsa_Baktashmotlagh1"], "authors": ["Yadan Luo", "Zhuoxiao Chen", "Zijian Wang", "Xin Yu", "Zi Huang", "Mahsa Baktashmotlagh"], "keywords": ["Active Learning", "3D Object Detection", "Lidar Point Clouds"], "abstract": "To alleviate the high annotation cost in LiDAR-based 3D object detection, active learning is a promising solution that learns to select only a small portion of unlabeled data to annotate, without compromising model performance. Our empirical study, however, suggests that mainstream uncertainty-based and diversity-based active learning policies are not effective when applied in the 3D detection task, as they fail to balance the trade-off between point cloud informativeness and box-level annotation costs. To overcome this limitation, we jointly investigate three novel criteria in our framework CRB for point cloud acquisition - label conciseness, feature representativeness and \ngeometric balance, which hierarchically filters out the point clouds of redundant 3D bounding box labels, latent features and geometric characteristics (e.g., point cloud density) from the unlabeled sample pool and greedily selects informative ones with fewer objects to annotate. Our theoretical analysis demonstrates that the proposed criteria aligns the marginal distributions of the selected subset and the prior distributions of the unseen test set, and minimizes the upper bound of the generalization error. To validate the effectiveness and applicability of CRB, we conduct extensive experiments on the two benchmark 3D object detection datasets of KITTI and Waymo and examine both one-stage (i.e., Second) and two-stage 3D detector (i.e., PV-RCNN). Experiments evidence that the proposed approach outperforms existing active learning strategies and achieves fully supervised performance requiring $1\\%$ and $8\\%$ annotations of bounding boxes and point clouds, respectively. ", "pdf": "/pdf/cbdf54e075523d503dc1b31538bc70e029256b15.pdf", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "General Machine Learning (ie none of the above)", "paperhash": "luo|exploring_active_3d_object_detection_from_a_generalization_perspective", "supplementary_material": "/attachment/f51cb80f98f84e37de4a788ea173a0b9dd425ebf.zip", "_bibtex": "@inproceedings{\nluo2023exploring,\ntitle={Exploring Active 3D Object Detection from a Generalization Perspective},\nauthor={Yadan Luo and Zhuoxiao Chen and Zijian Wang and Xin Yu and Zi Huang and Mahsa Baktashmotlagh},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=2RwXVje1rAh}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2301.09249/code)"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279130318, "odate": 1664468100000, "details": {"replyCount": 19}}, {"id": "iOc57X9KM54", "original": "Y5Jg46KcU8", "number": 822, "cdate": 1663849889788, "mdate": null, "ddate": null, "tcdate": 1663849889788, "tmdate": 1677741643056, "tddate": null, "forum": "iOc57X9KM54", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Neuro-Symbolic Procedural Planning with Commonsense Prompting", "authorids": ["~Yujie_Lu1", "~Weixi_Feng2", "~Wanrong_Zhu1", "~Wenda_Xu1", "~Xin_Eric_Wang2", "~Miguel_Eckstein1", "~William_Yang_Wang2"], "authors": ["Yujie Lu", "Weixi Feng", "Wanrong Zhu", "Wenda Xu", "Xin Eric Wang", "Miguel Eckstein", "William Yang Wang"], "keywords": ["Procedural Planning", "Commonsense Knowledge", "Prompting", "Neuro-Symbolic"], "TL;DR": "We propose a neuro-symbolic procedural planner that elicits procedural planning knowledge from the large language models with commonsense-infused prompting. We achieve state-of-the-art performance on WikiHow and RobotHow.", "abstract": "Procedural planning aims to implement complex high-level goals by decomposition into simpler low-level steps. Although procedural planning is a basic skill set for humans in daily life, it remains a challenge for large language models (LLMs) that lack a deep understanding of the cause-effect relations in procedures. Previous methods require manual exemplars to acquire procedural planning knowledge from LLMs in the zero-shot setting. However, such elicited pre-trained knowledge in LLMs induces spurious correlations between goals and steps, which impair the model generalization to unseen tasks. In contrast, this paper proposes a neuro-symbolic procedural PLANner (PLAN) that elicits procedural planning knowledge from the LLMs with commonsense-infused prompting. To mitigate spurious goal-step correlations, we use symbolic program executors on the latent procedural representations to formalize prompts from commonsense knowledge bases as a causal intervention toward the Structural Causal Model. Both automatic and human evaluations on WikiHow and RobotHow show the superiority of PLAN on procedural planning without further training or manual exemplars.", "pdf": "/pdf/3af66a16e02e6ec05187d765b1d2da8cabae2719.pdf", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Applications (eg, speech processing, computer vision, NLP)", "paperhash": "lu|neurosymbolic_procedural_planning_with_commonsense_prompting", "supplementary_material": "/attachment/503b1c818fb6638d3adc2c7745afbc1fe7f29592.zip", "_bibtex": "@inproceedings{\nlu2023neurosymbolic,\ntitle={Neuro-Symbolic Procedural Planning with Commonsense Prompting},\nauthor={Yujie Lu and Weixi Feng and Wanrong Zhu and Wenda Xu and Xin Eric Wang and Miguel Eckstein and William Yang Wang},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=iOc57X9KM54}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279129962, "odate": 1664468100000, "details": {"replyCount": 34}}, {"id": "urF_CBK5XC0", "original": "WAkQaTktOGZ", "number": 811, "cdate": 1663849888573, "mdate": null, "ddate": null, "tcdate": 1663849888573, "tmdate": 1697935793634, "tddate": null, "forum": "urF_CBK5XC0", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Generative Augmented Flow Networks", "authorids": ["~Ling_Pan1", "~Dinghuai_Zhang1", "~Aaron_Courville3", "~Longbo_Huang2", "~Yoshua_Bengio1"], "authors": ["Ling Pan", "Dinghuai Zhang", "Aaron Courville", "Longbo Huang", "Yoshua Bengio"], "keywords": ["Generative Flow Networks (GFlowNets)", "Exploration"], "TL;DR": "We propose a novel GFlowNet learning framework to incorporate intermediate rewards represented by intrinsic motivation to improve exploration.", "abstract": "The Generative Flow Network is a probabilistic framework where an agent learns a stochastic policy for object generation, such that the probability of generating an object is proportional to a given reward function. Its effectiveness has been shown in discovering high-quality and diverse solutions, compared to reward-maximizing reinforcement learning-based methods. Nonetheless, GFlowNets only learn from rewards of the terminal states, which can limit its applicability. Indeed, intermediate rewards play a critical role in learning, for example from intrinsic motivation to provide intermediate feedback even in particularly challenging sparse reward tasks. Inspired by this, we propose Generative Augmented Flow Networks (GAFlowNets), a novel learning framework to incorporate intermediate rewards into GFlowNets. We specify intermediate rewards by intrinsic motivation to tackle the exploration problem in sparse reward environments. GAFlowNets can leverage edge-based and state-based intrinsic rewards in a joint way to improve exploration. Based on extensive experiments on the GridWorld task, we demonstrate the effectiveness and efficiency of GAFlowNet in terms of convergence, performance, and diversity of solutions. We further show that GAFlowNet is scalable to a more complex and large-scale molecule generation domain, where it achieves consistent and significant performance improvement.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Probabilistic Methods (eg, variational inference, causal inference, Gaussian processes)", "paperhash": "pan|generative_augmented_flow_networks", "pdf": "/pdf/6f7969e92eef7ad5bb4561e7dbd141decf138128.pdf", "_bibtex": "@inproceedings{\npan2023generative,\ntitle={Generative Augmented Flow Networks},\nauthor={Ling Pan and Dinghuai Zhang and Aaron Courville and Longbo Huang and Yoshua Bengio},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=urF_CBK5XC0}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2210.03308/code)"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279129389, "odate": 1664468100000, "details": {"replyCount": 18}}, {"id": "rvsbw2YthH_", "original": "HqQPLKJPW2", "number": 788, "cdate": 1663849885581, "mdate": null, "ddate": null, "tcdate": 1663849885581, "tmdate": 1677621520241, "tddate": null, "forum": "rvsbw2YthH_", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "The Trade-off between Universality and Label Efficiency of Representations from Contrastive Learning", "authorids": ["~Zhenmei_Shi1", "~Jiefeng_Chen2", "~Kunyang_Li1", "~Jayaram_Raghuram1", "~Xi_Wu1", "~Yingyu_Liang1", "~Somesh_Jha1"], "authors": ["Zhenmei Shi", "Jiefeng Chen", "Kunyang Li", "Jayaram Raghuram", "Xi Wu", "Yingyu Liang", "Somesh Jha"], "keywords": ["Contrastive Learning", "Self-Supervised Learning", "Foundation Model", "Complexity"], "TL;DR": "We focus on contrastive learning and systematically study a trade-off between label efficiency and universality both empirically and theoretically.", "abstract": "Pre-training representations (a.k.a. foundation models) has recently become a prevalent learning paradigm, where one first pre-trains a representation using large-scale unlabeled data, and then learns simple predictors on top of the representation using small labeled data from the downstream tasks. There are two key desiderata for the representation: label efficiency (the ability to learn an accurate classifier on top of the representation with a small amount of labeled data) and universality (usefulness across a wide range of downstream tasks). In this paper, we focus on one of the most popular instantiations of this paradigm: contrastive learning with linear probing, i.e., learning a linear predictor on the representation pre-trained by contrastive learning. We show that there exists a trade-off between the two desiderata so that one may not be able to achieve both simultaneously. \nSpecifically, we provide analysis using a theoretical data model and show that,  while more diverse pre-training data result in more diverse features for different tasks (improving universality), it puts less emphasis on task-specific features, giving rise to larger sample complexity for down-stream supervised tasks, and thus worse prediction performance. Guided by this analysis, we propose a contrastive regularization method to improve the trade-off. We validate our analysis and method empirically with systematic experiments using real-world datasets and foundation models.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "paperhash": "shi|the_tradeoff_between_universality_and_label_efficiency_of_representations_from_contrastive_learning", "pdf": "/pdf/043603199adc5b3a50a0bd4a9a36f0faea6f3b13.pdf", "supplementary_material": "/attachment/2f581784186d9fa1b9570393ac7665f9443bc51b.zip", "Please_choose_the_closest_area_that_your_submission_falls_into": "Unsupervised and Self-supervised learning", "_bibtex": "@inproceedings{\nshi2023the,\ntitle={The Trade-off between Universality and Label Efficiency of Representations from Contrastive Learning},\nauthor={Zhenmei Shi and Jiefeng Chen and Kunyang Li and Jayaram Raghuram and Xi Wu and Yingyu Liang and Somesh Jha},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=rvsbw2YthH_}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279127986, "odate": 1664468100000, "details": {"replyCount": 16}}, {"id": "FUORz1tG8Og", "original": "RDHxXMF3vMy", "number": 761, "cdate": 1663849882534, "mdate": null, "ddate": null, "tcdate": 1663849882534, "tmdate": 1677632295593, "tddate": null, "forum": "FUORz1tG8Og", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "CROM: Continuous Reduced-Order Modeling of PDEs Using Implicit Neural Representations", "authorids": ["~Peter_Yichen_Chen1", "~Jinxu_Xiang1", "~Dong_Heon_Cho2", "~Yue_Chang1", "~G_A_Pershing1", "~Henrique_Teles_Maia1", "~Maurizio_M_Chiaramonte1", "~Kevin_Thomas_Carlberg1", "~Eitan_Grinspun3"], "authors": ["Peter Yichen Chen", "Jinxu Xiang", "Dong Heon Cho", "Yue Chang", "G A Pershing", "Henrique Teles Maia", "Maurizio M Chiaramonte", "Kevin Thomas Carlberg", "Eitan Grinspun"], "keywords": ["PDE", "implicit neural representation", "neural field", "latent space traversal", "reduced-order modeling", "numerical methods"], "TL;DR": "We accelerate PDE solvers via rapid latent space traversal of continuous vector fields leveraging implicit neural representations.", "abstract": "The long runtime of high-fidelity partial differential equation (PDE) solvers makes them unsuitable for time-critical applications. We propose to accelerate PDE solvers using reduced-order modeling (ROM). Whereas prior ROM approaches reduce the dimensionality of discretized vector fields, our continuous reduced-order modeling (CROM) approach builds a low-dimensional embedding of the continuous vector fields themselves, not their discretization. We represent this reduced manifold using continuously differentiable neural fields, which may train on any and all available numerical solutions of the continuous system, even when they are obtained using diverse methods or discretizations. We validate our approach on an extensive range of PDEs with training data from voxel grids, meshes, and point clouds. Compared to prior discretization-dependent ROM methods, such as linear subspace proper orthogonal decomposition (POD) and nonlinear manifold neural-network-based autoencoders, CROM features higher accuracy, lower memory consumption, dynamically adaptive resolutions, and applicability to any discretization. For equal latent space dimension, CROM exhibits 79$\\times$ and 49$\\times$ better accuracy, and 39$\\times$ and 132$\\times$ smaller memory footprint, than POD and autoencoder methods, respectively. Experiments demonstrate 109$\\times$ and 89$\\times$ wall-clock speedups over unreduced models on CPUs and GPUs, respectively. Videos and codes are available on the project page: https://crom-pde.github.io", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "paperhash": "chen|crom_continuous_reducedorder_modeling_of_pdes_using_implicit_neural_representations", "pdf": "/pdf/0b88dbf1d08790a512a587e20d57a19dea822933.pdf", "supplementary_material": "/attachment/41475a8caf3c6970b181a03a01741218f62703b3.zip", "Please_choose_the_closest_area_that_your_submission_falls_into": "Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )", "_bibtex": "@inproceedings{\nchen2023crom,\ntitle={{CROM}: Continuous Reduced-Order Modeling of {PDE}s Using Implicit Neural Representations},\nauthor={Peter Yichen Chen and Jinxu Xiang and Dong Heon Cho and Yue Chang and G A Pershing and Henrique Teles Maia and Maurizio M Chiaramonte and Kevin Thomas Carlberg and Eitan Grinspun},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=FUORz1tG8Og}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279126565, "odate": 1664468100000, "details": {"replyCount": 14}}, {"id": "G2Q2Mh3avow", "original": "VGOh5fWm8X", "number": 748, "cdate": 1663849880965, "mdate": null, "ddate": null, "tcdate": 1663849880965, "tmdate": 1697935800490, "tddate": null, "forum": "G2Q2Mh3avow", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Socratic Models: Composing Zero-Shot Multimodal Reasoning with Language", "authorids": ["~Andy_Zeng3", "~Maria_Attarian1", "~brian_ichter1", "~Krzysztof_Marcin_Choromanski1", "~Adrian_Wong1", "swelker@google.com", "~Federico_Tombari1", "aveek@google.com", "~Michael_S_Ryoo1", "~Vikas_Sindhwani1", "johnnylee@google.com", "~Vincent_Vanhoucke1", "~Pete_Florence1"], "authors": ["Andy Zeng", "Maria Attarian", "brian ichter", "Krzysztof Marcin Choromanski", "Adrian Wong", "Stefan Welker", "Federico Tombari", "Aveek Purohit", "Michael S Ryoo", "Vikas Sindhwani", "Johnny Lee", "Vincent Vanhoucke", "Pete Florence"], "keywords": ["prompt engineering", "multimodal applications", "visual language models", "large language models", "commonsense reasoning"], "TL;DR": "We present a modular class of systems in which multiple pretrained models may be composed zero-shot via multimodal-informed prompt engineering to capture new multimodal capabilities, without additional finetuning.", "abstract": "We investigate how multimodal prompt engineering can use language as the intermediate representation to combine complementary knowledge from different pretrained (potentially multimodal) language models for a variety of tasks. This approach is both distinct from and complementary to the dominant paradigm of joint multimodal training. It also recalls a traditional systems-building view as in classical NLP pipelines, but with prompting large pretrained multimodal models. We refer to these as Socratic Models (SMs): a modular class of systems in which multiple pretrained models may be composed zero-shot via multimodal-informed prompting to capture new multimodal capabilities, without additional finetuning. We show that these systems provide competitive state-of-the-art performance for zero-shot image captioning and video-to-text retrieval, and also enable new applications such as (i) answering free-form questions about egocentric video, (ii) engaging in multimodal assistive dialogue with people (e.g., for cooking recipes), and (iii) robot perception and planning. We hope this work provides (a) results for stronger zero-shot baseline performance with analysis also highlighting their limitations, (b) new perspectives for building multimodal systems powered by large pretrained models, and (c) practical application advantages in certain regimes limited by data scarcity, training compute, or model access.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "paperhash": "zeng|socratic_models_composing_zeroshot_multimodal_reasoning_with_language", "pdf": "/pdf/92b6e024f8a9e971e8041aa14e06de2802245730.pdf", "Please_choose_the_closest_area_that_your_submission_falls_into": "Applications (eg, speech processing, computer vision, NLP)", "_bibtex": "@inproceedings{\nzeng2023socratic,\ntitle={Socratic Models: Composing Zero-Shot Multimodal Reasoning with Language},\nauthor={Andy Zeng and Maria Attarian and brian ichter and Krzysztof Marcin Choromanski and Adrian Wong and Stefan Welker and Federico Tombari and Aveek Purohit and Michael S Ryoo and Vikas Sindhwani and Johnny Lee and Vincent Vanhoucke and Pete Florence},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=G2Q2Mh3avow}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 3 code implementations](https://www.catalyzex.com/paper/arxiv:2204.00598/code)"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279125732, "odate": 1664468100000, "details": {"replyCount": 13}}, {"id": "Bo7eeXm6An8", "original": "grVbSRF4POL", "number": 744, "cdate": 1663849880481, "mdate": null, "ddate": null, "tcdate": 1663849880481, "tmdate": 1697935800479, "tddate": null, "forum": "Bo7eeXm6An8", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Multi-lingual Evaluation of Code Generation Models", "authorids": ["~Ben_Athiwaratkun1", "~Sanjay_Krishna_Gouda1", "~Zijian_Wang1", "~Xiaopeng_Li1", "tiayuche@amazon.com", "~Ming_Tan2", "~Wasi_Uddin_Ahmad1", "~Shiqi_Wang2", "~Qing_Sun2", "~Mingyue_Shang1", "~Sujan_Kumar_Gonugondla1", "~Hantian_Ding1", "~Varun_Kumar3", "~Nathan_Fulton2", "~Arash_Farahani1", "~Siddhartha_Jain1", "~Robert_Giaquinto1", "~Haifeng_Qian1", "~Murali_Krishna_Ramanathan1", "~Ramesh_Nallapati1", "~Baishakhi_Ray2", "~Parminder_Bhatia1", "sudipta@amazon.com", "~Dan_Roth3", "~Bing_Xiang2"], "authors": ["Ben Athiwaratkun", "Sanjay Krishna Gouda", "Zijian Wang", "Xiaopeng Li", "Yuchen Tian", "Ming Tan", "Wasi Uddin Ahmad", "Shiqi Wang", "Qing Sun", "Mingyue Shang", "Sujan Kumar Gonugondla", "Hantian Ding", "Varun Kumar", "Nathan Fulton", "Arash Farahani", "Siddhartha Jain", "Robert Giaquinto", "Haifeng Qian", "Murali Krishna Ramanathan", "Ramesh Nallapati", "Baishakhi Ray", "Parminder Bhatia", "Sudipta Sengupta", "Dan Roth", "Bing Xiang"], "keywords": ["code generation", "execution-based evaluation", "test-based evaluation", "language models", "multi-lingual code generation benchmark", "code insertion", "code summarization", "robustness for code", "code translation", "zero-shot code translation", "multi-lingual", "mono-lingual", "language models."], "abstract": "We present two new benchmarks, MBXP and Multilingual HumanEval, designed to evaluate code completion models in over 10 programming languages. These datasets are generated using a conversion framework that transpiles prompts and test cases from the original MBPP and HumanEval datasets into the corresponding data in the target language. By using these benchmarks, we are able to assess the performance of code generation models in a multi-lingual fashion, and discovered generalization ability of language models on out-of-domain languages, advantages of multi-lingual models over mono-lingual, the ability of  few-shot prompting to teach the model new languages, and zero-shot translation abilities. In addition, we use our code generation model to perform large-scale bootstrapping to obtain synthetic canonical solutions in several languages, which can be used for other code-related evaluations such as code insertion, robustness, or summarization tasks.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Deep Learning and representational learning", "paperhash": "athiwaratkun|multilingual_evaluation_of_code_generation_models", "pdf": "/pdf/c2ba4659e44c45ec67969ec9a74097a37184ad62.pdf", "_bibtex": "@inproceedings{\nathiwaratkun2023multilingual,\ntitle={Multi-lingual Evaluation of Code Generation Models},\nauthor={Ben Athiwaratkun and Sanjay Krishna Gouda and Zijian Wang and Xiaopeng Li and Yuchen Tian and Ming Tan and Wasi Uddin Ahmad and Shiqi Wang and Qing Sun and Mingyue Shang and Sujan Kumar Gonugondla and Hantian Ding and Varun Kumar and Nathan Fulton and Arash Farahani and Siddhartha Jain and Robert Giaquinto and Haifeng Qian and Murali Krishna Ramanathan and Ramesh Nallapati and Baishakhi Ray and Parminder Bhatia and Sudipta Sengupta and Dan Roth and Bing Xiang},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=Bo7eeXm6An8}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 6 code implementations](https://www.catalyzex.com/paper/arxiv:2210.14868/code)"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279125573, "odate": 1664468100000, "details": {"replyCount": 11}}, {"id": "B_pCIsX8KL_", "original": "gQ8JUJfT2l3", "number": 743, "cdate": 1663849880362, "mdate": null, "ddate": null, "tcdate": 1663849880362, "tmdate": 1677632347807, "tddate": null, "forum": "B_pCIsX8KL_", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "GRACE-C: Generalized Rate Agnostic Causal Estimation via Constraints", "authorids": ["~Mohammadsajad_Abavisani1", "~David_Danks1", "~Sergey_Plis1"], "authors": ["Mohammadsajad Abavisani", "David Danks", "Sergey Plis"], "keywords": ["Causal structure learning", "causal learning", "graph theory", "brain imaging", "fMRI"], "TL;DR": "A novel method for causal structure discovery in undersampled time-series with three orders of magnitude speedup under the same theoretical guarantees.", "abstract": "Graphical structures estimated by causal learning algorithms from time series data can provide highly misleading causal information if the causal timescale of the generating process fails to match the measurement timescale of the data. Existing algorithms provide limited resources to respond to this challenge, and so researchers must either use models that they know are likely misleading, or else forego causal learning entirely. Existing methods face up-to-four distinct shortfalls, as they might a) require that the difference between causal and measurement timescales is known; b) only handle very small number of random variables when the timescale difference is unknown; c) only apply to pairs of variables (albeit with fewer assumptions about prior knowledge); or d) be unable to find a solution given statistical noise in the data. This paper aims to address these challenges. We present an approach that combines constraint programming with both theoretical insights into the problem structure and prior information about admissible causal interactions to achieve speed up of multiple orders of magnitude. The resulting system scales to significantly larger sets of random variables ($>100$) without knowledge of the timescale difference while maintaining  theoretical guarantees. This method is also robust to edge misidentification and can use parametric connection strengths, while optionally finding the optimal among many possible solutions.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "paperhash": "abavisani|gracec_generalized_rate_agnostic_causal_estimation_via_constraints", "pdf": "/pdf/c2afd6ed2baef8ba0d051c56c6a88ec4fdfd0cd9.pdf", "Please_choose_the_closest_area_that_your_submission_falls_into": "Probabilistic Methods (eg, variational inference, causal inference, Gaussian processes)", "_bibtex": "@inproceedings{\nabavisani2023gracec,\ntitle={{GRACE}-C: Generalized Rate Agnostic Causal Estimation via Constraints},\nauthor={Mohammadsajad Abavisani and David Danks and Sergey Plis},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=B_pCIsX8KL_}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279125259, "odate": 1664468100000, "details": {"replyCount": 16}}, {"id": "KwmPfARgOTD", "original": "6XtdxFzzeB", "number": 734, "cdate": 1663849879249, "mdate": null, "ddate": null, "tcdate": 1663849879249, "tmdate": 1697935802100, "tddate": null, "forum": "KwmPfARgOTD", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Equiformer: Equivariant Graph Attention Transformer for 3D Atomistic Graphs", "authorids": ["~Yi-Lun_Liao1", "~Tess_Smidt1"], "authors": ["Yi-Lun Liao", "Tess Smidt"], "keywords": ["equivariant neural networks", "graph neural networks", "computational physics", "transformer networks"], "TL;DR": "We propose an equivariant graph neural network based on Transformer networks and propose a novel attention mechanism, which improves upon self-attention in typical Transformers.", "abstract": "Despite their widespread success in various domains, Transformer networks have yet to perform well across datasets in the domain of 3D atomistic graphs such as molecules even when 3D-related inductive biases like translational invariance and rotational equivariance are considered. In this paper, we demonstrate that Transformers can generalize well to 3D atomistic graphs and present Equiformer, a graph neural network leveraging the strength of Transformer architectures and incorporating SE(3)/E(3)-equivariant features based on irreducible representations (irreps). First, we propose a simple and effective architecture by only replacing original operations in Transformers with their equivariant counterparts and including tensor products. Using equivariant operations enables encoding equivariant information in channels of irreps features without complicating graph structures. With minimal modifications to Transformers, this architecture has already achieved strong empirical results. Second, we propose a novel attention mechanism called equivariant graph attention, which improves upon typical attention in Transformers through replacing dot product attention with multi-layer perceptron attention and including non-linear message passing. With these two innovations, Equiformer achieves competitive results to previous models on QM9, MD17 and OC20 datasets.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )", "paperhash": "liao|equiformer_equivariant_graph_attention_transformer_for_3d_atomistic_graphs", "pdf": "/pdf/adc86be91e22b350b3f22fb21d5124250509a935.pdf", "_bibtex": "@inproceedings{\nliao2023equiformer,\ntitle={Equiformer: Equivariant Graph Attention Transformer for 3D Atomistic Graphs},\nauthor={Yi-Lun Liao and Tess Smidt},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=KwmPfARgOTD}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2206.11990/code)"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279124256, "odate": 1664468100000, "details": {"replyCount": 34}}, {"id": "CWmvjOEhgH-", "original": "RbXCu908Dy", "number": 719, "cdate": 1663849877417, "mdate": null, "ddate": null, "tcdate": 1663849877417, "tmdate": 1697935803647, "tddate": null, "forum": "CWmvjOEhgH-", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "MPCFORMER: FAST, PERFORMANT AND PRIVATE TRANSFORMER INFERENCE WITH MPC", "authorids": ["~Dacheng_Li1", "~Hongyi_Wang1", "~Rulin_Shao1", "~Han_Guo1", "~Eric_Xing1", "~Hao_Zhang2"], "authors": ["Dacheng Li", "Hongyi Wang", "Rulin Shao", "Han Guo", "Eric Xing", "Hao Zhang"], "keywords": ["Secure Multiparty Computation", "Privacy", "Machine Learning", "Transformer model"], "TL;DR": "We develop a framework that allows fast, performant, and private inference with MPC for Transformer models.", "abstract": "Enabling private inference is crucial for many cloud inference services that are based on Transformer models. However, existing private inference solutions can increase the inference latency by more than 60$\\times$ or significantly compromise the inference quality. In this paper, we design the framework MPCFORMER as a practical solution, using Secure Multi-Party Computation (MPC) and Knowledge Distillation (KD). Through extensive evaluations, we show that MPCFORMER significantly speeds up Transformer inference in MPC settings while achieving similar ML performance to the input model. On the IMDb dataset, it achieves similar performance to $\\text{BERT}_\\text{BASE}$, while being 5.3$\\times$ faster. On the GLUE benchmark, it achieves 97% performance of $\\text{BERT}_\\text{BASE}$ with a 2.2$\\times$ speedup. MPCFORMER remains effective with different trained Transformer weights such as $\\text{ROBERTA}_\\text{BASE}$ and larger models including $\\text{BERT}_\\text{LARGE}$. Code is available at https://github.com/MccRee177/MPCFormer.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)", "paperhash": "li|mpcformer_fast_performant_and_private_transformer_inference_with_mpc", "pdf": "/pdf/f2f107f5dbed42ef3523a9abb2677e2c00c61c31.pdf", "supplementary_material": "/attachment/8505517d4650b76652fe471fdd6e536b4160ddec.zip", "_bibtex": "@inproceedings{\nli2023mpcformer,\ntitle={{MPCFORMER}: {FAST}, {PERFORMANT} {AND} {PRIVATE} {TRANSFORMER} {INFERENCE} {WITH} {MPC}},\nauthor={Dacheng Li and Hongyi Wang and Rulin Shao and Han Guo and Eric Xing and Hao Zhang},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=CWmvjOEhgH-}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2211.01452/code)"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279120902, "odate": 1664468100000, "details": {"replyCount": 17}}, {"id": "qLOaeRvteqbx", "original": "ASMNqC5eGaE", "number": 715, "cdate": 1663849877060, "mdate": null, "ddate": null, "tcdate": 1663849877060, "tmdate": 1697935804375, "tddate": null, "forum": "qLOaeRvteqbx", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Disparate Impact in Differential Privacy from Gradient Misalignment", "authorids": ["~Maria_S._Esipova1", "~Atiyeh_Ashari_Ghomi1", "~Yaqiao_Luo2", "~Jesse_C_Cresswell1"], "authors": ["Maria S. Esipova", "Atiyeh Ashari Ghomi", "Yaqiao Luo", "Jesse C Cresswell"], "keywords": ["Differential privacy", "fairness", "privacy"], "TL;DR": "DPSGD can have unfair outcomes on protected groups because of direction errors caused by per-sample gradient clipping, but unfairness can be dramatically reduced with a global clipping technique.", "abstract": "As machine learning becomes more widespread throughout society, aspects including data privacy and fairness must be carefully considered, and are crucial for deployment in highly regulated industries. Unfortunately, the application of privacy enhancing technologies can worsen unfair tendencies in models. In particular, one of the most widely used techniques for private model training, differentially private stochastic gradient descent (DPSGD), frequently intensifies disparate impact on groups within data. In this work we study the fine-grained causes of unfairness in DPSGD and identify gradient misalignment due to inequitable gradient clipping as the most significant source. This observation leads us to a new method for reducing unfairness by preventing gradient misalignment in DPSGD.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "paperhash": "esipova|disparate_impact_in_differential_privacy_from_gradient_misalignment", "pdf": "/pdf/6101c980f75602f74261af8068d5b04eb74e1476.pdf", "supplementary_material": "/attachment/183a34edf3b3ad187c2311e607bb2b9298d34328.zip", "Please_choose_the_closest_area_that_your_submission_falls_into": "Social Aspects of Machine Learning (eg, AI safety, fairness, privacy, interpretability, human-AI interaction, ethics)", "_bibtex": "@inproceedings{\nesipova2023disparate,\ntitle={Disparate Impact in Differential Privacy from Gradient Misalignment},\nauthor={Maria S. Esipova and Atiyeh Ashari Ghomi and Yaqiao Luo and Jesse C Cresswell},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=qLOaeRvteqbx}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2206.07737/code)"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279120463, "odate": 1664468100000, "details": {"replyCount": 17}}, {"id": "cp5PvcI6w8_", "original": "JWq4_fVz18w", "number": 706, "cdate": 1663849875964, "mdate": null, "ddate": null, "tcdate": 1663849875964, "tmdate": 1677760171517, "tddate": null, "forum": "cp5PvcI6w8_", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "TabPFN: A Transformer That Solves Small Tabular Classification Problems in a Second", "authorids": ["~Noah_Hollmann1", "~Samuel_M\u00fcller1", "~Katharina_Eggensperger1", "~Frank_Hutter1"], "authors": ["Noah Hollmann", "Samuel M\u00fcller", "Katharina Eggensperger", "Frank Hutter"], "keywords": ["Tabular Data", "AutoML", "Green AI", "Bayesian prediction", "Causal Reasoning", "Real-time Machine Learning"], "TL;DR": "We present TabPFN, a trained Transformer that learned to solve small tabular data classification problems at SOTA level in less than a second by training on synthetic data generated by integrating principles from causal reasoning and simplicity. ", "abstract": "We present TabPFN, a trained Transformer that can do supervised classification for small tabular datasets in less than a second, needs no hyperparameter tuning and is competitive with state-of-the-art classification methods.\nTabPFN is fully entailed in the weights of our network, which accepts training and test samples as a set-valued input and yields predictions for the entire test set in a single forward pass.\nTabPFN is a Prior-Data Fitted Network (PFN) and is trained offline once, to approximate Bayesian inference on synthetic datasets drawn from our prior.\nThis prior incorporates ideas from causal reasoning: It entails a large space of structural causal models with a preference for simple structures.\nOn the $18$ datasets in the OpenML-CC18 suite that contain up to 1000 training data points, up to 100 purely numerical features without missing values, and up to 10 classes, we show that our method clearly outperforms boosted trees and performs on par with complex state-of-the-art AutoML systems with up to $230\\times$ speedup.\nThis increases to a $5\\,700\\times$ speedup when using a GPU. We also validate these results on an additional 67 small numerical datasets from OpenML.\nWe provide all our code, the trained TabPFN, an interactive browser demo and a Colab notebook at https://github.com/automl/TabPFN.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Deep Learning and representational learning", "paperhash": "hollmann|tabpfn_a_transformer_that_solves_small_tabular_classification_problems_in_a_second", "pdf": "/pdf/a14bada70718d8e2f05879f7f5dd162a0adbe28c.pdf", "_bibtex": "@inproceedings{\nhollmann2023tabpfn,\ntitle={Tab{PFN}: A Transformer That Solves Small Tabular Classification Problems in a Second},\nauthor={Noah Hollmann and Samuel M{\\\"u}ller and Katharina Eggensperger and Frank Hutter},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=cp5PvcI6w8_}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference", "supplementary_material": "/attachment/a107af382e892457e4ae320cf7c780ca3b07610f.zip"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279118183, "odate": 1664468100000, "details": {"replyCount": 24}}, {"id": "SJ1kSyO2jwu", "original": "1pqHnTwBdZn", "number": 698, "cdate": 1663849875127, "mdate": null, "ddate": null, "tcdate": 1663849875127, "tmdate": 1697935805728, "tddate": null, "forum": "SJ1kSyO2jwu", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Human Motion Diffusion Model", "authorids": ["~Guy_Tevet1", "~Sigal_Raab1", "~Brian_Gordon1", "~Yoni_Shafir1", "~Daniel_Cohen-or2", "~Amit_Haim_Bermano2"], "authors": ["Guy Tevet", "Sigal Raab", "Brian Gordon", "Yoni Shafir", "Daniel Cohen-or", "Amit Haim Bermano"], "keywords": [], "abstract": "Natural and expressive human motion generation is the holy grail of computer animation.\nIt is a challenging task, due to the diversity of possible motion, human perceptual sensitivity to it, and the difficulty of accurately describing it. Therefore, current generative solutions are either low-quality or limited in expressiveness. \nDiffusion models are promising candidates for the human motion domain since they\nhave already shown remarkable generative capabilities in other domains, and their many-to-many nature. \nIn this paper, we introduce Motion Diffusion Model (MDM), a carefully adapted classifier-free diffusion-based generative model for human motion data.  MDM is transformer-based, combining insights from motion generation literature. \nA notable design-choice is that it predicts the sample itself rather than the noise in each step to facilitate the use of established geometric losses on the locations and velocities of the motion, such as the foot contact loss. As we demonstrate, MDM is a generic approach, enabling different modes of conditioning, and different generation tasks. We show that our model is trained with lightweight resources and yet achieves state-of-the-art results on leading benchmarks for text-to-motion, action-to-motion, and unconditioned motion generation. ", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Applications (eg, speech processing, computer vision, NLP)", "paperhash": "tevet|human_motion_diffusion_model", "pdf": "/pdf/f0e30bdff6d93fdd5a01526aaea18c2fec384fc0.pdf", "supplementary_material": "/attachment/74f8649e23bb80a0a4b2c910705fd1764e157648.zip", "_bibtex": "@inproceedings{\ntevet2023human,\ntitle={Human Motion Diffusion Model},\nauthor={Guy Tevet and Sigal Raab and Brian Gordon and Yoni Shafir and Daniel Cohen-or and Amit Haim Bermano},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=SJ1kSyO2jwu}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 3 code implementations](https://www.catalyzex.com/paper/arxiv:2209.14916/code)"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279117832, "odate": 1664468100000, "details": {"replyCount": 17}}, {"id": "CsKwavjr7A", "original": "qTKaLmcW3M", "number": 606, "cdate": 1663849867076, "mdate": null, "ddate": null, "tcdate": 1663849867076, "tmdate": 1697935811820, "tddate": null, "forum": "CsKwavjr7A", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Visual Recognition with Deep Nearest Centroids", "authorids": ["~Wenguan_Wang4", "~Cheng_Han1", "~Tianfei_Zhou2", "~Dongfang_Liu1"], "authors": ["Wenguan Wang", "Cheng Han", "Tianfei Zhou", "Dongfang Liu"], "keywords": ["Nearest centroids classifier", "Cased-base reasoning", "Image classification", "Image segmentation", "Explainable neural networks"], "abstract": "We devise deep nearest centroids (DNC), a conceptually elegant yet surprisingly effective network for large-scale visual recognition, by revisiting Nearest Centroids, one of the most classic and simple classifiers. Current deep models learn the classifier in a fully parametric manner, ignoring the latent data structure and lacking simplicity and explainability. DNC instead conducts nonparametric, case-based reasoning; it utilizes sub-centroids of training samples to describe class distributions and clearly explains the classification as the proximity of test data and the class sub-centroids in the feature space. Due to the distance-based nature, the network output dimensionality is flexible, and all the learnable parameters are only for data embedding. That means all the knowledge learnt for ImageNet classification can be completely transferred for pixel recognition learning, under the \u2018pre-training and fine-tuning\u2019 paradigm. Apart from its nested simplicity and intuitive decision-making mechanism, DNC can even possess ad-hoc explainability when the sub-centroids are selected as actual training images that humans can view and inspect. Compared with parametric counterparts, DNC performs better on image classification (CIFAR-10, ImageNet) and greatly boots pixel recognition (ADE20K, Cityscapes), with improved transparency and fewer learnable parameters, using various network architectures (ResNet, Swin) and segmentation models (FCN, DeepLabV3, Swin). We feel this work brings fundamental insights into related fields. Our code is available at https://github.com/ChengHan111/DNC.", "pdf": "/pdf/cda95db26061bc6fad92b050d82b6ff54e19d475.pdf", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Deep Learning and representational learning", "paperhash": "wang|visual_recognition_with_deep_nearest_centroids", "_bibtex": "@inproceedings{\nwang2023visual,\ntitle={Visual Recognition with Deep Nearest Centroids},\nauthor={Wenguan Wang and Cheng Han and Tianfei Zhou and Dongfang Liu},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=CsKwavjr7A}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 3 code implementations](https://www.catalyzex.com/paper/arxiv:2209.07383/code)"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279113300, "odate": 1664468100000, "details": {"replyCount": 31}}, {"id": "B73niNjbPs", "original": "xpoR6Ke25g", "number": 584, "cdate": 1663849865203, "mdate": null, "ddate": null, "tcdate": 1663849865203, "tmdate": 1697935813737, "tddate": null, "forum": "B73niNjbPs", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Continuous PDE Dynamics Forecasting with Implicit Neural Representations", "authorids": ["~Yuan_Yin1", "~Matthieu_Kirchmeyer1", "~Jean-Yves_Franceschi1", "~Alain_Rakotomamonjy1", "~patrick_gallinari1"], "authors": ["Yuan Yin", "Matthieu Kirchmeyer", "Jean-Yves Franceschi", "Alain Rakotomamonjy", "patrick gallinari"], "keywords": ["spatiotemporal forecasting", "Partial Differential Equations", "PDEs", "Implicit Neural Representations", "INRs", "continuous models", "generalization", "dynamical systems", "physics"], "TL;DR": "We propose a continuous-time, continuous-space data-driven PDE forecasting model with extensive spatiotemporal extrapolation capabilities including generalization to unseen sparse meshes and resolutions.", "abstract": "Effective data-driven PDE forecasting methods often rely on fixed spatial and / or temporal discretizations. This raises limitations in real-world applications like weather prediction where flexible extrapolation at arbitrary spatiotemporal locations is required. We address this problem by introducing a new data-driven approach, DINo, that models a PDE's flow with continuous-time dynamics of spatially continuous functions. This is achieved by embedding spatial observations independently of their discretization via Implicit Neural Representations in a small latent space temporally driven by a learned ODE. This separate and flexible treatment of time and space makes DINo the first data-driven model to combine the following advantages. It extrapolates at arbitrary spatial and temporal locations; it can learn from sparse irregular grids or manifolds; at test time, it generalizes to new grids or resolutions. DINo outperforms alternative neural PDE forecasters in a variety of challenging generalization scenarios on representative PDE systems.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )", "paperhash": "yin|continuous_pde_dynamics_forecasting_with_implicit_neural_representations", "pdf": "/pdf/7870a5e000f8b6cb07adaf5eaf38552eecc48b6a.pdf", "_bibtex": "@inproceedings{\nyin2023continuous,\ntitle={Continuous {PDE} Dynamics Forecasting with Implicit Neural Representations},\nauthor={Yuan Yin and Matthieu Kirchmeyer and Jean-Yves Franceschi and Alain Rakotomamonjy and patrick gallinari},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=B73niNjbPs}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference", "supplementary_material": "/attachment/bf8ec3fb30847132318787051601182e5d15d563.zip", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2209.14855/code)"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279112234, "odate": 1664468100000, "details": {"replyCount": 21}}, {"id": "3Y5Uhf5KgGK", "original": "fpmzgBNNPCv", "number": 510, "cdate": 1663849857564, "mdate": null, "ddate": null, "tcdate": 1663849857564, "tmdate": 1677588798683, "tddate": null, "forum": "3Y5Uhf5KgGK", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "No Reason for No Supervision: Improved Generalization in Supervised Models", "authorids": ["~Mert_B\u00fclent_Sar\u0131y\u0131ld\u0131z1", "~Yannis_Kalantidis2", "~Karteek_Alahari1", "~Diane_Larlus1"], "authors": ["Mert B\u00fclent Sar\u0131y\u0131ld\u0131z", "Yannis Kalantidis", "Karteek Alahari", "Diane Larlus"], "keywords": ["supervised learning", "transfer learning", "representation learning"], "abstract": "We consider the problem of training a deep neural network on a given classification task, e.g., ImageNet-1K (IN1K), so that it excels at both the training task as well as at other (future) transfer tasks. These two seemingly contradictory properties impose a trade-off between improving the model\u2019s generalization and maintaining its performance on the original task. Models trained with self-supervised learning tend to generalize better than their supervised counterparts for transfer learning; yet, they still lag behind supervised models on IN1K. In this paper, we propose a supervised learning setup that leverages the best of both worlds. We extensively analyze supervised training using multi-scale crops for data augmentation and an expendable projector head, and reveal that the design of the projector allows us to control the trade-off between performance on the training task and transferability. We further replace the last layer of class weights with class prototypes computed on the fly using a memory bank and derive two models: t-ReX that achieves a new state of the art for transfer learning and outperforms top methods such as DINO and PAWS on IN1K, and t-ReX* that matches the highly optimized RSB-A1 model on IN1K while performing better on transfer tasks.\nCode and pretrained models: https://europe.naverlabs.com/t-rex", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Deep Learning and representational learning", "paperhash": "saryldz|no_reason_for_no_supervision_improved_generalization_in_supervised_models", "pdf": "/pdf/ebca9fb533c934341267ac07467bc1bb652f422e.pdf", "_bibtex": "@inproceedings{\nsar{\\i}y{\\i}ld{\\i}z2023no,\ntitle={No Reason for No Supervision: Improved Generalization in Supervised Models},\nauthor={Mert B{\\\"u}lent Sar{\\i}y{\\i}ld{\\i}z and Yannis Kalantidis and Karteek Alahari and Diane Larlus},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=3Y5Uhf5KgGK}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279108129, "odate": 1664468100000, "details": {"replyCount": 14}}, {"id": "g7U9jD_2CUr", "original": "S2gHPcwsDH6", "number": 503, "cdate": 1663849856847, "mdate": null, "ddate": null, "tcdate": 1663849856847, "tmdate": 1697935821437, "tddate": null, "forum": "g7U9jD_2CUr", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "EVA3D: Compositional 3D Human Generation from 2D Image Collections", "authorids": ["~Fangzhou_Hong1", "~Zhaoxi_Chen1", "~Yushi_LAN1", "~Liang_Pan2", "~Ziwei_Liu1"], "authors": ["Fangzhou Hong", "Zhaoxi Chen", "Yushi LAN", "Liang Pan", "Ziwei Liu"], "keywords": ["3D Human Generation", "Human NeRF", "Inverse Graphics"], "abstract": "Inverse graphics aims to recover 3D models from 2D observations. Utilizing differentiable rendering, recent 3D-aware generative models have shown impressive results of rigid object generation using 2D images. However, it remains challenging to generate articulated objects, like human bodies, due to their complexity and diversity in poses and appearances. In this work, we propose, EVA3D, an unconditional 3D human generative model learned from 2D image collections only. EVA3D can sample 3D humans with detailed geometry and render high-quality images (up to 512x256) without bells and whistles (e.g. super resolution). At the core of EVA3D is a compositional human NeRF representation, which divides the human body into local parts. Each part is represented by an individual volume. This compositional representation enables 1) inherent human priors, 2) adaptive allocation of network parameters, 3) efficient training and rendering. Moreover, to accommodate for the characteristics of sparse 2D human image collections (e.g. imbalanced pose distribution), we propose a pose-guided sampling strategy for better GAN learning. Extensive experiments validate that EVA3D achieves state-of-the-art 3D human generation performance regarding both geometry and texture quality. Notably, EVA3D demonstrates great potential and scalability to \"inverse-graphics\" diverse human bodies with a clean framework.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Generative models", "paperhash": "hong|eva3d_compositional_3d_human_generation_from_2d_image_collections", "TL;DR": "We propose EVA3D, a high-quality unconditional 3D human generative model learned from 2D image collections.", "pdf": "/pdf/554f7af511783002653244a77c3f8ac31ae45c7c.pdf", "supplementary_material": "/attachment/b66de03e8980bca410d7badcb5f49a558141273e.zip", "_bibtex": "@inproceedings{\nhong2023evad,\ntitle={{EVA}3D: Compositional 3D Human Generation from 2D Image Collections},\nauthor={Fangzhou Hong and Zhaoxi Chen and Yushi LAN and Liang Pan and Ziwei Liu},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=g7U9jD_2CUr}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2210.04888/code)"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279107430, "odate": 1664468100000, "details": {"replyCount": 9}}, {"id": "DSy8tP4WctmZ", "original": "1PZdjzk64aJ", "number": 495, "cdate": 1663849855994, "mdate": null, "ddate": null, "tcdate": 1663849855994, "tmdate": 1697935822260, "tddate": null, "forum": "DSy8tP4WctmZ", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Voxurf: Voxel-based Efficient and Accurate Neural Surface Reconstruction", "authorids": ["~Tong_Wu2", "~Jiaqi_Wang1", "~Xingang_Pan1", "~Xudong_XU1", "~Christian_Theobalt2", "~Ziwei_Liu1", "~Dahua_Lin1"], "authors": ["Tong Wu", "Jiaqi Wang", "Xingang Pan", "Xudong XU", "Christian Theobalt", "Ziwei Liu", "Dahua Lin"], "keywords": ["Surface Reconstruction", "Neural Radiance Field"], "abstract": "Neural surface reconstruction aims to reconstruct accurate 3D surfaces based on multi-view images. Previous methods based on neural volume rendering mostly train a fully implicit model with MLPs, which typically require hours of training for a single scene. Recent efforts explore the explicit volumetric representation to accelerate the optimization via memorizing significant information with learnable voxel grids. However, existing voxel-based methods often struggle in reconstructing fine-grained geometry, even when combined with an SDF-based volume rendering scheme. We reveal that this is because 1) the voxel grids tend to break the color-geometry dependency that facilitates fine-geometry learning, and 2) the under-constrained voxel grids lack spatial coherence and are vulnerable to local minima. In this work, we present Voxurf, a voxel-based surface reconstruction approach that is both efficient and accurate. Voxurf addresses the aforementioned issues via several key designs, including 1) a two-stage training procedure that attains a coherent coarse shape and recovers fine details successively, 2) a dual color network that maintains color-geometry dependency, and 3) a hierarchical geometry feature to encourage information propagation across voxels. Extensive experiments show that Voxurf achieves high efficiency and high quality at the same time. On the DTU benchmark, Voxurf achieves higher reconstruction quality with a 20x training speedup compared to previous fully implicit methods. Our code is publicly available at https://github.com/wutong16/Voxurf/.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Deep Learning and representational learning", "paperhash": "wu|voxurf_voxelbased_efficient_and_accurate_neural_surface_reconstruction", "TL;DR": "We present Voxurf, a voxel-based approach for efficient and accurate neural surface reconstruction.", "pdf": "/pdf/8385b49620c0d807cbd7621fce00e5a6302d95ef.pdf", "supplementary_material": "/attachment/babbd940967b424157f96e3f6a6ba4e961958b05.zip", "_bibtex": "@inproceedings{\nwu2023voxurf,\ntitle={Voxurf: Voxel-based Efficient and Accurate Neural Surface Reconstruction},\nauthor={Tong Wu and Jiaqi Wang and Xingang Pan and Xudong XU and Christian Theobalt and Ziwei Liu and Dahua Lin},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=DSy8tP4WctmZ}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 3 code implementations](https://www.catalyzex.com/paper/arxiv:2208.12697/code)"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279107024, "odate": 1664468100000, "details": {"replyCount": 11}}, {"id": "UkU05GOH7_6", "original": "nOjozy4TJ1I", "number": 449, "cdate": 1663849850874, "mdate": null, "ddate": null, "tcdate": 1663849850874, "tmdate": 1677592970796, "tddate": null, "forum": "UkU05GOH7_6", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Generating Diverse Cooperative Agents by Learning Incompatible Policies", "authorids": ["~Rujikorn_Charakorn1", "~Poramate_Manoonpong1", "~Nat_Dilokthanakul1"], "authors": ["Rujikorn Charakorn", "Poramate Manoonpong", "Nat Dilokthanakul"], "keywords": ["multi-agent systems", "cooperation", "collaboration", "reinforcement learning", "diversity", "robustness"], "TL;DR": "We show that incompatible poclies are not similar. LIPO generates diverse cooperative partners by learning a population of incompatible policies.", "abstract": "Training a robust cooperative agent requires diverse partner agents. However, obtaining those agents is difficult. Previous works aim to learn diverse behaviors by changing the state-action distribution of agents. But, without information about the task's goal, the diversified agents are not guided to find other important, albeit sub-optimal, solutions: the agents might learn only variations of the same solution. In this work, we propose to learn diverse behaviors via policy compatibility. Conceptually, policy compatibility measures whether policies of interest can coordinate effectively. We theoretically show that incompatible policies are not similar. Thus, policy compatibility\u2014which has been used exclusively as a measure of robustness\u2014can be used as a proxy for learning diverse behaviors. Then, we incorporate the proposed objective into a population-based training scheme to allow concurrent training of multiple agents. Additionally, we use state-action information to induce local variations of each policy. Empirically, the proposed method consistently discovers more solutions than baseline methods across various multi-goal cooperative environments. Finally, in multi-recipe Overcooked, we show that our method produces populations of behaviorally diverse agents, which enables generalist agents trained with such a population to be more robust.\n\nSee our project page at https://bit.ly/marl-lipo\n", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Reinforcement Learning (eg, decision and control, planning, hierarchical RL, robotics)", "paperhash": "charakorn|generating_diverse_cooperative_agents_by_learning_incompatible_policies", "pdf": "/pdf/ac9e4f47a8a7afc2d31fe69575bb97700dd88071.pdf", "supplementary_material": "/attachment/8a7836bf00c2ebc37033b5c24b64acc6cb8e4074.zip", "_bibtex": "@inproceedings{\ncharakorn2023generating,\ntitle={Generating Diverse Cooperative Agents by Learning Incompatible Policies},\nauthor={Rujikorn Charakorn and Poramate Manoonpong and Nat Dilokthanakul},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=UkU05GOH7_6}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279100427, "odate": 1664468100000, "details": {"replyCount": 13}}, {"id": "KbYevcLjnc", "original": "Q1Aoj9qNkj", "number": 429, "cdate": 1663849848707, "mdate": null, "ddate": null, "tcdate": 1663849848707, "tmdate": 1677746565233, "tddate": null, "forum": "KbYevcLjnc", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "PEER: A Collaborative Language Model", "authorids": ["~Timo_Schick1", "~Jane_A._Yu1", "~Zhengbao_Jiang2", "~Fabio_Petroni2", "~Patrick_Lewis2", "~Gautier_Izacard1", "qingfeiyou@fb.com", "~Christoforos_Nalmpantis1", "~Edouard_Grave1", "~Sebastian_Riedel1"], "authors": ["Timo Schick", "Jane A. Yu", "Zhengbao Jiang", "Fabio Petroni", "Patrick Lewis", "Gautier Izacard", "Qingfei You", "Christoforos Nalmpantis", "Edouard Grave", "Sebastian Riedel"], "keywords": ["Language Models", "Controllability", "Prompting", "Zero-Shot Learning", "Editing"], "TL;DR": "We introduce PEER, a language model trained to mimic the collaborative editing process by which humans often write text.", "abstract": "Textual content is often the output of a collaborative writing process: We start with an initial draft, ask for suggestions, and repeatedly make changes.\nAgnostic of this process, today\u2019s language models are trained to generate only the final result. As a consequence, they lack several abilities crucial for collaborative writing: They are unable to update existing texts, difficult to control and incapable of verbally planning or explaining their actions.\nTo address these shortcomings, we introduce PEER, a collaborative language model that is trained to imitate the entire writing process itself. PEER can write drafts, add suggestions, propose edits and provide explanations for its actions. Crucially, we train multiple instances of PEER able to infill various parts of the writing process, enabling the use of self-training techniques for increasing the quality, amount and diversity of training data. This unlocks PEER's full potential by making it applicable in domains for which no edit histories are available and improving its ability to follow instructions, to write useful comments, and to explain its actions. We show that PEER achieves strong performance across various domains and editing tasks.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "paperhash": "schick|peer_a_collaborative_language_model", "pdf": "/pdf/e50eaf58c25ddb7ed0ec57bcc796b131b7046154.pdf", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Applications (eg, speech processing, computer vision, NLP)", "_bibtex": "@inproceedings{\nschick2023peer,\ntitle={{PEER}: A Collaborative Language Model},\nauthor={Timo Schick and Jane A. Yu and Zhengbao Jiang and Fabio Petroni and Patrick Lewis and Gautier Izacard and Qingfei You and Christoforos Nalmpantis and Edouard Grave and Sebastian Riedel},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=KbYevcLjnc}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279098327, "odate": 1664468100000, "details": {"replyCount": 9}}, {"id": "GMRodZ8OlVr", "original": "Fcwxmib2vF8", "number": 420, "cdate": 1663849847329, "mdate": null, "ddate": null, "tcdate": 1663849847329, "tmdate": 1677516394074, "tddate": null, "forum": "GMRodZ8OlVr", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "ISS: Image as Stepping Stone for Text-Guided 3D Shape Generation", "authorids": ["~Zhengzhe_Liu1", "~Peng_Dai3", "~Ruihui_Li1", "~XIAOJUAN_QI2", "~Chi-Wing_Fu2"], "authors": ["Zhengzhe Liu", "Peng Dai", "Ruihui Li", "XIAOJUAN QI", "Chi-Wing Fu"], "keywords": ["Text", "3D shape", "CLIP", "differentiable rendering"], "abstract": "Text-guided 3D shape generation remains challenging due to the absence of large paired text-shape dataset, the substantial semantic gap between these two modalities, and the structural complexity of 3D shapes. This paper presents a new framework called Image as Stepping Stone (ISS) for the task by introducing 2D image as a stepping stone to connect the two modalities and to eliminate the need for paired text-shape data. Our key contribution is a two-stage feature-space-alignment approach that maps CLIP features to shapes by harnessing a pre-trained single-view reconstruction (SVR) model with multi-view supervisions: first map the CLIP image feature to the detail-rich shape space in the SVR model, then map the CLIP text feature to the shape space and optimize the mapping by encouraging CLIP consistency between the input text and the rendered images. Further, we formulate a textguided shape stylization module to dress up the output shapes with novel structures and textures. Beyond existing works on 3D shape generation from text, our new approach is general for creating shapes in a broad range of categories, without requiring paired text-shape data. Experimental results manifest that our approach outperforms the state-of-the-arts and our baselines in terms of fidelity and consistency with text. Further, our approach can stylize the generated shapes with both realistic and fantasy structures and textures. Codes are available at https://github.com/liuzhengzhe/ISS-Image-as-Stepping-Stone-for-Text-Guided-3D-Shape-Generation.", "pdf": "/pdf/ed35cc59666dab7baf7735f5b066cdda25ff209c.pdf", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "supplementary_material": "/attachment/cd376a997dab9aeecf90bb23091d4829c0f003a8.zip", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Applications (eg, speech processing, computer vision, NLP)", "paperhash": "liu|iss_image_as_stepping_stone_for_textguided_3d_shape_generation", "TL;DR": "An efficient text-guided 3D shape generation framework without needing paired text and shape. ", "_bibtex": "@inproceedings{\nliu2023iss,\ntitle={{ISS}: Image as Stepping Stone for Text-Guided 3D Shape Generation},\nauthor={Zhengzhe Liu and Peng Dai and Ruihui Li and XIAOJUAN QI and Chi-Wing Fu},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=GMRodZ8OlVr}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279098110, "odate": 1664468100000, "details": {"replyCount": 16}}, {"id": "1C_kSW1-k0", "original": "yOoqiJQHS4B", "number": 409, "cdate": 1663849845958, "mdate": null, "ddate": null, "tcdate": 1663849845958, "tmdate": 1677703100194, "tddate": null, "forum": "1C_kSW1-k0", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "STREET: A MULTI-TASK STRUCTURED REASONING AND EXPLANATION BENCHMARK", "authorids": ["~Danilo_Neves_Ribeiro1", "~Shen_Wang2", "~Xiaofei_Ma1", "~Henghui_Zhu1", "~Rui_Dong1", "~Deguang_Kong1", "~Juliette_Burger1", "~Anjelica_Ramos1", "~zhiheng_huang4", "~William_Yang_Wang2", "~George_Karypis1", "~Bing_Xiang2", "~Dan_Roth3"], "authors": ["Danilo Neves Ribeiro", "Shen Wang", "Xiaofei Ma", "Henghui Zhu", "Rui Dong", "Deguang Kong", "Juliette Burger", "Anjelica Ramos", "zhiheng huang", "William Yang Wang", "George Karypis", "Bing Xiang", "Dan Roth"], "keywords": ["natural language understanding", "question answering", "structured explanations", "soft reasoning", "dataset"], "abstract": "We introduce STREET, a unified multi-task and multi-domain natural language reasoning and explanation benchmark. Unlike most existing question-answering (QA) datasets, we expect models to not only answer questions, but also produce step-by-step structured explanations describing how premises in the question are used to produce intermediate conclusions that can prove the correctness of a certain answer. We perform extensive evaluation with popular language models such as few-shot prompting GPT-3 and fine-tuned T5. We find that these models still lag behind human performance when producing such structured reasoning steps. We believe this work will provide a way for the community to better train and test systems on multi-step reasoning and explanations in natural language.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "paperhash": "ribeiro|street_a_multitask_structured_reasoning_and_explanation_benchmark", "TL;DR": "We introduce STREET, a unified multi-task and multi-domain natural language reasoning and explanation benchmark.", "pdf": "/pdf/1b74d54ce93b0d4d1558e20806f96d4b743468ea.pdf", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Infrastructure (eg, datasets, competitions, implementations, libraries)", "_bibtex": "@inproceedings{\nribeiro2023street,\ntitle={{STREET}: A {MULTI}-{TASK} {STRUCTURED} {REASONING} {AND} {EXPLANATION} {BENCHMARK}},\nauthor={Danilo Neves Ribeiro and Shen Wang and Xiaofei Ma and Henghui Zhu and Rui Dong and Deguang Kong and Juliette Burger and Anjelica Ramos and zhiheng huang and William Yang Wang and George Karypis and Bing Xiang and Dan Roth},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=1C_kSW1-k0}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279097621, "odate": 1664468100000, "details": {"replyCount": 12}}, {"id": "y5W8tpojhtJ", "original": "MbVzgl5Mkjz", "number": 337, "cdate": 1663849838323, "mdate": null, "ddate": null, "tcdate": 1663849838323, "tmdate": 1677574788538, "tddate": null, "forum": "y5W8tpojhtJ", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Neural Collapse Inspired Feature-Classifier Alignment for Few-Shot Class-Incremental Learning", "authorids": ["~Yibo_Yang2", "~Haobo_Yuan1", "~Xiangtai_Li1", "~Zhouchen_Lin1", "~Philip_Torr1", "~Dacheng_Tao1"], "authors": ["Yibo Yang", "Haobo Yuan", "Xiangtai Li", "Zhouchen Lin", "Philip Torr", "Dacheng Tao"], "keywords": ["few-shot class-incremental learning", "neural collapse"], "TL;DR": "An interpretable solution inspired by neural collapse for few-shot class-incremental learning", "abstract": "Few-shot class-incremental learning (FSCIL) has been a challenging problem as only a few training samples are accessible for each novel class in the new sessions. Finetuning the backbone or adjusting the classifier prototypes trained in the prior sessions would inevitably cause a misalignment between the feature and classifier of old classes, which explains the well-known catastrophic forgetting problem. In this paper, we deal with this misalignment dilemma in FSCIL inspired by the recently discovered phenomenon named neural collapse, which reveals that the last-layer features of the same class will collapse into a vertex, and the vertices of all classes are aligned with the classifier prototypes, which are formed as a simplex equiangular tight frame (ETF). It corresponds to an optimal geometric structure for classification due to the maximized Fisher Discriminant Ratio. We propose a neural collapse inspired framework for FSCIL. A group of classifier prototypes are pre-assigned as a simplex ETF for the whole label space, including the base session and all the incremental sessions. During training, the classifier prototypes are not learnable, and we adopt a novel loss function that drives the features into their corresponding prototypes. Theoretical analysis shows that our method holds the neural collapse optimality and does not break the feature-classifier alignment in an incremental fashion. Experiments on the miniImageNet, CUB-200, and CIFAR-100 datasets demonstrate that our proposed framework outperforms the state-of-the-art performances. Code address: https://github.com/NeuralCollapseApplications/FSCIL ", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Deep Learning and representational learning", "paperhash": "yang|neural_collapse_inspired_featureclassifier_alignment_for_fewshot_classincremental_learning", "pdf": "/pdf/0ffbc09764bcd3fed340d49d2404429bae5277f5.pdf", "_bibtex": "@inproceedings{\nyang2023neural,\ntitle={Neural Collapse Inspired Feature-Classifier Alignment for Few-Shot Class-Incremental Learning},\nauthor={Yibo Yang and Haobo Yuan and Xiangtai Li and Zhouchen Lin and Philip Torr and Dacheng Tao},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=y5W8tpojhtJ}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279094852, "odate": 1664468100000, "details": {"replyCount": 19}}, {"id": "WbxHAzkeQcn", "original": "TYYjM8ZBjU", "number": 320, "cdate": 1663849836215, "mdate": null, "ddate": null, "tcdate": 1663849836215, "tmdate": 1697935836943, "tddate": null, "forum": "WbxHAzkeQcn", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Neural Networks and the Chomsky Hierarchy", "authorids": ["~Gregoire_Deletang1", "~Anian_Ruoss1", "~Jordi_Grau-Moya2", "~Tim_Genewein1", "~Li_Kevin_Wenliang1", "~Elliot_Catt1", "~Chris_Cundy1", "~Marcus_Hutter1", "~Shane_Legg1", "~Joel_Veness2", "~Pedro_A_Ortega1"], "authors": ["Gregoire Deletang", "Anian Ruoss", "Jordi Grau-Moya", "Tim Genewein", "Li Kevin Wenliang", "Elliot Catt", "Chris Cundy", "Marcus Hutter", "Shane Legg", "Joel Veness", "Pedro A Ortega"], "keywords": ["length generalization", "memory-augmented neural networks", "recurrent neural networks"], "abstract": "Reliable generalization lies at the heart of safe ML and AI. However, understanding when and how neural networks generalize remains one of the most important unsolved problems in the field. In this work, we conduct an extensive empirical study (20'910 models, 15 tasks) to investigate whether insights from the theory of computation can predict the limits of neural network generalization in practice. We demonstrate that grouping tasks according to the Chomsky hierarchy allows us to forecast whether certain architectures will be able to generalize to out-of-distribution inputs. This includes negative results where even extensive amounts of data and training time never lead to any non-trivial generalization, despite models having sufficient capacity to fit the training data perfectly. Our results show that, for our subset of tasks, RNNs and Transformers fail to generalize on non-regular tasks, LSTMs can solve regular and counter-language tasks, and only networks augmented with structured memory (such as a stack or memory tape) can successfully generalize on context-free and context-sensitive tasks.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "paperhash": "deletang|neural_networks_and_the_chomsky_hierarchy", "TL;DR": "Large-scale empirical study to determine the computational complexity class of a number of neural network architectures, which allows forecasting limitations on generalization capabilities.", "pdf": "/pdf/e3f8464e2b508de864e993df3d7e0162aa25d7ff.pdf", "supplementary_material": "/attachment/272b6261239e64c09fa9d924fea847dc30baf41f.zip", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Deep Learning and representational learning", "_bibtex": "@inproceedings{\ndeletang2023neural,\ntitle={Neural Networks and the Chomsky Hierarchy},\nauthor={Gregoire Deletang and Anian Ruoss and Jordi Grau-Moya and Tim Genewein and Li Kevin Wenliang and Elliot Catt and Chris Cundy and Marcus Hutter and Shane Legg and Joel Veness and Pedro A Ortega},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=WbxHAzkeQcn}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2207.02098/code)"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279093898, "odate": 1664468100000, "details": {"replyCount": 17}}, {"id": "D1Iqfm7WTkk", "original": "Is50w_OpRw", "number": 318, "cdate": 1663849835984, "mdate": null, "ddate": null, "tcdate": 1663849835984, "tmdate": 1677574895371, "tddate": null, "forum": "D1Iqfm7WTkk", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Neural ePDOs: Spatially Adaptive Equivariant Partial Differential Operator Based  Networks", "authorids": ["~Lingshen_He1", "~Yuxuan_Chen2", "~Zhengyang_Shen3", "~Yibo_Yang2", "~Zhouchen_Lin1"], "authors": ["Lingshen He", "Yuxuan Chen", "Zhengyang Shen", "Yibo Yang", "Zhouchen Lin"], "keywords": ["Equivariance", "Partial differential operators"], "TL;DR": "We propose a novel spatial adaptive equivariant PDOs-based network which achieves superior performance than previous works. ", "abstract": "Endowing deep learning models with symmetry priors can lead to a considerable performance improvement. As an interesting bridge between physics and deep learning, the equivariant partial differential operators (PDOs) have drawn much researchers' attention recently. However, to ensure the PDOs translation equivariance, previous works have to require coefficient matrices to be constant and spatially shared for their linearity, which could lead to the sub-optimal feature learning at each position. In this work, we propose a novel nonlinear PDOs scheme that is both spatially adaptive and translation equivariant. The coefficient matrices are obtained by local features through a generator rather than spatially shared. Besides, we establish a new theory on incorporating more equivariance like rotations for such PDOs. Based on our theoretical results, we efficiently implement the generator with an equivariant multilayer perceptron (EMLP). As such equivariant PDOs are generated by neural networks, we call them Neural ePDOs. In experiments, we show that our method can significantly improve previous works with smaller model size in various datasets. Especially, we achieve the state-of-the-art performance on the MNIST-rot dataset with only half parameters of the previous best model.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Deep Learning and representational learning", "paperhash": "he|neural_epdos_spatially_adaptive_equivariant_partial_differential_operator_based_networks", "pdf": "/pdf/c4b5cb80999f0dac523cd50129e5c768bdbbcaf9.pdf", "supplementary_material": "/attachment/2cf284dafe3be848e309cb9aa5d9f95414e91523.zip", "_bibtex": "@inproceedings{\nhe2023neural,\ntitle={Neural e{PDO}s: Spatially Adaptive Equivariant Partial Differential Operator Based  Networks},\nauthor={Lingshen He and Yuxuan Chen and Zhengyang Shen and Yibo Yang and Zhouchen Lin},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=D1Iqfm7WTkk}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279093892, "odate": 1664468100000, "details": {"replyCount": 15}}, {"id": "NAQvF08TcyG", "original": "UYZbDk6R2yM", "number": 317, "cdate": 1663849835866, "mdate": null, "ddate": null, "tcdate": 1663849835866, "tmdate": 1697935837291, "tddate": null, "forum": "NAQvF08TcyG", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "An Image is Worth One Word: Personalizing Text-to-Image Generation using Textual Inversion", "authorids": ["~Rinon_Gal1", "~Yuval_Alaluf1", "~Yuval_Atzmon1", "~Or_Patashnik1", "~Amit_Haim_Bermano2", "~Gal_Chechik1", "~Daniel_Cohen-or2"], "authors": ["Rinon Gal", "Yuval Alaluf", "Yuval Atzmon", "Or Patashnik", "Amit Haim Bermano", "Gal Chechik", "Daniel Cohen-or"], "keywords": ["Personalized generation", "text-to-image", "inversion"], "TL;DR": "We present the task of personalized text-to-image generation, and introduce an inversion-based method that allows us to synthesize novel scenes of user-provided visual concepts, guided by natural language instructions.", "abstract": "Text-to-image models offer unprecedented freedom to guide creation through natural language. Yet, it is unclear how such freedom can be exercised to generate images of specific unique concepts, modify their appearance, or compose them in new roles and novel scenes.\nIn other words, we ask: how can we use language-guided models to turn *our* cat into a painting, or imagine a new product based on *our* favorite toy? \nHere we present a simple approach that allows such creative freedom. Using only $3$-$5$ images of a user-provided concept, like an object or a style, we learn to represent it through new ``words\" in the embedding space of a frozen text-to-image model.\nThese ``words\" can be composed into natural language sentences, guiding *personalized* creation in an intuitive way.\nNotably, we find evidence that a *single* word embedding is sufficient for capturing unique and varied concepts. \nWe compare our approach to a wide range of baselines, and demonstrate that it can more faithfully portray the concepts across a range of applications and tasks. Our code, data and new words will be available.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Generative models", "paperhash": "gal|an_image_is_worth_one_word_personalizing_texttoimage_generation_using_textual_inversion", "pdf": "/pdf/dd5c5803a1a63bd0d148c2be26a9ee612d1615f8.pdf", "_bibtex": "@inproceedings{\ngal2023an,\ntitle={An Image is Worth One Word: Personalizing Text-to-Image Generation using Textual Inversion},\nauthor={Rinon Gal and Yuval Alaluf and Yuval Atzmon and Or Patashnik and Amit Haim Bermano and Gal Chechik and Daniel Cohen-or},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=NAQvF08TcyG}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2208.01618/code)"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279093889, "odate": 1664468100000, "details": {"replyCount": 15}}, {"id": "nUmCcZ5RKF", "original": "7T1PFvGWBhV", "number": 220, "cdate": 1663849825475, "mdate": null, "ddate": null, "tcdate": 1663849825475, "tmdate": 1697935845961, "tddate": null, "forum": "nUmCcZ5RKF", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "IS SYNTHETIC DATA FROM GENERATIVE MODELS READY FOR IMAGE RECOGNITION?", "authorids": ["~Ruifei_He1", "~Shuyang_Sun1", "~Xin_Yu6", "~Chuhui_Xue2", "~Wenqing_Zhang1", "~Philip_Torr1", "~Song_Bai3", "~XIAOJUAN_QI2"], "authors": ["Ruifei He", "Shuyang Sun", "Xin Yu", "Chuhui Xue", "Wenqing Zhang", "Philip Torr", "Song Bai", "XIAOJUAN QI"], "keywords": ["data generation", "image recognition", "text-to-image synthesis"], "abstract": "Recent text-to-image generation models have shown promising results in generating high-fidelity photo-realistic images. Though the results are astonishing to human eyes, how applicable these generated images are for recognition tasks remains under-explored. In this work, we extensively study whether and how synthetic images generated from state-of-the-art text-to-image generation models can be used for image recognition tasks, and focus on two perspectives: synthetic data for improving classification models in the data-scare settings (i.e. zero-shot and few-shot), and synthetic data for large-scale model pre-training for transfer learning. We showcase the powerfulness and shortcomings of synthetic data from existing generative models, and propose strategies for better applying synthetic data for recognition tasks. Code: https://github.com/CVMI-Lab/SyntheticData. ", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Applications (eg, speech processing, computer vision, NLP)", "paperhash": "he|is_synthetic_data_from_generative_models_ready_for_image_recognition", "TL;DR": "We present the first study on the state-of-the-art text-to-image generation models for image recognition.", "pdf": "/pdf/530478d6bc03dbd80ae4d0e00c93647edd522adc.pdf", "supplementary_material": "/attachment/090c20f07b954f9d113c8781398891207d0f9dd9.zip", "_bibtex": "@inproceedings{\nhe2023is,\ntitle={{IS} {SYNTHETIC} {DATA} {FROM} {GENERATIVE} {MODELS} {READY} {FOR} {IMAGE} {RECOGNITION}?},\nauthor={Ruifei He and Shuyang Sun and Xin Yu and Chuhui Xue and Wenqing Zhang and Philip Torr and Song Bai and XIAOJUAN QI},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=nUmCcZ5RKF}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2210.07574/code)"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279089910, "odate": 1664468100000, "details": {"replyCount": 21}}, {"id": "k7p_YAO7yE", "original": "1LRUGyy_9qL", "number": 214, "cdate": 1663849824750, "mdate": null, "ddate": null, "tcdate": 1663849824750, "tmdate": 1697935846907, "tddate": null, "forum": "k7p_YAO7yE", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "MapTR: Structured Modeling and Learning for Online Vectorized HD Map Construction", "authorids": ["~Bencheng_Liao1", "~Shaoyu_Chen1", "~Xinggang_Wang1", "~Tianheng_Cheng1", "~Qian_Zhang7", "~Wenyu_Liu3", "~Chang_Huang3"], "authors": ["Bencheng Liao", "Shaoyu Chen", "Xinggang Wang", "Tianheng Cheng", "Qian Zhang", "Wenyu Liu", "Chang Huang"], "keywords": ["Autonomous Driving", "Online Vectorized HD Map Construction", "End-to-End"], "abstract": "High-definition (HD) map provides abundant and precise environmental information of the driving scene, serving as a fundamental and indispensable component for planning in autonomous driving system. We present MapTR, a structured end-to-end Transformer for efficient online vectorized HD map construction. We propose a unified permutation-equivalent modeling approach, i.e., modeling map element as a point set with a group of equivalent permutations, which accurately describes the shape of map element and stabilizes the learning process. We design a hierarchical query embedding scheme to flexibly encode structured map information and perform hierarchical bipartite matching for map element learning. MapTR achieves the best performance and efficiency with only camera input among existing vectorized map construction approaches on nuScenes dataset. In particular, MapTR-nano runs at real-time inference speed ($25.1$ FPS) on RTX 3090, $8\\times$ faster than the existing state-of-the-art camera-based method while achieving $5.0$ higher mAP. Even compared with the existing state-of-the-art multi-modality method, MapTR-nano achieves $0.7$ higher mAP and $8\\times$ faster inference speed, and MapTR-tiny achieves $13.5$ higher mAP and $3\\times$ faster inference speed. Abundant qualitative results show that MapTR maintains stable and robust map construction quality in complex and various driving scenes. MapTR is of great application value in autonomous driving. Code and more demos are available at https://github.com/hustvl/MapTR.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Applications (eg, speech processing, computer vision, NLP)", "paperhash": "liao|maptr_structured_modeling_and_learning_for_online_vectorized_hd_map_construction", "TL;DR": "We present a structured end-to-end framework for efficient online vectorized HD map construction.", "pdf": "/pdf/f0aa5f3818d2d071eed47bfd84263b7b217b437a.pdf", "supplementary_material": "/attachment/b03de645fd5a4e9560131b071f18dbc33600b21b.zip", "_bibtex": "@inproceedings{\nliao2023maptr,\ntitle={Map{TR}: Structured Modeling and Learning for Online Vectorized {HD} Map Construction},\nauthor={Bencheng Liao and Shaoyu Chen and Xinggang Wang and Tianheng Cheng and Qian Zhang and Wenyu Liu and Chang Huang},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=k7p_YAO7yE}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2208.14437/code)"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279089657, "odate": 1664468100000, "details": {"replyCount": 14}}, {"id": "zEn1BhaNYsC", "original": "JWgYu-tT6xb", "number": 156, "cdate": 1663849818110, "mdate": null, "ddate": null, "tcdate": 1663849818110, "tmdate": 1677640447685, "tddate": null, "forum": "zEn1BhaNYsC", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Minimax Optimal Kernel Operator Learning via Multilevel Training", "authorids": ["~Jikai_Jin1", "~Yiping_Lu1", "~Jose_Blanchet1", "~Lexing_Ying1"], "authors": ["Jikai Jin", "Yiping Lu", "Jose Blanchet", "Lexing Ying"], "keywords": [], "abstract": "Learning mappings between infinite-dimensional function spaces have achieved empirical success in many disciplines of machine learning, including generative modeling, functional data analysis, causal inference, and multi-agent reinforcement learning. In this paper, we study the statistical limit of learning a Hilbert-Schmidt operator between two infinite-dimensional Sobolev reproducing kernel Hilbert spaces. We establish the information-theoretic lower bound in terms of the Sobolev Hilbert-Schmidt norm and show that a regularization that learns the spectral components below the bias contour and ignores the ones above the variance contour can achieve the optimal learning rate. At the same time, the spectral components between the bias and variance contours give us flexibility in designing computationally feasible machine learning algorithms. Based on this observation, we develop a multilevel kernel operator learning algorithm that is optimal when learning linear operators between infinite-dimensional function spaces.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Machine Learning for Sciences (eg biology, physics, health sciences, social sciences, climate/sustainability )", "paperhash": "jin|minimax_optimal_kernel_operator_learning_via_multilevel_training", "pdf": "/pdf/5133e05de4997ce07895732d586909263b656b92.pdf", "_bibtex": "@inproceedings{\njin2023minimax,\ntitle={Minimax Optimal Kernel Operator Learning via Multilevel Training},\nauthor={Jikai Jin and Yiping Lu and Jose Blanchet and Lexing Ying},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=zEn1BhaNYsC}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference", "supplementary_material": ""}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279087296, "odate": 1664468100000, "details": {"replyCount": 17}}, {"id": "NRxydtWup1S", "original": "yG_vy3vZYR", "number": 113, "cdate": 1663849812800, "mdate": null, "ddate": null, "tcdate": 1663849812800, "tmdate": 1697935854579, "tddate": null, "forum": "NRxydtWup1S", "replyto": null, "invitation": "ICLR.cc/2023/Conference/-/Blind_Submission", "content": {"title": "Designing BERT for Convolutional Networks: Sparse and Hierarchical Masked Modeling", "authorids": ["~Keyu_Tian1", "~Yi_Jiang2", "~qishuai_diao1", "~Chen_Lin2", "~Liwei_Wang1", "~Zehuan_Yuan1"], "authors": ["Keyu Tian", "Yi Jiang", "qishuai diao", "Chen Lin", "Liwei Wang", "Zehuan Yuan"], "keywords": ["Self-Supervised Learning", "Masked Autoencoding", "Masked Pre-training", "Masked Modeling", "Convolutional Neural Networks"], "TL;DR": "This paper presents a simple yet powerful framework to pre-train convolutional network (convnet) with Sparse masKed modeling.", "abstract": "We identify and overcome two key obstacles in extending the success of BERT-style pre-training, or masked image modeling, to convolutional networks (convnets): (i) convolution operation cannot handle irregular, randomly masked input images; (ii) the single-scale nature of BERT pre-training is inconsistent with convnet\u2019s hierarchical structure. For (i), we treat unmasked pixels as sparse voxels of 3D point clouds and use sparse convolution to encode. This is the first use of sparse convolution for 2D masked modeling. For (ii), we develop a hierarchical decoder to reconstruct images from multi-scale encoded features. Our method, called Sparse masKed modeling (SparK), is general: it can be used directly on any convolutional model without backbone modifications. We validate it on both classical (ResNet) and modern (ConvNeXt) models: on three downstream tasks, it surpasses both state-of-the-art contrastive learning and transformer-based masked modeling by similarly large margins (around +1.0%). The improvements on object detection and instance segmentation are more significant (up to +3.5%), validating the strong transferability of features learned. We also find SparK\u2019s favorable scaling behavior by observing more gains on larger networks. All of these findings support the promising future of generative pre-training on convnets. Both codes and pre-trained models have been released at https://github.com/keyu-tian/SparK.", "anonymous_url": "I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.", "no_acknowledgement_section": "I certify that there is no acknowledgement section in this submission for double blind review.", "code_of_ethics": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics", "submission_guidelines": "Yes", "resubmission": "", "student_author": "", "Please_choose_the_closest_area_that_your_submission_falls_into": "Unsupervised and Self-supervised learning", "paperhash": "tian|designing_bert_for_convolutional_networks_sparse_and_hierarchical_masked_modeling", "pdf": "/pdf/1f583ce7b466371efb133c5c74c8283ffc7fb6f7.pdf", "_bibtex": "@inproceedings{\ntian2023designing,\ntitle={Designing {BERT} for Convolutional Networks: Sparse and Hierarchical Masked Modeling},\nauthor={Keyu Tian and Yi Jiang and qishuai diao and Chen Lin and Liwei Wang and Zehuan Yuan},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=NRxydtWup1S}\n}", "venue": "ICLR 2023 notable top 25%", "venueid": "ICLR.cc/2023/Conference", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2301.03580/code)"}, "signatures": ["ICLR.cc/2023/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["ICLR.cc/2023/Conference"], "pdate": 1675279085418, "odate": 1664468100000, "details": {"replyCount": 17}}], "count": 281}