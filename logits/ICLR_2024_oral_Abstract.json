{"notes": [{"id": "KS8mIvetg2", "forum": "KS8mIvetg2", "signatures": ["ICLR.cc/2024/Conference/Submission9019/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission9019/Authors"], "content": {"title": {"value": "Proving Test Set Contamination in Black-Box Language Models"}, "authors": {"value": ["Yonatan Oren", "Nicole Meister", "Niladri S. Chatterji", "Faisal Ladhak", "Tatsunori Hashimoto"]}, "authorids": {"value": ["~Yonatan_Oren1", "~Nicole_Meister1", "~Niladri_S._Chatterji1", "~Faisal_Ladhak2", "~Tatsunori_Hashimoto1"]}, "keywords": {"value": ["language modeling", "memorization", "dataset contamination"]}, "abstract": {"value": "Large language models are trained on vast amounts of internet data, prompting concerns that they have memorized public benchmarks. Detecting this type of contamination is challenging because the pretraining data used by proprietary models are often not publicly accessible.\n\nWe propose a procedure for detecting test set contamination of language models with exact false positive guarantees and without access to pretraining data or model weights. Our approach leverages the fact that when there is no data contamination, all orderings of an exchangeable benchmark should be equally likely. In contrast, the tendency for language models to memorize example order means that a contaminated language model will find certain canonical orderings to be much more likely than others. Our test flags potential contamination whenever the likelihood of a canonically ordered benchmark dataset is significantly higher than the likelihood after shuffling the examples.\n\nWe demonstrate that our procedure is sensitive enough to reliably detect contamination in challenging situations, including models as small as 1.4 billion parameters, on small test sets only 1000 examples, and datasets that appear only a few times in the pretraining corpus. Finally, we evaluate LLaMA-2 to apply our test in a realistic setting and find our results to be consistent with existing contamination evaluations."}, "primary_area": {"value": "societal considerations including fairness, safety, privacy"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 oral"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/cfd79aaab7bdcd4f7c032c57fe7e607058042c80.pdf"}, "supplementary_material": {"value": "/attachment/aa53d1c5e16ec98e4af4f92f0eef6c0e5dfe7646.zip"}, "_bibtex": {"value": "@inproceedings{\noren2024proving,\ntitle={Proving Test Set Contamination in Black-Box Language Models},\nauthor={Yonatan Oren and Nicole Meister and Niladri S. Chatterji and Faisal Ladhak and Tatsunori Hashimoto},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=KS8mIvetg2}\n}"}, "paperhash": {"value": "oren|proving_test_set_contamination_in_blackbox_language_models"}}, "number": 9019, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission9019/-/Revision", "ICLR.cc/2024/Conference/Submission9019/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission9019/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695534774121, "cdate": 1695534774121, "tmdate": 1713672762124, "mdate": 1713672762124, "pdate": 1705411055804, "version": 2, "details": {"replyCount": 12, "presentation": [{"name": "title", "order": 1}, {"name": "authors", "order": 3}, {"name": "code_of_ethics", "order": 3, "input": "checkbox", "value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "description": null}, {"name": "authorids", "order": 4}, {"name": "keywords", "order": 4}, {"name": "submission_guidelines", "order": 4, "input": "checkbox", "value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide.", "description": null}, {"name": "TLDR", "order": 5, "fieldName": "TL;DR"}, {"name": "abstract", "order": 6, "input": "textarea", "markdown": true}, {"name": "pdf", "order": 7}, {"name": "anonymous_url", "order": 7, "input": "checkbox", "value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "description": null}, {"name": "supplementary_material", "order": 8}, {"name": "no_acknowledgement_section", "order": 8, "input": "checkbox", "value": "I certify that there is no acknowledgement section in this submission for double blind review.", "description": null}, {"name": "primary_area", "order": 9, "input": "select", "value": "societal considerations including fairness, safety, privacy", "description": null}, {"name": "resubmission"}, {"name": "student_author"}, {"name": "large_language_models"}, {"name": "other_comments_on_LLMs"}, {"name": "venue", "hidden": true}, {"name": "venueid", "hidden": true}, {"name": "_bibtex", "input": "textarea"}, {"name": "other_comments"}]}}, {"id": "7Ttk3RzDeu", "forum": "7Ttk3RzDeu", "signatures": ["ICLR.cc/2024/Conference/Submission8848/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8848/Authors"], "content": {"title": {"value": "BooookScore: A systematic exploration of book-length summarization in the era of LLMs"}, "authors": {"value": ["Yapei Chang", "Kyle Lo", "Tanya Goyal", "Mohit Iyyer"]}, "authorids": {"value": ["~Yapei_Chang1", "~Kyle_Lo1", "~Tanya_Goyal1", "~Mohit_Iyyer1"]}, "keywords": {"value": ["summarization", "evaluation", "long context", "prompting", "LLM"]}, "abstract": {"value": "Summarizing book-length documents ($>$100K tokens)  that exceed the context window size of large language models (LLMs) requires first breaking the input document into smaller chunks and then prompting an LLM to merge, update, and compress chunk-level summaries. Despite the complexity and importance of this task, it has yet to be meaningfully studied due to the challenges of evaluation: existing book-length summarization datasets (e.g., BookSum) are in the pretraining data of most public LLMs, and existing evaluation methods struggle to capture errors made by modern LLM summarizers. In this paper, we present the first study of the coherence of LLM-based book-length summarizers implemented via two prompting workflows: (1) hierarchically merging chunk-level summaries, and (2) incrementally updating a running summary. We obtain 1193 fine-grained human annotations on GPT-4 generated summaries of 100 recently-published books and identify eight common types of coherence errors made by LLMs. Because human evaluation is expensive and time-consuming, we develop an automatic metric, BooookScore, that measures the proportion of sentences in a summary that do not contain any of the identified error types. BooookScore has high agreement with human annotations and allows us to systematically evaluate the impact of many other critical parameters (e.g., chunk size, base LLM) while saving \\$15K USD and 500 hours in human evaluation costs. We find that closed-source LLMs such as GPT-4 and Claude 2 produce summaries with higher BooookScore than those generated by open-source models. While LLaMA 2 falls behind other models, Mixtral achieves performance on par with GPT-3.5-Turbo. Incremental updating yields lower BooookScore but higher level of detail than hierarchical merging, a trade-off sometimes preferred by annotators. We release code and annotations to spur more principled research on book-length summarization."}, "primary_area": {"value": "datasets and benchmarks"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 oral"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/975e393e430362eb39a2c1ceb2c750bd4bb80143.pdf"}, "_bibtex": {"value": "@inproceedings{\nchang2024booookscore,\ntitle={BooookScore: A systematic exploration of book-length summarization in the era of {LLM}s},\nauthor={Yapei Chang and Kyle Lo and Tanya Goyal and Mohit Iyyer},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=7Ttk3RzDeu}\n}"}, "paperhash": {"value": "chang|booookscore_a_systematic_exploration_of_booklength_summarization_in_the_era_of_llms"}}, "number": 8848, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8848/-/Revision", "ICLR.cc/2024/Conference/Submission8848/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8848/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695526597280, "cdate": 1695526597280, "tmdate": 1713045491214, "mdate": 1713045491214, "pdate": 1705411051634, "version": 2, "details": {"replyCount": 12, "presentation": [{"name": "title", "order": 1}, {"name": "authors", "order": 3}, {"name": "code_of_ethics", "order": 3, "input": "checkbox", "value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "description": null}, {"name": "authorids", "order": 4}, {"name": "keywords", "order": 4}, {"name": "submission_guidelines", "order": 4, "input": "checkbox", "value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide.", "description": null}, {"name": "TLDR", "order": 5, "fieldName": "TL;DR"}, {"name": "abstract", "order": 6, "input": "textarea", "markdown": true}, {"name": "pdf", "order": 7}, {"name": "anonymous_url", "order": 7, "input": "checkbox", "value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "description": null}, {"name": "supplementary_material", "order": 8}, {"name": "no_acknowledgement_section", "order": 8, "input": "checkbox", "value": "I certify that there is no acknowledgement section in this submission for double blind review.", "description": null}, {"name": "primary_area", "order": 9, "input": "select", "value": "datasets and benchmarks", "description": null}, {"name": "resubmission"}, {"name": "student_author"}, {"name": "large_language_models"}, {"name": "other_comments_on_LLMs"}, {"name": "venue", "hidden": true}, {"name": "venueid", "hidden": true}, {"name": "_bibtex", "input": "textarea"}, {"name": "other_comments"}]}}, {"id": "ANvmVS2Yr0", "forum": "ANvmVS2Yr0", "signatures": ["ICLR.cc/2024/Conference/Submission8660/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8660/Authors"], "content": {"title": {"value": "Generalization in diffusion models arises from geometry-adaptive harmonic representations"}, "authors": {"value": ["Zahra Kadkhodaie", "Florentin Guth", "Eero P Simoncelli", "St\u00e9phane Mallat"]}, "authorids": {"value": ["~Zahra_Kadkhodaie1", "~Florentin_Guth1", "~Eero_P_Simoncelli1", "~St\u00e9phane_Mallat1"]}, "keywords": {"value": ["diffusion models", "memorization", "generalization", "inductive bias", "curse of dimensionality", "denoising", "geometry-adaptive harmonic basis"]}, "abstract": {"value": "Deep neural networks (DNNs) trained for image denoising are able to generate high-quality samples with score-based reverse diffusion algorithms. These impressive capabilities seem to imply an escape from the curse of dimensionality, but recent reports of memorization of the training set raise the question of whether these networks are learning the \"true\" continuous density of the data. Here, we show that two DNNs trained on non-overlapping subsets of a dataset learn nearly the same score function, and thus the same density, when the number of training images is large enough.  In this regime of strong generalization, diffusion-generated images are distinct from the training set, and are of high visual quality, suggesting that the inductive biases of the DNNs are well-aligned with the data density. We analyze the learned denoising functions and show that the inductive biases give rise to a shrinkage operation in a basis adapted to the underlying image. Examination of these bases reveals oscillating harmonic structures along contours and in homogeneous regions. We demonstrate that trained denoisers are inductively biased towards these geometry-adaptive harmonic bases since they arise not only when the network is trained on photographic images, but also when it is trained on image classes supported on low-dimensional manifolds for which the harmonic basis is suboptimal. Finally, we show that when trained on regular image classes for which the optimal basis is known to be geometry-adaptive and harmonic, the denoising performance of the networks is near-optimal."}, "primary_area": {"value": "generative models"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 oral"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/84eb681ff8d070ce8c829cb2120dc133901594ce.pdf"}, "TLDR": {"value": "Diffusion models transition from memorization to generalization by being inductively biased towards geometry-adaptive harmonic representations."}, "_bibtex": {"value": "@inproceedings{\nkadkhodaie2024generalization,\ntitle={Generalization in diffusion models arises from geometry-adaptive harmonic representations},\nauthor={Zahra Kadkhodaie and Florentin Guth and Eero P Simoncelli and St{\\'e}phane Mallat},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=ANvmVS2Yr0}\n}"}, "paperhash": {"value": "kadkhodaie|generalization_in_diffusion_models_arises_from_geometryadaptive_harmonic_representations"}}, "number": 8660, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8660/-/Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8660/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695520324208, "cdate": 1695520324208, "tmdate": 1713672934776, "mdate": 1713672934776, "pdate": 1705411046073, "version": 2, "details": {"replyCount": 12, "presentation": [{"name": "title", "order": 1}, {"name": "authors", "order": 3}, {"name": "code_of_ethics", "order": 3, "input": "checkbox", "value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "description": null}, {"name": "authorids", "order": 4}, {"name": "keywords", "order": 4}, {"name": "submission_guidelines", "order": 4, "input": "checkbox", "value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide.", "description": null}, {"name": "TLDR", "order": 5, "fieldName": "TL;DR"}, {"name": "abstract", "order": 6, "input": "textarea", "markdown": true}, {"name": "pdf", "order": 7}, {"name": "anonymous_url", "order": 7, "input": "checkbox", "value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "description": null}, {"name": "supplementary_material", "order": 8}, {"name": "no_acknowledgement_section", "order": 8, "input": "checkbox", "value": "I certify that there is no acknowledgement section in this submission for double blind review.", "description": null}, {"name": "primary_area", "order": 9, "input": "select", "value": "generative models", "description": null}, {"name": "resubmission"}, {"name": "student_author"}, {"name": "large_language_models"}, {"name": "other_comments_on_LLMs"}, {"name": "venue", "hidden": true}, {"name": "venueid", "hidden": true}, {"name": "_bibtex", "input": "textarea"}, {"name": "other_comments"}]}}, {"id": "ekeyCgeRfC", "forum": "ekeyCgeRfC", "signatures": ["ICLR.cc/2024/Conference/Submission8569/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8569/Authors"], "content": {"title": {"value": "Understanding In-Context Learning in Transformers and LLMs by Learning to Learn Discrete Functions"}, "authors": {"value": ["Satwik Bhattamishra", "Arkil Patel", "Phil Blunsom", "Varun Kanade"]}, "authorids": {"value": ["~Satwik_Bhattamishra1", "~Arkil_Patel1", "~Phil_Blunsom1", "~Varun_Kanade1"]}, "keywords": {"value": ["In-context learning", "Transformers", "Large language models", "Boolean functions"]}, "abstract": {"value": "In order to understand the in-context learning phenomenon, recent works have adopted a stylized experimental framework and demonstrated that Transformers can match the performance of gradient-based learning algorithms for various classes of real-valued functions. However, the limitations of Transformers in implementing learning algorithms, and their ability to learn other forms of algorithms are not well understood. Additionally, the degree to which these capabilities are confined to attention-based models is unclear. Furthermore, it remains to be seen whether the insights derived from these stylized settings can be extrapolated to pretrained Large Language Models (LLMs). In this work, we take a step towards answering these questions by demonstrating the following: (a) On a test-bed with a variety of Boolean function classes, we find that Transformers can nearly match the optimal learning algorithm for 'simpler' tasks, while their performance deteriorates on more 'complex' tasks. Additionally, we find that certain attention-free models perform (almost) identically to Transformers on a range of tasks. (b) When provided a *teaching sequence*, i.e. a set of examples that uniquely identifies a function in a class, we show that Transformers learn more sample-efficiently. Interestingly, our results show that Transformers can learn to implement *two distinct* algorithms to solve a *single* task, and can adaptively select the more sample-efficient algorithm depending on the sequence of in-context examples. (c) Lastly, we show that extant LLMs, e.g. LLaMA-2, GPT-4, can compete with nearest-neighbor baselines on prediction tasks that are guaranteed to not be in their training set."}, "primary_area": {"value": "general machine learning (i.e., none of the above)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 oral"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/816f489eb70fe677c4ebc1cf159cf38b3062956b.pdf"}, "supplementary_material": {"value": "/attachment/e414066ad28bae7c4efd18f9c257beec11cc6eb5.zip"}, "_bibtex": {"value": "@inproceedings{\nbhattamishra2024understanding,\ntitle={Understanding In-Context Learning in Transformers and {LLM}s by Learning to Learn Discrete Functions},\nauthor={Satwik Bhattamishra and Arkil Patel and Phil Blunsom and Varun Kanade},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=ekeyCgeRfC}\n}"}, "paperhash": {"value": "bhattamishra|understanding_incontext_learning_in_transformers_and_llms_by_learning_to_learn_discrete_functions"}}, "number": 8569, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8569/-/Revision", "ICLR.cc/2024/Conference/Submission8569/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8569/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695515867779, "cdate": 1695515867779, "tmdate": 1710542360461, "mdate": 1710542360461, "pdate": 1705411043977, "version": 2, "details": {"replyCount": 32, "presentation": [{"name": "title", "order": 1}, {"name": "authors", "order": 3}, {"name": "code_of_ethics", "order": 3, "input": "checkbox", "value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "description": null}, {"name": "authorids", "order": 4}, {"name": "keywords", "order": 4}, {"name": "submission_guidelines", "order": 4, "input": "checkbox", "value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide.", "description": null}, {"name": "TLDR", "order": 5, "fieldName": "TL;DR"}, {"name": "abstract", "order": 6, "input": "textarea", "markdown": true}, {"name": "pdf", "order": 7}, {"name": "anonymous_url", "order": 7, "input": "checkbox", "value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "description": null}, {"name": "supplementary_material", "order": 8}, {"name": "no_acknowledgement_section", "order": 8, "input": "checkbox", "value": "I certify that there is no acknowledgement section in this submission for double blind review.", "description": null}, {"name": "primary_area", "order": 9, "input": "select", "value": "general machine learning (i.e., none of the above)", "description": null}, {"name": "resubmission"}, {"name": "student_author"}, {"name": "large_language_models"}, {"name": "other_comments_on_LLMs"}, {"name": "venue", "hidden": true}, {"name": "venueid", "hidden": true}, {"name": "_bibtex", "input": "textarea"}, {"name": "other_comments"}]}}, {"id": "aN4Jf6Cx69", "forum": "aN4Jf6Cx69", "signatures": ["ICLR.cc/2024/Conference/Submission8504/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8504/Authors"], "content": {"title": {"value": "The mechanistic basis of data dependence and abrupt learning in an in-context classification task"}, "authors": {"value": ["Gautam Reddy"]}, "authorids": {"value": ["~Gautam_Reddy1"]}, "keywords": {"value": ["in-context learning", "mechanistic interpretability", "language models", "induction heads"]}, "TLDR": {"value": "We characterize the loss landscape of an in-context classification task and identify the factors that lead to abrupt transitions during learning."}, "abstract": {"value": "Transformer models exhibit in-context learning: the ability to accurately predict the response to a novel query based on illustrative examples in the input sequence, which contrasts with traditional in-weights learning of query-output relationships. What aspects of the training data distribution and architecture favor in-context vs in-weights learning? Recent work has shown that specific distributional properties inherent in language, such as burstiness, large dictionaries and skewed rank-frequency distributions, control the trade-off or simultaneous appearance of these two forms of learning. We first show that these results are recapitulated in a minimal attention-only network trained on a simplified dataset. In-context learning (ICL) is driven by the abrupt emergence of an induction head, which subsequently competes with in-weights learning. By identifying progress measures that precede in-context learning and targeted experiments, we construct a two-parameter model of an induction head which emulates the full data distributional dependencies displayed by the attention-based network. A phenomenological model of induction head formation traces its abrupt emergence to the sequential learning of three nested logits enabled by an intrinsic curriculum. We propose that the sharp transitions in attention-based networks arise due to a specific chain of multi-layer operations necessary to achieve ICL, which is implemented by nested nonlinearities sequentially learned during training."}, "primary_area": {"value": "general machine learning (i.e., none of the above)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 oral"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/4de2c24997e6d25adcda68f174ed540f41a217e8.pdf"}, "_bibtex": {"value": "@inproceedings{\nreddy2024the,\ntitle={The mechanistic basis of data dependence and abrupt learning in an in-context classification task},\nauthor={Gautam Reddy},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=aN4Jf6Cx69}\n}"}, "paperhash": {"value": "reddy|the_mechanistic_basis_of_data_dependence_and_abrupt_learning_in_an_incontext_classification_task"}}, "number": 8504, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8504/-/Revision", "ICLR.cc/2024/Conference/Submission8504/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8504/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695512883715, "cdate": 1695512883715, "tmdate": 1710344148402, "mdate": 1710344148402, "pdate": 1705411042134, "version": 2, "details": {"replyCount": 14, "presentation": [{"name": "title", "order": 1}, {"name": "authors", "order": 3}, {"name": "code_of_ethics", "order": 3, "input": "checkbox", "value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "description": null}, {"name": "authorids", "order": 4}, {"name": "keywords", "order": 4}, {"name": "submission_guidelines", "order": 4, "input": "checkbox", "value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide.", "description": null}, {"name": "TLDR", "order": 5, "fieldName": "TL;DR"}, {"name": "abstract", "order": 6, "input": "textarea", "markdown": true}, {"name": "pdf", "order": 7}, {"name": "anonymous_url", "order": 7, "input": "checkbox", "value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "description": null}, {"name": "supplementary_material", "order": 8}, {"name": "no_acknowledgement_section", "order": 8, "input": "checkbox", "value": "I certify that there is no acknowledgement section in this submission for double blind review.", "description": null}, {"name": "primary_area", "order": 9, "input": "select", "value": "general machine learning (i.e., none of the above)", "description": null}, {"name": "resubmission"}, {"name": "student_author"}, {"name": "large_language_models"}, {"name": "other_comments_on_LLMs"}, {"name": "venue", "hidden": true}, {"name": "venueid", "hidden": true}, {"name": "_bibtex", "input": "textarea"}, {"name": "other_comments"}]}}, {"id": "WNzy9bRDvG", "forum": "WNzy9bRDvG", "signatures": ["ICLR.cc/2024/Conference/Submission8410/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8410/Authors"], "content": {"title": {"value": "Improved Techniques for Training Consistency Models"}, "authors": {"value": ["Yang Song", "Prafulla Dhariwal"]}, "authorids": {"value": ["~Yang_Song1", "~Prafulla_Dhariwal1"]}, "keywords": {"value": ["Consistency Models", "Consistency Training", "Diffusion Models", "Score-Based Generative Models", "Score-Based Diffusion Models", "Distillation"]}, "abstract": {"value": "Consistency models are a nascent family of generative models that can sample high quality data in one step without the need for adversarial training. Current consistency models achieve optimal sample quality by distilling from pre-trained diffusion models and employing learned metrics such as LPIPS. However, distillation limits the quality of consistency models to that of the pre-trained diffusion model, and LPIPS causes undesirable bias in evaluation. To tackle these challenges, we present improved techniques for consistency training, where consistency models learn directly from data without distillation. We delve into the theory behind consistency training and identify a previously overlooked flaw, which we address by eliminating Exponential Moving Average from the teacher consistency model. To replace learned metrics like LPIPS, we adopt Pseudo-Huber losses from robust statistics. Additionally, we introduce a lognormal noise schedule for the consistency training objective, and propose to double total discretization steps every set number of training iterations. Combined with better hyperparameter tuning, these modifications enable consistency models to achieve FID scores of 2.51 and 3.25 on CIFAR-10 and ImageNet $64\\times 64$ respectively in a single sampling step. These scores mark a 3.5$\\times$ and 4$\\times$ improvement compared to prior consistency training approaches. Through two-step sampling, we further reduce FID scores to 2.24 and 2.77 on these two datasets, surpassing those obtained via distillation in both one-step and two-step settings, while narrowing the gap between consistency models and other state-of-the-art generative models."}, "primary_area": {"value": "generative models"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 oral"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "TLDR": {"value": "Consistency training works better than consistency distillation with improved techniques"}, "pdf": {"value": "/pdf/c40d76fe68ec3195a55ba242266828b01fdb06c5.pdf"}, "_bibtex": {"value": "@inproceedings{\nsong2024improved,\ntitle={Improved Techniques for Training Consistency Models},\nauthor={Yang Song and Prafulla Dhariwal},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=WNzy9bRDvG}\n}"}, "paperhash": {"value": "song|improved_techniques_for_training_consistency_models"}}, "number": 8410, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8410/-/Revision", "ICLR.cc/2024/Conference/Submission8410/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8410/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695509291604, "cdate": 1695509291604, "tmdate": 1713119404391, "mdate": 1713119404391, "pdate": 1705411039848, "version": 2, "details": {"replyCount": 17, "presentation": [{"name": "title", "order": 1}, {"name": "authors", "order": 3}, {"name": "code_of_ethics", "order": 3, "input": "checkbox", "value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "description": null}, {"name": "authorids", "order": 4}, {"name": "keywords", "order": 4}, {"name": "submission_guidelines", "order": 4, "input": "checkbox", "value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide.", "description": null}, {"name": "TLDR", "order": 5, "fieldName": "TL;DR"}, {"name": "abstract", "order": 6, "input": "textarea", "markdown": true}, {"name": "pdf", "order": 7}, {"name": "anonymous_url", "order": 7, "input": "checkbox", "value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "description": null}, {"name": "supplementary_material", "order": 8}, {"name": "no_acknowledgement_section", "order": 8, "input": "checkbox", "value": "I certify that there is no acknowledgement section in this submission for double blind review.", "description": null}, {"name": "primary_area", "order": 9, "input": "select", "value": "generative models", "description": null}, {"name": "resubmission"}, {"name": "student_author"}, {"name": "large_language_models"}, {"name": "other_comments_on_LLMs"}, {"name": "venue", "hidden": true}, {"name": "venueid", "hidden": true}, {"name": "_bibtex", "input": "textarea"}, {"name": "other_comments"}]}}, {"id": "7VPTUWkiDQ", "forum": "7VPTUWkiDQ", "signatures": ["ICLR.cc/2024/Conference/Submission8400/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8400/Authors"], "content": {"title": {"value": "Provable Compositional Generalization for Object-Centric Learning"}, "authors": {"value": ["Thadd\u00e4us Wiedemer", "Jack Brady", "Alexander Panfilov", "Attila Juhos", "Matthias Bethge", "Wieland Brendel"]}, "authorids": {"value": ["~Thadd\u00e4us_Wiedemer1", "~Jack_Brady1", "~Alexander_Panfilov1", "~Attila_Juhos1", "~Matthias_Bethge1", "~Wieland_Brendel1"]}, "keywords": {"value": ["compositional generalization", "identifiability", "object-centric learning", "generalization", "OOD generalization", "unsupervised learning", "slot attention", "disentanglement", "autoencoders", "representation learning"]}, "TLDR": {"value": "We show theoretical conditions under which compositional generalization is guaranteed for object-centric representation learning."}, "abstract": {"value": "Learning representations that generalize to novel compositions of known concepts is crucial for bridging the gap between human and machine perception. One prominent effort is learning object-centric representations, which are widely conjectured to enable compositional generalization. Yet, it remains unclear when this conjecture will be true, as a principled theoretical or empirical understanding of compositional generalization is lacking. In this work, we investigate when compositional generalization is guaranteed for object-centric representations through the lens of identifiability theory. We show that autoencoders that satisfy structural assumptions on the decoder and enforce encoder-decoder consistency will learn object-centric representations that provably generalize compositionally. We validate our theoretical result and highlight the practical relevance of our assumptions through experiments on synthetic image data."}, "primary_area": {"value": "unsupervised, self-supervised, semi-supervised, and supervised representation learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 oral"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/70cd6e52cd58ee0e0b07dfea409db6acc228b343.pdf"}, "supplementary_material": {"value": "/attachment/33fd1c9b517dded8403690a54c5761cbb95fa832.zip"}, "_bibtex": {"value": "@inproceedings{\nwiedemer2024provable,\ntitle={Provable Compositional Generalization for Object-Centric Learning},\nauthor={Thadd{\\\"a}us Wiedemer and Jack Brady and Alexander Panfilov and Attila Juhos and Matthias Bethge and Wieland Brendel},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=7VPTUWkiDQ}\n}"}, "paperhash": {"value": "wiedemer|provable_compositional_generalization_for_objectcentric_learning"}}, "number": 8400, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8400/-/Revision", "ICLR.cc/2024/Conference/Submission8400/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8400/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695508922068, "cdate": 1695508922068, "tmdate": 1710517264274, "mdate": 1710517264274, "pdate": 1705411039660, "version": 2, "details": {"replyCount": 12, "presentation": [{"name": "title", "order": 1}, {"name": "authors", "order": 3}, {"name": "code_of_ethics", "order": 3, "input": "checkbox", "value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "description": null}, {"name": "authorids", "order": 4}, {"name": "keywords", "order": 4}, {"name": "submission_guidelines", "order": 4, "input": "checkbox", "value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide.", "description": null}, {"name": "TLDR", "order": 5, "fieldName": "TL;DR"}, {"name": "abstract", "order": 6, "input": "textarea", "markdown": true}, {"name": "pdf", "order": 7}, {"name": "anonymous_url", "order": 7, "input": "checkbox", "value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "description": null}, {"name": "supplementary_material", "order": 8}, {"name": "no_acknowledgement_section", "order": 8, "input": "checkbox", "value": "I certify that there is no acknowledgement section in this submission for double blind review.", "description": null}, {"name": "primary_area", "order": 9, "input": "select", "value": "unsupervised, self-supervised, semi-supervised, and supervised representation learning", "description": null}, {"name": "resubmission"}, {"name": "student_author"}, {"name": "large_language_models"}, {"name": "other_comments_on_LLMs"}, {"name": "venue", "hidden": true}, {"name": "venueid", "hidden": true}, {"name": "_bibtex", "input": "textarea"}, {"name": "other_comments"}]}}, {"id": "agPpmEgf8C", "forum": "agPpmEgf8C", "signatures": ["ICLR.cc/2024/Conference/Submission8258/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8258/Authors"], "content": {"title": {"value": "Predictive auxiliary objectives in deep RL mimic learning in the brain"}, "authors": {"value": ["Ching Fang", "Kim Stachenfeld"]}, "authorids": {"value": ["~Ching_Fang2", "~Kim_Stachenfeld1"]}, "keywords": {"value": ["hippocampus", "neuroscience", "cognitive science", "deep reinforcement learning", "representation learning", "prediction"]}, "abstract": {"value": "The ability to predict upcoming events has been hypothesized to comprise a key aspect of natural and machine cognition. This is supported by trends in deep reinforcement learning (RL), where self-supervised auxiliary objectives such as prediction are widely used to support representation learning and improve task performance. Here, we study the effects predictive auxiliary objectives have on representation learning across different modules of an RL system and how these mimic representational changes observed in the brain. We find that predictive objectives improve and stabilize learning particularly in resource-limited architectures, and we identify settings where longer predictive horizons better support representational transfer. Furthermore, we find that representational changes in this RL system bear a striking resemblance to changes in neural activity observed in the brain across various experiments. Specifically, we draw a connection between the auxiliary predictive model of the RL system and hippocampus, an area thought to learn a predictive model to support memory-guided behavior. We also connect the encoder network and the value learning network of the RL system to visual cortex and striatum in the brain, respectively. This work demonstrates how representation learning in deep RL systems can provide an interpretable framework for modeling multi-region interactions in the brain. The deep RL perspective taken here also suggests an additional role of the hippocampus in the brain-- that of an auxiliary learning system that benefits representation learning in other regions."}, "primary_area": {"value": "applications to neuroscience & cognitive science"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 oral"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/23365fd987e6b67de035adbd3b3bb679d36ddce7.pdf"}, "supplementary_material": {"value": "/attachment/82cbd73a501379a665cbc47213454979b9d5d8f2.pdf"}, "_bibtex": {"value": "@inproceedings{\nfang2024predictive,\ntitle={Predictive auxiliary objectives in deep {RL} mimic learning in the brain},\nauthor={Ching Fang and Kim Stachenfeld},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=agPpmEgf8C}\n}"}, "paperhash": {"value": "fang|predictive_auxiliary_objectives_in_deep_rl_mimic_learning_in_the_brain"}}, "number": 8258, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8258/-/Revision", "ICLR.cc/2024/Conference/Submission8258/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8258/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695502361071, "cdate": 1695502361071, "tmdate": 1713301733451, "mdate": 1713301733451, "pdate": 1705411036210, "version": 2, "details": {"replyCount": 14, "presentation": [{"name": "title", "order": 1}, {"name": "authors", "order": 3}, {"name": "code_of_ethics", "order": 3, "input": "checkbox", "value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "description": null}, {"name": "authorids", "order": 4}, {"name": "keywords", "order": 4}, {"name": "submission_guidelines", "order": 4, "input": "checkbox", "value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide.", "description": null}, {"name": "TLDR", "order": 5, "fieldName": "TL;DR"}, {"name": "abstract", "order": 6, "input": "textarea", "markdown": true}, {"name": "pdf", "order": 7}, {"name": "anonymous_url", "order": 7, "input": "checkbox", "value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "description": null}, {"name": "supplementary_material", "order": 8}, {"name": "no_acknowledgement_section", "order": 8, "input": "checkbox", "value": "I certify that there is no acknowledgement section in this submission for double blind review.", "description": null}, {"name": "primary_area", "order": 9, "input": "select", "value": "applications to neuroscience & cognitive science", "description": null}, {"name": "resubmission"}, {"name": "student_author"}, {"name": "large_language_models"}, {"name": "other_comments_on_LLMs"}, {"name": "venue", "hidden": true}, {"name": "venueid", "hidden": true}, {"name": "_bibtex", "input": "textarea"}, {"name": "other_comments"}]}}, {"id": "o2IEmeLL9r", "forum": "o2IEmeLL9r", "signatures": ["ICLR.cc/2024/Conference/Submission8189/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission8189/Authors"], "content": {"title": {"value": "Pre-Training Goal-based Models for Sample-Efficient Reinforcement Learning"}, "authors": {"value": ["Haoqi Yuan", "Zhancun Mu", "Feiyang Xie", "Zongqing Lu"]}, "authorids": {"value": ["~Haoqi_Yuan1", "~Zhancun_Mu1", "~Feiyang_Xie1", "~Zongqing_Lu2"]}, "keywords": {"value": ["reinforcement learning", "pre-training", "goal-conditioned RL", "open-world environments"]}, "abstract": {"value": "Pre-training on task-agnostic large datasets is a promising approach for enhancing the sample efficiency of reinforcement learning (RL) in solving complex tasks. We present PTGM, a novel method that pre-trains goal-based models to augment RL by providing temporal abstractions and behavior regularization. PTGM involves pre-training a low-level, goal-conditioned policy and training a high-level policy to generate goals for subsequent RL tasks. To address the challenges posed by the high-dimensional goal space, while simultaneously maintaining the agent's capability to accomplish various skills, we propose clustering goals in the dataset to form a discrete high-level action space. Additionally, we introduce a pre-trained goal prior model to regularize the behavior of the high-level policy in RL, enhancing sample efficiency and learning stability. Experimental results in a robotic simulation environment and the challenging open-world environment of Minecraft demonstrate PTGM\u2019s superiority in sample efficiency and task performance compared to baselines. Moreover, PTGM exemplifies enhanced interpretability and generalization of the acquired low-level skills."}, "primary_area": {"value": "reinforcement learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 oral"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/97ae12300fd1715ec484f1be154d49a619911fff.pdf"}, "_bibtex": {"value": "@inproceedings{\nyuan2024pretraining,\ntitle={Pre-Training Goal-based Models for Sample-Efficient Reinforcement Learning},\nauthor={Haoqi Yuan and Zhancun Mu and Feiyang Xie and Zongqing Lu},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=o2IEmeLL9r}\n}"}, "paperhash": {"value": "yuan|pretraining_goalbased_models_for_sampleefficient_reinforcement_learning"}}, "number": 8189, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission8189/-/Revision", "ICLR.cc/2024/Conference/Submission8189/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission8189/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695500211085, "cdate": 1695500211085, "tmdate": 1709661546710, "mdate": 1709661546710, "pdate": 1705411033730, "version": 2, "details": {"replyCount": 15, "presentation": [{"name": "title", "order": 1}, {"name": "authors", "order": 3}, {"name": "code_of_ethics", "order": 3, "input": "checkbox", "value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "description": null}, {"name": "authorids", "order": 4}, {"name": "keywords", "order": 4}, {"name": "submission_guidelines", "order": 4, "input": "checkbox", "value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide.", "description": null}, {"name": "TLDR", "order": 5, "fieldName": "TL;DR"}, {"name": "abstract", "order": 6, "input": "textarea", "markdown": true}, {"name": "pdf", "order": 7}, {"name": "anonymous_url", "order": 7, "input": "checkbox", "value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "description": null}, {"name": "supplementary_material", "order": 8}, {"name": "no_acknowledgement_section", "order": 8, "input": "checkbox", "value": "I certify that there is no acknowledgement section in this submission for double blind review.", "description": null}, {"name": "primary_area", "order": 9, "input": "select", "value": "reinforcement learning", "description": null}, {"name": "resubmission"}, {"name": "student_author"}, {"name": "large_language_models"}, {"name": "other_comments_on_LLMs"}, {"name": "venue", "hidden": true}, {"name": "venueid", "hidden": true}, {"name": "_bibtex", "input": "textarea"}, {"name": "other_comments"}]}}, {"id": "hTEGyKf0dZ", "forum": "hTEGyKf0dZ", "signatures": ["ICLR.cc/2024/Conference/Submission7972/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7972/Authors"], "content": {"title": {"value": "Fine-tuning Aligned Language Models Compromises Safety, Even When Users Do Not Intend To!"}, "authors": {"value": ["Xiangyu Qi", "Yi Zeng", "Tinghao Xie", "Pin-Yu Chen", "Ruoxi Jia", "Prateek Mittal", "Peter Henderson"]}, "authorids": {"value": ["~Xiangyu_Qi2", "~Yi_Zeng3", "~Tinghao_Xie1", "~Pin-Yu_Chen1", "~Ruoxi_Jia1", "~Prateek_Mittal1", "~Peter_Henderson1"]}, "keywords": {"value": ["AI Safety", "Large Language Models", "Fine-tuning", "Jailbreaking", "AI Alignment"]}, "TLDR": {"value": "Fine-tuning aligned Large Language Models introduces new safety risks that current alignment infrastructures fall short of addressing."}, "abstract": {"value": "Optimizing large language models (LLMs) for downstream use cases often involves the customization of pre-trained LLMs through further fine-tuning. Meta's open-source release of Llama models and OpenAI's APIs for fine-tuning GPT-3.5 Turbo on customized datasets accelerate this trend. But, what are the safety costs associated with such customized fine-tuning? While existing safety alignment techniques restrict harmful behaviors of LLMs at inference time, they do not cover safety risks when fine-tuning privileges are extended to end-users. Our red teaming studies find that the safety alignment of LLMs can be compromised by fine-tuning with only a few adversarially designed training examples. For instance, we jailbreak GPT-3.5 Turbo's safety guardrails by fine-tuning it on only 10 such examples at a cost of less than $0.20 via OpenAI's APIs, making the model responsive to nearly any harmful instructions. Disconcertingly, our research also reveals that, even without malicious intent, simply fine-tuning with benign and commonly used datasets can also inadvertently degrade the safety alignment of LLMs, though to a lesser extent. These findings suggest that fine-tuning aligned LLMs introduces new safety risks that current safety infrastructures fall short of addressing --- even if a model's initial safety alignment is impeccable, how can it be maintained after customized fine-tuning? We outline and critically analyze potential mitigations and advocate for further research efforts toward reinforcing safety protocols for the customized fine-tuning of aligned LLMs.  (This paper contains red-teaming data and model-generated content that can be offensive in nature.)"}, "primary_area": {"value": "societal considerations including fairness, safety, privacy"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 oral"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/cf8a15c7b5a808ae67357cdde0c8f2bbd5c4b8ed.pdf"}, "_bibtex": {"value": "@inproceedings{\nqi2024finetuning,\ntitle={Fine-tuning Aligned Language Models Compromises Safety, Even When Users Do Not Intend To!},\nauthor={Xiangyu Qi and Yi Zeng and Tinghao Xie and Pin-Yu Chen and Ruoxi Jia and Prateek Mittal and Peter Henderson},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=hTEGyKf0dZ}\n}"}, "paperhash": {"value": "qi|finetuning_aligned_language_models_compromises_safety_even_when_users_do_not_intend_to"}}, "number": 7972, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7972/-/Revision", "ICLR.cc/2024/Conference/Submission7972/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7972/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695492383773, "cdate": 1695492383773, "tmdate": 1710514437125, "mdate": 1710514437125, "pdate": 1705411025344, "version": 2, "details": {"replyCount": 27, "presentation": [{"name": "title", "order": 1}, {"name": "authors", "order": 3}, {"name": "code_of_ethics", "order": 3, "input": "checkbox", "value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "description": null}, {"name": "authorids", "order": 4}, {"name": "keywords", "order": 4}, {"name": "submission_guidelines", "order": 4, "input": "checkbox", "value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide.", "description": null}, {"name": "TLDR", "order": 5, "fieldName": "TL;DR"}, {"name": "abstract", "order": 6, "input": "textarea", "markdown": true}, {"name": "pdf", "order": 7}, {"name": "anonymous_url", "order": 7, "input": "checkbox", "value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "description": null}, {"name": "supplementary_material", "order": 8}, {"name": "no_acknowledgement_section", "order": 8, "input": "checkbox", "value": "I certify that there is no acknowledgement section in this submission for double blind review.", "description": null}, {"name": "primary_area", "order": 9, "input": "select", "value": "societal considerations including fairness, safety, privacy", "description": null}, {"name": "resubmission"}, {"name": "student_author"}, {"name": "large_language_models"}, {"name": "other_comments_on_LLMs"}, {"name": "venue", "hidden": true}, {"name": "venueid", "hidden": true}, {"name": "_bibtex", "input": "textarea"}, {"name": "other_comments"}]}}, {"id": "PdaPky8MUn", "forum": "PdaPky8MUn", "signatures": ["ICLR.cc/2024/Conference/Submission7782/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7782/Authors"], "content": {"title": {"value": "Never Train from Scratch: Fair Comparison of Long-Sequence Models Requires Data-Driven Priors"}, "authors": {"value": ["Ido Amos", "Jonathan Berant", "Ankit Gupta"]}, "authorids": {"value": ["~Ido_Amos1", "~Jonathan_Berant1", "~Ankit_Gupta3"]}, "keywords": {"value": ["Pre Training", "Transformers", "State Space Models", "Long Range Models", "Fair Evaluation"]}, "abstract": {"value": "Modeling long-range dependencies across sequences is a longstanding goal in machine learning and has led to architectures, such as state space models, that dramatically outperform Transformers on long sequences. However, these impressive empirical gains have been by and large demonstrated on benchmarks (e.g. Long Range Arena), where models are randomly initialized and trained to predict a target label from an input sequence. In this work, we show that random initialization leads to gross overestimation of the differences between architectures and that pretraining with standard denoising objectives, *using only the downstream task data*, leads to dramatic gains across multiple architectures and to very small gaps between Transformers and state space models (SSMs). In stark contrast to prior works, we find vanilla Transformers to match the performance of S4 on Long Range Arena when properly pretrained, and we improve the best reported results of SSMs on the PathX-256 task by 20 absolute points. Subsequently, we analyze the utility of previously-proposed structured parameterizations for SSMs and show they become mostly redundant in the presence of data-driven initialization obtained through pretraining. Our work shows that, when evaluating different architectures on supervised tasks, incorporation of data-driven priors via pretraining is essential for reliable performance estimation, and can be done efficiently."}, "primary_area": {"value": "unsupervised, self-supervised, semi-supervised, and supervised representation learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 oral"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/0f82cdb6beb87821d0a243ee526230c73d7ae798.pdf"}, "TLDR": {"value": "Training a model directly on a dataset from sctrach can lead to grossly under-estimated performance. For proper evaluation, one must first pretrain on the dataset and then finetune."}, "_bibtex": {"value": "@inproceedings{\namos2024never,\ntitle={Never Train from Scratch: Fair Comparison of Long-Sequence Models Requires Data-Driven Priors},\nauthor={Ido Amos and Jonathan Berant and Ankit Gupta},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=PdaPky8MUn}\n}"}, "paperhash": {"value": "amos|never_train_from_scratch_fair_comparison_of_longsequence_models_requires_datadriven_priors"}}, "number": 7782, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7782/-/Revision", "ICLR.cc/2024/Conference/Submission7782/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7782/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695485756547, "cdate": 1695485756547, "tmdate": 1710436135709, "mdate": 1710436135709, "pdate": 1705411020178, "version": 2, "details": {"replyCount": 20, "presentation": [{"name": "title", "order": 1}, {"name": "authors", "order": 3}, {"name": "code_of_ethics", "order": 3, "input": "checkbox", "value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "description": null}, {"name": "authorids", "order": 4}, {"name": "keywords", "order": 4}, {"name": "submission_guidelines", "order": 4, "input": "checkbox", "value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide.", "description": null}, {"name": "TLDR", "order": 5, "fieldName": "TL;DR"}, {"name": "abstract", "order": 6, "input": "textarea", "markdown": true}, {"name": "pdf", "order": 7}, {"name": "anonymous_url", "order": 7, "input": "checkbox", "value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "description": null}, {"name": "supplementary_material", "order": 8}, {"name": "no_acknowledgement_section", "order": 8, "input": "checkbox", "value": "I certify that there is no acknowledgement section in this submission for double blind review.", "description": null}, {"name": "primary_area", "order": 9, "input": "select", "value": "unsupervised, self-supervised, semi-supervised, and supervised representation learning", "description": null}, {"name": "resubmission"}, {"name": "student_author"}, {"name": "large_language_models"}, {"name": "other_comments_on_LLMs"}, {"name": "venue", "hidden": true}, {"name": "venueid", "hidden": true}, {"name": "_bibtex", "input": "textarea"}, {"name": "other_comments"}]}}, {"id": "LzPWWPAdY4", "forum": "LzPWWPAdY4", "signatures": ["ICLR.cc/2024/Conference/Submission7536/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7536/Authors"], "content": {"title": {"value": "LoftQ: LoRA-Fine-Tuning-aware Quantization for Large Language Models"}, "authors": {"value": ["Yixiao Li", "Yifan Yu", "Chen Liang", "Nikos Karampatziakis", "Pengcheng He", "Weizhu Chen", "Tuo Zhao"]}, "authorids": {"value": ["~Yixiao_Li2", "~Yifan_Yu4", "~Chen_Liang3", "~Nikos_Karampatziakis1", "~Pengcheng_He2", "~Weizhu_Chen1", "~Tuo_Zhao1"]}, "keywords": {"value": ["quantization", "compression", "large language models", "NLP", "machine learning", "low rank"]}, "abstract": {"value": "Quantization is an indispensable technique for serving Large Language Models (LLMs) and has recently found its way into LoRA fine-tuning (Dettmers et al., 2023). In this work we focus on the scenario where quantization and LoRA fine- tuning are applied together on a pre-trained model. In such cases it is common to observe a consistent gap in the performance on downstream tasks between full fine-tuning and quantization plus LoRA fine-tuning approach. In response, we propose LoftQ (LoRA-Fine-Tuning-aware Quantization), a novel quantization framework that simultaneously quantizes an LLM and finds a proper low-rank initialization for LoRA fine-tuning. Such an initialization alleviates the discrep- ancy between the quantized and full-precision model and significantly improves the generalization in downstream tasks. We evaluate our method on natural lan- guage understanding, question answering, summarization, and natural language generation tasks. Experiments show that our method is highly effective and out- performs existing quantization methods, especially in the challenging 2-bit and 2/4-bit mixed precision regimes. We will release our code."}, "primary_area": {"value": "optimization"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 oral"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/c8a3b2454c94e0374c1778862e8fca63e370ba5b.pdf"}, "_bibtex": {"value": "@inproceedings{\nli2024loftq,\ntitle={LoftQ: Lo{RA}-Fine-Tuning-aware Quantization for Large Language Models},\nauthor={Yixiao Li and Yifan Yu and Chen Liang and Nikos Karampatziakis and Pengcheng He and Weizhu Chen and Tuo Zhao},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=LzPWWPAdY4}\n}"}, "paperhash": {"value": "li|loftq_lorafinetuningaware_quantization_for_large_language_models"}}, "number": 7536, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7536/-/Revision", "ICLR.cc/2024/Conference/Submission7536/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7536/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695478136846, "cdate": 1695478136846, "tmdate": 1710583312042, "mdate": 1710583312042, "pdate": 1705411012215, "version": 2, "details": {"replyCount": 9, "presentation": [{"name": "title", "order": 1}, {"name": "authors", "order": 3}, {"name": "code_of_ethics", "order": 3, "input": "checkbox", "value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "description": null}, {"name": "authorids", "order": 4}, {"name": "keywords", "order": 4}, {"name": "submission_guidelines", "order": 4, "input": "checkbox", "value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide.", "description": null}, {"name": "TLDR", "order": 5, "fieldName": "TL;DR"}, {"name": "abstract", "order": 6, "input": "textarea", "markdown": true}, {"name": "pdf", "order": 7}, {"name": "anonymous_url", "order": 7, "input": "checkbox", "value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "description": null}, {"name": "supplementary_material", "order": 8}, {"name": "no_acknowledgement_section", "order": 8, "input": "checkbox", "value": "I certify that there is no acknowledgement section in this submission for double blind review.", "description": null}, {"name": "primary_area", "order": 9, "input": "select", "value": "optimization", "description": null}, {"name": "resubmission"}, {"name": "student_author"}, {"name": "large_language_models"}, {"name": "other_comments_on_LLMs"}, {"name": "venue", "hidden": true}, {"name": "venueid", "hidden": true}, {"name": "_bibtex", "input": "textarea"}, {"name": "other_comments"}]}}, {"id": "oO6FsMyDBt", "forum": "oO6FsMyDBt", "signatures": ["ICLR.cc/2024/Conference/Submission7510/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7510/Authors"], "content": {"title": {"value": "Graph Neural Networks for Learning Equivariant Representations of Neural Networks"}, "authors": {"value": ["Miltiadis Kofinas", "Boris Knyazev", "Yan Zhang", "Yunlu Chen", "Gertjan J. Burghouts", "Efstratios Gavves", "Cees G. M. Snoek", "David W. Zhang"]}, "authorids": {"value": ["~Miltiadis_Kofinas2", "~Boris_Knyazev1", "~Yan_Zhang1", "~Yunlu_Chen1", "~Gertjan_J._Burghouts1", "~Efstratios_Gavves1", "~Cees_G._M._Snoek1", "~David_W._Zhang1"]}, "keywords": {"value": ["Deep weight space", "Graph neural networks", "Transformers", "Permutation equivariance", "Implicit neural representations", "Networks for networks", "Neural graphs"]}, "TLDR": {"value": "We propose graph neural networks that learn permutation equivariant representations of other neural networks"}, "abstract": {"value": "Neural networks that process the parameters of other neural networks find applications in domains as diverse as classifying implicit neural representations, generating neural network weights, and predicting generalization errors. However, existing approaches either overlook the inherent permutation symmetry in the neural network or rely on intricate weight-sharing patterns to achieve equivariance, while ignoring the impact of the network architecture itself. In this work, we propose to represent neural networks as computational graphs of parameters, which allows us to harness powerful graph neural networks and transformers that preserve permutation symmetry. Consequently, our approach enables a single model to encode neural computational graphs with diverse architectures. We showcase the effectiveness of our method on a wide range of tasks, including classification and editing of implicit neural representations, predicting generalization performance, and learning to optimize, while consistently outperforming state-of-the-art methods. The source code is open-sourced at https://github.com/mkofinas/neural-graphs."}, "primary_area": {"value": "learning on graphs and other geometries & topologies"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 oral"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/338609142f1f45e68ec5fc8b5d6c9a3c0247ee30.pdf"}, "supplementary_material": {"value": "/attachment/1e7b5b69325338b8f37fe9e58c18d76ca055edf5.zip"}, "_bibtex": {"value": "@inproceedings{\nkofinas2024graph,\ntitle={Graph Neural Networks for Learning Equivariant Representations of Neural Networks},\nauthor={Miltiadis Kofinas and Boris Knyazev and Yan Zhang and Yunlu Chen and Gertjan J. Burghouts and Efstratios Gavves and Cees G. M. Snoek and David W. Zhang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=oO6FsMyDBt}\n}"}, "paperhash": {"value": "kofinas|graph_neural_networks_for_learning_equivariant_representations_of_neural_networks"}}, "number": 7510, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7510/-/Revision", "ICLR.cc/2024/Conference/Submission7510/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7510/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695476894164, "cdate": 1695476894164, "tmdate": 1710763567050, "mdate": 1710763567050, "pdate": 1705411011331, "version": 2, "details": {"replyCount": 11, "presentation": [{"name": "title", "order": 1}, {"name": "authors", "order": 3}, {"name": "code_of_ethics", "order": 3, "input": "checkbox", "value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "description": null}, {"name": "authorids", "order": 4}, {"name": "keywords", "order": 4}, {"name": "submission_guidelines", "order": 4, "input": "checkbox", "value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide.", "description": null}, {"name": "TLDR", "order": 5, "fieldName": "TL;DR"}, {"name": "abstract", "order": 6, "input": "textarea", "markdown": true}, {"name": "pdf", "order": 7}, {"name": "anonymous_url", "order": 7, "input": "checkbox", "value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "description": null}, {"name": "supplementary_material", "order": 8}, {"name": "no_acknowledgement_section", "order": 8, "input": "checkbox", "value": "I certify that there is no acknowledgement section in this submission for double blind review.", "description": null}, {"name": "primary_area", "order": 9, "input": "select", "value": "learning on graphs and other geometries & topologies", "description": null}, {"name": "resubmission"}, {"name": "student_author"}, {"name": "large_language_models"}, {"name": "other_comments_on_LLMs"}, {"name": "venue", "hidden": true}, {"name": "venueid", "hidden": true}, {"name": "_bibtex", "input": "textarea"}, {"name": "other_comments"}]}}, {"id": "IGzaH538fz", "forum": "IGzaH538fz", "signatures": ["ICLR.cc/2024/Conference/Submission7488/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7488/Authors"], "content": {"title": {"value": "GNNCert: Deterministic Certification of Graph Neural Networks against Adversarial Perturbations"}, "authors": {"value": ["zaishuo xia", "Han Yang", "Binghui Wang", "Jinyuan Jia"]}, "authorids": {"value": ["~zaishuo_xia1", "~Han_Yang9", "~Binghui_Wang2", "~Jinyuan_Jia2"]}, "keywords": {"value": ["Adversarial attacks to graph classification; provable robustness"]}, "abstract": {"value": "Graph classification, which aims to predict a label for a graph, has many real-world applications such as malware detection, fraud detection, and healthcare. However, many studies show an attacker could carefully perturb the structure and/or node features in a graph such that a graph classifier misclassifies the perturbed graph. Such vulnerability impedes the deployment of graph classification in security/safety-critical applications. Existing empirical defenses lack formal robustness guarantees and could be broken by adaptive or unknown attacks. Existing provable defenses have the following limitations: 1)  they achieve sub-optimal robustness guarantees for graph structure perturbation, 2) they cannot provide robustness guarantees for arbitrarily node feature perturbations, 3) their robustness guarantees are probabilistic, meaning they could be incorrect with a non-zero probability, and 4) they incur large computation costs. We aim to address those limitations in this work. We propose GNNCert, a certified defense against both graph structure and node feature perturbations for graph classification. Our GNNCert provably predicts the same label for a graph when the number of perturbed edges and the number of nodes with perturbed features are bounded. Our results on 8 benchmark datasets show that GNNCert outperforms three state-of-the-art methods."}, "primary_area": {"value": "societal considerations including fairness, safety, privacy"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 oral"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/03ea622e3c66547d24c4da2f725ddf1fe5db2233.pdf"}, "_bibtex": {"value": "@inproceedings{\nxia2024gnncert,\ntitle={{GNNC}ert: Deterministic Certification of Graph Neural Networks against Adversarial Perturbations},\nauthor={zaishuo xia and Han Yang and Binghui Wang and Jinyuan Jia},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=IGzaH538fz}\n}"}, "paperhash": {"value": "xia|gnncert_deterministic_certification_of_graph_neural_networks_against_adversarial_perturbations"}}, "number": 7488, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7488/-/Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7488/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695475919263, "cdate": 1695475919263, "tmdate": 1713672791712, "mdate": 1713672791712, "pdate": 1705411010869, "version": 2, "details": {"replyCount": 19, "presentation": [{"name": "title", "order": 1}, {"name": "authors", "order": 3}, {"name": "code_of_ethics", "order": 3, "input": "checkbox", "value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "description": null}, {"name": "authorids", "order": 4}, {"name": "keywords", "order": 4}, {"name": "submission_guidelines", "order": 4, "input": "checkbox", "value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide.", "description": null}, {"name": "TLDR", "order": 5, "fieldName": "TL;DR"}, {"name": "abstract", "order": 6, "input": "textarea", "markdown": true}, {"name": "pdf", "order": 7}, {"name": "anonymous_url", "order": 7, "input": "checkbox", "value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "description": null}, {"name": "supplementary_material", "order": 8}, {"name": "no_acknowledgement_section", "order": 8, "input": "checkbox", "value": "I certify that there is no acknowledgement section in this submission for double blind review.", "description": null}, {"name": "primary_area", "order": 9, "input": "select", "value": "societal considerations including fairness, safety, privacy", "description": null}, {"name": "resubmission"}, {"name": "student_author"}, {"name": "large_language_models"}, {"name": "other_comments_on_LLMs"}, {"name": "venue", "hidden": true}, {"name": "venueid", "hidden": true}, {"name": "_bibtex", "input": "textarea"}, {"name": "other_comments"}]}}, {"id": "LjivA1SLZ6", "forum": "LjivA1SLZ6", "signatures": ["ICLR.cc/2024/Conference/Submission7321/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7321/Authors"], "content": {"title": {"value": "Efficient Episodic Memory Utilization of Cooperative Multi-Agent Reinforcement Learning"}, "authors": {"value": ["Hyungho Na", "Yunkyeong Seo", "Il-chul Moon"]}, "authorids": {"value": ["~Hyungho_Na1", "~Yunkyeong_Seo1", "~Il-chul_Moon1"]}, "keywords": {"value": ["Multi-agent reinforcement learning", "episodic control", "episodic incentive", "state embedding"]}, "TLDR": {"value": "We introduce a framework that enhances memory utilization in cooperative multi-agent reinforcement learning to achieve a common goal through semantic embedding and episodic incentives."}, "abstract": {"value": "In cooperative multi-agent reinforcement learning (MARL), agents aim to achieve a common goal, such as defeating enemies or scoring a goal. Existing MARL algorithms are effective but still require significant learning time and often get trapped in local optima by complex tasks, subsequently failing to discover a goal-reaching policy. To address this, we introduce Efficient episodic Memory Utilization (EMU) for MARL, with two primary objectives: (a) accelerating reinforcement learning by leveraging semantically coherent memory from an episodic buffer and (b) selectively promoting desirable transitions to prevent local convergence. To achieve (a), EMU incorporates a trainable encoder/decoder structure alongside MARL, creating coherent memory embeddings that facilitate exploratory memory recall. To achieve (b), EMU introduces a novel reward structure called episodic incentive based on the desirability of states. This reward improves the TD target in Q-learning and acts as an additional incentive for desirable transitions. We provide theoretical support for the proposed incentive and demonstrate the effectiveness of EMU compared to conventional episodic control. The proposed method is evaluated in StarCraft II and Google Research Football, and empirical results indicate further performance improvement over state-of-the-art methods."}, "primary_area": {"value": "reinforcement learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 oral"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/8b2d5ac5539754d00bf99458a60c63157c74fbdb.pdf"}, "supplementary_material": {"value": "/attachment/aca81eae23a15faf63dd814c4dafba4d4933455a.zip"}, "_bibtex": {"value": "@inproceedings{\nna2024efficient,\ntitle={Efficient Episodic Memory Utilization of Cooperative Multi-Agent Reinforcement Learning},\nauthor={Hyungho Na and Yunkyeong Seo and Il-chul Moon},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=LjivA1SLZ6}\n}"}, "paperhash": {"value": "na|efficient_episodic_memory_utilization_of_cooperative_multiagent_reinforcement_learning"}}, "number": 7321, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7321/-/Revision", "ICLR.cc/2024/Conference/Submission7321/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7321/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695467628362, "cdate": 1695467628362, "tmdate": 1709790543033, "mdate": 1709790543033, "pdate": 1705411006224, "version": 2, "details": {"replyCount": 22, "presentation": [{"name": "title", "order": 1}, {"name": "authors", "order": 3}, {"name": "code_of_ethics", "order": 3, "input": "checkbox", "value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "description": null}, {"name": "authorids", "order": 4}, {"name": "keywords", "order": 4}, {"name": "submission_guidelines", "order": 4, "input": "checkbox", "value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide.", "description": null}, {"name": "TLDR", "order": 5, "fieldName": "TL;DR"}, {"name": "abstract", "order": 6, "input": "textarea", "markdown": true}, {"name": "pdf", "order": 7}, {"name": "anonymous_url", "order": 7, "input": "checkbox", "value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "description": null}, {"name": "supplementary_material", "order": 8}, {"name": "no_acknowledgement_section", "order": 8, "input": "checkbox", "value": "I certify that there is no acknowledgement section in this submission for double blind review.", "description": null}, {"name": "primary_area", "order": 9, "input": "select", "value": "reinforcement learning", "description": null}, {"name": "resubmission"}, {"name": "student_author"}, {"name": "large_language_models"}, {"name": "other_comments_on_LLMs"}, {"name": "venue", "hidden": true}, {"name": "venueid", "hidden": true}, {"name": "_bibtex", "input": "textarea"}, {"name": "other_comments"}]}}, {"id": "xuY33XhEGR", "forum": "xuY33XhEGR", "signatures": ["ICLR.cc/2024/Conference/Submission7174/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission7174/Authors"], "content": {"title": {"value": "ClimODE: Climate and Weather Forecasting with Physics-informed Neural ODEs"}, "authors": {"value": ["Yogesh Verma", "Markus Heinonen", "Vikas Garg"]}, "authorids": {"value": ["~Yogesh_Verma1", "~Markus_Heinonen1", "~Vikas_Garg2"]}, "keywords": {"value": ["neural ODE", "time-series forecasting", "climate prediction", "physics-informed ML"]}, "TLDR": {"value": "We introduce a novel climate and weather modeling approach, inspired by physics, using ODEs that capture underlying inductive biases and allow for uncertainty quantification in predictions."}, "abstract": {"value": "Climate and weather prediction traditionally relies on complex numerical simulations of atmospheric physics. Deep learning approaches, such as transformers, have recently challenged the simulation paradigm with complex network forecasts. However, they often act as data-driven black-box models that neglect the underlying physics and lack uncertainty quantification. We address these limitations with ClimODE, a  spatiotemporal continuous-time process that implements a key principle of advection from statistical mechanics, namely, weather changes due to a spatial movement of quantities over time. ClimODE models precise weather evolution with value-conserving dynamics, learning global weather transport as a neural flow, which also enables estimating the uncertainty in predictions. Our approach outperforms existing data-driven methods in global and regional forecasting with an order of magnitude smaller parameterization, establishing a new state of the art."}, "primary_area": {"value": "applications to physical sciences (physics, chemistry, biology, etc.)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 oral"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/d6e043c8dac8d842d6ba1816e2b687862e46f2bb.pdf"}, "supplementary_material": {"value": "/attachment/4ab11e1b180cfcb265a6b4d81efec2238b2ee878.zip"}, "_bibtex": {"value": "@inproceedings{\nverma2024climode,\ntitle={Clim{ODE}: Climate and Weather Forecasting with Physics-informed Neural {ODE}s},\nauthor={Yogesh Verma and Markus Heinonen and Vikas Garg},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=xuY33XhEGR}\n}"}, "paperhash": {"value": "verma|climode_climate_and_weather_forecasting_with_physicsinformed_neural_odes"}}, "number": 7174, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission7174/-/Revision", "ICLR.cc/2024/Conference/Submission7174/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission7174/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695459335703, "cdate": 1695459335703, "tmdate": 1713672052718, "mdate": 1713672052718, "pdate": 1705411001076, "version": 2, "details": {"replyCount": 23, "presentation": [{"name": "title", "order": 1}, {"name": "authors", "order": 3}, {"name": "code_of_ethics", "order": 3, "input": "checkbox", "value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "description": null}, {"name": "authorids", "order": 4}, {"name": "keywords", "order": 4}, {"name": "submission_guidelines", "order": 4, "input": "checkbox", "value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide.", "description": null}, {"name": "TLDR", "order": 5, "fieldName": "TL;DR"}, {"name": "abstract", "order": 6, "input": "textarea", "markdown": true}, {"name": "pdf", "order": 7}, {"name": "anonymous_url", "order": 7, "input": "checkbox", "value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "description": null}, {"name": "supplementary_material", "order": 8}, {"name": "no_acknowledgement_section", "order": 8, "input": "checkbox", "value": "I certify that there is no acknowledgement section in this submission for double blind review.", "description": null}, {"name": "primary_area", "order": 9, "input": "select", "value": "applications to physical sciences (physics, chemistry, biology, etc.)", "description": null}, {"name": "resubmission"}, {"name": "student_author"}, {"name": "large_language_models"}, {"name": "other_comments_on_LLMs"}, {"name": "venue", "hidden": true}, {"name": "venueid", "hidden": true}, {"name": "_bibtex", "input": "textarea"}, {"name": "other_comments"}]}}, {"id": "4Ay23yeuz0", "forum": "4Ay23yeuz0", "signatures": ["ICLR.cc/2024/Conference/Submission6938/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6938/Authors"], "content": {"title": {"value": "Mixed-Type Tabular Data Synthesis with Score-based Diffusion in Latent Space"}, "authors": {"value": ["Hengrui Zhang", "Jiani Zhang", "Zhengyuan Shen", "Balasubramaniam Srinivasan", "Xiao Qin", "Christos Faloutsos", "Huzefa Rangwala", "George Karypis"]}, "authorids": {"value": ["~Hengrui_Zhang1", "~Jiani_Zhang2", "~Zhengyuan_Shen1", "~Balasubramaniam_Srinivasan1", "~Xiao_Qin3", "~Christos_Faloutsos1", "~Huzefa_Rangwala2", "~George_Karypis1"]}, "keywords": {"value": ["Tabular data", "tabular generation", "diffusion models"]}, "abstract": {"value": "Recent advances in tabular data generation have greatly enhanced synthetic data quality. However, extending diffusion models to tabular data is challenging due to the intricately varied distributions and a blend of data types of tabular data. This paper introduces TabSyn, a methodology that synthesizes tabular data by leveraging a diffusion model within a variational autoencoder (VAE) crafted latent space. The key advantages of the proposed Tabsyn include (1) Generality: the ability to handle a broad spectrum of data types by converting them into a single unified space and explicitly capturing inter-column relations; (2) Quality: optimizing the distribution of latent embeddings to enhance the subsequent training of diffusion models, which helps generate high-quality synthetic data; (3) Speed: much fewer number of reverse steps and faster synthesis speed than existing diffusion-based methods. Extensive experiments on six datasets with five metrics demonstrate that Tabsyn outperforms existing methods. Specifically, it reduces the error rates by 86% and 67% for column-wise distribution and pair-wise column correlation estimations compared with the most competitive baselines. The code has been made available at https://github.com/amazon-science/tabsyn."}, "primary_area": {"value": "generative models"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 oral"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/a916d9616f8be0fc9c47c323b6afe8398acf898d.pdf"}, "_bibtex": {"value": "@inproceedings{\nzhang2024mixedtype,\ntitle={Mixed-Type Tabular Data Synthesis with Score-based Diffusion in Latent Space},\nauthor={Hengrui Zhang and Jiani Zhang and Zhengyuan Shen and Balasubramaniam Srinivasan and Xiao Qin and Christos Faloutsos and Huzefa Rangwala and George Karypis},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=4Ay23yeuz0}\n}"}, "paperhash": {"value": "zhang|mixedtype_tabular_data_synthesis_with_scorebased_diffusion_in_latent_space"}}, "number": 6938, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6938/-/Revision", "ICLR.cc/2024/Conference/Submission6938/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6938/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695447541558, "cdate": 1695447541558, "tmdate": 1709661536299, "mdate": 1709661536299, "pdate": 1705410992710, "version": 2, "details": {"replyCount": 21, "presentation": [{"name": "title", "order": 1}, {"name": "authors", "order": 3}, {"name": "code_of_ethics", "order": 3, "input": "checkbox", "value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "description": null}, {"name": "authorids", "order": 4}, {"name": "keywords", "order": 4}, {"name": "submission_guidelines", "order": 4, "input": "checkbox", "value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide.", "description": null}, {"name": "TLDR", "order": 5, "fieldName": "TL;DR"}, {"name": "abstract", "order": 6, "input": "textarea", "markdown": true}, {"name": "pdf", "order": 7}, {"name": "anonymous_url", "order": 7, "input": "checkbox", "value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "description": null}, {"name": "supplementary_material", "order": 8}, {"name": "no_acknowledgement_section", "order": 8, "input": "checkbox", "value": "I certify that there is no acknowledgement section in this submission for double blind review.", "description": null}, {"name": "primary_area", "order": 9, "input": "select", "value": "generative models", "description": null}, {"name": "resubmission"}, {"name": "student_author"}, {"name": "large_language_models"}, {"name": "other_comments_on_LLMs"}, {"name": "venue", "hidden": true}, {"name": "venueid", "hidden": true}, {"name": "_bibtex", "input": "textarea"}, {"name": "other_comments"}]}}, {"id": "bNt7oajl2a", "forum": "bNt7oajl2a", "signatures": ["ICLR.cc/2024/Conference/Submission6886/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6886/Authors"], "content": {"title": {"value": "Phenomenal Yet Puzzling: Testing Inductive Reasoning Capabilities of Language Models with Hypothesis Refinement"}, "authors": {"value": ["Linlu Qiu", "Liwei Jiang", "Ximing Lu", "Melanie Sclar", "Valentina Pyatkin", "Chandra Bhagavatula", "Bailin Wang", "Yoon Kim", "Yejin Choi", "Nouha Dziri", "Xiang Ren"]}, "authorids": {"value": ["~Linlu_Qiu1", "~Liwei_Jiang2", "~Ximing_Lu1", "~Melanie_Sclar1", "~Valentina_Pyatkin1", "~Chandra_Bhagavatula1", "~Bailin_Wang3", "~Yoon_Kim1", "~Yejin_Choi1", "~Nouha_Dziri2", "~Xiang_Ren1"]}, "keywords": {"value": ["language model", "natural language processing", "inductive reasoning"]}, "abstract": {"value": "The ability to derive underlying principles from a handful of observations and then generalize to novel situations---known as inductive reasoning---is central to human intelligence. Prior work suggests that language models (LMs) often fall short on inductive reasoning, despite achieving impressive success on research benchmarks. In this work, we conduct a systematic study of the inductive reasoning capabilities of LMs through $\\textit{iterative hypothesis refinement}$, a technique that more closely mirrors the human inductive process than standard input-output prompting. Iterative hypothesis refinement employs a three-step process: proposing, selecting, and refining hypotheses in the form of textual rules. By examining the intermediate rules, we observe that LMs are phenomenal $\\textit{hypothesis proposers}$ (i.e., generating candidate rules), and when coupled with a (task-specific) symbolic interpreter that is able to systematically filter the proposed set of rules, this hybrid approach achieves strong results across inductive reasoning benchmarks that require inducing causal relations, language-like instructions, and symbolic concepts. However, they also behave as puzzling $\\textit{inductive reasoners}$, showing notable performance gaps between rule induction (i.e., identifying plausible rules) and rule application (i.e., applying proposed rules to instances), suggesting that LMs are proposing hypotheses without being able to actually apply the rules. Through empirical and human analyses, we further reveal several discrepancies between the inductive reasoning processes of LMs and humans, shedding light on both the potentials and limitations of using LMs in inductive reasoning tasks."}, "primary_area": {"value": "general machine learning (i.e., none of the above)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 oral"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/4032df754ed3bcf600b7b70606e1de283e796547.pdf"}, "_bibtex": {"value": "@inproceedings{\nqiu2024phenomenal,\ntitle={Phenomenal Yet Puzzling: Testing Inductive Reasoning Capabilities of Language Models with Hypothesis Refinement},\nauthor={Linlu Qiu and Liwei Jiang and Ximing Lu and Melanie Sclar and Valentina Pyatkin and Chandra Bhagavatula and Bailin Wang and Yoon Kim and Yejin Choi and Nouha Dziri and Xiang Ren},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=bNt7oajl2a}\n}"}, "paperhash": {"value": "qiu|phenomenal_yet_puzzling_testing_inductive_reasoning_capabilities_of_language_models_with_hypothesis_refinement"}}, "number": 6886, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6886/-/Revision", "ICLR.cc/2024/Conference/Submission6886/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6886/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695444342366, "cdate": 1695444342366, "tmdate": 1710791353423, "mdate": 1710791353423, "pdate": 1705410990790, "version": 2, "details": {"replyCount": 20, "presentation": [{"name": "title", "order": 1}, {"name": "authors", "order": 3}, {"name": "code_of_ethics", "order": 3, "input": "checkbox", "value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "description": null}, {"name": "authorids", "order": 4}, {"name": "keywords", "order": 4}, {"name": "submission_guidelines", "order": 4, "input": "checkbox", "value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide.", "description": null}, {"name": "TLDR", "order": 5, "fieldName": "TL;DR"}, {"name": "abstract", "order": 6, "input": "textarea", "markdown": true}, {"name": "pdf", "order": 7}, {"name": "anonymous_url", "order": 7, "input": "checkbox", "value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "description": null}, {"name": "supplementary_material", "order": 8}, {"name": "no_acknowledgement_section", "order": 8, "input": "checkbox", "value": "I certify that there is no acknowledgement section in this submission for double blind review.", "description": null}, {"name": "primary_area", "order": 9, "input": "select", "value": "general machine learning (i.e., none of the above)", "description": null}, {"name": "resubmission"}, {"name": "student_author"}, {"name": "large_language_models"}, {"name": "other_comments_on_LLMs"}, {"name": "venue", "hidden": true}, {"name": "venueid", "hidden": true}, {"name": "_bibtex", "input": "textarea"}, {"name": "other_comments"}]}}, {"id": "HSKaGOi7Ar", "forum": "HSKaGOi7Ar", "signatures": ["ICLR.cc/2024/Conference/Submission6795/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6795/Authors"], "content": {"title": {"value": "Beyond Weisfeiler-Lehman: A Quantitative Framework for GNN Expressiveness"}, "authors": {"value": ["Bohang Zhang", "Jingchu Gai", "Yiheng Du", "Qiwei Ye", "Di He", "Liwei Wang"]}, "authorids": {"value": ["~Bohang_Zhang1", "~Jingchu_Gai1", "~Yiheng_Du1", "~Qiwei_Ye1", "~Di_He1", "~Liwei_Wang1"]}, "keywords": {"value": ["Graph Neural Networks", "Expressive Power", "Homomorphism", "Subgraph Counting", "Weisfeiler-Lehman"]}, "abstract": {"value": "Designing expressive Graph Neural Networks (GNNs) is a fundamental topic in the graph learning community. So far, GNN expressiveness has been primarily assessed via the Weisfeiler-Lehman (WL) hierarchy. However, such an expressivity measure has notable limitations: it is inherently coarse, qualitative, and may not well reflect practical requirements (e.g., the ability to encode substructures). In this paper, we introduce a novel framework for quantitatively studying the expressiveness of GNN architectures, addressing all the above limitations. Specifically, we identify a fundamental expressivity measure termed homomorphism expressivity, which quantifies the ability of GNN models to count graphs under homomorphism. Homomorphism expressivity offers a complete and practical assessment tool: the completeness enables direct expressivity comparisons between GNN models, while the practicality allows for understanding concrete GNN abilities such as subgraph counting. By examining four classes of prominent GNNs as case studies, we derive simple, unified, and elegant descriptions of their homomorphism expressivity for both invariant and equivariant settings. Our results provide novel insights into a series of previous work, unify the landscape of different subareas in the community, and settle several open questions. Empirically, extensive experiments on both synthetic and real-world tasks verify our theory, showing that the practical performance of GNN models aligns well with the proposed metric."}, "primary_area": {"value": "unsupervised, self-supervised, semi-supervised, and supervised representation learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 oral"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/1cdf9d7930ee08e1c02c2c2819a16e7a2cc56a4b.pdf"}, "_bibtex": {"value": "@inproceedings{\nzhang2024beyond,\ntitle={Beyond Weisfeiler-Lehman: A Quantitative Framework for {GNN} Expressiveness},\nauthor={Bohang Zhang and Jingchu Gai and Yiheng Du and Qiwei Ye and Di He and Liwei Wang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=HSKaGOi7Ar}\n}"}, "paperhash": {"value": "zhang|beyond_weisfeilerlehman_a_quantitative_framework_for_gnn_expressiveness"}}, "number": 6795, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6795/-/Revision", "ICLR.cc/2024/Conference/Submission6795/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6795/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695439977927, "cdate": 1695439977927, "tmdate": 1710475662290, "mdate": 1710475662290, "pdate": 1705410987419, "version": 2, "details": {"replyCount": 24, "presentation": [{"name": "title", "order": 1}, {"name": "authors", "order": 3}, {"name": "code_of_ethics", "order": 3, "input": "checkbox", "value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "description": null}, {"name": "authorids", "order": 4}, {"name": "keywords", "order": 4}, {"name": "submission_guidelines", "order": 4, "input": "checkbox", "value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide.", "description": null}, {"name": "TLDR", "order": 5, "fieldName": "TL;DR"}, {"name": "abstract", "order": 6, "input": "textarea", "markdown": true}, {"name": "pdf", "order": 7}, {"name": "anonymous_url", "order": 7, "input": "checkbox", "value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "description": null}, {"name": "supplementary_material", "order": 8}, {"name": "no_acknowledgement_section", "order": 8, "input": "checkbox", "value": "I certify that there is no acknowledgement section in this submission for double blind review.", "description": null}, {"name": "primary_area", "order": 9, "input": "select", "value": "unsupervised, self-supervised, semi-supervised, and supervised representation learning", "description": null}, {"name": "resubmission"}, {"name": "student_author"}, {"name": "large_language_models"}, {"name": "other_comments_on_LLMs"}, {"name": "venue", "hidden": true}, {"name": "venueid", "hidden": true}, {"name": "_bibtex", "input": "textarea"}, {"name": "other_comments"}]}}, {"id": "KUNzEQMWU7", "forum": "KUNzEQMWU7", "signatures": ["ICLR.cc/2024/Conference/Submission6738/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6738/Authors"], "content": {"title": {"value": "MathVista: Evaluating Mathematical Reasoning of Foundation Models in Visual Contexts"}, "authors": {"value": ["Pan Lu", "Hritik Bansal", "Tony Xia", "Jiacheng Liu", "Chunyuan Li", "Hannaneh Hajishirzi", "Hao Cheng", "Kai-Wei Chang", "Michel Galley", "Jianfeng Gao"]}, "authorids": {"value": ["~Pan_Lu2", "~Hritik_Bansal2", "~Tony_Xia1", "~Jiacheng_Liu2", "~Chunyuan_Li1", "~Hannaneh_Hajishirzi1", "~Hao_Cheng4", "~Kai-Wei_Chang1", "~Michel_Galley1", "~Jianfeng_Gao1"]}, "keywords": {"value": ["large language models", "large multimodal models", "mathematical reasoning", "vision-language reasoning", "foundation models and their evaluations"]}, "abstract": {"value": "Large Language Models (LLMs) and Large Multimodal Models (LMMs) exhibit impressive problem-solving skills in many tasks and domains, but their ability in mathematical reasoning in visual contexts has not been systematically studied. To bridge this gap, we present MathVista, a benchmark designed to combine challenges from diverse mathematical and visual tasks. It consists of 6,141 examples, derived from 28 existing multimodal datasets involving mathematics and 3 newly created datasets (i.e., IQTest, FunctionQA, and PaperQA). Completing these tasks requires fine-grained, deep visual understanding and compositional reasoning, which all state-of-the-art foundation models find challenging. With MathVista, we have conducted a comprehensive, quantitative evaluation of 12 prominent foundation models. The best-performing GPT-4V model achieves an overall accuracy of 49.9%, substantially outperforming Bard, the second-best performer, by 15.1%. Our in-depth analysis reveals that the superiority of GPT-4V is mainly attributed to its enhanced visual perception and mathematical reasoning. However, GPT-4V still falls short of human performance by 10.4%, as it often struggles to understand complex figures and perform rigorous reasoning. This significant gap underscores the critical role that MathVista will play in the development of general-purpose AI agents capable of tackling mathematically intensive and visually rich real-world tasks. We further explore the new ability of self-verification, the application of self-consistency, and the interactive chatbot capabilities of GPT-4V, highlighting its promising potential for future research. The project is available at https://mathvista.github.io/."}, "primary_area": {"value": "datasets and benchmarks"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 oral"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/787a339a2bb6e601216540a43a659322ff3e4e9e.pdf"}, "TLDR": {"value": "We introduce MathVista, a novel benchmark for evaluating mathematical reasoning capabilities within visual contexts, and conduct extensive experiments on 11 foundation models."}, "_bibtex": {"value": "@inproceedings{\nlu2024mathvista,\ntitle={MathVista: Evaluating Mathematical Reasoning of Foundation Models in Visual Contexts},\nauthor={Pan Lu and Hritik Bansal and Tony Xia and Jiacheng Liu and Chunyuan Li and Hannaneh Hajishirzi and Hao Cheng and Kai-Wei Chang and Michel Galley and Jianfeng Gao},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=KUNzEQMWU7}\n}"}, "paperhash": {"value": "lu|mathvista_evaluating_mathematical_reasoning_of_foundation_models_in_visual_contexts"}}, "number": 6738, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6738/-/Revision", "ICLR.cc/2024/Conference/Submission6738/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6738/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695437335328, "cdate": 1695437335328, "tmdate": 1710461815644, "mdate": 1710461815644, "pdate": 1705410985360, "version": 2, "details": {"replyCount": 26, "presentation": [{"name": "title", "order": 1}, {"name": "authors", "order": 3}, {"name": "code_of_ethics", "order": 3, "input": "checkbox", "value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "description": null}, {"name": "authorids", "order": 4}, {"name": "keywords", "order": 4}, {"name": "submission_guidelines", "order": 4, "input": "checkbox", "value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide.", "description": null}, {"name": "TLDR", "order": 5, "fieldName": "TL;DR"}, {"name": "abstract", "order": 6, "input": "textarea", "markdown": true}, {"name": "pdf", "order": 7}, {"name": "anonymous_url", "order": 7, "input": "checkbox", "value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "description": null}, {"name": "supplementary_material", "order": 8}, {"name": "no_acknowledgement_section", "order": 8, "input": "checkbox", "value": "I certify that there is no acknowledgement section in this submission for double blind review.", "description": null}, {"name": "primary_area", "order": 9, "input": "select", "value": "datasets and benchmarks", "description": null}, {"name": "resubmission"}, {"name": "student_author"}, {"name": "large_language_models"}, {"name": "other_comments_on_LLMs"}, {"name": "venue", "hidden": true}, {"name": "venueid", "hidden": true}, {"name": "_bibtex", "input": "textarea"}, {"name": "other_comments"}]}}, {"id": "zMPHKOmQNb", "forum": "zMPHKOmQNb", "signatures": ["ICLR.cc/2024/Conference/Submission6610/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6610/Authors"], "content": {"title": {"value": "Protein Discovery with Discrete Walk-Jump Sampling"}, "authors": {"value": ["Nathan C. Frey", "Dan Berenberg", "Karina Zadorozhny", "Joseph Kleinhenz", "Julien Lafrance-Vanasse", "Isidro Hotzel", "Yan Wu", "Stephen Ra", "Richard Bonneau", "Kyunghyun Cho", "Andreas Loukas", "Vladimir Gligorijevic", "Saeed Saremi"]}, "authorids": {"value": ["~Nathan_C._Frey1", "~Dan_Berenberg1", "~Karina_Zadorozhny1", "~Joseph_Kleinhenz1", "~Julien_Lafrance-Vanasse1", "~Isidro_Hotzel1", "~Yan_Wu7", "~Stephen_Ra1", "~Richard_Bonneau2", "~Kyunghyun_Cho1", "~Andreas_Loukas1", "~Vladimir_Gligorijevic2", "~Saeed_Saremi1"]}, "keywords": {"value": ["generative modeling", "langevin mcmc", "energy-based models", "score-based models", "protein design", "protein discovery"]}, "TLDR": {"value": "We resolve difficulties in training and sampling from a discrete generative model by learning a smoothed energy function, sampling from the smoothed data manifold, and projecting back to the true data manifold with one-step denoising."}, "abstract": {"value": "We resolve difficulties in training and sampling from a discrete generative model by learning a smoothed energy function, sampling from the smoothed data manifold with Langevin Markov chain Monte Carlo (MCMC), and projecting back to the true data manifold with one-step denoising. Our $\\textit{Discrete Walk-Jump Sampling}$ formalism combines the contrastive divergence training of an energy-based model and improved sample quality of a score-based model, while simplifying training and sampling by requiring only a single noise level. We evaluate the robustness of our approach on generative modeling of antibody proteins and introduce the $\\textit{distributional conformity score}$ to benchmark protein generative models. By optimizing and sampling from our models for the proposed distributional conformity score, 97-100\\% of generated samples are successfully expressed and purified and 70\\% of functional designs show equal or improved binding affinity compared to known functional antibodies on the first attempt in a single round of laboratory experiments. We also report the first demonstration of long-run fast-mixing MCMC chains where diverse antibody protein classes are visited in a single MCMC chain."}, "primary_area": {"value": "applications to physical sciences (physics, chemistry, biology, etc.)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 oral"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/bd2adb2c58bf36a145a6eb40e827467a71d7aaf1.pdf"}, "_bibtex": {"value": "@inproceedings{\nfrey2024protein,\ntitle={Protein Discovery with Discrete Walk-Jump Sampling},\nauthor={Nathan C. Frey and Dan Berenberg and Karina Zadorozhny and Joseph Kleinhenz and Julien Lafrance-Vanasse and Isidro Hotzel and Yan Wu and Stephen Ra and Richard Bonneau and Kyunghyun Cho and Andreas Loukas and Vladimir Gligorijevic and Saeed Saremi},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=zMPHKOmQNb}\n}"}, "paperhash": {"value": "frey|protein_discovery_with_discrete_walkjump_sampling"}}, "number": 6610, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6610/-/Revision", "ICLR.cc/2024/Conference/Submission6610/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6610/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695430573478, "cdate": 1695430573478, "tmdate": 1713256134191, "mdate": 1713256134191, "pdate": 1705410981054, "version": 2, "details": {"replyCount": 9, "presentation": [{"name": "title", "order": 1}, {"name": "authors", "order": 3}, {"name": "code_of_ethics", "order": 3, "input": "checkbox", "value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "description": null}, {"name": "authorids", "order": 4}, {"name": "keywords", "order": 4}, {"name": "submission_guidelines", "order": 4, "input": "checkbox", "value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide.", "description": null}, {"name": "TLDR", "order": 5, "fieldName": "TL;DR"}, {"name": "abstract", "order": 6, "input": "textarea", "markdown": true}, {"name": "pdf", "order": 7}, {"name": "anonymous_url", "order": 7, "input": "checkbox", "value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "description": null}, {"name": "supplementary_material", "order": 8}, {"name": "no_acknowledgement_section", "order": 8, "input": "checkbox", "value": "I certify that there is no acknowledgement section in this submission for double blind review.", "description": null}, {"name": "primary_area", "order": 9, "input": "select", "value": "applications to physical sciences (physics, chemistry, biology, etc.)", "description": null}, {"name": "resubmission"}, {"name": "student_author"}, {"name": "large_language_models"}, {"name": "other_comments_on_LLMs"}, {"name": "venue", "hidden": true}, {"name": "venueid", "hidden": true}, {"name": "_bibtex", "input": "textarea"}, {"name": "other_comments"}]}}, {"id": "oTRwljRgiv", "forum": "oTRwljRgiv", "signatures": ["ICLR.cc/2024/Conference/Submission6600/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6600/Authors"], "content": {"title": {"value": "ExeDec: Execution Decomposition for Compositional Generalization in Neural Program Synthesis"}, "authors": {"value": ["Kensen Shi", "Joey Hong", "Yinlin Deng", "Pengcheng Yin", "Manzil Zaheer", "Charles Sutton"]}, "authorids": {"value": ["~Kensen_Shi1", "~Joey_Hong2", "yinlind2@illinois.edu", "~Pengcheng_Yin1", "~Manzil_Zaheer1", "~Charles_Sutton1"]}, "keywords": {"value": ["Program Synthesis", "Programming By Example", "Generalization", "Compositional Generalization"]}, "TLDR": {"value": "We describe different forms of compositional generalization that are desirable in program synthesis, and present a decomposition-based approach to synthesis achieving higher compositional generalization on two domains compared to prior approaches."}, "abstract": {"value": "When writing programs, people have the ability to tackle a new complex task by decomposing it into smaller and more familiar subtasks. While it is difficult to measure whether neural program synthesis methods have similar capabilities, we can measure whether they compositionally generalize, that is, whether a model that has been trained on the simpler subtasks is subsequently able to solve more complex tasks. In this paper, we characterize several different forms of compositional generalization that are desirable in program synthesis, forming a meta-benchmark which we use to create generalization tasks for two popular datasets, RobustFill and DeepCoder. We then propose ExeDec, a novel decomposition-based synthesis strategy that predicts execution subgoals to solve problems step-by-step informed by program execution at each step. When used with Transformer models trained from scratch, ExeDec has better synthesis performance and greatly improved compositional generalization ability compared to baselines. Finally, we use our benchmarks to demonstrate that LLMs struggle to compositionally generalize when asked to do programming-by-example in a few-shot setting, but an ExeDec-style prompting approach can improve the generalization ability and overall performance."}, "primary_area": {"value": "generative models"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 oral"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/a69b0e436a40cc8061344c5a3db100f446f53ee6.pdf"}, "_bibtex": {"value": "@inproceedings{\nshi2024exedec,\ntitle={ExeDec: Execution Decomposition for Compositional Generalization in Neural Program Synthesis},\nauthor={Kensen Shi and Joey Hong and Yinlin Deng and Pengcheng Yin and Manzil Zaheer and Charles Sutton},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=oTRwljRgiv}\n}"}, "paperhash": {"value": "shi|exedec_execution_decomposition_for_compositional_generalization_in_neural_program_synthesis"}}, "number": 6600, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6600/-/Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6600/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695430027086, "cdate": 1695430027086, "tmdate": 1713474622369, "mdate": 1713474622369, "pdate": 1705410980702, "version": 2, "details": {"replyCount": 13, "presentation": [{"name": "title", "order": 1}, {"name": "authors", "order": 3}, {"name": "code_of_ethics", "order": 3, "input": "checkbox", "value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "description": null}, {"name": "authorids", "order": 4}, {"name": "keywords", "order": 4}, {"name": "submission_guidelines", "order": 4, "input": "checkbox", "value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide.", "description": null}, {"name": "TLDR", "order": 5, "fieldName": "TL;DR"}, {"name": "abstract", "order": 6, "input": "textarea", "markdown": true}, {"name": "pdf", "order": 7}, {"name": "anonymous_url", "order": 7, "input": "checkbox", "value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "description": null}, {"name": "supplementary_material", "order": 8}, {"name": "no_acknowledgement_section", "order": 8, "input": "checkbox", "value": "I certify that there is no acknowledgement section in this submission for double blind review.", "description": null}, {"name": "primary_area", "order": 9, "input": "select", "value": "generative models", "description": null}, {"name": "resubmission"}, {"name": "student_author"}, {"name": "large_language_models"}, {"name": "other_comments_on_LLMs"}, {"name": "venue", "hidden": true}, {"name": "venueid", "hidden": true}, {"name": "_bibtex", "input": "textarea"}, {"name": "other_comments"}]}}, {"id": "w4abltTZ2f", "forum": "w4abltTZ2f", "signatures": ["ICLR.cc/2024/Conference/Submission6581/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6581/Authors"], "content": {"title": {"value": "Batched Low-Rank Adaptation of Foundation Models"}, "authors": {"value": ["Yeming Wen", "Swarat Chaudhuri"]}, "authorids": {"value": ["~Yeming_Wen1", "~Swarat_Chaudhuri1"]}, "keywords": {"value": ["LLM Adaptation", "Low-rank", "Code Generation"]}, "abstract": {"value": "Low-Rank Adaptation (LoRA) has recently gained attention for fine-tuning foundation models by incorporating trainable low-rank matrices, thereby reducing the number of trainable parameters. While \\lora/ offers numerous advantages, its applicability for real-time serving to a diverse and global user base \nis constrained by its incapability to handle multiple task-specific adapters efficiently. This imposes a performance bottleneck in scenarios requiring personalized, task-specific adaptations for each incoming request.\n\nTo address this, we introduce FLoRA (Fast LoRA), a framework in which each input example in a minibatch can be associated with its unique low-rank adaptation weights, allowing for efficient batching of heterogeneous requests. We empirically demonstrate that \\flora/ retains the performance merits of \\lora/, showcasing competitive results on the MultiPL-E code generation benchmark spanning over 8 languages and a multilingual speech recognition task across 6 languages."}, "primary_area": {"value": "generative models"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 oral"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/49eea165a2219adfe98557e7d54b6ca13ebb7db9.pdf"}, "supplementary_material": {"value": "/attachment/b123c13d023bc1349d947752af263bddf3009be5.zip"}, "TLDR": {"value": "we introduce Fast LoRA (FLoRA), a framework in which each input example in a minibatch can be associated with its unique low-rank adaptation weights, allowing for efficient batching for diverse LLM queries."}, "_bibtex": {"value": "@inproceedings{\nwen2024batched,\ntitle={Batched Low-Rank Adaptation of Foundation Models},\nauthor={Yeming Wen and Swarat Chaudhuri},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=w4abltTZ2f}\n}"}, "paperhash": {"value": "wen|batched_lowrank_adaptation_of_foundation_models"}}, "number": 6581, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6581/-/Revision", "ICLR.cc/2024/Conference/Submission6581/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6581/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695429166581, "cdate": 1695429166581, "tmdate": 1711666047477, "mdate": 1711666047477, "pdate": 1705410980167, "version": 2, "details": {"replyCount": 13, "presentation": [{"name": "title", "order": 1}, {"name": "authors", "order": 3}, {"name": "code_of_ethics", "order": 3, "input": "checkbox", "value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "description": null}, {"name": "authorids", "order": 4}, {"name": "keywords", "order": 4}, {"name": "submission_guidelines", "order": 4, "input": "checkbox", "value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide.", "description": null}, {"name": "TLDR", "order": 5, "fieldName": "TL;DR"}, {"name": "abstract", "order": 6, "input": "textarea", "markdown": true}, {"name": "pdf", "order": 7}, {"name": "anonymous_url", "order": 7, "input": "checkbox", "value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "description": null}, {"name": "supplementary_material", "order": 8}, {"name": "no_acknowledgement_section", "order": 8, "input": "checkbox", "value": "I certify that there is no acknowledgement section in this submission for double blind review.", "description": null}, {"name": "primary_area", "order": 9, "input": "select", "value": "generative models", "description": null}, {"name": "resubmission"}, {"name": "student_author"}, {"name": "large_language_models"}, {"name": "other_comments_on_LLMs"}, {"name": "venue", "hidden": true}, {"name": "venueid", "hidden": true}, {"name": "_bibtex", "input": "textarea"}, {"name": "other_comments"}]}}, {"id": "IYxDy2jDFL", "forum": "IYxDy2jDFL", "signatures": ["ICLR.cc/2024/Conference/Submission6552/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6552/Authors"], "content": {"title": {"value": "Improved Active Learning via Dependent Leverage Score Sampling"}, "authors": {"value": ["Atsushi Shimizu", "Xiaoou Cheng", "Christopher Musco", "Jonathan Weare"]}, "authorids": {"value": ["~Atsushi_Shimizu1", "~Xiaoou_Cheng1", "~Christopher_Musco1", "~Jonathan_Weare1"]}, "keywords": {"value": ["leverage score sampling", "active learning", "polynomial regression", "differential equations", "pivotal sampling"]}, "TLDR": {"value": "Better active learning (in theory and practice) in the presence of adversarial noise via non-independent leverage score sampling."}, "abstract": {"value": "We show how to obtain improved active learning methods in the agnostic (adversarial noise) setting by combining marginal leverage score sampling with non-independent sampling strategies that promote spatial coverage. In particular, we propose an easily implemented method based on the \\emph{pivotal sampling algorithm}, which we test on problems motivated by learning-based methods for parametric PDEs and uncertainty quantification. In comparison to independent sampling, our method reduces the number of samples needed to reach a given target accuracy by up to $50\\%$.\n\nWe support our findings with two theoretical results. First, we show that any non-independent leverage score sampling method that obeys a weak \\emph{one-sided $\\ell_{\\infty}$ independence condition} (which includes pivotal sampling) can actively learn $d$ dimensional linear functions with $O(d\\log d)$ samples, matching independent sampling. This result extends recent work on matrix Chernoff bounds under $\\ell_{\\infty}$ independence, and may be of interest for analyzing other sampling strategies beyond pivotal sampling. Second, we show that, for the important case of polynomial regression, our pivotal method obtains an improved bound of $O(d)$ samples."}, "primary_area": {"value": "general machine learning (i.e., none of the above)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 oral"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/98b84fd00d5f25df5c6927e10d5e51cde527543e.pdf"}, "_bibtex": {"value": "@inproceedings{\nshimizu2024improved,\ntitle={Improved Active Learning via Dependent Leverage Score Sampling},\nauthor={Atsushi Shimizu and Xiaoou Cheng and Christopher Musco and Jonathan Weare},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=IYxDy2jDFL}\n}"}, "paperhash": {"value": "shimizu|improved_active_learning_via_dependent_leverage_score_sampling"}}, "number": 6552, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6552/-/Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6552/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695427300576, "cdate": 1695427300576, "tmdate": 1712711315761, "mdate": 1712711315761, "pdate": 1705410979213, "version": 2, "details": {"replyCount": 16, "presentation": [{"name": "title", "order": 1}, {"name": "authors", "order": 3}, {"name": "code_of_ethics", "order": 3, "input": "checkbox", "value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "description": null}, {"name": "authorids", "order": 4}, {"name": "keywords", "order": 4}, {"name": "submission_guidelines", "order": 4, "input": "checkbox", "value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide.", "description": null}, {"name": "TLDR", "order": 5, "fieldName": "TL;DR"}, {"name": "abstract", "order": 6, "input": "textarea", "markdown": true}, {"name": "pdf", "order": 7}, {"name": "anonymous_url", "order": 7, "input": "checkbox", "value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "description": null}, {"name": "supplementary_material", "order": 8}, {"name": "no_acknowledgement_section", "order": 8, "input": "checkbox", "value": "I certify that there is no acknowledgement section in this submission for double blind review.", "description": null}, {"name": "primary_area", "order": 9, "input": "select", "value": "general machine learning (i.e., none of the above)", "description": null}, {"name": "resubmission"}, {"name": "student_author"}, {"name": "large_language_models"}, {"name": "other_comments_on_LLMs"}, {"name": "venue", "hidden": true}, {"name": "venueid", "hidden": true}, {"name": "_bibtex", "input": "textarea"}, {"name": "other_comments"}]}}, {"id": "uNrFpDPMyo", "forum": "uNrFpDPMyo", "signatures": ["ICLR.cc/2024/Conference/Submission6547/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6547/Authors"], "content": {"title": {"value": "Model Tells You What to Discard: Adaptive KV Cache Compression for LLMs"}, "authors": {"value": ["Suyu Ge", "Yunan Zhang", "Liyuan Liu", "Minjia Zhang", "Jiawei Han", "Jianfeng Gao"]}, "authorids": {"value": ["~Suyu_Ge1", "~Yunan_Zhang1", "~Liyuan_Liu3", "~Minjia_Zhang1", "~Jiawei_Han1", "~Jianfeng_Gao1"]}, "keywords": {"value": ["Large Language Model", "Efficient Inference", "Generative Inference", "Key-Value Cache"]}, "TLDR": {"value": "We introduce adaptive KV cache compression, a plug-and-play method that reduces the memory footprint of generative inference for Large Language Models (LLMs) and accelerates its generation throughput."}, "abstract": {"value": "In this study, we introduce adaptive KV cache compression, a plug-and-play method that reduces the memory footprint of generative inference for Large Language Models (LLMs). Different from the conventional KV cache that retains key and value vectors for all context tokens, we conduct targeted profiling to discern the intrinsic structure of attention modules. Based on the recognized structure, we then construct the KV cache in an adaptive manner: evicting long-range contexts on attention heads emphasizing local contexts, discarding non-special tokens on attention heads centered on special tokens, and only employing the standard KV cache for attention heads that broadly attend to all tokens. Moreover, with the lightweight attention profiling used to guide the construction of the adaptive KV cache, FastGen can be deployed without resource-intensive fine-tuning or re-training. In our experiments across various asks, FastGen demonstrates substantial reduction on GPU memory consumption with negligible generation quality loss. We will release our code and the compatible CUDA kernel for reproducibility."}, "primary_area": {"value": "representation learning for computer vision, audio, language, and other modalities"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 oral"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/757a55aa24be0345fe1687e09fa5ca448934e52f.pdf"}, "_bibtex": {"value": "@inproceedings{\nge2024model,\ntitle={Model Tells You What to Discard: Adaptive {KV} Cache Compression for {LLM}s},\nauthor={Suyu Ge and Yunan Zhang and Liyuan Liu and Minjia Zhang and Jiawei Han and Jianfeng Gao},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=uNrFpDPMyo}\n}"}, "paperhash": {"value": "ge|model_tells_you_what_to_discard_adaptive_kv_cache_compression_for_llms"}}, "number": 6547, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6547/-/Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6547/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695427043679, "cdate": 1695427043679, "tmdate": 1710571899831, "mdate": 1710571899831, "pdate": 1705410979091, "version": 2, "details": {"replyCount": 23, "presentation": [{"name": "title", "order": 1}, {"name": "authors", "order": 3}, {"name": "code_of_ethics", "order": 3, "input": "checkbox", "value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "description": null}, {"name": "authorids", "order": 4}, {"name": "keywords", "order": 4}, {"name": "submission_guidelines", "order": 4, "input": "checkbox", "value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide.", "description": null}, {"name": "TLDR", "order": 5, "fieldName": "TL;DR"}, {"name": "abstract", "order": 6, "input": "textarea", "markdown": true}, {"name": "pdf", "order": 7}, {"name": "anonymous_url", "order": 7, "input": "checkbox", "value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "description": null}, {"name": "supplementary_material", "order": 8}, {"name": "no_acknowledgement_section", "order": 8, "input": "checkbox", "value": "I certify that there is no acknowledgement section in this submission for double blind review.", "description": null}, {"name": "primary_area", "order": 9, "input": "select", "value": "representation learning for computer vision, audio, language, and other modalities", "description": null}, {"name": "resubmission"}, {"name": "student_author"}, {"name": "large_language_models"}, {"name": "other_comments_on_LLMs"}, {"name": "venue", "hidden": true}, {"name": "venueid", "hidden": true}, {"name": "_bibtex", "input": "textarea"}, {"name": "other_comments"}]}}, {"id": "0BqyZSWfzo", "forum": "0BqyZSWfzo", "signatures": ["ICLR.cc/2024/Conference/Submission6514/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6514/Authors"], "content": {"title": {"value": "One-shot Empirical Privacy Estimation for Federated Learning"}, "authors": {"value": ["Galen Andrew", "Peter Kairouz", "Sewoong Oh", "Alina Oprea", "Hugh Brendan McMahan", "Vinith Menon Suriyakumar"]}, "authorids": {"value": ["~Galen_Andrew1", "~Peter_Kairouz1", "~Sewoong_Oh3", "~Alina_Oprea1", "~Hugh_Brendan_McMahan1", "~Vinith_Menon_Suriyakumar1"]}, "keywords": {"value": ["differential privacy", "federated learning", "empirical privacy"]}, "TLDR": {"value": "Empirical estimation of privacy during training with minimal overhead, useful when tight analytical bounds are not known, e.g. when the adversary observes only the final model."}, "abstract": {"value": "Privacy estimation techniques for differentially private (DP) algorithms are useful for comparing against analytical bounds, or to empirically measure privacy loss in settings where known analytical bounds are not tight. However, existing privacy auditing techniques usually make strong assumptions on the adversary (e.g., knowledge of intermediate model iterates or the training data distribution), are tailored to specific tasks, model architectures, or DP algorithm, and/or require retraining the model many times (typically on the order of thousands). These shortcomings make deploying such techniques at scale difficult in practice, especially in federated settings where model training can take days or weeks. In this work, we present a novel \u201cone-shot\u201d approach that can systematically address these challenges, allowing efficient auditing or estimation of the privacy loss of a model during the same, single training run used to fit model parameters, and without requiring any a priori knowledge about the model architecture, task, or DP algorithm. We show that our method provides provably correct estimates for the privacy loss under the Gaussian mechanism, and we demonstrate its performance on a well-established FL benchmark dataset under several adversarial threat models."}, "primary_area": {"value": "societal considerations including fairness, safety, privacy"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 oral"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/7808a17938a3798b99894957cc00136bbf609c65.pdf"}, "_bibtex": {"value": "@inproceedings{\nandrew2024oneshot,\ntitle={One-shot Empirical Privacy Estimation for Federated Learning},\nauthor={Galen Andrew and Peter Kairouz and Sewoong Oh and Alina Oprea and Hugh Brendan McMahan and Vinith Menon Suriyakumar},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=0BqyZSWfzo}\n}"}, "paperhash": {"value": "andrew|oneshot_empirical_privacy_estimation_for_federated_learning"}}, "number": 6514, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6514/-/Revision", "ICLR.cc/2024/Conference/Submission6514/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6514/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695425536254, "cdate": 1695425536254, "tmdate": 1713301063975, "mdate": 1713301063975, "pdate": 1705410978238, "version": 2, "details": {"replyCount": 23, "presentation": [{"name": "title", "order": 1}, {"name": "authors", "order": 3}, {"name": "code_of_ethics", "order": 3, "input": "checkbox", "value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "description": null}, {"name": "authorids", "order": 4}, {"name": "keywords", "order": 4}, {"name": "submission_guidelines", "order": 4, "input": "checkbox", "value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide.", "description": null}, {"name": "TLDR", "order": 5, "fieldName": "TL;DR"}, {"name": "abstract", "order": 6, "input": "textarea", "markdown": true}, {"name": "pdf", "order": 7}, {"name": "anonymous_url", "order": 7, "input": "checkbox", "value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "description": null}, {"name": "supplementary_material", "order": 8}, {"name": "no_acknowledgement_section", "order": 8, "input": "checkbox", "value": "I certify that there is no acknowledgement section in this submission for double blind review.", "description": null}, {"name": "primary_area", "order": 9, "input": "select", "value": "societal considerations including fairness, safety, privacy", "description": null}, {"name": "resubmission"}, {"name": "student_author"}, {"name": "large_language_models"}, {"name": "other_comments_on_LLMs"}, {"name": "venue", "hidden": true}, {"name": "venueid", "hidden": true}, {"name": "_bibtex", "input": "textarea"}, {"name": "other_comments"}]}}, {"id": "VTF8yNQM66", "forum": "VTF8yNQM66", "signatures": ["ICLR.cc/2024/Conference/Submission6476/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6476/Authors"], "content": {"title": {"value": "SWE-bench: Can Language Models Resolve Real-world Github Issues?"}, "authors": {"value": ["Carlos E Jimenez", "John Yang", "Alexander Wettig", "Shunyu Yao", "Kexin Pei", "Ofir Press", "Karthik R Narasimhan"]}, "authorids": {"value": ["~Carlos_E_Jimenez1", "~John_Yang3", "~Alexander_Wettig1", "~Shunyu_Yao1", "~Kexin_Pei1", "~Ofir_Press1", "~Karthik_R_Narasimhan1"]}, "keywords": {"value": ["Language models", "Natural language processing", "Software engineering"]}, "TLDR": {"value": "A novel benchmark for evaluating language models that introduces software engineering as a task."}, "abstract": {"value": "Language models have outpaced our ability to evaluate them effectively, but for their future development it is essential to study the frontier of their capabilities. We find real-world software engineering to be a rich, sustainable, and challenging testbed for evaluating the next generation of language models. To this end, we introduce SWE-bench, an evaluation framework consisting of 2,294 software engineering problems drawn from real GitHub issues and corresponding pull requests across 12 popular Python repositories. Given a codebase along with a description of an issue to be resolved, a language model is tasked with editing the codebase to address the issue. Resolving issues in SWE-bench frequently requires understanding and coordinating changes across multiple functions, classes, and even files simultaneously, calling for models to interact with execution environments, process extremely long contexts and perform complex reasoning that goes far beyond traditional code generation tasks. Our evaluations show that both state-of-the-art proprietary models and our fine-tuned model SWE-Llama can resolve only the simplest issues. The best-performing model, Claude 2, is able to solve a mere 1.96% of the issues. Advances on SWE-bench represent steps towards LMs that are more practical, intelligent, and autonomous."}, "primary_area": {"value": "datasets and benchmarks"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 oral"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/c2a76eb44300a738cbd7cb95f5bc04df621f4d25.pdf"}, "supplementary_material": {"value": "/attachment/26a8695734e7f6d2919446fc0aebea1ead373486.zip"}, "_bibtex": {"value": "@inproceedings{\njimenez2024swebench,\ntitle={{SWE}-bench: Can Language Models Resolve Real-world Github Issues?},\nauthor={Carlos E Jimenez and John Yang and Alexander Wettig and Shunyu Yao and Kexin Pei and Ofir Press and Karthik R Narasimhan},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=VTF8yNQM66}\n}"}, "paperhash": {"value": "jimenez|swebench_can_language_models_resolve_realworld_github_issues"}}, "number": 6476, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6476/-/Revision", "ICLR.cc/2024/Conference/Submission6476/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6476/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695423889273, "cdate": 1695423889273, "tmdate": 1710446176753, "mdate": 1710446176753, "pdate": 1705410977147, "version": 2, "details": {"replyCount": 13, "presentation": [{"name": "title", "order": 1}, {"name": "authors", "order": 3}, {"name": "code_of_ethics", "order": 3, "input": "checkbox", "value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "description": null}, {"name": "authorids", "order": 4}, {"name": "keywords", "order": 4}, {"name": "submission_guidelines", "order": 4, "input": "checkbox", "value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide.", "description": null}, {"name": "TLDR", "order": 5, "fieldName": "TL;DR"}, {"name": "abstract", "order": 6, "input": "textarea", "markdown": true}, {"name": "pdf", "order": 7}, {"name": "anonymous_url", "order": 7, "input": "checkbox", "value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "description": null}, {"name": "supplementary_material", "order": 8}, {"name": "no_acknowledgement_section", "order": 8, "input": "checkbox", "value": "I certify that there is no acknowledgement section in this submission for double blind review.", "description": null}, {"name": "primary_area", "order": 9, "input": "select", "value": "datasets and benchmarks", "description": null}, {"name": "resubmission"}, {"name": "student_author"}, {"name": "large_language_models"}, {"name": "other_comments_on_LLMs"}, {"name": "venue", "hidden": true}, {"name": "venueid", "hidden": true}, {"name": "_bibtex", "input": "textarea"}, {"name": "other_comments"}]}}, {"id": "osoWxY8q2E", "forum": "osoWxY8q2E", "signatures": ["ICLR.cc/2024/Conference/Submission6429/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6429/Authors"], "content": {"title": {"value": "ReLU Strikes Back: Exploiting Activation Sparsity in Large Language Models"}, "authors": {"value": ["Seyed Iman Mirzadeh", "Keivan Alizadeh-Vahid", "Sachin Mehta", "Carlo C del Mundo", "Oncel Tuzel", "Golnoosh Samei", "Mohammad Rastegari", "Mehrdad Farajtabar"]}, "authorids": {"value": ["~Seyed_Iman_Mirzadeh1", "~Keivan_Alizadeh-Vahid1", "~Sachin_Mehta1", "~Carlo_C_del_Mundo1", "~Oncel_Tuzel2", "~Golnoosh_Samei1", "~Mohammad_Rastegari2", "~Mehrdad_Farajtabar1"]}, "keywords": {"value": ["Large Language Models", "Sparsity", "Activation Function", "ReLU Activation Function"]}, "abstract": {"value": "Large Language Models (LLMs) with billions of parameters have drastically transformed AI applications. However, their demanding computation during inference has raised significant challenges for deployment on resource-constrained devices. Despite recent trends favoring alternative activation functions such as GELU or SiLU, known for increased computation, this study strongly advocates for reinstating ReLU activation in LLMs. We demonstrate that using the ReLU activation function has a negligible impact on convergence and performance while significantly reducing computation and weight transfer. This reduction is particularly valuable during the memory-bound inference step, where efficiency is paramount. Exploring sparsity patterns in ReLU-based LLMs, we unveil the reutilization of activated neurons for generating new tokens and leveraging these insights, we propose practical strategies to substantially reduce LLM inference computation up to three times, using ReLU activations with minimal performance trade-offs."}, "primary_area": {"value": "general machine learning (i.e., none of the above)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 oral"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/a407324c94efa754d43a6c1718e24541d34e2f24.pdf"}, "_bibtex": {"value": "@inproceedings{\nmirzadeh2024relu,\ntitle={Re{LU} Strikes Back: Exploiting Activation Sparsity in Large Language Models},\nauthor={Seyed Iman Mirzadeh and Keivan Alizadeh-Vahid and Sachin Mehta and Carlo C del Mundo and Oncel Tuzel and Golnoosh Samei and Mohammad Rastegari and Mehrdad Farajtabar},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=osoWxY8q2E}\n}"}, "paperhash": {"value": "mirzadeh|relu_strikes_back_exploiting_activation_sparsity_in_large_language_models"}}, "number": 6429, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6429/-/Revision", "ICLR.cc/2024/Conference/Submission6429/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6429/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695421296768, "cdate": 1695421296768, "tmdate": 1710566212279, "mdate": 1710566212279, "pdate": 1705410975733, "version": 2, "details": {"replyCount": 15, "presentation": [{"name": "title", "order": 1}, {"name": "authors", "order": 3}, {"name": "code_of_ethics", "order": 3, "input": "checkbox", "value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "description": null}, {"name": "authorids", "order": 4}, {"name": "keywords", "order": 4}, {"name": "submission_guidelines", "order": 4, "input": "checkbox", "value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide.", "description": null}, {"name": "TLDR", "order": 5, "fieldName": "TL;DR"}, {"name": "abstract", "order": 6, "input": "textarea", "markdown": true}, {"name": "pdf", "order": 7}, {"name": "anonymous_url", "order": 7, "input": "checkbox", "value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "description": null}, {"name": "supplementary_material", "order": 8}, {"name": "no_acknowledgement_section", "order": 8, "input": "checkbox", "value": "I certify that there is no acknowledgement section in this submission for double blind review.", "description": null}, {"name": "primary_area", "order": 9, "input": "select", "value": "general machine learning (i.e., none of the above)", "description": null}, {"name": "resubmission"}, {"name": "student_author"}, {"name": "large_language_models"}, {"name": "other_comments_on_LLMs"}, {"name": "venue", "hidden": true}, {"name": "venueid", "hidden": true}, {"name": "_bibtex", "input": "textarea"}, {"name": "other_comments"}]}}, {"id": "ze7DOLi394", "forum": "ze7DOLi394", "signatures": ["ICLR.cc/2024/Conference/Submission6358/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6358/Authors"], "content": {"title": {"value": "On the Joint Interaction of Models, Data, and Features"}, "authors": {"value": ["Yiding Jiang", "Christina Baek", "J Zico Kolter"]}, "authorids": {"value": ["~Yiding_Jiang2", "~Christina_Baek2", "~J_Zico_Kolter1"]}, "keywords": {"value": ["Generalization", "feature learning", "empirical phenomena"]}, "abstract": {"value": "Learning features from data is one of the defining characteristics of deep learning,\nbut the theoretical understanding of the role features play in deep learning is still in\nearly development. To address this gap, we introduce a new tool, the interaction\ntensor, for empirically analyzing the interaction between data and model through\nfeatures. With the interaction tensor, we make several key observations about\nhow features are distributed in data and how models with different random seeds\nlearn different features. Based on these observations, we propose a conceptual\nframework for feature learning. Under this framework, the expected accuracy for a\nsingle hypothesis and agreement for a pair of hypotheses can both be derived in\nclosed form. We demonstrate that the proposed framework can explain empirically\nobserved phenomena, including the recently discovered Generalization Disagreement Equality (GDE) that allows for estimating the generalization error with only\nunlabeled data. Further, our theory also provides explicit construction of natural\ndata distributions that break the GDE. Thus, we believe this work provides valuable\nnew insight into our understanding of feature learning."}, "primary_area": {"value": "visualization or interpretation of learned representations"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 oral"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/86a102e47488a58d90fc222cf560db16f68dc65d.pdf"}, "supplementary_material": {"value": "/attachment/7f182dd585626e040afef3bdb2c8ab2af85d88ba.zip"}, "TLDR": {"value": "We propose a framework for feature learning that can explain previously not understood phenommena in deep learning."}, "_bibtex": {"value": "@inproceedings{\njiang2024on,\ntitle={On the Joint Interaction of Models, Data, and Features},\nauthor={Yiding Jiang and Christina Baek and J Zico Kolter},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=ze7DOLi394}\n}"}, "paperhash": {"value": "jiang|on_the_joint_interaction_of_models_data_and_features"}}, "number": 6358, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6358/-/Revision", "ICLR.cc/2024/Conference/Submission6358/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6358/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695418673184, "cdate": 1695418673184, "tmdate": 1712367257270, "mdate": 1712367257270, "pdate": 1705410973491, "version": 2, "details": {"replyCount": 18, "presentation": [{"name": "title", "order": 1}, {"name": "authors", "order": 3}, {"name": "code_of_ethics", "order": 3, "input": "checkbox", "value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "description": null}, {"name": "authorids", "order": 4}, {"name": "keywords", "order": 4}, {"name": "submission_guidelines", "order": 4, "input": "checkbox", "value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide.", "description": null}, {"name": "TLDR", "order": 5, "fieldName": "TL;DR"}, {"name": "abstract", "order": 6, "input": "textarea", "markdown": true}, {"name": "pdf", "order": 7}, {"name": "anonymous_url", "order": 7, "input": "checkbox", "value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "description": null}, {"name": "supplementary_material", "order": 8}, {"name": "no_acknowledgement_section", "order": 8, "input": "checkbox", "value": "I certify that there is no acknowledgement section in this submission for double blind review.", "description": null}, {"name": "primary_area", "order": 9, "input": "select", "value": "visualization or interpretation of learned representations", "description": null}, {"name": "resubmission"}, {"name": "student_author"}, {"name": "large_language_models"}, {"name": "other_comments_on_LLMs"}, {"name": "venue", "hidden": true}, {"name": "venueid", "hidden": true}, {"name": "_bibtex", "input": "textarea"}, {"name": "other_comments"}]}}, {"id": "dLrhRIMVmB", "forum": "dLrhRIMVmB", "signatures": ["ICLR.cc/2024/Conference/Submission6314/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6314/Authors"], "content": {"title": {"value": "Topological data analysis on noisy quantum computers"}, "authors": {"value": ["Ismail Yunus Akhalwaya", "Shashanka Ubaru", "Kenneth L. Clarkson", "Mark S. Squillante", "Vishnu Jejjala", "Yang-Hui He", "Kugendran Naidoo", "Vasileios Kalantzis", "Lior Horesh"]}, "authorids": {"value": ["~Ismail_Yunus_Akhalwaya1", "~Shashanka_Ubaru1", "~Kenneth_L._Clarkson1", "~Mark_S._Squillante1", "~Vishnu_Jejjala1", "~Yang-Hui_He1", "~Kugendran_Naidoo1", "~Vasileios_Kalantzis1", "~Lior_Horesh1"]}, "keywords": {"value": ["Topological data analysis", "quantum computing", "unsupervised learning", "feature extraction"]}, "abstract": {"value": "Topological data analysis (TDA) is a powerful technique for extracting complex and valuable shape-related summaries of high-dimensional data. However, the computational demands of classical algorithms for computing TDA are exorbitant, and quickly become impractical for high-order characteristics. Quantum computers offer the potential of achieving significant speedup for certain computational problems. Indeed, TDA has been purported to be one such problem, yet, quantum computing algorithms proposed for the problem, such as the original Quantum TDA (QTDA) formulation by Lloyd, Garnerone and Zanardi, require fault-tolerance qualifications that are currently unavailable. In this study, we present NISQ-TDA, a fully implemented end-to-end quantum machine learning algorithm needing only a short circuit-depth, that is applicable to high-dimensional classical data, and with provable asymptotic speedup for certain classes of problems. The algorithm neither suffers from the data-loading problem nor does it need to store the input data on the quantum computer explicitly. The algorithm was successfully executed on quantum computing devices, as well as on noisy quantum simulators, applied to small datasets. Preliminary empirical results suggest that the algorithm is robust to noise."}, "primary_area": {"value": "unsupervised, self-supervised, semi-supervised, and supervised representation learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 oral"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/07776ae8b91f82e5061d6b246a4e9aacc7bddb41.pdf"}, "_bibtex": {"value": "@inproceedings{\nakhalwaya2024topological,\ntitle={Topological data analysis on noisy quantum computers},\nauthor={Ismail Yunus Akhalwaya and Shashanka Ubaru and Kenneth L. Clarkson and Mark S. Squillante and Vishnu Jejjala and Yang-Hui He and Kugendran Naidoo and Vasileios Kalantzis and Lior Horesh},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=dLrhRIMVmB}\n}"}, "paperhash": {"value": "akhalwaya|topological_data_analysis_on_noisy_quantum_computers"}}, "number": 6314, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6314/-/Revision", "ICLR.cc/2024/Conference/-/PC_Revision", "ICLR.cc/2024/Conference/Submission6314/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6314/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695416858689, "cdate": 1695416858689, "tmdate": 1713151545521, "mdate": 1713151545521, "pdate": 1705410972042, "version": 2, "details": {"replyCount": 14, "presentation": [{"name": "title", "order": 1}, {"name": "authors", "order": 3}, {"name": "code_of_ethics", "order": 3, "input": "checkbox", "value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "description": null}, {"name": "authorids", "order": 4}, {"name": "keywords", "order": 4}, {"name": "submission_guidelines", "order": 4, "input": "checkbox", "value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide.", "description": null}, {"name": "TLDR", "order": 5, "fieldName": "TL;DR"}, {"name": "resubmission", "order": 5, "input": "radio"}, {"name": "abstract", "order": 6, "input": "textarea", "markdown": true}, {"name": "student_author", "order": 6, "input": "radio"}, {"name": "pdf", "order": 7}, {"name": "anonymous_url", "order": 7, "input": "checkbox", "value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "description": null}, {"name": "supplementary_material", "order": 8}, {"name": "no_acknowledgement_section", "order": 8, "input": "checkbox", "value": "I certify that there is no acknowledgement section in this submission for double blind review.", "description": null}, {"name": "primary_area", "order": 9, "input": "select", "value": "unsupervised, self-supervised, semi-supervised, and supervised representation learning", "description": null}, {"name": "large_language_models", "order": 9, "input": "checkbox"}, {"name": "other_comments_on_LLMs", "order": 10, "input": "textarea"}, {"name": "venue", "hidden": true}, {"name": "venueid", "hidden": true}, {"name": "_bibtex", "input": "textarea"}, {"name": "other_comments"}]}}, {"id": "hSyW5go0v8", "forum": "hSyW5go0v8", "signatures": ["ICLR.cc/2024/Conference/Submission6283/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6283/Authors"], "content": {"title": {"value": "Self-RAG: Learning to Retrieve, Generate, and Critique through Self-Reflection"}, "authors": {"value": ["Akari Asai", "Zeqiu Wu", "Yizhong Wang", "Avirup Sil", "Hannaneh Hajishirzi"]}, "authorids": {"value": ["~Akari_Asai2", "~Zeqiu_Wu1", "~Yizhong_Wang2", "~Avirup_Sil1", "~Hannaneh_Hajishirzi1"]}, "keywords": {"value": ["Retrieval-augmented Generation", "Language Models", "Retrieval-augmented LMs", "Factuality"]}, "TLDR": {"value": "We introduce Self-RAG, a new training and inference framework to enable an LM learn to retrieve, generate and critique."}, "abstract": {"value": "Despite their remarkable capabilities, large language models (LLMs) often produce responses containing factual inaccuracies due to their sole reliance on the parametric knowledge they encapsulate. Retrieval-Augmented Generation (RAG), an ad hoc approach that augments LMs with retrieval of relevant knowledge, decreases such issues. However, indiscriminately retrieving and incorporating a fixed number of retrieved passages, regardless of whether retrieval is necessary, or passages are relevant, diminishes LM versatility or can lead to unhelpful response generation. We introduce a new framework called **Self-Reflective Retrieval-Augmented Generation (Self-RAG)** that enhances an LM's quality and factuality through retrieval and self-reflection. \nOur framework trains a single arbitrary LM that adaptively retrieves passages on-demand, and generates and reflects on retrieved passages and its generations using special tokens, called {\\it reflection} tokens. Generating reflection tokens makes the LM controllable during the inference phase, enabling it to tailor its behavior to diverse task requirements. \nExperiments show that Self-RAG (7B and 13B parameters) significantly outperforms state-of-the-art LLMs and retrieval-augmented models on a diverse set of tasks. \nSpecifically, Self-RAG outperforms ChatGPT and retrieval-augmented Llama2-chat on Open-domain QA, reasoning, and fact verification tasks, and it shows significant gains in improving factuality and citation accuracy for long-form generations relative to these models. Our code and trained models are available at https://selfrag.github.io/"}, "primary_area": {"value": "representation learning for computer vision, audio, language, and other modalities"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 oral"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/9a78cf641fab9032078e65ae2734293ae8e2f398.pdf"}, "_bibtex": {"value": "@inproceedings{\nasai2024selfrag,\ntitle={Self-{RAG}: Learning to Retrieve, Generate, and Critique through Self-Reflection},\nauthor={Akari Asai and Zeqiu Wu and Yizhong Wang and Avirup Sil and Hannaneh Hajishirzi},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=hSyW5go0v8}\n}"}, "paperhash": {"value": "asai|selfrag_learning_to_retrieve_generate_and_critique_through_selfreflection"}}, "number": 6283, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6283/-/Revision", "ICLR.cc/2024/Conference/Submission6283/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Desk_Rejected_Submission", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6283/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695415509020, "cdate": 1695415509020, "tmdate": 1710178010465, "mdate": 1710178010465, "pdate": 1706843939993, "version": 2, "details": {"replyCount": 18, "presentation": [{"name": "title", "order": 1}, {"name": "authors", "order": 3}, {"name": "code_of_ethics", "order": 3, "input": "checkbox", "value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "description": null}, {"name": "authorids", "order": 4}, {"name": "keywords", "order": 4}, {"name": "submission_guidelines", "order": 4, "input": "checkbox", "value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide.", "description": null}, {"name": "TLDR", "order": 5, "fieldName": "TL;DR"}, {"name": "abstract", "order": 6, "input": "textarea", "markdown": true}, {"name": "pdf", "order": 7}, {"name": "anonymous_url", "order": 7, "input": "checkbox", "value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "description": null}, {"name": "supplementary_material", "order": 8}, {"name": "no_acknowledgement_section", "order": 8, "input": "checkbox", "value": "I certify that there is no acknowledgement section in this submission for double blind review.", "description": null}, {"name": "primary_area", "order": 9, "input": "select", "value": "representation learning for computer vision, audio, language, and other modalities", "description": null}, {"name": "resubmission"}, {"name": "student_author"}, {"name": "large_language_models"}, {"name": "other_comments_on_LLMs"}, {"name": "venue"}, {"name": "venueid"}, {"name": "_bibtex", "input": "textarea"}, {"name": "other_comments"}]}}, {"id": "HE9eUQlAvo", "forum": "HE9eUQlAvo", "signatures": ["ICLR.cc/2024/Conference/Submission6213/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6213/Authors"], "content": {"title": {"value": "\"What Data Benefits My Classifier?\" Enhancing Model Performance and Interpretability through Influence-Based Data Selection"}, "authors": {"value": ["Anshuman Chhabra", "Peizhao Li", "Prasant Mohapatra", "Hongfu Liu"]}, "authorids": {"value": ["~Anshuman_Chhabra1", "~Peizhao_Li1", "~Prasant_Mohapatra1", "~Hongfu_Liu2"]}, "keywords": {"value": ["Data Selection", "Interpretability", "Fairness", "Robustness"]}, "abstract": {"value": "Classification models are ubiquitously deployed in society and necessitate high utility, fairness, and robustness performance. Current research efforts mainly focus on improving model architectures and learning algorithms on fixed datasets to achieve this goal. In contrast, in this paper, we address an orthogonal yet crucial problem: given a fixed convex learning model (or a convex surrogate for a non-convex model) and a function of interest, we assess what data benefits the model by interpreting the feature space, and then aim to improve performance as measured by this function. To this end, we propose the use of influence estimation models for interpreting the classifier's performance from the perspective of the data feature space. Additionally, we propose data selection approaches based on influence that enhance model utility, fairness, and robustness. Through extensive experiments on synthetic and real-world datasets, we validate and demonstrate the effectiveness of our approaches not only for conventional classification scenarios, but also under more challenging scenarios such as distribution shifts, fairness poisoning attacks, utility evasion attacks, online learning, and active learning."}, "primary_area": {"value": "general machine learning (i.e., none of the above)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 oral"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/c9c086d91e0480dcd349f7bb625a5031fabcc53a.pdf"}, "_bibtex": {"value": "@inproceedings{\nchhabra2024what,\ntitle={''What Data Benefits My Classifier?'' Enhancing Model Performance and Interpretability through Influence-Based Data Selection},\nauthor={Anshuman Chhabra and Peizhao Li and Prasant Mohapatra and Hongfu Liu},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=HE9eUQlAvo}\n}"}, "paperhash": {"value": "chhabra|what_data_benefits_my_classifier_enhancing_model_performance_and_interpretability_through_influencebased_data_selection"}}, "number": 6213, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6213/-/Revision", "ICLR.cc/2024/Conference/Submission6213/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6213/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695413290465, "cdate": 1695413290465, "tmdate": 1709661528905, "mdate": 1709661528905, "pdate": 1705410969153, "version": 2, "details": {"replyCount": 32, "presentation": [{"name": "title", "order": 1}, {"name": "authors", "order": 3}, {"name": "code_of_ethics", "order": 3, "input": "checkbox", "value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "description": null}, {"name": "authorids", "order": 4}, {"name": "keywords", "order": 4}, {"name": "submission_guidelines", "order": 4, "input": "checkbox", "value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide.", "description": null}, {"name": "TLDR", "order": 5, "fieldName": "TL;DR"}, {"name": "abstract", "order": 6, "input": "textarea", "markdown": true}, {"name": "pdf", "order": 7}, {"name": "anonymous_url", "order": 7, "input": "checkbox", "value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "description": null}, {"name": "supplementary_material", "order": 8}, {"name": "no_acknowledgement_section", "order": 8, "input": "checkbox", "value": "I certify that there is no acknowledgement section in this submission for double blind review.", "description": null}, {"name": "primary_area", "order": 9, "input": "select", "value": "general machine learning (i.e., none of the above)", "description": null}, {"name": "resubmission"}, {"name": "student_author"}, {"name": "large_language_models"}, {"name": "other_comments_on_LLMs"}, {"name": "venue", "hidden": true}, {"name": "venueid", "hidden": true}, {"name": "_bibtex", "input": "textarea"}, {"name": "other_comments"}]}}, {"id": "tUtGjQEDd4", "forum": "tUtGjQEDd4", "signatures": ["ICLR.cc/2024/Conference/Submission6045/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission6045/Authors"], "content": {"title": {"value": "Generative Modeling with Phase Stochastic Bridge"}, "authors": {"value": ["Tianrong Chen", "Jiatao Gu", "Laurent Dinh", "Evangelos Theodorou", "Joshua M. Susskind", "Shuangfei Zhai"]}, "authorids": {"value": ["~Tianrong_Chen1", "~Jiatao_Gu1", "~Laurent_Dinh1", "~Evangelos_Theodorou1", "~Joshua_M._Susskind1", "~Shuangfei_Zhai3"]}, "keywords": {"value": ["Generative Modeling", "Stochastic Optimal Control", "Diffusion Model"]}, "abstract": {"value": "Diffusion models (DMs) represent state-of-the-art generative models for continuous inputs. DMs work by constructing a Stochastic Differential Equation (SDE) in the input space (ie, position space), and using a neural network to reverse it. In this work, we introduce a novel generative modeling framework grounded in \\textbf{phase space dynamics}, where a phase space is defined as {an augmented space encompassing both position and velocity.} Leveraging insights from Stochastic Optimal Control, we construct a path measure in the phase space that enables efficient sampling. {In contrast to DMs, our framework demonstrates the capability to generate realistic data points at an early stage of dynamics propagation.} This early prediction sets the stage for efficient data generation by leveraging additional velocity information along the trajectory. On standard image generation benchmarks, our model yields favorable performance over baselines in the regime of small Number of Function Evaluations (NFEs). Furthermore, our approach rivals the performance of diffusion models equipped with efficient sampling techniques, underscoring its potential as a new tool generative modeling."}, "primary_area": {"value": "generative models"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 oral"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/5d5ddf9cd03dbc97896ca72e62060b33d19f59e7.pdf"}, "supplementary_material": {"value": "/attachment/4c8aa96d9f830e3027a2636aa174785b89edda08.pdf"}, "_bibtex": {"value": "@inproceedings{\nchen2024generative,\ntitle={Generative Modeling with Phase Stochastic Bridge},\nauthor={Tianrong Chen and Jiatao Gu and Laurent Dinh and Evangelos Theodorou and Joshua M. Susskind and Shuangfei Zhai},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=tUtGjQEDd4}\n}"}, "paperhash": {"value": "chen|generative_modeling_with_phase_stochastic_bridge"}}, "number": 6045, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission6045/-/Revision", "ICLR.cc/2024/Conference/Submission6045/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission6045/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "tcdate": 1695406134192, "cdate": 1695406134192, "tmdate": 1713231899997, "mdate": 1713231899997, "pdate": 1705410962903, "version": 2, "details": {"replyCount": 13, "presentation": [{"name": "title", "order": 1}, {"name": "authors", "order": 3}, {"name": "code_of_ethics", "order": 3, "input": "checkbox", "value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "description": null}, {"name": "authorids", "order": 4}, {"name": "keywords", "order": 4}, {"name": "submission_guidelines", "order": 4, "input": "checkbox", "value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide.", "description": null}, {"name": "TLDR", "order": 5, "fieldName": "TL;DR"}, {"name": "abstract", "order": 6, "input": "textarea", "markdown": true}, {"name": "pdf", "order": 7}, {"name": "anonymous_url", "order": 7, "input": "checkbox", "value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "description": null}, {"name": "supplementary_material", "order": 8}, {"name": "no_acknowledgement_section", "order": 8, "input": "checkbox", "value": "I certify that there is no acknowledgement section in this submission for double blind review.", "description": null}, {"name": "primary_area", "order": 9, "input": "select", "value": "generative models", "description": null}, {"name": "resubmission"}, {"name": "student_author"}, {"name": "large_language_models"}, {"name": "other_comments_on_LLMs"}, {"name": "venue", "hidden": true}, {"name": "venueid", "hidden": true}, {"name": "_bibtex", "input": "textarea"}, {"name": "other_comments"}]}}, {"id": "9WD9KwssyT", "forum": "9WD9KwssyT", "number": 5586, "cdate": 1695391973841, "tcdate": 1695391973841, "mdate": 1712664351857, "tmdate": 1712664351857, "signatures": ["ICLR.cc/2024/Conference/Submission5586/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5586/Authors"], "content": {"title": {"value": "Zipformer: A faster and better encoder for automatic speech recognition"}, "authors": {"value": ["Zengwei Yao", "Liyong Guo", "Xiaoyu Yang", "Wei Kang", "Fangjun Kuang", "Yifan Yang", "Zengrui Jin", "Long Lin", "Daniel Povey"]}, "authorids": {"value": ["~Zengwei_Yao1", "~Liyong_Guo1", "~Xiaoyu_Yang7", "~Wei_Kang3", "~Fangjun_Kuang1", "~Yifan_Yang11", "~Zengrui_Jin1", "~Long_Lin1", "~Daniel_Povey2"]}, "keywords": {"value": ["Zipformer", "ScaledAdam", "automatic speech recognition"]}, "abstract": {"value": "The Conformer has become the most popular encoder model for automatic speech recognition (ASR).  It adds convolution modules to a transformer to learn both local and global dependencies. In this work we describe a faster, more memory-efficient, and better-performing transformer, called Zipformer.  Modeling changes include: 1) a U-Net-like encoder structure where middle stacks operate at lower frame rates; 2) reorganized block structure with more modules, within which we re-use attention weights for efficiency; 3) a modified form of LayerNorm called BiasNorm allows us to retain some length information; 4)  new activation functions SwooshR and SwooshL work better than Swish.  We also propose a new optimizer, called ScaledAdam, which scales the update by each tensor's current scale to keep the relative change about the same, and also explictly learns the parameter scale. It achieves faster converge and better performance than Adam. Extensive experiments on LibriSpeech, Aishell-1, and WenetSpeech datasets demonstrate the effectiveness of our proposed Zipformer over other state-of-the-art ASR models. Our code is publicly available at https://github.com/k2-fsa/icefall."}, "primary_area": {"value": "representation learning for computer vision, audio, language, and other modalities"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 oral"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/73f36dfc4a1fa9d3dd37fdb3cb11d5be19364046.pdf"}, "_bibtex": {"value": "@inproceedings{\nyao2024zipformer,\ntitle={Zipformer: A faster and better encoder for automatic speech recognition},\nauthor={Zengwei Yao and Liyong Guo and Xiaoyu Yang and Wei Kang and Fangjun Kuang and Yifan Yang and Zengrui Jin and Long Lin and Daniel Povey},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=9WD9KwssyT}\n}"}, "paperhash": {"value": "yao|zipformer_a_faster_and_better_encoder_for_automatic_speech_recognition"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5586/-/Revision", "ICLR.cc/2024/Conference/Submission5586/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5586/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410944313, "version": 2, "details": {"replyCount": 15, "presentation": [{"name": "title", "order": 1}, {"name": "authors", "order": 3}, {"name": "code_of_ethics", "order": 3, "input": "checkbox", "value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "description": null}, {"name": "authorids", "order": 4}, {"name": "keywords", "order": 4}, {"name": "submission_guidelines", "order": 4, "input": "checkbox", "value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide.", "description": null}, {"name": "TLDR", "order": 5, "fieldName": "TL;DR"}, {"name": "abstract", "order": 6, "input": "textarea", "markdown": true}, {"name": "pdf", "order": 7}, {"name": "anonymous_url", "order": 7, "input": "checkbox", "value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "description": null}, {"name": "supplementary_material", "order": 8}, {"name": "no_acknowledgement_section", "order": 8, "input": "checkbox", "value": "I certify that there is no acknowledgement section in this submission for double blind review.", "description": null}, {"name": "primary_area", "order": 9, "input": "select", "value": "representation learning for computer vision, audio, language, and other modalities", "description": null}, {"name": "resubmission"}, {"name": "student_author"}, {"name": "large_language_models"}, {"name": "other_comments_on_LLMs"}, {"name": "venue", "hidden": true}, {"name": "venueid", "hidden": true}, {"name": "_bibtex", "input": "textarea"}, {"name": "other_comments"}]}}, {"id": "VtmBAGCN7o", "forum": "VtmBAGCN7o", "number": 5488, "cdate": 1695388572615, "tcdate": 1695388572615, "mdate": 1713672554320, "tmdate": 1713672554320, "signatures": ["ICLR.cc/2024/Conference/Submission5488/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5488/Authors"], "content": {"title": {"value": "MetaGPT: Meta Programming for A Multi-Agent Collaborative Framework"}, "authors": {"value": ["Sirui Hong", "Mingchen Zhuge", "Jonathan Chen", "Xiawu Zheng", "Yuheng Cheng", "Jinlin Wang", "Ceyao Zhang", "Zili Wang", "Steven Ka Shing Yau", "Zijuan Lin", "Liyang Zhou", "Chenyu Ran", "Lingfeng Xiao", "Chenglin Wu", "J\u00fcrgen Schmidhuber"]}, "authorids": {"value": ["~Sirui_Hong1", "~Mingchen_Zhuge2", "~Jonathan_Chen3", "~Xiawu_Zheng1", "~Yuheng_Cheng1", "~Jinlin_Wang1", "~Ceyao_Zhang1", "~Zili_Wang1", "~Steven_Ka_Shing_Yau1", "~Zijuan_Lin1", "~Liyang_Zhou2", "~Chenyu_Ran1", "~Lingfeng_Xiao1", "~Chenglin_Wu2", "~J\u00fcrgen_Schmidhuber1"]}, "keywords": {"value": ["Autonomous Agent", "Meta Programming", "Multi-Agent Society", "Group Intelligence"]}, "abstract": {"value": "Recently, remarkable progress has been made on automated problem solving through societies of agents based on large language models (LLMs). Previous LLM-based multi-agent systems can already solve simple dialogue tasks. More complex tasks, however, face challenges through logic inconsistencies due to cascading hallucinations caused by naively chaining LLMs. Here we introduce MetaGPT, an innovative meta-programming framework incorporating efficient human workflows into LLM-based multi-agent collaborations. MetaGPT encodes Standardized Operating Procedures (SOPs) into prompt sequences for more streamlined workflows, thus allowing agents with human-like domain expertise to verify intermediate results and reduce errors.  MetaGPT utilizes an assembly line paradigm to assign diverse roles to various agents, efficiently breaking down complex tasks into subtasks involving many agents working together.  On collaborative software engineering benchmarks, MetaGPT generates more coherent solutions than previous chat-based multi-agent systems."}, "primary_area": {"value": "applications to robotics, autonomy, planning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 oral"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "TLDR": {"value": "This paper introduces MetaGPT, an innovative meta-programming framework for LLM-based multi-agent collaborations."}, "pdf": {"value": "/pdf/474fc6dad3bd9bf7fdb97c7cd72b2cc0649a9647.pdf"}, "_bibtex": {"value": "@inproceedings{\nhong2024metagpt,\ntitle={Meta{GPT}: Meta Programming for A Multi-Agent Collaborative Framework},\nauthor={Sirui Hong and Mingchen Zhuge and Jonathan Chen and Xiawu Zheng and Yuheng Cheng and Jinlin Wang and Ceyao Zhang and Zili Wang and Steven Ka Shing Yau and Zijuan Lin and Liyang Zhou and Chenyu Ran and Lingfeng Xiao and Chenglin Wu and J{\\\"u}rgen Schmidhuber},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=VtmBAGCN7o}\n}"}, "paperhash": {"value": "hong|metagpt_meta_programming_for_a_multiagent_collaborative_framework"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5488/-/Revision", "ICLR.cc/2024/Conference/Submission5488/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5488/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410940732, "version": 2, "details": {"replyCount": 16, "presentation": [{"name": "title", "order": 1}, {"name": "authors", "order": 3}, {"name": "code_of_ethics", "order": 3, "input": "checkbox", "value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "description": null}, {"name": "authorids", "order": 4}, {"name": "keywords", "order": 4}, {"name": "submission_guidelines", "order": 4, "input": "checkbox", "value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide.", "description": null}, {"name": "TLDR", "order": 5, "fieldName": "TL;DR"}, {"name": "abstract", "order": 6, "input": "textarea", "markdown": true}, {"name": "pdf", "order": 7}, {"name": "anonymous_url", "order": 7, "input": "checkbox", "value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "description": null}, {"name": "supplementary_material", "order": 8}, {"name": "no_acknowledgement_section", "order": 8, "input": "checkbox", "value": "I certify that there is no acknowledgement section in this submission for double blind review.", "description": null}, {"name": "primary_area", "order": 9, "input": "select", "value": "applications to robotics, autonomy, planning", "description": null}, {"name": "resubmission"}, {"name": "student_author"}, {"name": "large_language_models"}, {"name": "other_comments_on_LLMs"}, {"name": "venue", "hidden": true}, {"name": "venueid", "hidden": true}, {"name": "_bibtex", "input": "textarea"}, {"name": "other_comments"}]}}, {"id": "yV6fD7LYkF", "forum": "yV6fD7LYkF", "number": 5104, "cdate": 1695372675691, "tcdate": 1695372675691, "mdate": 1709817153338, "tmdate": 1709817153338, "signatures": ["ICLR.cc/2024/Conference/Submission5104/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission5104/Authors"], "content": {"title": {"value": "ValUES: A Framework for Systematic Validation of Uncertainty Estimation in Semantic Segmentation"}, "authors": {"value": ["Kim-Celine Kahl", "Carsten T. L\u00fcth", "Maximilian Zenk", "Klaus Maier-Hein", "Paul F Jaeger"]}, "authorids": {"value": ["~Kim-Celine_Kahl1", "~Carsten_T._L\u00fcth1", "~Maximilian_Zenk1", "~Klaus_Maier-Hein1", "~Paul_F_Jaeger1"]}, "keywords": {"value": ["uncertainty", "segmentation", "validation"]}, "TLDR": {"value": "We address the flawed validation in uncertainty estimation for segmentation by introducing a framework that explores uncertainty types, essential components, and effective methods, with empirical results from simulated and real-world data."}, "abstract": {"value": "Uncertainty estimation is an essential and heavily-studied component for the reliable application of semantic segmentation methods. While various studies exist claiming methodological advances on the one hand, and successful application on the other hand, the field is currently hampered by a gap between theory and practice leaving fundamental questions unanswered: Can data-related and model-related uncertainty really be separated in practice? Which components of an uncertainty method are essential for real-world performance? Which uncertainty method works well for which application? In this work, we link this research gap to a lack of systematic and comprehensive evaluation of uncertainty methods. Specifically, we identify three key pitfalls in current literature and present an evaluation framework that bridges the research gap by providing 1) a controlled environment for studying data ambiguities as well as distribution shifts, 2) systematic ablations of relevant method components, and 3) test-beds for the five predominant uncertainty applications: OoD-detection, active learning, failure detection, calibration, and ambiguity modeling. Empirical results on simulated as well as real-world data demonstrate how the proposed framework is able to answer the predominant questions in the field revealing for instance that 1) separation of uncertainty types works on simulated data but does not necessarily translate to real-world data, 2) aggregation of scores is a crucial but currently neglected component of uncertainty methods, 3) While ensembles are performing most robustly across the different downstream tasks and settings, test-time augmentation often constitutes a light-weight alternative. Code is at: https://github.com/IML-DKFZ/values"}, "primary_area": {"value": "datasets and benchmarks"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 oral"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/f1a6b968ddfb2f0ebdeb46499417239973e92e7e.pdf"}, "supplementary_material": {"value": "/attachment/da48ee545fec241de3759e5647a0b300eea57b0d.pdf"}, "_bibtex": {"value": "@inproceedings{\nkahl2024values,\ntitle={Val{UES}: A Framework for Systematic Validation of Uncertainty Estimation in Semantic Segmentation},\nauthor={Kim-Celine Kahl and Carsten T. L{\\\"u}th and Maximilian Zenk and Klaus Maier-Hein and Paul F Jaeger},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=yV6fD7LYkF}\n}"}, "paperhash": {"value": "kahl|values_a_framework_for_systematic_validation_of_uncertainty_estimation_in_semantic_segmentation"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission5104/-/Revision", "ICLR.cc/2024/Conference/Submission5104/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission5104/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410927302, "version": 2, "details": {"replyCount": 18, "presentation": [{"name": "title", "order": 1}, {"name": "authors", "order": 3}, {"name": "code_of_ethics", "order": 3, "input": "checkbox", "value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "description": null}, {"name": "authorids", "order": 4}, {"name": "keywords", "order": 4}, {"name": "submission_guidelines", "order": 4, "input": "checkbox", "value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide.", "description": null}, {"name": "TLDR", "order": 5, "fieldName": "TL;DR"}, {"name": "abstract", "order": 6, "input": "textarea", "markdown": true}, {"name": "pdf", "order": 7}, {"name": "anonymous_url", "order": 7, "input": "checkbox", "value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "description": null}, {"name": "supplementary_material", "order": 8}, {"name": "no_acknowledgement_section", "order": 8, "input": "checkbox", "value": "I certify that there is no acknowledgement section in this submission for double blind review.", "description": null}, {"name": "primary_area", "order": 9, "input": "select", "value": "datasets and benchmarks", "description": null}, {"name": "resubmission"}, {"name": "student_author"}, {"name": "large_language_models"}, {"name": "other_comments_on_LLMs"}, {"name": "venue", "hidden": true}, {"name": "venueid", "hidden": true}, {"name": "_bibtex", "input": "textarea"}, {"name": "other_comments"}]}}, {"id": "hnrB5YHoYu", "forum": "hnrB5YHoYu", "number": 4906, "cdate": 1695366799988, "tcdate": 1695366799988, "mdate": 1712651154627, "tmdate": 1712651154627, "signatures": ["ICLR.cc/2024/Conference/Submission4906/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission4906/Authors"], "content": {"title": {"value": "Finetuning Text-to-Image Diffusion Models for Fairness"}, "authors": {"value": ["Xudong Shen", "Chao Du", "Tianyu Pang", "Min Lin", "Yongkang Wong", "Mohan Kankanhalli"]}, "authorids": {"value": ["~Xudong_Shen1", "~Chao_Du1", "~Tianyu_Pang1", "~Min_Lin1", "~Yongkang_Wong1", "~Mohan_Kankanhalli1"]}, "keywords": {"value": ["Fairness", "Alignment", "Diffusion Models", "Text-to-Image Generation"]}, "abstract": {"value": "The rapid adoption of text-to-image diffusion models in society underscores an urgent need to address their biases. Without interventions, these biases could propagate a skewed worldview and restrict opportunities for minority groups. In this work, we frame fairness as a distributional alignment problem. Our solution consists of two main technical contributions: (1) a distributional alignment loss that steers specific characteristics of the generated images towards a user-defined target distribution, and (2) adjusted direct finetuning of diffusion model's sampling process (adjusted DFT), which leverages an adjusted gradient to directly optimize losses defined on the generated images. Empirically, our method markedly reduces gender, racial, and their intersectional biases for occupational prompts. Gender bias is significantly reduced even when finetuning just five soft tokens. Crucially, our method supports diverse perspectives of fairness beyond absolute equality, which is demonstrated by controlling age to a 75% young and 25% old distribution while simultaneously debiasing gender and race. Finally, our method is scalable: it can debias multiple concepts at once by simply including these prompts in the finetuning data. We share code and various fair diffusion model adaptors at https://sail-sg.github.io/finetune-fair-diffusion/."}, "primary_area": {"value": "societal considerations including fairness, safety, privacy"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 oral"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/9fa6cd12f622fa7dffccbd1c62d26545e012eafa.pdf"}, "supplementary_material": {"value": "/attachment/755530331a7e40fd2c39db790490f008339f9711.zip"}, "TLDR": {"value": "A flexible and scalable supervised fine-tuning method is introduced to align the generated images of a text-to-image diffusion model with a desired distribution."}, "_bibtex": {"value": "@inproceedings{\nshen2024finetuning,\ntitle={Finetuning Text-to-Image Diffusion Models for Fairness},\nauthor={Xudong Shen and Chao Du and Tianyu Pang and Min Lin and Yongkang Wong and Mohan Kankanhalli},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=hnrB5YHoYu}\n}"}, "paperhash": {"value": "shen|finetuning_texttoimage_diffusion_models_for_fairness"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission4906/-/Revision", "ICLR.cc/2024/Conference/Submission4906/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission4906/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410921513, "version": 2, "details": {"replyCount": 17, "presentation": [{"name": "title", "order": 1}, {"name": "authors", "order": 3}, {"name": "code_of_ethics", "order": 3, "input": "checkbox", "value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "description": null}, {"name": "authorids", "order": 4}, {"name": "keywords", "order": 4}, {"name": "submission_guidelines", "order": 4, "input": "checkbox", "value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide.", "description": null}, {"name": "TLDR", "order": 5, "fieldName": "TL;DR"}, {"name": "abstract", "order": 6, "input": "textarea", "markdown": true}, {"name": "pdf", "order": 7}, {"name": "anonymous_url", "order": 7, "input": "checkbox", "value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "description": null}, {"name": "supplementary_material", "order": 8}, {"name": "no_acknowledgement_section", "order": 8, "input": "checkbox", "value": "I certify that there is no acknowledgement section in this submission for double blind review.", "description": null}, {"name": "primary_area", "order": 9, "input": "select", "value": "societal considerations including fairness, safety, privacy", "description": null}, {"name": "resubmission"}, {"name": "student_author"}, {"name": "large_language_models"}, {"name": "other_comments_on_LLMs"}, {"name": "venue", "hidden": true}, {"name": "venueid", "hidden": true}, {"name": "_bibtex", "input": "textarea"}, {"name": "other_comments"}]}}, {"id": "WbWtOYIzIK", "forum": "WbWtOYIzIK", "number": 4686, "cdate": 1695358673938, "tcdate": 1695358673938, "mdate": 1710141887146, "tmdate": 1710141887146, "signatures": ["ICLR.cc/2024/Conference/Submission4686/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission4686/Authors"], "content": {"title": {"value": "Knowledge Card: Filling LLMs' Knowledge Gaps with Plug-in Specialized Language Models"}, "authors": {"value": ["Shangbin Feng", "Weijia Shi", "Yuyang Bai", "Vidhisha Balachandran", "Tianxing He", "Yulia Tsvetkov"]}, "authorids": {"value": ["~Shangbin_Feng1", "~Weijia_Shi1", "~Yuyang_Bai1", "~Vidhisha_Balachandran1", "~Tianxing_He1", "~Yulia_Tsvetkov1"]}, "keywords": {"value": ["large language models", "black-box language models", "modular and collaborative knowledge"]}, "abstract": {"value": "By design, large language models (LLMs) are static general-purpose models, expensive to retrain or update frequently. As they are increasingly adopted for knowledge-intensive tasks, it becomes evident that these design choices lead to failures to generate factual, relevant, and up-to-date knowledge. To this end, we propose Knowledge Card, a modular framework to plug in new factual and relevant knowledge into general-purpose LLMs. We first introduce knowledge cards---specialized language models trained on corpora from specific domains and sources. Knowledge cards serve as parametric repositories that are selected at inference time to generate background knowledge for the base LLM. We then propose three content selectors to dynamically select and retain information in documents generated by knowledge cards, specifically controlling for relevance, brevity, and factuality of outputs. Finally, we propose two complementary integration approaches to augment the base LLM with the (relevant, factual) knowledge curated from the specialized LMs. Through extensive experiments, we demonstrate that Knowledge Card achieves state-of-the-art performance on six benchmark datasets. Ultimately, Knowledge Card framework enables dynamic synthesis and updates of knowledge from diverse domains. Its modularity will ensure that relevant knowledge can be continuously updated through the collective efforts of the research community."}, "primary_area": {"value": "representation learning for computer vision, audio, language, and other modalities"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 oral"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/93b8f30fd873a0887265f980d789959bfeb89e40.pdf"}, "_bibtex": {"value": "@inproceedings{\nfeng2024knowledge,\ntitle={Knowledge Card: Filling {LLM}s' Knowledge Gaps with Plug-in Specialized Language Models},\nauthor={Shangbin Feng and Weijia Shi and Yuyang Bai and Vidhisha Balachandran and Tianxing He and Yulia Tsvetkov},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=WbWtOYIzIK}\n}"}, "paperhash": {"value": "feng|knowledge_card_filling_llms_knowledge_gaps_with_plugin_specialized_language_models"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission4686/-/Revision", "ICLR.cc/2024/Conference/Submission4686/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission4686/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410914629, "version": 2, "details": {"replyCount": 14, "presentation": [{"name": "title", "order": 1}, {"name": "authors", "order": 3}, {"name": "code_of_ethics", "order": 3, "input": "checkbox", "value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "description": null}, {"name": "authorids", "order": 4}, {"name": "keywords", "order": 4}, {"name": "submission_guidelines", "order": 4, "input": "checkbox", "value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide.", "description": null}, {"name": "TLDR", "order": 5, "fieldName": "TL;DR"}, {"name": "abstract", "order": 6, "input": "textarea", "markdown": true}, {"name": "pdf", "order": 7}, {"name": "anonymous_url", "order": 7, "input": "checkbox", "value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "description": null}, {"name": "supplementary_material", "order": 8}, {"name": "no_acknowledgement_section", "order": 8, "input": "checkbox", "value": "I certify that there is no acknowledgement section in this submission for double blind review.", "description": null}, {"name": "primary_area", "order": 9, "input": "select", "value": "representation learning for computer vision, audio, language, and other modalities", "description": null}, {"name": "resubmission"}, {"name": "student_author"}, {"name": "large_language_models"}, {"name": "other_comments_on_LLMs"}, {"name": "venue", "hidden": true}, {"name": "venueid", "hidden": true}, {"name": "_bibtex", "input": "textarea"}, {"name": "other_comments"}]}}, {"id": "c5pwL0Soay", "forum": "c5pwL0Soay", "number": 4678, "cdate": 1695358396942, "tcdate": 1695358396942, "mdate": 1710044143965, "tmdate": 1710044143965, "signatures": ["ICLR.cc/2024/Conference/Submission4678/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission4678/Authors"], "content": {"title": {"value": "METRA: Scalable Unsupervised RL with Metric-Aware Abstraction"}, "authors": {"value": ["Seohong Park", "Oleh Rybkin", "Sergey Levine"]}, "authorids": {"value": ["~Seohong_Park1", "~Oleh_Rybkin1", "~Sergey_Levine1"]}, "keywords": {"value": ["reinforcement learning"]}, "abstract": {"value": "Unsupervised pre-training strategies have proven to be highly effective in natural language processing and computer vision. Likewise, unsupervised reinforcement learning (RL) holds the promise of discovering a variety of potentially useful behaviors that can accelerate the learning of a wide array of downstream tasks. Previous unsupervised RL approaches have mainly focused on pure exploration and mutual information skill learning. However, despite the previous attempts, making unsupervised RL truly scalable still remains a major open challenge: pure exploration approaches might struggle in complex environments with large state spaces, where covering every possible transition is infeasible, and mutual information skill learning approaches might completely fail to explore the environment due to the lack of incentives. To make unsupervised RL scalable to complex, high-dimensional environments, we propose a novel unsupervised RL objective, which we call Metric-Aware Abstraction (METRA). Our main idea is, instead of directly covering the entire state space, to only cover a compact latent space $\\mathcal{Z}$ that is metrically connected to the state space $\\mathcal{S}$ by temporal distances. By learning to move in every direction in the latent space, METRA obtains a tractable set of diverse behaviors that approximately cover the state space, being scalable to high-dimensional environments. Through our experiments in five locomotion and manipulation environments, we demonstrate that METRA can discover a variety of useful behaviors even in complex, pixel-based environments, being the first unsupervised RL method that discovers diverse locomotion behaviors in pixel-based Quadruped and Humanoid. Our code and videos are available at https://seohong.me/projects/metra/"}, "primary_area": {"value": "reinforcement learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 oral"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/957e22f4e911e7ad35fff291d142a0a622982c0a.pdf"}, "_bibtex": {"value": "@inproceedings{\npark2024metra,\ntitle={{METRA}: Scalable Unsupervised {RL} with Metric-Aware Abstraction},\nauthor={Seohong Park and Oleh Rybkin and Sergey Levine},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=c5pwL0Soay}\n}"}, "paperhash": {"value": "park|metra_scalable_unsupervised_rl_with_metricaware_abstraction"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission4678/-/Revision", "ICLR.cc/2024/Conference/Submission4678/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission4678/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410914312, "version": 2, "details": {"replyCount": 15, "presentation": [{"name": "title", "order": 1}, {"name": "authors", "order": 3}, {"name": "code_of_ethics", "order": 3, "input": "checkbox", "value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "description": null}, {"name": "authorids", "order": 4}, {"name": "keywords", "order": 4}, {"name": "submission_guidelines", "order": 4, "input": "checkbox", "value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide.", "description": null}, {"name": "TLDR", "order": 5, "fieldName": "TL;DR"}, {"name": "abstract", "order": 6, "input": "textarea", "markdown": true}, {"name": "pdf", "order": 7}, {"name": "anonymous_url", "order": 7, "input": "checkbox", "value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "description": null}, {"name": "supplementary_material", "order": 8}, {"name": "no_acknowledgement_section", "order": 8, "input": "checkbox", "value": "I certify that there is no acknowledgement section in this submission for double blind review.", "description": null}, {"name": "primary_area", "order": 9, "input": "select", "value": "reinforcement learning", "description": null}, {"name": "resubmission"}, {"name": "student_author"}, {"name": "large_language_models"}, {"name": "other_comments_on_LLMs"}, {"name": "venue", "hidden": true}, {"name": "venueid", "hidden": true}, {"name": "_bibtex", "input": "textarea"}, {"name": "other_comments"}]}}, {"id": "TpD2aG1h0D", "forum": "TpD2aG1h0D", "number": 4430, "cdate": 1695348410465, "tcdate": 1695348410465, "mdate": 1713357934733, "tmdate": 1713357934733, "signatures": ["ICLR.cc/2024/Conference/Submission4430/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission4430/Authors"], "content": {"title": {"value": "Meta Continual Learning Revisited: Implicitly Enhancing Online Hessian Approximation via Variance Reduction"}, "authors": {"value": ["Yichen Wu", "Long-Kai Huang", "Renzhen Wang", "Deyu Meng", "Ying Wei"]}, "authorids": {"value": ["~Yichen_Wu2", "~Long-Kai_Huang1", "~Renzhen_Wang1", "~Deyu_Meng1", "~Ying_Wei1"]}, "keywords": {"value": ["Continual Learning"]}, "TLDR": {"value": "We provide a new perspective to Meta-continual learning and propose a Variance Reduction Meta-CL based on the novel understanding."}, "abstract": {"value": "Regularization-based methods have so far been among the *de facto* choices for continual learning. Recent theoretical studies have revealed that these methods all boil down to relying on the Hessian matrix approximation of model weights. \nHowever, these methods suffer from suboptimal trade-offs between knowledge transfer and forgetting due to fixed and unchanging Hessian estimations during training.\nAnother seemingly parallel strand of Meta-Continual Learning (Meta-CL) algorithms enforces alignment between gradients of previous tasks and that of the current task. \nIn this work we revisit Meta-CL and for the first time bridge it with regularization-based methods. Concretely, Meta-CL implicitly approximates Hessian in an online manner, which enjoys the benefits of timely adaptation but meantime suffers from high variance induced by random memory buffer sampling. \nWe are thus highly motivated to combine the best of both worlds, through the proposal of Variance Reduced Meta-CL (VR-MCL) to achieve both timely and accurate Hessian approximation.\nThrough comprehensive experiments across three datasets and various settings, we consistently observe that VR-MCL outperforms other SOTA methods, which further validates the effectiveness of VR-MCL."}, "primary_area": {"value": "transfer learning, meta learning, and lifelong learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 oral"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/28a552d86247251eb46610359a599b07e5b3e5eb.pdf"}, "_bibtex": {"value": "@inproceedings{\nwu2024meta,\ntitle={Meta Continual Learning Revisited: Implicitly Enhancing Online Hessian Approximation via Variance Reduction},\nauthor={Yichen Wu and Long-Kai Huang and Renzhen Wang and Deyu Meng and Ying Wei},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=TpD2aG1h0D}\n}"}, "paperhash": {"value": "wu|meta_continual_learning_revisited_implicitly_enhancing_online_hessian_approximation_via_variance_reduction"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission4430/-/Revision", "ICLR.cc/2024/Conference/Submission4430/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission4430/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410906182, "version": 2, "details": {"replyCount": 18, "presentation": [{"name": "title", "order": 1}, {"name": "authors", "order": 3}, {"name": "code_of_ethics", "order": 3, "input": "checkbox", "value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "description": null}, {"name": "authorids", "order": 4}, {"name": "keywords", "order": 4}, {"name": "submission_guidelines", "order": 4, "input": "checkbox", "value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide.", "description": null}, {"name": "TLDR", "order": 5, "fieldName": "TL;DR"}, {"name": "abstract", "order": 6, "input": "textarea", "markdown": true}, {"name": "pdf", "order": 7}, {"name": "anonymous_url", "order": 7, "input": "checkbox", "value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "description": null}, {"name": "supplementary_material", "order": 8}, {"name": "no_acknowledgement_section", "order": 8, "input": "checkbox", "value": "I certify that there is no acknowledgement section in this submission for double blind review.", "description": null}, {"name": "primary_area", "order": 9, "input": "select", "value": "transfer learning, meta learning, and lifelong learning", "description": null}, {"name": "resubmission"}, {"name": "student_author"}, {"name": "large_language_models"}, {"name": "other_comments_on_LLMs"}, {"name": "venue", "hidden": true}, {"name": "venueid", "hidden": true}, {"name": "_bibtex", "input": "textarea"}, {"name": "other_comments"}]}}, {"id": "L0r0GphlIL", "forum": "L0r0GphlIL", "number": 4278, "cdate": 1695342393587, "tcdate": 1695342393587, "mdate": 1711841535445, "tmdate": 1711841535445, "signatures": ["ICLR.cc/2024/Conference/Submission4278/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission4278/Authors"], "content": {"title": {"value": "Improving Convergence and Generalization Using Parameter Symmetries"}, "authors": {"value": ["Bo Zhao", "Robert M. Gower", "Robin Walters", "Rose Yu"]}, "authorids": {"value": ["~Bo_Zhao6", "~Robert_M._Gower1", "~Robin_Walters1", "~Rose_Yu1"]}, "keywords": {"value": ["Symmetry", "optimization", "generalization"]}, "TLDR": {"value": "We provide theoretical guarantees that teleportation accelerates the convergence rate, show that teleportation can be used to improve generalization, and integrate teleportation into various optimization algorithms such as meta-learning."}, "abstract": {"value": "In many neural networks, different values of the parameters may result in the same loss value. Parameter space symmetries are loss-invariant transformations that change the model parameters. Teleportation applies such transformations to accelerate optimization. However, the exact mechanism behind this algorithm's success is not well understood. In this paper, we show that teleportation not only speeds up optimization in the short-term, but gives overall faster time to convergence. Additionally, teleporting to minima with different curvatures improves generalization, which suggests a connection between the curvature of the minimum and generalization ability. Finally, we show that integrating teleportation into a wide range of optimization algorithms and optimization-based meta-learning improves convergence. Our results showcase the versatility of teleportation and demonstrate the potential of incorporating symmetry in optimization."}, "primary_area": {"value": "optimization"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 oral"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/5c8faf4be06ab48f03f7a0b88199632f8db72f7c.pdf"}, "_bibtex": {"value": "@inproceedings{\nzhao2024improving,\ntitle={Improving Convergence and Generalization Using Parameter Symmetries},\nauthor={Bo Zhao and Robert M. Gower and Robin Walters and Rose Yu},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=L0r0GphlIL}\n}"}, "paperhash": {"value": "zhao|improving_convergence_and_generalization_using_parameter_symmetries"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission4278/-/Revision", "ICLR.cc/2024/Conference/Submission4278/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission4278/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410901509, "version": 2, "details": {"replyCount": 19, "presentation": [{"name": "title", "order": 1}, {"name": "authors", "order": 3}, {"name": "code_of_ethics", "order": 3, "input": "checkbox", "value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "description": null}, {"name": "authorids", "order": 4}, {"name": "keywords", "order": 4}, {"name": "submission_guidelines", "order": 4, "input": "checkbox", "value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide.", "description": null}, {"name": "TLDR", "order": 5, "fieldName": "TL;DR"}, {"name": "abstract", "order": 6, "input": "textarea", "markdown": true}, {"name": "pdf", "order": 7}, {"name": "anonymous_url", "order": 7, "input": "checkbox", "value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "description": null}, {"name": "supplementary_material", "order": 8}, {"name": "no_acknowledgement_section", "order": 8, "input": "checkbox", "value": "I certify that there is no acknowledgement section in this submission for double blind review.", "description": null}, {"name": "primary_area", "order": 9, "input": "select", "value": "optimization", "description": null}, {"name": "resubmission"}, {"name": "student_author"}, {"name": "large_language_models"}, {"name": "other_comments_on_LLMs"}, {"name": "venue", "hidden": true}, {"name": "venueid", "hidden": true}, {"name": "_bibtex", "input": "textarea"}, {"name": "other_comments"}]}}, {"id": "g7ohDlTITL", "forum": "g7ohDlTITL", "number": 4262, "cdate": 1695341435162, "tcdate": 1695341435162, "mdate": 1709661507991, "tmdate": 1709661507991, "signatures": ["ICLR.cc/2024/Conference/Submission4262/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission4262/Authors"], "content": {"title": {"value": "Flow Matching on General Geometries"}, "authors": {"value": ["Ricky T. Q. Chen", "Yaron Lipman"]}, "authorids": {"value": ["~Ricky_T._Q._Chen1", "~Yaron_Lipman1"]}, "keywords": {"value": ["general manifolds", "diffusion models", "continuous normalizing flow"]}, "TLDR": {"value": "We derive sufficient conditions for Conditional Flow Matching on general manifolds, with significant algorithmic improvements to diffusion-based approaches even on simple manifolds, and the first to tackle more general manifolds."}, "abstract": {"value": "We propose Riemannian Flow Matching (RFM), a simple yet powerful framework for training continuous normalizing flows on manifolds. Existing methods for generative modeling on manifolds either require expensive simulation, are inherently unable to scale to high dimensions, or use approximations for limiting quantities that result in biased training objectives. Riemannian Flow Matching bypasses these limitations and offers several advantages over previous approaches: it is simulation-free on simple geometries, does not require divergence computation, and computes its target vector field in closed-form. The key ingredient behind RFM is the construction of a relatively simple premetric for defining target vector fields, which encompasses the existing Euclidean case. To extend to general geometries, we rely on the use of spectral decompositions to efficiently compute premetrics on the fly. Our method achieves state-of-the-art performance on real-world non-Euclidean datasets, and we demonstrate tractable training on general geometries, including triangular meshes with highly non-trivial curvature and boundaries."}, "primary_area": {"value": "learning on graphs and other geometries & topologies"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 oral"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/00e980dec1d5ee17094141c71986553014f8a41a.pdf"}, "supplementary_material": {"value": "/attachment/dbdc756913aa45bdcb7198345036276ec0daaacc.zip"}, "_bibtex": {"value": "@inproceedings{\nchen2024flow,\ntitle={Flow Matching on General Geometries},\nauthor={Ricky T. Q. Chen and Yaron Lipman},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=g7ohDlTITL}\n}"}, "paperhash": {"value": "chen|flow_matching_on_general_geometries"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission4262/-/Revision", "ICLR.cc/2024/Conference/Submission4262/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission4262/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410900844, "version": 2, "details": {"replyCount": 11, "presentation": [{"name": "title", "order": 1}, {"name": "authors", "order": 3}, {"name": "code_of_ethics", "order": 3, "input": "checkbox", "value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "description": null}, {"name": "authorids", "order": 4}, {"name": "keywords", "order": 4}, {"name": "submission_guidelines", "order": 4, "input": "checkbox", "value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide.", "description": null}, {"name": "TLDR", "order": 5, "fieldName": "TL;DR"}, {"name": "abstract", "order": 6, "input": "textarea", "markdown": true}, {"name": "pdf", "order": 7}, {"name": "anonymous_url", "order": 7, "input": "checkbox", "value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "description": null}, {"name": "supplementary_material", "order": 8}, {"name": "no_acknowledgement_section", "order": 8, "input": "checkbox", "value": "I certify that there is no acknowledgement section in this submission for double blind review.", "description": null}, {"name": "primary_area", "order": 9, "input": "select", "value": "learning on graphs and other geometries & topologies", "description": null}, {"name": "resubmission"}, {"name": "student_author"}, {"name": "large_language_models"}, {"name": "other_comments_on_LLMs"}, {"name": "venue", "hidden": true}, {"name": "venueid", "hidden": true}, {"name": "_bibtex", "input": "textarea"}, {"name": "other_comments"}]}}, {"id": "Ad87VjRqUw", "forum": "Ad87VjRqUw", "number": 4227, "cdate": 1695339456388, "tcdate": 1695339456388, "mdate": 1710421366251, "tmdate": 1710421366251, "signatures": ["ICLR.cc/2024/Conference/Submission4227/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission4227/Authors"], "content": {"title": {"value": "Ghost on the Shell: An Expressive Representation of General 3D Shapes"}, "authors": {"value": ["Zhen Liu", "Yao Feng", "Yuliang Xiu", "Weiyang Liu", "Liam Paull", "Michael J. Black", "Bernhard Sch\u00f6lkopf"]}, "authorids": {"value": ["~Zhen_Liu6", "~Yao_Feng3", "~Yuliang_Xiu2", "~Weiyang_Liu1", "~Liam_Paull1", "~Michael_J._Black1", "~Bernhard_Sch\u00f6lkopf1"]}, "keywords": {"value": ["Non-watertight mesh; generative model; 3D geometry; differentiable rendering"]}, "TLDR": {"value": "We propose a general 3D mesh representation to include non-watertight meshes, which enables efficient mesh reconstruction and generative models."}, "abstract": {"value": "The creation of photorealistic virtual worlds requires the accurate modeling of 3D surface geometry for a wide range of objects. For this, meshes are appealing since they enable 1) fast physics-based rendering with realistic material and lighting, 2) physical simulation, and 3) are memory-efficient for modern graphics pipelines. Recent work on reconstructing and statistically modeling 3D shape, however, has critiqued meshes as being topologically inflexible. To capture a wide range of object shapes, any 3D representation must be able to model solid, watertight, shapes as well as thin, open, surfaces. Recent work has focused on the former, and methods for reconstructing open surfaces do not support fast reconstruction with material and lighting or unconditional generative modelling. Inspired by the observation that open surfaces can be seen as islands floating on watertight surfaces, we parametrize open surfaces by defining a manifold signed distance field on watertight templates. With this parametrization, we further develop a grid-based and differentiable representation that parametrizes both watertight and non-watertight meshes of arbitrary topology. Our new representation, called Ghost-on-the-Shell (G-Shell), enables two important applications:  differentiable rasterization-based reconstruction from multiview images and generative modelling of non-watertight meshes. We empirically demonstrate that G-Shell achieves state-of-the-art performance on non-watertight mesh reconstruction and generation tasks, while also performing effectively for watertight meshes."}, "primary_area": {"value": "representation learning for computer vision, audio, language, and other modalities"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 oral"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/97f11bc98d70c1fbee4e5f3325299c53225c6bfc.pdf"}, "_bibtex": {"value": "@inproceedings{\nliu2024ghost,\ntitle={Ghost on the Shell: An Expressive Representation of General 3D Shapes},\nauthor={Zhen Liu and Yao Feng and Yuliang Xiu and Weiyang Liu and Liam Paull and Michael J. Black and Bernhard Sch{\\\"o}lkopf},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=Ad87VjRqUw}\n}"}, "paperhash": {"value": "liu|ghost_on_the_shell_an_expressive_representation_of_general_3d_shapes"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission4227/-/Revision", "ICLR.cc/2024/Conference/Submission4227/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission4227/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410899624, "version": 2, "details": {"replyCount": 18, "presentation": [{"name": "title", "order": 1}, {"name": "authors", "order": 3}, {"name": "code_of_ethics", "order": 3, "input": "checkbox", "value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "description": null}, {"name": "authorids", "order": 4}, {"name": "keywords", "order": 4}, {"name": "submission_guidelines", "order": 4, "input": "checkbox", "value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide.", "description": null}, {"name": "TLDR", "order": 5, "fieldName": "TL;DR"}, {"name": "abstract", "order": 6, "input": "textarea", "markdown": true}, {"name": "pdf", "order": 7}, {"name": "anonymous_url", "order": 7, "input": "checkbox", "value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "description": null}, {"name": "supplementary_material", "order": 8}, {"name": "no_acknowledgement_section", "order": 8, "input": "checkbox", "value": "I certify that there is no acknowledgement section in this submission for double blind review.", "description": null}, {"name": "primary_area", "order": 9, "input": "select", "value": "representation learning for computer vision, audio, language, and other modalities", "description": null}, {"name": "resubmission"}, {"name": "student_author"}, {"name": "large_language_models"}, {"name": "other_comments_on_LLMs"}, {"name": "venue", "hidden": true}, {"name": "venueid", "hidden": true}, {"name": "_bibtex", "input": "textarea"}, {"name": "other_comments"}]}}, {"id": "gU58d5QeGv", "forum": "gU58d5QeGv", "number": 4208, "cdate": 1695338181850, "tcdate": 1695338181850, "mdate": 1709661507312, "tmdate": 1709661507312, "signatures": ["ICLR.cc/2024/Conference/Submission4208/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission4208/Authors"], "content": {"title": {"value": "W\u00fcrstchen: An Efficient Architecture for Large-Scale Text-to-Image Diffusion Models"}, "authors": {"value": ["Pablo Pernias", "Dominic Rampas", "Mats Leon Richter", "Christopher Pal", "Marc Aubreville"]}, "authorids": {"value": ["~Pablo_Pernias1", "~Dominic_Rampas1", "~Mats_Leon_Richter1", "~Christopher_Pal1", "~Marc_Aubreville1"]}, "keywords": {"value": ["Latent Diffusion Model", "Text-to-Image", "Neural Architectures", "Foundation Models"]}, "TLDR": {"value": "We propose an efficient text-to-image model that only requires 1/8th of Stable Diffusion 2.1's compute budget for training and has comparable, if not better image quality with less than half the inference time."}, "abstract": {"value": "We introduce W\u00fcrstchen, a novel architecture for text-to-image synthesis that combines competitive performance with unprecedented cost-effectiveness for large-scale text-to-image diffusion models.\nA key contribution of our work is to develop a latent diffusion technique in which we learn a detailed but extremely compact semantic image representation used to guide the diffusion process. This highly compressed representation of an image provides much more detailed guidance compared to latent representations of language and this significantly reduces the computational requirements to achieve state-of-the-art results. Our approach also improves the quality of text-conditioned image generation based on our user preference study.\nThe training requirements of our approach consists of 24,602 A100-GPU hours - compared to Stable Diffusion 2.1's 200,000 GPU hours.  \nOur approach also requires less training data to achieve these results. Furthermore, our compact latent representations allows us to perform inference over twice as fast, slashing the usual costs and carbon footprint of a state-of-the-art (SOTA) diffusion model significantly, without compromising the end performance. In a broader comparison against SOTA models our approach is substantially more efficient and compares favourably in terms of image quality.\nWe believe that this work motivates more emphasis on the prioritization of both performance and computational accessibility."}, "primary_area": {"value": "generative models"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 oral"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/31506ae62c31613539a0623777d341cb424cf5b9.pdf"}, "supplementary_material": {"value": "/attachment/019a923f4f8092ea3e4d81c87abfcf428eec3447.pdf"}, "_bibtex": {"value": "@inproceedings{\npernias2024wrstchen,\ntitle={W\\\"urstchen: An Efficient Architecture for Large-Scale Text-to-Image Diffusion Models},\nauthor={Pablo Pernias and Dominic Rampas and Mats Leon Richter and Christopher Pal and Marc Aubreville},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=gU58d5QeGv}\n}"}, "paperhash": {"value": "pernias|w\u00fcrstchen_an_efficient_architecture_for_largescale_texttoimage_diffusion_models"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission4208/-/Revision", "ICLR.cc/2024/Conference/Submission4208/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission4208/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410899066, "version": 2, "details": {"replyCount": 18, "presentation": [{"name": "title", "order": 1}, {"name": "authors", "order": 3}, {"name": "code_of_ethics", "order": 3, "input": "checkbox", "value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "description": null}, {"name": "authorids", "order": 4}, {"name": "keywords", "order": 4}, {"name": "submission_guidelines", "order": 4, "input": "checkbox", "value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide.", "description": null}, {"name": "TLDR", "order": 5, "fieldName": "TL;DR"}, {"name": "abstract", "order": 6, "input": "textarea", "markdown": true}, {"name": "pdf", "order": 7}, {"name": "anonymous_url", "order": 7, "input": "checkbox", "value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "description": null}, {"name": "supplementary_material", "order": 8}, {"name": "no_acknowledgement_section", "order": 8, "input": "checkbox", "value": "I certify that there is no acknowledgement section in this submission for double blind review.", "description": null}, {"name": "primary_area", "order": 9, "input": "select", "value": "generative models", "description": null}, {"name": "resubmission"}, {"name": "student_author"}, {"name": "large_language_models"}, {"name": "other_comments_on_LLMs"}, {"name": "venue", "hidden": true}, {"name": "venueid", "hidden": true}, {"name": "_bibtex", "input": "textarea"}, {"name": "other_comments"}]}}, {"id": "NSVtmmzeRB", "forum": "NSVtmmzeRB", "number": 3873, "cdate": 1695325403147, "tcdate": 1695325403147, "mdate": 1710566762171, "tmdate": 1710566762171, "signatures": ["ICLR.cc/2024/Conference/Submission3873/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission3873/Authors"], "content": {"title": {"value": "Unified Generative Modeling of 3D Molecules with Bayesian Flow Networks"}, "authors": {"value": ["Yuxuan Song", "Jingjing Gong", "Hao Zhou", "Mingyue Zheng", "Jingjing Liu", "Wei-Ying Ma"]}, "authorids": {"value": ["~Yuxuan_Song2", "~Jingjing_Gong3", "~Hao_Zhou5", "~Mingyue_Zheng1", "~Jingjing_Liu2", "~Wei-Ying_Ma2"]}, "keywords": {"value": ["Drug Design", "Molecule Generation", "Deep Learning", "Computational Biology"]}, "TLDR": {"value": "A new 3D molecule generative model based on Bayesian Flow Networks"}, "abstract": {"value": "Advanced generative model (\\textit{e.g.}, diffusion model) derived from simplified continuity assumptions of data distribution, though showing promising progress, has been difficult to apply directly to geometry generation applications due to the \\textit{multi-modality} and \\textit{noise-sensitive} nature of molecule geometry. \nThis work introduces Geometric Bayesian Flow Networks (GeoBFN), which naturally fits molecule geometry by modeling diverse modalities in the differentiable parameter space of distributions. GeoBFN maintains the SE-(3) invariant density modeling property by incorporating equivariant inter-dependency modeling on parameters of distributions and unifying the probabilistic modeling of different modalities. \nThrough optimized training and sampling techniques, we demonstrate that GeoBFN achieves state-of-the-art performance on multiple 3D molecule generation benchmarks in terms of generation quality (90.87\\% molecule stability in QM9 and 85.6\\% atom stability in GEOM-DRUG\\footnote{The scores are reported at 1k sampling steps for fair comparison, and our scores could be further improved if sampling sufficiently longer steps.}). GeoBFN can also conduct sampling with any number of steps to reach an optimal trade-off between efficiency and quality (\\textit{e.g.}, 20$\\times$ speedup without sacrificing performance)."}, "primary_area": {"value": "applications to physical sciences (physics, chemistry, biology, etc.)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 oral"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/ddfe46bc639f9c1dc849398c8b3d978ffd171431.pdf"}, "supplementary_material": {"value": "/attachment/2f0308097d267fdb30f1893a268041ec91cfd73d.zip"}, "_bibtex": {"value": "@inproceedings{\nsong2024unified,\ntitle={Unified Generative Modeling of 3D Molecules with Bayesian Flow Networks},\nauthor={Yuxuan Song and Jingjing Gong and Hao Zhou and Mingyue Zheng and Jingjing Liu and Wei-Ying Ma},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=NSVtmmzeRB}\n}"}, "paperhash": {"value": "song|unified_generative_modeling_of_3d_molecules_with_bayesian_flow_networks"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission3873/-/Revision", "ICLR.cc/2024/Conference/Submission3873/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission3873/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410887263, "version": 2, "details": {"replyCount": 26, "presentation": [{"name": "title", "order": 1}, {"name": "authors", "order": 3}, {"name": "code_of_ethics", "order": 3, "input": "checkbox", "value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "description": null}, {"name": "authorids", "order": 4}, {"name": "keywords", "order": 4}, {"name": "submission_guidelines", "order": 4, "input": "checkbox", "value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide.", "description": null}, {"name": "TLDR", "order": 5, "fieldName": "TL;DR"}, {"name": "abstract", "order": 6, "input": "textarea", "markdown": true}, {"name": "pdf", "order": 7}, {"name": "anonymous_url", "order": 7, "input": "checkbox", "value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "description": null}, {"name": "supplementary_material", "order": 8}, {"name": "no_acknowledgement_section", "order": 8, "input": "checkbox", "value": "I certify that there is no acknowledgement section in this submission for double blind review.", "description": null}, {"name": "primary_area", "order": 9, "input": "select", "value": "applications to physical sciences (physics, chemistry, biology, etc.)", "description": null}, {"name": "resubmission"}, {"name": "student_author"}, {"name": "large_language_models"}, {"name": "other_comments_on_LLMs"}, {"name": "venue", "hidden": true}, {"name": "venueid", "hidden": true}, {"name": "_bibtex", "input": "textarea"}, {"name": "other_comments"}]}}, {"id": "d8w0pmvXbZ", "forum": "d8w0pmvXbZ", "number": 3794, "cdate": 1695319542925, "tcdate": 1695319542925, "mdate": 1709661502312, "tmdate": 1709661502312, "signatures": ["ICLR.cc/2024/Conference/Submission3794/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission3794/Authors"], "content": {"title": {"value": "Small-scale proxies for large-scale Transformer training instabilities"}, "authors": {"value": ["Mitchell Wortsman", "Peter J Liu", "Lechao Xiao", "Katie E Everett", "Alexander A Alemi", "Ben Adlam", "John D Co-Reyes", "Izzeddin Gur", "Abhishek Kumar", "Roman Novak", "Jeffrey Pennington", "Jascha Sohl-Dickstein", "Kelvin Xu", "Jaehoon Lee", "Justin Gilmer", "Simon Kornblith"]}, "authorids": {"value": ["~Mitchell_Wortsman1", "~Peter_J_Liu1", "~Lechao_Xiao2", "~Katie_E_Everett1", "~Alexander_A_Alemi1", "~Ben_Adlam1", "~John_D_Co-Reyes1", "~Izzeddin_Gur1", "~Abhishek_Kumar1", "~Roman_Novak2", "~Jeffrey_Pennington1", "~Jascha_Sohl-Dickstein2", "~Kelvin_Xu2", "~Jaehoon_Lee2", "~Justin_Gilmer1", "~Simon_Kornblith1"]}, "keywords": {"value": ["Small Transformers", "Training", "Stability"]}, "abstract": {"value": "Teams that have trained large Transformer-based models have reported training instabilities at large scale that did not appear when training with the same hyperparameters at smaller scales. Although the causes of such instabilities are of scientific interest, the amount of resources required to reproduce them has made investigation difficult. In this work, we seek ways to reproduce and study training instability at smaller scales. First, we focus on two sources of training instability described in previous work: the growth of logits in attention layers (Dehghani et al., 2023) and divergence of the output logits from the log probabilities (Chowdhery et al., 2022). By measuring the relationship between learning rate and loss across scales, we show that these instabilities also appear in small models when training at high learning rates, and that mitigations previously employed at large scales are equally effective in this regime. This prompts us to investigate the extent to which other known optimizer and model interventions influence the sensitivity of the final loss to changes in the learning rate. To this end, we study methods such as warm-up, weight decay, and the MuParam (Yang et al., 2022), and combine techniques to train small models that achieve similar losses across orders of magnitude of learning rate variation. Finally, to conclude our exploration we study two cases where instabilities can be predicted before they emerge by examining the scaling behavior of model characteristics such as activation and gradient norms."}, "primary_area": {"value": "optimization"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 oral"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/779db5974973fe74f026f4a70e3f08d16c11cadb.pdf"}, "TLDR": {"value": "We seek ways to reproduce, study and predict training instability with smaller models."}, "_bibtex": {"value": "@inproceedings{\nwortsman2024smallscale,\ntitle={Small-scale proxies for large-scale Transformer training instabilities},\nauthor={Mitchell Wortsman and Peter J Liu and Lechao Xiao and Katie E Everett and Alexander A Alemi and Ben Adlam and John D Co-Reyes and Izzeddin Gur and Abhishek Kumar and Roman Novak and Jeffrey Pennington and Jascha Sohl-Dickstein and Kelvin Xu and Jaehoon Lee and Justin Gilmer and Simon Kornblith},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=d8w0pmvXbZ}\n}"}, "paperhash": {"value": "wortsman|smallscale_proxies_for_largescale_transformer_training_instabilities"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission3794/-/Revision", "ICLR.cc/2024/Conference/Submission3794/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission3794/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410885047, "version": 2, "details": {"replyCount": 15, "presentation": [{"name": "title", "order": 1}, {"name": "authors", "order": 3}, {"name": "code_of_ethics", "order": 3, "input": "checkbox", "value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "description": null}, {"name": "authorids", "order": 4}, {"name": "keywords", "order": 4}, {"name": "submission_guidelines", "order": 4, "input": "checkbox", "value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide.", "description": null}, {"name": "TLDR", "order": 5, "fieldName": "TL;DR"}, {"name": "abstract", "order": 6, "input": "textarea", "markdown": true}, {"name": "pdf", "order": 7}, {"name": "anonymous_url", "order": 7, "input": "checkbox", "value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "description": null}, {"name": "supplementary_material", "order": 8}, {"name": "no_acknowledgement_section", "order": 8, "input": "checkbox", "value": "I certify that there is no acknowledgement section in this submission for double blind review.", "description": null}, {"name": "primary_area", "order": 9, "input": "select", "value": "optimization", "description": null}, {"name": "resubmission"}, {"name": "student_author"}, {"name": "large_language_models"}, {"name": "other_comments_on_LLMs"}, {"name": "venue", "hidden": true}, {"name": "venueid", "hidden": true}, {"name": "_bibtex", "input": "textarea"}, {"name": "other_comments"}]}}, {"id": "pzElnMrgSD", "forum": "pzElnMrgSD", "number": 3760, "cdate": 1695316478892, "tcdate": 1695316478892, "mdate": 1712227473392, "tmdate": 1712227473392, "signatures": ["ICLR.cc/2024/Conference/Submission3760/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission3760/Authors"], "content": {"title": {"value": "How I Warped Your Noise: a Temporally-Correlated Noise Prior for Diffusion Models"}, "authors": {"value": ["Pascal Chang", "Jingwei Tang", "Markus Gross", "Vinicius C. Azevedo"]}, "authorids": {"value": ["~Pascal_Chang1", "~Jingwei_Tang1", "~Markus_Gross1", "~Vinicius_C._Azevedo1"]}, "keywords": {"value": ["diffusion models; temporal coherency; Gaussian noise field; continuous white noise; noise transport"]}, "abstract": {"value": "Video editing and generation methods often rely on pre-trained image-based diffusion models. During the diffusion process, however, the reliance on rudimentary noise sampling techniques that do not preserve correlations present in subsequent frames of a video is detrimental to the quality of the results. This either produces high-frequency flickering, or texture-sticking artifacts that are not amenable to post-processing. With this in mind, we propose a novel method for preserving temporal correlations in a sequence of noise samples. This approach is materialized by a novel noise representation, dubbed $\\int$-noise (integral noise), that reinterprets individual noise samples as a continuously integrated noise field: pixel values do not represent discrete values, but are rather the integral of an underlying infinite-resolution noise over the pixel area. Additionally, we propose a carefully tailored transport method that uses $\\int$-noise to accurately advect noise samples over a sequence of frames, maximizing the correlation between different frames while also preserving the noise properties. Our results demonstrate that the proposed $\\int$-noise can be used for a variety of tasks, such as video restoration, surrogate rendering, and conditional video generation."}, "primary_area": {"value": "generative models"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 oral"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/c35a99656514c0312f7f69d2ecda8ffec1a632de.pdf"}, "TLDR": {"value": "We propose a method to warp a Gaussian noise sample while keeping it Gaussian and apply it to diffusion models to help temporal coherency."}, "_bibtex": {"value": "@inproceedings{\nchang2024how,\ntitle={How I Warped Your Noise: a Temporally-Correlated Noise Prior for Diffusion Models},\nauthor={Pascal Chang and Jingwei Tang and Markus Gross and Vinicius C. Azevedo},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=pzElnMrgSD}\n}"}, "paperhash": {"value": "chang|how_i_warped_your_noise_a_temporallycorrelated_noise_prior_for_diffusion_models"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission3760/-/Revision", "ICLR.cc/2024/Conference/Submission3760/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission3760/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410883967, "version": 2, "details": {"replyCount": 16, "presentation": [{"name": "title", "order": 1}, {"name": "authors", "order": 3}, {"name": "code_of_ethics", "order": 3, "input": "checkbox", "value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "description": null}, {"name": "authorids", "order": 4}, {"name": "keywords", "order": 4}, {"name": "submission_guidelines", "order": 4, "input": "checkbox", "value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide.", "description": null}, {"name": "TLDR", "order": 5, "fieldName": "TL;DR"}, {"name": "abstract", "order": 6, "input": "textarea", "markdown": true}, {"name": "pdf", "order": 7}, {"name": "anonymous_url", "order": 7, "input": "checkbox", "value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "description": null}, {"name": "supplementary_material", "order": 8}, {"name": "no_acknowledgement_section", "order": 8, "input": "checkbox", "value": "I certify that there is no acknowledgement section in this submission for double blind review.", "description": null}, {"name": "primary_area", "order": 9, "input": "select", "value": "generative models", "description": null}, {"name": "resubmission"}, {"name": "student_author"}, {"name": "large_language_models"}, {"name": "other_comments_on_LLMs"}, {"name": "venue", "hidden": true}, {"name": "venueid", "hidden": true}, {"name": "_bibtex", "input": "textarea"}, {"name": "other_comments"}]}}, {"id": "2dnO3LLiJ1", "forum": "2dnO3LLiJ1", "number": 3647, "cdate": 1695309238042, "tcdate": 1695309238042, "mdate": 1712911788804, "tmdate": 1712911788804, "signatures": ["ICLR.cc/2024/Conference/Submission3647/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission3647/Authors"], "content": {"title": {"value": "Vision Transformers Need Registers"}, "authors": {"value": ["Timoth\u00e9e Darcet", "Maxime Oquab", "Julien Mairal", "Piotr Bojanowski"]}, "authorids": {"value": ["~Timoth\u00e9e_Darcet1", "~Maxime_Oquab1", "~Julien_Mairal1", "~Piotr_Bojanowski1"]}, "keywords": {"value": ["representation", "vision", "transformer", "register", "SSL", "CLIP", "attention", "attention map", "interpretability", "DINO", "DINOv2"]}, "TLDR": {"value": "We find artifacts in ViT features. We add new tokens (\u201cregisters\u201d) that fix this issue."}, "abstract": {"value": "Transformers have recently emerged as a powerful tool for learning visual representations. In this paper, we identify and characterize artifacts in feature maps of both supervised and self-supervised ViT networks. The artifacts correspond to high-norm tokens appearing during inference primarily in low-informative background areas of images, that are repurposed for internal computations. We propose a simple yet effective solution based on providing additional tokens to the input sequence of the Vision Transformer to fill that role. We show that this solution fixes that problem entirely for both supervised and self-supervised models, sets a new state of the art for self-supervised visual models on dense visual prediction tasks, enables object discovery methods with larger models, and most importantly leads to smoother feature maps and attention maps for downstream visual processing."}, "primary_area": {"value": "unsupervised, self-supervised, semi-supervised, and supervised representation learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 oral"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/1db45cd6c97acf30b37c4ee9ac6e79d4f3ac7763.pdf"}, "_bibtex": {"value": "@inproceedings{\ndarcet2024vision,\ntitle={Vision Transformers Need Registers},\nauthor={Timoth{\\'e}e Darcet and Maxime Oquab and Julien Mairal and Piotr Bojanowski},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=2dnO3LLiJ1}\n}"}, "paperhash": {"value": "darcet|vision_transformers_need_registers"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission3647/-/Revision", "ICLR.cc/2024/Conference/Submission3647/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission3647/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410880910, "version": 2, "details": {"replyCount": 14, "presentation": [{"name": "title", "order": 1}, {"name": "authors", "order": 3}, {"name": "code_of_ethics", "order": 3, "input": "checkbox", "value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "description": null}, {"name": "authorids", "order": 4}, {"name": "keywords", "order": 4}, {"name": "submission_guidelines", "order": 4, "input": "checkbox", "value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide.", "description": null}, {"name": "TLDR", "order": 5, "fieldName": "TL;DR"}, {"name": "abstract", "order": 6, "input": "textarea", "markdown": true}, {"name": "pdf", "order": 7}, {"name": "anonymous_url", "order": 7, "input": "checkbox", "value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "description": null}, {"name": "supplementary_material", "order": 8}, {"name": "no_acknowledgement_section", "order": 8, "input": "checkbox", "value": "I certify that there is no acknowledgement section in this submission for double blind review.", "description": null}, {"name": "primary_area", "order": 9, "input": "select", "value": "unsupervised, self-supervised, semi-supervised, and supervised representation learning", "description": null}, {"name": "resubmission"}, {"name": "student_author"}, {"name": "large_language_models"}, {"name": "other_comments_on_LLMs"}, {"name": "venue", "hidden": true}, {"name": "venueid", "hidden": true}, {"name": "_bibtex", "input": "textarea"}, {"name": "other_comments"}]}}, {"id": "mE52zURNGc", "forum": "mE52zURNGc", "number": 3498, "cdate": 1695300958535, "tcdate": 1695300958535, "mdate": 1713186296187, "tmdate": 1713186296187, "signatures": ["ICLR.cc/2024/Conference/Submission3498/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission3498/Authors"], "content": {"title": {"value": "An Analytical Solution to Gauss-Newton Loss for Direct Image Alignment"}, "authors": {"value": ["Sergei Solonets", "Daniil Sinitsyn", "Lukas Von Stumberg", "Nikita Araslanov", "Daniel Cremers"]}, "authorids": {"value": ["~Sergei_Solonets1", "~Daniil_Sinitsyn1", "~Lukas_Von_Stumberg1", "~Nikita_Araslanov1", "~Daniel_Cremers1"]}, "keywords": {"value": ["featuremetric image alignment"]}, "abstract": {"value": "Direct image alignment is a widely used technique for relative 6DoF pose estimation between two images, but its accuracy strongly depends on pose initialization.\nTherefore, recent end-to-end frameworks increase the convergence basin of the learned feature descriptors with special training objectives, such as the Gauss-Newton loss.\nHowever, the training data may exhibit bias toward a specific type of motion and pose initialization,\nthus limiting the generalization of these methods.\nIn this work, we derive a closed-form solution to the expected optimum of the Gauss-Newton loss. \nThe solution is agnostic to the underlying feature representation and allows us to dynamically adjust the basin of convergence according to our assumptions about the uncertainty in the current estimates. These properties allow for effective control over the convergence in the alignment process.\nDespite using self-supervised feature embeddings, our solution achieves compelling accuracy w.r.t. the state-of-the-art direct image alignment methods trained end-to-end with pose supervision, and demonstrates improved robustness to pose initialization.\nOur analytical solution exposes some inherent limitations of end-to-end learning with the Gauss-Newton loss, and establishes an intriguing connection between direct image alignment and feature-matching approaches."}, "primary_area": {"value": "optimization"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 oral"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/8cc6141bff9dadb82d553ab8ac1b1ff6d4f434a9.pdf"}, "_bibtex": {"value": "@inproceedings{\nsolonets2024an,\ntitle={An Analytical Solution to Gauss-Newton Loss for Direct Image Alignment},\nauthor={Sergei Solonets and Daniil Sinitsyn and Lukas Von Stumberg and Nikita Araslanov and Daniel Cremers},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=mE52zURNGc}\n}"}, "paperhash": {"value": "solonets|an_analytical_solution_to_gaussnewton_loss_for_direct_image_alignment"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission3498/-/Revision", "ICLR.cc/2024/Conference/Submission3498/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission3498/-/Camera_Ready_Revision", "ICLR.cc/2024/Conference/-/PC_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410876689, "version": 2, "details": {"replyCount": 10, "presentation": [{"name": "title", "order": 1}, {"name": "supplementary_material", "order": 1}, {"name": "authors", "order": 2, "hidden": true}, {"name": "primary_area", "order": 2, "input": "select", "value": "optimization", "description": null}, {"name": "authorids", "order": 3}, {"name": "code_of_ethics", "order": 3, "input": "checkbox", "value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "description": null}, {"name": "keywords", "order": 4}, {"name": "submission_guidelines", "order": 4, "input": "checkbox", "value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide.", "description": null}, {"name": "TLDR", "order": 5, "fieldName": "TL;DR"}, {"name": "resubmission", "order": 5, "input": "radio"}, {"name": "abstract", "order": 6, "input": "textarea", "markdown": true}, {"name": "student_author", "order": 6, "input": "radio"}, {"name": "pdf", "order": 7}, {"name": "anonymous_url", "order": 7, "input": "checkbox", "value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "description": null}, {"name": "no_acknowledgement_section", "order": 8, "input": "checkbox", "value": "I certify that there is no acknowledgement section in this submission for double blind review.", "description": null}, {"name": "large_language_models", "order": 9, "input": "checkbox"}, {"name": "other_comments_on_LLMs", "order": 10, "input": "textarea"}, {"name": "venue", "hidden": true}, {"name": "venueid", "hidden": true}, {"name": "_bibtex", "input": "textarea"}, {"name": "other_comments"}]}}, {"id": "P15CHILQlg", "forum": "P15CHILQlg", "number": 3483, "cdate": 1695299594922, "tcdate": 1695299594922, "mdate": 1713672664000, "tmdate": 1713672664000, "signatures": ["ICLR.cc/2024/Conference/Submission3483/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission3483/Authors"], "content": {"title": {"value": "Learning Energy Decompositions for Partial Inference in GFlowNets"}, "authors": {"value": ["Hyosoon Jang", "Minsu Kim", "Sungsoo Ahn"]}, "authorids": {"value": ["~Hyosoon_Jang3", "~Minsu_Kim2", "~Sungsoo_Ahn1"]}, "keywords": {"value": ["Generative flow networks", "reinforcement learning", "generative models"]}, "abstract": {"value": "This paper studies generative flow networks (GFlowNets) to sample objects from the Boltzmann energy distribution via a sequence of actions. In particular, we focus on improving GFlowNet with partial inference: training flow functions with the evaluation of the intermediate states or transitions. To this end, the recently developed forward-looking GFlowNet reparameterizes the flow functions based on evaluating the energy of intermediate states. However, such an evaluation of intermediate energies may (i) be too expensive or impossible to evaluate and (ii) even provide misleading training signals under large energy fluctuations along the sequence of actions. To resolve this issue, we propose learning energy decompositions for GFlowNets (LED-GFN). Our main idea is to (i) decompose the energy of an object into learnable potential functions defined on state transitions and (ii) reparameterize the flow functions using the potential functions. In particular, to produce informative local credits, we propose to regularize the potential to change smoothly over the sequence of actions. It is also noteworthy that training GFlowNet with our learned potential can preserve the optimal policy. We empirically verify the superiority of LED-GFN in five problems including the generation of unstructured and maximum independent sets, molecular graphs, and RNA sequences."}, "primary_area": {"value": "generative models"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 oral"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/54bfe1a393ed4a31554ead18c45d5b62548007be.pdf"}, "supplementary_material": {"value": "/attachment/f1868360d56cb347bbcc40415615c66e725a4d97.zip"}, "TLDR": {"value": "We investigate a learning-based approach to produce informative local credits that facilitate the partial inference of GFlowNet"}, "_bibtex": {"value": "@inproceedings{\njang2024learning,\ntitle={Learning Energy Decompositions for Partial Inference in {GF}lowNets},\nauthor={Hyosoon Jang and Minsu Kim and Sungsoo Ahn},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=P15CHILQlg}\n}"}, "paperhash": {"value": "jang|learning_energy_decompositions_for_partial_inference_in_gflownets"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission3483/-/Revision", "ICLR.cc/2024/Conference/Submission3483/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission3483/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410876428, "version": 2, "details": {"replyCount": 19, "presentation": [{"name": "title", "order": 1}, {"name": "authors", "order": 3}, {"name": "code_of_ethics", "order": 3, "input": "checkbox", "value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "description": null}, {"name": "authorids", "order": 4}, {"name": "keywords", "order": 4}, {"name": "submission_guidelines", "order": 4, "input": "checkbox", "value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide.", "description": null}, {"name": "TLDR", "order": 5, "fieldName": "TL;DR"}, {"name": "abstract", "order": 6, "input": "textarea", "markdown": true}, {"name": "pdf", "order": 7}, {"name": "anonymous_url", "order": 7, "input": "checkbox", "value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "description": null}, {"name": "supplementary_material", "order": 8}, {"name": "no_acknowledgement_section", "order": 8, "input": "checkbox", "value": "I certify that there is no acknowledgement section in this submission for double blind review.", "description": null}, {"name": "primary_area", "order": 9, "input": "select", "value": "generative models", "description": null}, {"name": "resubmission"}, {"name": "student_author"}, {"name": "large_language_models"}, {"name": "other_comments_on_LLMs"}, {"name": "venue", "hidden": true}, {"name": "venueid", "hidden": true}, {"name": "_bibtex", "input": "textarea"}, {"name": "other_comments"}]}}, {"id": "cc8h3I3V4E", "forum": "cc8h3I3V4E", "number": 3469, "cdate": 1695298892160, "tcdate": 1695298892160, "mdate": 1712935500795, "tmdate": 1712935500795, "signatures": ["ICLR.cc/2024/Conference/Submission3469/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission3469/Authors"], "content": {"title": {"value": "Approximating Nash Equilibria in Normal-Form Games via Stochastic Optimization"}, "authors": {"value": ["Ian Gemp", "Luke Marris", "Georgios Piliouras"]}, "authorids": {"value": ["~Ian_Gemp1", "~Luke_Marris2", "~Georgios_Piliouras1"]}, "keywords": {"value": ["game theory", "stochastic optimization", "nash equilbrium", "normal-form game", "x-armed bandits"]}, "TLDR": {"value": "We propose the first stochastic NE loss for normal-form games."}, "abstract": {"value": "We propose the first loss function for approximate Nash equilibria of normal-form games that is amenable to unbiased Monte Carlo estimation. This construction allows us to deploy standard non-convex stochastic optimization techniques for approximating Nash equilibria, resulting in novel algorithms  with provable guarantees. We complement our theoretical analysis with experiments demonstrating that stochastic gradient descent can outperform previous state-of-the-art approaches."}, "primary_area": {"value": "general machine learning (i.e., none of the above)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 oral"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/6116af6dc392a3153d1462f038b9dac4f8305ca6.pdf"}, "_bibtex": {"value": "@inproceedings{\ngemp2024approximating,\ntitle={Approximating Nash Equilibria in Normal-Form Games via Stochastic Optimization},\nauthor={Ian Gemp and Luke Marris and Georgios Piliouras},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=cc8h3I3V4E}\n}"}, "paperhash": {"value": "gemp|approximating_nash_equilibria_in_normalform_games_via_stochastic_optimization"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission3469/-/Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission3469/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410875988, "version": 2, "details": {"replyCount": 11, "presentation": [{"name": "title", "order": 1}, {"name": "authors", "order": 3}, {"name": "code_of_ethics", "order": 3, "input": "checkbox", "value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "description": null}, {"name": "authorids", "order": 4}, {"name": "keywords", "order": 4}, {"name": "submission_guidelines", "order": 4, "input": "checkbox", "value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide.", "description": null}, {"name": "TLDR", "order": 5, "fieldName": "TL;DR"}, {"name": "abstract", "order": 6, "input": "textarea", "markdown": true}, {"name": "pdf", "order": 7}, {"name": "anonymous_url", "order": 7, "input": "checkbox", "value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "description": null}, {"name": "supplementary_material", "order": 8}, {"name": "no_acknowledgement_section", "order": 8, "input": "checkbox", "value": "I certify that there is no acknowledgement section in this submission for double blind review.", "description": null}, {"name": "primary_area", "order": 9, "input": "select", "value": "general machine learning (i.e., none of the above)", "description": null}, {"name": "resubmission"}, {"name": "student_author"}, {"name": "large_language_models"}, {"name": "other_comments_on_LLMs"}, {"name": "venue", "hidden": true}, {"name": "venueid", "hidden": true}, {"name": "_bibtex", "input": "textarea"}, {"name": "other_comments"}]}}, {"id": "h922Qhkmx1", "forum": "h922Qhkmx1", "number": 3354, "cdate": 1695288602570, "tcdate": 1695288602570, "mdate": 1710462173926, "tmdate": 1710462173926, "signatures": ["ICLR.cc/2024/Conference/Submission3354/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission3354/Authors"], "content": {"title": {"value": "Multi-Source Diffusion Models for Simultaneous Music Generation and Separation"}, "authors": {"value": ["Giorgio Mariani", "Irene Tallini", "Emilian Postolache", "Michele Mancusi", "Luca Cosmo", "Emanuele Rodol\u00e0"]}, "authorids": {"value": ["~Giorgio_Mariani1", "~Irene_Tallini1", "~Emilian_Postolache1", "~Michele_Mancusi1", "~Luca_Cosmo2", "~Emanuele_Rodol\u00e01"]}, "keywords": {"value": ["source separation", "probabilistic diffusion models", "music generation"]}, "abstract": {"value": "In this work, we define a diffusion-based generative model capable of both music generation and source separation by learning the score of the joint probability density of sources sharing a context. Alongside the classic total inference tasks (i.e., generating a mixture, separating the sources), we also introduce and experiment on the partial generation task of source imputation, where we generate a subset of the sources given the others (e.g., play a piano track that goes well with the drums). Additionally, we introduce a novel inference method for the separation task based on Dirac likelihood functions. We train our model on Slakh2100, a standard dataset for musical source separation, provide qualitative results in the generation settings, and showcase competitive quantitative results in the source separation setting. Our method is the first example of a single model that can handle both generation and separation tasks, thus representing a step toward general audio models."}, "primary_area": {"value": "generative models"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 oral"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/e9d4d9aabe25aa6dc764b915d5844871ff4bcd7c.pdf"}, "supplementary_material": {"value": "/attachment/ce96fbc2ccc8d79e2984ab1973c671b0c29238a0.zip"}, "TLDR": {"value": "In this work, we define a diffusion-based generative model which is the first to be capable of both music generation and source separation. We also introduce the partial generation task, where we generate a subset of the sources given the others."}, "_bibtex": {"value": "@inproceedings{\nmariani2024multisource,\ntitle={Multi-Source Diffusion Models for Simultaneous Music Generation and Separation},\nauthor={Giorgio Mariani and Irene Tallini and Emilian Postolache and Michele Mancusi and Luca Cosmo and Emanuele Rodol{\\`a}},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=h922Qhkmx1}\n}"}, "paperhash": {"value": "mariani|multisource_diffusion_models_for_simultaneous_music_generation_and_separation"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission3354/-/Revision", "ICLR.cc/2024/Conference/Submission3354/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission3354/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410871998, "version": 2, "details": {"replyCount": 17, "presentation": [{"name": "title", "order": 1}, {"name": "authors", "order": 3}, {"name": "code_of_ethics", "order": 3, "input": "checkbox", "value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "description": null}, {"name": "authorids", "order": 4}, {"name": "keywords", "order": 4}, {"name": "submission_guidelines", "order": 4, "input": "checkbox", "value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide.", "description": null}, {"name": "TLDR", "order": 5, "fieldName": "TL;DR"}, {"name": "abstract", "order": 6, "input": "textarea", "markdown": true}, {"name": "pdf", "order": 7}, {"name": "anonymous_url", "order": 7, "input": "checkbox", "value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "description": null}, {"name": "supplementary_material", "order": 8}, {"name": "no_acknowledgement_section", "order": 8, "input": "checkbox", "value": "I certify that there is no acknowledgement section in this submission for double blind review.", "description": null}, {"name": "primary_area", "order": 9, "input": "select", "value": "generative models", "description": null}, {"name": "resubmission"}, {"name": "student_author"}, {"name": "large_language_models"}, {"name": "other_comments_on_LLMs"}, {"name": "venue", "hidden": true}, {"name": "venueid", "hidden": true}, {"name": "_bibtex", "input": "textarea"}, {"name": "other_comments"}]}}, {"id": "3f5PALef5B", "forum": "3f5PALef5B", "number": 3246, "cdate": 1695281882698, "tcdate": 1695281882698, "mdate": 1710122690636, "tmdate": 1710122690636, "signatures": ["ICLR.cc/2024/Conference/Submission3246/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission3246/Authors"], "content": {"title": {"value": "LEGO-Prover: Neural Theorem Proving with Growing Libraries"}, "authors": {"value": ["Haiming Wang", "Huajian Xin", "Chuanyang Zheng", "Zhengying Liu", "Qingxing Cao", "Yinya Huang", "Jing Xiong", "Han Shi", "Enze Xie", "Jian Yin", "Zhenguo Li", "Xiaodan Liang"]}, "authorids": {"value": ["~Haiming_Wang1", "~Huajian_Xin1", "~Chuanyang_Zheng3", "~Zhengying_Liu2", "~Qingxing_Cao1", "~Yinya_Huang1", "~Jing_Xiong4", "~Han_Shi1", "~Enze_Xie1", "~Jian_Yin3", "~Zhenguo_Li1", "~Xiaodan_Liang2"]}, "keywords": {"value": ["Theorem proving", "Large language model", "Autoformalization"]}, "abstract": {"value": "Despite the success of large language models (LLMs), the task of theorem proving still remains one of the hardest reasoning tasks that is far from being fully solved. Prior methods using language models have demonstrated promising results, but they still struggle to prove even middle school level theorems. One common limitation of these methods is that they assume a fixed theorem library during the whole theorem proving process. However, as we all know, creating new useful theorems or even new theories is not only helpful but crucial and necessary for advancing mathematics and proving harder and deeper results. In this work, we present LEGO-Prover, which employs a growing skill library containing verified lemmas as skills to augment the capability of LLMs used in theorem proving. By constructing the proof modularly, LEGO-Prover enables LLMs to utilize existing skills retrieved from the library and to create new skills during the proving process. These skills are further evolved (by prompting an LLM) to enrich the library on another scale. Modular and reusable skills are constantly added to the library to enable tackling increasingly intricate mathematical problems. Moreover, the learned library further bridges the gap between human proofs and formal proofs by making it easier to impute missing steps. LEGO-Prover advances the state-of-the-art pass rate on miniF2F-valid (48.0\\% to 57.0\\%) and miniF2F-test (45.5\\% to 50.0\\%). During the proving process, LEGO-Prover also generates over 20,000 skills (theorems/lemmas) and adds them to the growing library. Our ablation study indicates that these newly added skills are indeed helpful for proving theorems, resulting in a 4.9\\% improvement in success rate"}, "primary_area": {"value": "neurosymbolic & hybrid AI systems (physics-informed, logic & formal reasoning, etc.)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 oral"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/3133380a86db246c6a9e18dabc0a301196b70cd6.pdf"}, "_bibtex": {"value": "@inproceedings{\nwang2024legoprover,\ntitle={{LEGO}-Prover: Neural Theorem Proving with Growing Libraries},\nauthor={Haiming Wang and Huajian Xin and Chuanyang Zheng and Zhengying Liu and Qingxing Cao and Yinya Huang and Jing Xiong and Han Shi and Enze Xie and Jian Yin and Zhenguo Li and Xiaodan Liang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=3f5PALef5B}\n}"}, "paperhash": {"value": "wang|legoprover_neural_theorem_proving_with_growing_libraries"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission3246/-/Revision", "ICLR.cc/2024/Conference/Submission3246/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission3246/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410868784, "version": 2, "details": {"replyCount": 33, "presentation": [{"name": "title", "order": 1}, {"name": "authors", "order": 3}, {"name": "code_of_ethics", "order": 3, "input": "checkbox", "value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "description": null}, {"name": "authorids", "order": 4}, {"name": "keywords", "order": 4}, {"name": "submission_guidelines", "order": 4, "input": "checkbox", "value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide.", "description": null}, {"name": "TLDR", "order": 5, "fieldName": "TL;DR"}, {"name": "abstract", "order": 6, "input": "textarea", "markdown": true}, {"name": "pdf", "order": 7}, {"name": "anonymous_url", "order": 7, "input": "checkbox", "value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "description": null}, {"name": "supplementary_material", "order": 8}, {"name": "no_acknowledgement_section", "order": 8, "input": "checkbox", "value": "I certify that there is no acknowledgement section in this submission for double blind review.", "description": null}, {"name": "primary_area", "order": 9, "input": "select", "value": "neurosymbolic & hybrid AI systems (physics-informed, logic & formal reasoning, etc.)", "description": null}, {"name": "resubmission"}, {"name": "student_author"}, {"name": "large_language_models"}, {"name": "other_comments_on_LLMs"}, {"name": "venue", "hidden": true}, {"name": "venueid", "hidden": true}, {"name": "_bibtex", "input": "textarea"}, {"name": "other_comments"}]}}, {"id": "jNR6s6OSBT", "forum": "jNR6s6OSBT", "number": 3016, "cdate": 1695261367459, "tcdate": 1695261367459, "mdate": 1713672323235, "tmdate": 1713672323235, "signatures": ["ICLR.cc/2024/Conference/Submission3016/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission3016/Authors"], "content": {"title": {"value": "ASID: Active Exploration for System Identification in Robotic Manipulation"}, "authors": {"value": ["Marius Memmel", "Andrew Wagenmaker", "Chuning Zhu", "Dieter Fox", "Abhishek Gupta"]}, "authorids": {"value": ["~Marius_Memmel1", "~Andrew_Wagenmaker1", "~Chuning_Zhu1", "~Dieter_Fox1", "~Abhishek_Gupta1"]}, "keywords": {"value": ["sim2real", "system identification", "exploration"]}, "abstract": {"value": "Model-free control strategies such as reinforcement learning have shown the ability to learn control strategies without requiring an accurate model or simulator of the world. While this is appealing due to the lack of modeling requirements, such methods can be sample inefficient, making them impractical in many real-world domains. On the other hand, model-based control techniques leveraging accurate simulators can circumvent these challenges and use a large amount of cheap simulation data to learn controllers that can effectively transfer to the real world. The challenge with such model-based techniques is the requirement for an extremely accurate simulation, requiring both the specification of appropriate simulation assets and physical parameters. This requires considerable human effort to design for every environment being considered. In this work, we propose a learning system that can leverage a small amount of real-world data to autonomously refine a simulation model and then plan an accurate control strategy that can be deployed in the real world. Our approach critically relies on utilizing an initial (possibly inaccurate) simulator to design effective exploration policies that, when deployed in the real world, collect high-quality data. We demonstrate the efficacy of this paradigm in identifying articulation, mass, and other physical parameters in several challenging robotic manipulation tasks, and illustrate that only a small amount of real-world data can allow for effective sim-to-real transfer."}, "primary_area": {"value": "applications to robotics, autonomy, planning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 oral"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/f456ef2115275fac2aa0977b3c7db68ed00add89.pdf"}, "_bibtex": {"value": "@inproceedings{\nmemmel2024asid,\ntitle={{ASID}: Active Exploration for System Identification in Robotic Manipulation},\nauthor={Marius Memmel and Andrew Wagenmaker and Chuning Zhu and Dieter Fox and Abhishek Gupta},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=jNR6s6OSBT}\n}"}, "paperhash": {"value": "memmel|asid_active_exploration_for_system_identification_in_robotic_manipulation"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission3016/-/Revision", "ICLR.cc/2024/Conference/Submission3016/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission3016/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410862516, "version": 2, "details": {"replyCount": 18, "presentation": [{"name": "title", "order": 1}, {"name": "authors", "order": 3}, {"name": "code_of_ethics", "order": 3, "input": "checkbox", "value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "description": null}, {"name": "authorids", "order": 4}, {"name": "keywords", "order": 4}, {"name": "submission_guidelines", "order": 4, "input": "checkbox", "value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide.", "description": null}, {"name": "TLDR", "order": 5, "fieldName": "TL;DR"}, {"name": "abstract", "order": 6, "input": "textarea", "markdown": true}, {"name": "pdf", "order": 7}, {"name": "anonymous_url", "order": 7, "input": "checkbox", "value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "description": null}, {"name": "supplementary_material", "order": 8}, {"name": "no_acknowledgement_section", "order": 8, "input": "checkbox", "value": "I certify that there is no acknowledgement section in this submission for double blind review.", "description": null}, {"name": "primary_area", "order": 9, "input": "select", "value": "applications to robotics, autonomy, planning", "description": null}, {"name": "resubmission"}, {"name": "student_author"}, {"name": "large_language_models"}, {"name": "other_comments_on_LLMs"}, {"name": "venue", "hidden": true}, {"name": "venueid", "hidden": true}, {"name": "_bibtex", "input": "textarea"}, {"name": "other_comments"}]}}, {"id": "HhfcNgQn6p", "forum": "HhfcNgQn6p", "number": 2837, "cdate": 1695238535944, "tcdate": 1695238535944, "mdate": 1712863345688, "tmdate": 1712863345688, "signatures": ["ICLR.cc/2024/Conference/Submission2837/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission2837/Authors"], "content": {"title": {"value": "Towards a statistical theory of data selection under weak supervision"}, "authors": {"value": ["Germain Kolossov", "Andrea Montanari", "Pulkit Tandon"]}, "authorids": {"value": ["~Germain_Kolossov1", "~Andrea_Montanari1", "~Pulkit_Tandon1"]}, "keywords": {"value": ["Data Selection", "Empirical Risk Minimization", "Influence Functions", "High dimensional asymptotics"]}, "abstract": {"value": "Given a sample of size $N$, it is often useful to select a subsample of smaller size $n<N$ to be used for statistical estimation or learning.  Such a data selection step is useful to reduce the requirements of data labeling and the computational complexity of learning. We assume to be given $N$ unlabeled samples $x_{i}$, and to be given access to a  'surrogate model' that can predict labels $y_i$ better than random guessing. Our goal is to select a subset of the samples, to be denoted by {$x_{i}$}$_{i\\in G}$, of size $|G|=n<N$. We then acquire labels for this set and we use them to train a model via regularized empirical risk minimization. By using a mixture of numerical experiments on real and synthetic data, and mathematical derivations under low- and high- dimensional asymptotics, we show that: $(i)$ Data selection can be very effective, in particular beating training on the full sample in some cases; $(ii)$ Certain popular choices in data selection methods (e.g. unbiased reweighted subsampling, or influence function-based subsampling) can be substantially suboptimal."}, "primary_area": {"value": "unsupervised, self-supervised, semi-supervised, and supervised representation learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 oral"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/3afcd7230f6f462e837b839132c8cdd6cfceb037.pdf"}, "supplementary_material": {"value": "/attachment/f5c561e59a49e56e07bbc82994cc66894f6d625f.pdf"}, "_bibtex": {"value": "@inproceedings{\nkolossov2024towards,\ntitle={Towards a statistical theory of data selection under weak supervision},\nauthor={Germain Kolossov and Andrea Montanari and Pulkit Tandon},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=HhfcNgQn6p}\n}"}, "paperhash": {"value": "kolossov|towards_a_statistical_theory_of_data_selection_under_weak_supervision"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission2837/-/Revision", "ICLR.cc/2024/Conference/Submission2837/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission2837/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410858121, "version": 2, "details": {"replyCount": 16, "presentation": [{"name": "title", "order": 1}, {"name": "authors", "order": 3}, {"name": "code_of_ethics", "order": 3, "input": "checkbox", "value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "description": null}, {"name": "authorids", "order": 4}, {"name": "keywords", "order": 4}, {"name": "submission_guidelines", "order": 4, "input": "checkbox", "value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide.", "description": null}, {"name": "TLDR", "order": 5, "fieldName": "TL;DR"}, {"name": "abstract", "order": 6, "input": "textarea", "markdown": true}, {"name": "pdf", "order": 7}, {"name": "anonymous_url", "order": 7, "input": "checkbox", "value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "description": null}, {"name": "supplementary_material", "order": 8}, {"name": "no_acknowledgement_section", "order": 8, "input": "checkbox", "value": "I certify that there is no acknowledgement section in this submission for double blind review.", "description": null}, {"name": "primary_area", "order": 9, "input": "select", "value": "unsupervised, self-supervised, semi-supervised, and supervised representation learning", "description": null}, {"name": "resubmission"}, {"name": "student_author"}, {"name": "large_language_models"}, {"name": "other_comments_on_LLMs"}, {"name": "venue", "hidden": true}, {"name": "venueid", "hidden": true}, {"name": "_bibtex", "input": "textarea"}, {"name": "other_comments"}]}}, {"id": "1vDArHJ68h", "forum": "1vDArHJ68h", "number": 2796, "cdate": 1695234407246, "tcdate": 1695234407246, "mdate": 1710543756220, "tmdate": 1710543756220, "signatures": ["ICLR.cc/2024/Conference/Submission2796/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission2796/Authors"], "content": {"title": {"value": "Mastering Memory Tasks with World Models"}, "authors": {"value": ["Mohammad Reza Samsami", "Artem Zholus", "Janarthanan Rajendran", "Sarath Chandar"]}, "authorids": {"value": ["~Mohammad_Reza_Samsami1", "~Artem_Zholus1", "~Janarthanan_Rajendran1", "~Sarath_Chandar1"]}, "keywords": {"value": ["model-based reinforcement learning", "state space models", "memory in reinforcement learning"]}, "TLDR": {"value": "We propose R2I, a model-based agent with enhanced memory capabilities which shines in challenging memory reinforcement learning tasks."}, "abstract": {"value": "Current model-based reinforcement learning (MBRL) agents struggle with long-term dependencies. This limits their ability to effectively solve tasks involving extended time gaps between actions and outcomes, or tasks demanding the recalling of distant observations to inform current actions. To improve temporal coherence, we integrate a new family of state space models (SSMs) in world models of MBRL agents to present a new method, Recall to Imagine (R2I). This integration aims to enhance both long-term memory and long-horizon credit assignment. Through a diverse set of illustrative tasks, we systematically demonstrate that R2I not only establishes a new state-of-the-art for challenging memory and credit assignment RL tasks, such as BSuite and POPGym, but also showcases superhuman performance in the complex memory domain of Memory Maze. At the same time, it upholds comparable performance in classic RL tasks, such as Atari and DMC, suggesting the generality of our method. We also show that R2I is faster than the state-of-the-art MBRL method, DreamerV3, resulting in faster wall-time convergence."}, "primary_area": {"value": "reinforcement learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 oral"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/152e0fd1736694958db18ece2cda594d14c79969.pdf"}, "_bibtex": {"value": "@inproceedings{\nsamsami2024mastering,\ntitle={Mastering Memory Tasks with World Models},\nauthor={Mohammad Reza Samsami and Artem Zholus and Janarthanan Rajendran and Sarath Chandar},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=1vDArHJ68h}\n}"}, "paperhash": {"value": "samsami|mastering_memory_tasks_with_world_models"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission2796/-/Revision", "ICLR.cc/2024/Conference/Submission2796/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission2796/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410856738, "version": 2, "details": {"replyCount": 20, "presentation": [{"name": "title", "order": 1}, {"name": "authors", "order": 3}, {"name": "code_of_ethics", "order": 3, "input": "checkbox", "value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "description": null}, {"name": "authorids", "order": 4}, {"name": "keywords", "order": 4}, {"name": "submission_guidelines", "order": 4, "input": "checkbox", "value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide.", "description": null}, {"name": "TLDR", "order": 5, "fieldName": "TL;DR"}, {"name": "abstract", "order": 6, "input": "textarea", "markdown": true}, {"name": "pdf", "order": 7}, {"name": "anonymous_url", "order": 7, "input": "checkbox", "value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "description": null}, {"name": "supplementary_material", "order": 8}, {"name": "no_acknowledgement_section", "order": 8, "input": "checkbox", "value": "I certify that there is no acknowledgement section in this submission for double blind review.", "description": null}, {"name": "primary_area", "order": 9, "input": "select", "value": "reinforcement learning", "description": null}, {"name": "resubmission"}, {"name": "student_author"}, {"name": "large_language_models"}, {"name": "other_comments_on_LLMs"}, {"name": "venue", "hidden": true}, {"name": "venueid", "hidden": true}, {"name": "_bibtex", "input": "textarea"}, {"name": "other_comments"}]}}, {"id": "nHESwXvxWK", "forum": "nHESwXvxWK", "number": 2746, "cdate": 1695229780105, "tcdate": 1695229780105, "mdate": 1713672248212, "tmdate": 1713672248212, "signatures": ["ICLR.cc/2024/Conference/Submission2746/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission2746/Authors"], "content": {"title": {"value": "Monte Carlo guided Denoising Diffusion models for Bayesian linear inverse problems."}, "authors": {"value": ["Gabriel Cardoso", "Yazid Janati el idrissi", "Sylvain Le Corff", "Eric Moulines"]}, "authorids": {"value": ["~Gabriel_Cardoso1", "~Yazid_Janati_el_idrissi3", "~Sylvain_Le_Corff1", "~Eric_Moulines1"]}, "keywords": {"value": ["Monte Carlo", "Denoising Diffusion model", "score-based generative models", "Sequential Monte Carlo", "Bayesian Inverse Problems", "Generative Models."]}, "abstract": {"value": "Ill-posed linear inverse problems arise frequently in various applications, from computational photography to medical imaging.\nA recent line of research exploits Bayesian inference with informative priors to handle the ill-posedness of such problems.\nAmongst such priors, score-based generative models (SGM) have recently been successfully applied to several different inverse problems.\nIn this study, we exploit the particular structure of the prior defined by the SGM to define a sequence of intermediate linear inverse problems. As the noise level decreases, the posteriors of these inverse problems get closer to the target posterior of the original inverse problem. \nTo sample from this sequence of posteriors, we propose the use of Sequential Monte Carlo (SMC) methods.\nThe proposed algorithm, \\algo, is shown to be theoretically grounded and we provide numerical simulations showing that it outperforms competing baselines when dealing with ill-posed inverse problems in a Bayesian setting."}, "pdf": {"value": "/pdf/c0015dd72ccf0837042cc9453b2722e3b53f1893.pdf"}, "primary_area": {"value": "probabilistic methods (Bayesian methods, variational inference, sampling, UQ, etc.)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 oral"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "_bibtex": {"value": "@inproceedings{\ncardoso2024monte,\ntitle={Monte Carlo guided Denoising Diffusion models for Bayesian linear inverse problems.},\nauthor={Gabriel Cardoso and Yazid Janati el idrissi and Sylvain Le Corff and Eric Moulines},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=nHESwXvxWK}\n}"}, "paperhash": {"value": "cardoso|monte_carlo_guided_denoising_diffusion_models_for_bayesian_linear_inverse_problems"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission2746/-/Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission2746/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410855461, "version": 2, "details": {"replyCount": 13, "presentation": [{"name": "title", "order": 1}, {"name": "authors", "order": 3}, {"name": "code_of_ethics", "order": 3, "input": "checkbox", "value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "description": null}, {"name": "authorids", "order": 4}, {"name": "keywords", "order": 4}, {"name": "submission_guidelines", "order": 4, "input": "checkbox", "value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide.", "description": null}, {"name": "TLDR", "order": 5, "fieldName": "TL;DR"}, {"name": "abstract", "order": 6, "input": "textarea", "markdown": true}, {"name": "pdf", "order": 7}, {"name": "anonymous_url", "order": 7, "input": "checkbox", "value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "description": null}, {"name": "supplementary_material", "order": 8}, {"name": "no_acknowledgement_section", "order": 8, "input": "checkbox", "value": "I certify that there is no acknowledgement section in this submission for double blind review.", "description": null}, {"name": "primary_area", "order": 9, "input": "select", "value": "probabilistic methods (Bayesian methods, variational inference, sampling, UQ, etc.)", "description": null}, {"name": "resubmission"}, {"name": "student_author"}, {"name": "large_language_models"}, {"name": "other_comments_on_LLMs"}, {"name": "venue", "hidden": true}, {"name": "venueid", "hidden": true}, {"name": "_bibtex", "input": "textarea"}, {"name": "other_comments"}]}}, {"id": "1oijHJBRsT", "forum": "1oijHJBRsT", "number": 2743, "cdate": 1695229634675, "tcdate": 1695229634675, "mdate": 1710205578251, "tmdate": 1710205578251, "signatures": ["ICLR.cc/2024/Conference/Submission2743/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission2743/Authors"], "content": {"title": {"value": "Self-Alignment with Instruction Backtranslation"}, "authors": {"value": ["Xian Li", "Ping Yu", "Chunting Zhou", "Timo Schick", "Omer Levy", "Luke Zettlemoyer", "Jason E Weston", "Mike Lewis"]}, "authorids": {"value": ["~Xian_Li1", "~Ping_Yu2", "~Chunting_Zhou1", "~Timo_Schick1", "~Omer_Levy1", "~Luke_Zettlemoyer1", "~Jason_E_Weston1", "~Mike_Lewis1"]}, "keywords": {"value": ["large language models", "self-supervised learning", "data augmentation"]}, "abstract": {"value": "We present a scalable method to build a high quality instruction following language model by automatically labelling human-written text with corresponding instructions. Our approach, named instruction backtranslation, starts with a language model finetuned on a small amount of seed data, and a given web corpus. The seed model is used to construct training examples by generating instruction prompts for web documents (self-augmentation), and then  selecting high quality examples from among these candidates (self-curation).  This data is then used to finetune a stronger model.  Finetuning LLaMa on two iterations of our approach yields a model that outperforms all other LLaMa-based models on the Alpaca leaderboard not relying on distillation data, demonstrating highly effective self-alignment."}, "primary_area": {"value": "generative models"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 oral"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/1d2560a0bb5b83c6bafcac88a94445a60971be31.pdf"}, "_bibtex": {"value": "@inproceedings{\nli2024selfalignment,\ntitle={Self-Alignment with Instruction Backtranslation},\nauthor={Xian Li and Ping Yu and Chunting Zhou and Timo Schick and Omer Levy and Luke Zettlemoyer and Jason E Weston and Mike Lewis},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=1oijHJBRsT}\n}"}, "paperhash": {"value": "li|selfalignment_with_instruction_backtranslation"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission2743/-/Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission2743/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410855386, "version": 2, "details": {"replyCount": 11, "presentation": [{"name": "title", "order": 1}, {"name": "authors", "order": 3}, {"name": "code_of_ethics", "order": 3, "input": "checkbox", "value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "description": null}, {"name": "authorids", "order": 4}, {"name": "keywords", "order": 4}, {"name": "submission_guidelines", "order": 4, "input": "checkbox", "value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide.", "description": null}, {"name": "TLDR", "order": 5, "fieldName": "TL;DR"}, {"name": "abstract", "order": 6, "input": "textarea", "markdown": true}, {"name": "pdf", "order": 7}, {"name": "anonymous_url", "order": 7, "input": "checkbox", "value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "description": null}, {"name": "supplementary_material", "order": 8}, {"name": "no_acknowledgement_section", "order": 8, "input": "checkbox", "value": "I certify that there is no acknowledgement section in this submission for double blind review.", "description": null}, {"name": "primary_area", "order": 9, "input": "select", "value": "generative models", "description": null}, {"name": "resubmission"}, {"name": "student_author"}, {"name": "large_language_models"}, {"name": "other_comments_on_LLMs"}, {"name": "venue", "hidden": true}, {"name": "venueid", "hidden": true}, {"name": "_bibtex", "input": "textarea"}, {"name": "other_comments"}]}}, {"id": "sFyTZEqmUY", "forum": "sFyTZEqmUY", "number": 2698, "cdate": 1695225593569, "tcdate": 1695225593569, "mdate": 1714529756562, "tmdate": 1714529756562, "signatures": ["ICLR.cc/2024/Conference/Submission2698/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission2698/Authors"], "content": {"title": {"value": "Learning Interactive Real-World Simulators"}, "authors": {"value": ["Sherry Yang", "Yilun Du", "Seyed Kamyar Seyed Ghasemipour", "Jonathan Tompson", "Leslie Pack Kaelbling", "Dale Schuurmans", "Pieter Abbeel"]}, "authorids": {"value": ["~Sherry_Yang1", "~Yilun_Du1", "~Seyed_Kamyar_Seyed_Ghasemipour1", "~Jonathan_Tompson1", "~Leslie_Pack_Kaelbling1", "~Dale_Schuurmans1", "~Pieter_Abbeel2"]}, "keywords": {"value": ["Generative simulator", "simulating real-world interactions", "planning", "reinforcement learning", "vision language models", "video generation"]}, "TLDR": {"value": "We learn an interactive real-world simulator from broad data rich in different axes that enables long-horizon interactions with humans, vision language models, and reinforcement learning agents."}, "abstract": {"value": "Generative models trained on internet data have revolutionized how text, image, and video content can be created. Perhaps the next milestone for generative models is to simulate realistic experience in response to actions taken by humans, robots, and other interactive agents. Applications of a real-world simulator range from controllable content creation in games and movies, to training embodied agents purely in simulation that can be directly deployed in the real world. We explore the possibility of learning a universal simulator (UniSim) of real-world interaction through generative modeling. We first make the important observation that natural datasets available for learning a real-world simulator are often rich along different axes (e.g., abundant objects in image data, densely sampled actions in robotics data, and diverse movements in navigation data). With careful orchestration of diverse datasets, each providing a different aspect of the overall experience, UniSim can emulate how humans and agents interact with the world by simulating the visual outcome of both high-level instructions such as \u201copen the drawer\u201d and low-level controls such as \u201cmove by x,y\u201d from otherwise static scenes and objects. There are numerous use cases for such a real-world simulator. As an example, we use UniSim to train both high-level vision-language planners and low-level reinforcement learning policies, each of which exhibit zero-shot real-world transfer after training purely in a learned real-world simulator. We also show that other types of intelligence such as video captioning models can benefit from training with simulated experience in UniSim, opening up even wider applications."}, "primary_area": {"value": "applications to robotics, autonomy, planning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 oral"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/ebbd0d77e65c2e2ffb1eef300c8c55e4f2f27c86.pdf"}, "_bibtex": {"value": "@inproceedings{\nyang2024learning,\ntitle={Learning Interactive Real-World Simulators},\nauthor={Sherry Yang and Yilun Du and Seyed Kamyar Seyed Ghasemipour and Jonathan Tompson and Leslie Pack Kaelbling and Dale Schuurmans and Pieter Abbeel},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=sFyTZEqmUY}\n}"}, "paperhash": {"value": "yang|learning_interactive_realworld_simulators"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission2698/-/Revision", "ICLR.cc/2024/Conference/Submission2698/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission2698/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410854266, "version": 2, "details": {"replyCount": 17, "presentation": [{"name": "title", "order": 1}, {"name": "authors", "order": 3}, {"name": "code_of_ethics", "order": 3, "input": "checkbox", "value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "description": null}, {"name": "authorids", "order": 4}, {"name": "keywords", "order": 4}, {"name": "submission_guidelines", "order": 4, "input": "checkbox", "value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide.", "description": null}, {"name": "TLDR", "order": 5, "fieldName": "TL;DR"}, {"name": "abstract", "order": 6, "input": "textarea", "markdown": true}, {"name": "pdf", "order": 7}, {"name": "anonymous_url", "order": 7, "input": "checkbox", "value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "description": null}, {"name": "supplementary_material", "order": 8}, {"name": "no_acknowledgement_section", "order": 8, "input": "checkbox", "value": "I certify that there is no acknowledgement section in this submission for double blind review.", "description": null}, {"name": "primary_area", "order": 9, "input": "select", "value": "applications to robotics, autonomy, planning", "description": null}, {"name": "resubmission"}, {"name": "student_author"}, {"name": "large_language_models"}, {"name": "other_comments_on_LLMs"}, {"name": "venue", "hidden": true}, {"name": "venueid", "hidden": true}, {"name": "_bibtex", "input": "textarea"}, {"name": "other_comments"}]}}, {"id": "Fk5IzauJ7F", "forum": "Fk5IzauJ7F", "number": 2682, "cdate": 1695224361045, "tcdate": 1695224361045, "mdate": 1711361593473, "tmdate": 1711361593473, "signatures": ["ICLR.cc/2024/Conference/Submission2682/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission2682/Authors"], "content": {"title": {"value": "Candidate Label Set Pruning: A Data-centric Perspective for Deep Partial-label Learning"}, "authors": {"value": ["Shuo He", "Chaojie Wang", "Guowu Yang", "Lei Feng"]}, "authorids": {"value": ["~Shuo_He1", "~Chaojie_Wang1", "~Guowu_Yang1", "~Lei_Feng1"]}, "keywords": {"value": ["partial label learning", "label disambiguation", "candidate label set pruning"]}, "abstract": {"value": "Partial-label learning (PLL) allows each training example to be equipped with a set of candidate labels. Existing deep PLL research focuses on a \\emph{learning-centric} perspective to design various training strategies for label disambiguation i.e., identifying the concealed true label from the candidate label set, for model training. However, when the size of the candidate label set becomes excessively large, these learning-centric strategies would be unable to find the true label for model training, thereby causing performance degradation. This motivates us to think from a \\emph{data-centric} perspective and pioneer a new PLL-related task called candidate label set pruning (CLSP) that aims to filter out certain potential false candidate labels in a training-free manner. To this end, we propose the first CLSP method based on the inconsistency between the representation space and the candidate label space. Specifically, for each candidate label of a training instance, if it is not a candidate label of the instance's nearest neighbors in the representation space, then it has a high probability of being a false label. Based on this intuition, we employ a per-example pruning scheme that filters out a specific proportion of high-probability false candidate labels. Theoretically, we prove an upper bound of the pruning error rate and analyze how the quality of representations affects our proposed method. Empirically, extensive experiments on both benchmark-simulated and real-world PLL datasets validate the great value of CLSP to significantly improve many state-of-the-art deep PLL methods."}, "primary_area": {"value": "unsupervised, self-supervised, semi-supervised, and supervised representation learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 oral"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/acca7b23067f28f766cd4bad4ec9bc2875702fc8.pdf"}, "supplementary_material": {"value": "/attachment/e98e8e6e979da6eba336f2681663b47ea771ee42.zip"}, "_bibtex": {"value": "@inproceedings{\nhe2024candidate,\ntitle={Candidate Label Set Pruning: A Data-centric Perspective for Deep Partial-label Learning},\nauthor={Shuo He and Chaojie Wang and Guowu Yang and Lei Feng},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=Fk5IzauJ7F}\n}"}, "TLDR": {"value": "We pioneer a new task called candidate label  set pruning (CLSP) for the problem of deep partial label learning, and propose a new CLSP algorithm."}, "paperhash": {"value": "he|candidate_label_set_pruning_a_datacentric_perspective_for_deep_partiallabel_learning"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission2682/-/Revision", "ICLR.cc/2024/Conference/Submission2682/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission2682/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410853772, "version": 2, "details": {"replyCount": 17, "presentation": [{"name": "title", "order": 1}, {"name": "authors", "order": 3}, {"name": "code_of_ethics", "order": 3, "input": "checkbox", "value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "description": null}, {"name": "authorids", "order": 4}, {"name": "keywords", "order": 4}, {"name": "submission_guidelines", "order": 4, "input": "checkbox", "value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide.", "description": null}, {"name": "TLDR", "order": 5, "fieldName": "TL;DR"}, {"name": "abstract", "order": 6, "input": "textarea", "markdown": true}, {"name": "pdf", "order": 7}, {"name": "anonymous_url", "order": 7, "input": "checkbox", "value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "description": null}, {"name": "supplementary_material", "order": 8}, {"name": "no_acknowledgement_section", "order": 8, "input": "checkbox", "value": "I certify that there is no acknowledgement section in this submission for double blind review.", "description": null}, {"name": "primary_area", "order": 9, "input": "select", "value": "unsupervised, self-supervised, semi-supervised, and supervised representation learning", "description": null}, {"name": "resubmission"}, {"name": "student_author"}, {"name": "large_language_models"}, {"name": "other_comments_on_LLMs"}, {"name": "venue", "hidden": true}, {"name": "venueid", "hidden": true}, {"name": "_bibtex", "input": "textarea"}, {"name": "other_comments"}]}}, {"id": "pOoKI3ouv1", "forum": "pOoKI3ouv1", "number": 2566, "cdate": 1695216042957, "tcdate": 1695216042957, "mdate": 1712740478214, "tmdate": 1712740478214, "signatures": ["ICLR.cc/2024/Conference/Submission2566/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission2566/Authors"], "content": {"title": {"value": "Robust agents learn causal world models"}, "authors": {"value": ["Jonathan Richens", "Tom Everitt"]}, "authorids": {"value": ["~Jonathan_Richens1", "~Tom_Everitt1"]}, "keywords": {"value": ["causality", "generalisation", "causal discovery", "domain adaptation", "out-of-distribution generalization"]}, "TLDR": {"value": "We prove that agents that are capable of adapting to distributional shifts must have learned a causal model of their environment, establishing a formal equivalence between causality and transfer learning"}, "abstract": {"value": "It has long been hypothesised that causal reasoning plays a fundamental role in robust and general intelligence. However, it is not known if agents must learn causal models in order to generalise to new domains, or if other inductive biases are sufficient. We answer this question, showing that any agent capable of satisfying a regret bound for a large set of distributional shifts must have learned an approximate causal model of the data generating process, which converges to the true causal model for optimal agents. We discuss the implications of this result for several research areas including transfer learning and causal inference."}, "primary_area": {"value": "causal reasoning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 oral"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/82e4b7b89fa93d52b6278d9d868ccb4800abb8ff.pdf"}, "supplementary_material": {"value": "/attachment/27f701951145ff768b952c31420f76aac0c32817.pdf"}, "_bibtex": {"value": "@inproceedings{\nrichens2024robust,\ntitle={Robust agents learn causal world models},\nauthor={Jonathan Richens and Tom Everitt},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=pOoKI3ouv1}\n}"}, "paperhash": {"value": "richens|robust_agents_learn_causal_world_models"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission2566/-/Revision", "ICLR.cc/2024/Conference/Submission2566/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission2566/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410850319, "version": 2, "details": {"replyCount": 14, "presentation": [{"name": "title", "order": 1}, {"name": "authors", "order": 3}, {"name": "code_of_ethics", "order": 3, "input": "checkbox", "value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "description": null}, {"name": "authorids", "order": 4}, {"name": "keywords", "order": 4}, {"name": "submission_guidelines", "order": 4, "input": "checkbox", "value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide.", "description": null}, {"name": "TLDR", "order": 5, "fieldName": "TL;DR"}, {"name": "abstract", "order": 6, "input": "textarea", "markdown": true}, {"name": "pdf", "order": 7}, {"name": "anonymous_url", "order": 7, "input": "checkbox", "value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "description": null}, {"name": "supplementary_material", "order": 8}, {"name": "no_acknowledgement_section", "order": 8, "input": "checkbox", "value": "I certify that there is no acknowledgement section in this submission for double blind review.", "description": null}, {"name": "primary_area", "order": 9, "input": "select", "value": "causal reasoning", "description": null}, {"name": "resubmission"}, {"name": "student_author"}, {"name": "large_language_models"}, {"name": "other_comments_on_LLMs"}, {"name": "venue", "hidden": true}, {"name": "venueid", "hidden": true}, {"name": "_bibtex", "input": "textarea"}, {"name": "other_comments"}]}}, {"id": "H3UayAQWoE", "forum": "H3UayAQWoE", "number": 2500, "cdate": 1695210123177, "tcdate": 1695210123177, "mdate": 1709661489287, "tmdate": 1709661489287, "signatures": ["ICLR.cc/2024/Conference/Submission2500/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission2500/Authors"], "content": {"title": {"value": "On the Humanity of Conversational AI: Evaluating the Psychological Portrayal of LLMs"}, "authors": {"value": ["Jen-tse Huang", "Wenxuan Wang", "Eric John Li", "Man Ho LAM", "Shujie Ren", "Youliang Yuan", "Wenxiang Jiao", "Zhaopeng Tu", "Michael Lyu"]}, "authorids": {"value": ["~Jen-tse_Huang1", "~Wenxuan_Wang2", "~Eric_John_Li1", "~Man_Ho_LAM1", "~Shujie_Ren1", "~Youliang_Yuan1", "~Wenxiang_Jiao1", "~Zhaopeng_Tu1", "~Michael_Lyu1"]}, "keywords": {"value": ["LLM", "Benchmark", "Evaluation", "Psychometrics"]}, "abstract": {"value": "Large Language Models (LLMs) have recently showcased their remarkable capacities, not only in natural language processing tasks but also across diverse domains such as clinical medicine, legal consultation, and education. LLMs become more than mere applications, evolving into assistants capable of addressing diverse user requests. This narrows the distinction between human beings and artificial intelligence agents, raising intriguing questions regarding the potential manifestation of personalities, temperaments, and emotions within LLMs. In this paper, we propose a framework, PsychoBench, for evaluating diverse psychological aspects of LLMs. Comprising thirteen scales commonly used in clinical psychology, PsychoBench further classifies these scales into four distinct categories: personality traits, interpersonal relationships, motivational tests, and emotional abilities. Our study examines five popular models, namely text-davinci-003, ChatGPT, GPT-4, LLaMA-2-7b, and LLaMA-2-13b. Additionally, we employ a jailbreak approach to bypass the safety alignment protocols and test the intrinsic natures of LLMs. We have made PsychoBench openly accessible via https://github.com/CUHK-ARISE/PsychoBench."}, "primary_area": {"value": "societal considerations including fairness, safety, privacy"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 oral"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/b229e8ebcec1e8bef4ab8642d47d29495fdc9534.pdf"}, "supplementary_material": {"value": "/attachment/e1a6dd583f45c6e3e14f255592329602b01fbb75.zip"}, "TLDR": {"value": "We propose PsychoBench, a framework for evaluating the psychological portrayal of LLMs. We provide insights on the humanity of LLM leveraging our tool."}, "_bibtex": {"value": "@inproceedings{\nhuang2024on,\ntitle={On the Humanity of Conversational {AI}: Evaluating the Psychological Portrayal of {LLM}s},\nauthor={Jen-tse Huang and Wenxuan Wang and Eric John Li and Man Ho LAM and Shujie Ren and Youliang Yuan and Wenxiang Jiao and Zhaopeng Tu and Michael Lyu},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=H3UayAQWoE}\n}"}, "paperhash": {"value": "huang|on_the_humanity_of_conversational_ai_evaluating_the_psychological_portrayal_of_llms"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission2500/-/Revision", "ICLR.cc/2024/Conference/Submission2500/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission2500/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410848680, "version": 2, "details": {"replyCount": 15, "presentation": [{"name": "title", "order": 1}, {"name": "authors", "order": 3}, {"name": "code_of_ethics", "order": 3, "input": "checkbox", "value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "description": null}, {"name": "authorids", "order": 4}, {"name": "keywords", "order": 4}, {"name": "submission_guidelines", "order": 4, "input": "checkbox", "value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide.", "description": null}, {"name": "TLDR", "order": 5, "fieldName": "TL;DR"}, {"name": "abstract", "order": 6, "input": "textarea", "markdown": true}, {"name": "pdf", "order": 7}, {"name": "anonymous_url", "order": 7, "input": "checkbox", "value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "description": null}, {"name": "supplementary_material", "order": 8}, {"name": "no_acknowledgement_section", "order": 8, "input": "checkbox", "value": "I certify that there is no acknowledgement section in this submission for double blind review.", "description": null}, {"name": "primary_area", "order": 9, "input": "select", "value": "societal considerations including fairness, safety, privacy", "description": null}, {"name": "resubmission"}, {"name": "student_author"}, {"name": "large_language_models"}, {"name": "other_comments_on_LLMs"}, {"name": "venue", "hidden": true}, {"name": "venueid", "hidden": true}, {"name": "_bibtex", "input": "textarea"}, {"name": "other_comments"}]}}, {"id": "Zsfiqpft6K", "forum": "Zsfiqpft6K", "number": 2370, "cdate": 1695196772187, "tcdate": 1695196772187, "mdate": 1710509334118, "tmdate": 1710509334118, "signatures": ["ICLR.cc/2024/Conference/Submission2370/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission2370/Authors"], "content": {"title": {"value": "Diffusion Model for Dense Matching"}, "authors": {"value": ["Jisu Nam", "Gyuseong Lee", "Sunwoo Kim", "Hyeonsu Kim", "Hyoungwon Cho", "Seyeon Kim", "Seungryong Kim"]}, "authorids": {"value": ["~Jisu_Nam1", "~Gyuseong_Lee1", "~Sunwoo_Kim2", "~Hyeonsu_Kim2", "~Hyoungwon_Cho1", "~Seyeon_Kim2", "~Seungryong_Kim1"]}, "keywords": {"value": ["Diffusion Models", "Visual Correspondence"]}, "abstract": {"value": "The objective for establishing dense correspondence between paired images con- sists of two terms: a data term and a prior term. While conventional techniques focused on defining hand-designed prior terms, which are difficult to formulate, re- cent approaches have focused on learning the data term with deep neural networks without explicitly modeling the prior, assuming that the model itself has the capacity to learn an optimal prior from a large-scale dataset. The performance improvement was obvious, however, they often fail to address inherent ambiguities of matching, such as textureless regions, repetitive patterns, large displacements, or noises. To address this, we propose DiffMatch, a novel conditional diffusion-based framework designed to explicitly model both the data and prior terms for dense matching. This is accomplished by leveraging a conditional denoising diffusion model that explic- itly takes matching cost and injects the prior within generative process. However, limited input resolution of the diffusion model is a major hindrance. We address this with a cascaded pipeline, starting with a low-resolution model, followed by a super-resolution model that successively upsamples and incorporates finer details to the matching field. Our experimental results demonstrate significant performance improvements of our method over existing approaches, and the ablation studies validate our design choices along with the effectiveness of each component. Code and pretrained weights are available at https://ku-cvlab.github.io/DiffMatch."}, "primary_area": {"value": "generative models"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 oral"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/08dc4021186fe33924d3253d7640112693991448.pdf"}, "_bibtex": {"value": "@inproceedings{\nnam2024diffusion,\ntitle={Diffusion Model for Dense Matching},\nauthor={Jisu Nam and Gyuseong Lee and Sunwoo Kim and Hyeonsu Kim and Hyoungwon Cho and Seyeon Kim and Seungryong Kim},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=Zsfiqpft6K}\n}"}, "paperhash": {"value": "nam|diffusion_model_for_dense_matching"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission2370/-/Revision", "ICLR.cc/2024/Conference/Submission2370/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission2370/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410845552, "version": 2, "details": {"replyCount": 25, "presentation": [{"name": "title", "order": 1}, {"name": "authors", "order": 3}, {"name": "code_of_ethics", "order": 3, "input": "checkbox", "value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "description": null}, {"name": "authorids", "order": 4}, {"name": "keywords", "order": 4}, {"name": "submission_guidelines", "order": 4, "input": "checkbox", "value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide.", "description": null}, {"name": "TLDR", "order": 5, "fieldName": "TL;DR"}, {"name": "abstract", "order": 6, "input": "textarea", "markdown": true}, {"name": "pdf", "order": 7}, {"name": "anonymous_url", "order": 7, "input": "checkbox", "value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "description": null}, {"name": "supplementary_material", "order": 8}, {"name": "no_acknowledgement_section", "order": 8, "input": "checkbox", "value": "I certify that there is no acknowledgement section in this submission for double blind review.", "description": null}, {"name": "primary_area", "order": 9, "input": "select", "value": "generative models", "description": null}, {"name": "resubmission"}, {"name": "student_author"}, {"name": "large_language_models"}, {"name": "other_comments_on_LLMs"}, {"name": "venue", "hidden": true}, {"name": "venueid", "hidden": true}, {"name": "_bibtex", "input": "textarea"}, {"name": "other_comments"}]}}, {"id": "Yen1lGns2o", "forum": "Yen1lGns2o", "number": 2314, "cdate": 1695193403860, "tcdate": 1695193403860, "mdate": 1712499096321, "tmdate": 1712499096321, "signatures": ["ICLR.cc/2024/Conference/Submission2314/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission2314/Authors"], "content": {"title": {"value": "Is ImageNet worth 1 video? Learning strong image encoders from 1 long unlabelled video"}, "authors": {"value": ["Shashanka Venkataramanan", "Mamshad Nayeem Rizve", "Joao Carreira", "Yuki M Asano", "Yannis Avrithis"]}, "authorids": {"value": ["~Shashanka_Venkataramanan2", "~Mamshad_Nayeem_Rizve1", "~Joao_Carreira1", "~Yuki_M_Asano1", "~Yannis_Avrithis2"]}, "keywords": {"value": ["self-supervised image-pretraining", "egocentric video", "Walking Tour dataset", "multi-object tracking"]}, "abstract": {"value": "Self-supervised learning has unlocked the potential of scaling up pretraining to billions of images, since annotation is unnecessary. But are we making the best use of data? How more economical can we be? In this work, we attempt to answer this question by making two contributions. First, we investigate first-person videos and introduce a ``Walking Tours'' dataset. These videos are high-resolution, hours-long, captured in a single uninterrupted take, depicting a large number of objects and actions with natural scene transitions. They are unlabeled and uncurated, thus realistic for self-supervision and comparable with human learning. \n\nSecond, we introduce a novel self-supervised image pretraining method tailored for learning from continuous videos. Existing methods typically adapt image-based pretraining approaches to incorporate more frames. Instead, we advocate a ``tracking to learn to recognize'' approach. Our method called DoRA, leads to attention maps that **D**isc**O**ver and t**RA**ck objects over time in an end-to-end manner, using transformer cross-attention. We derive multiple views from the tracks and use them in a classical self-supervised distillation loss. Using our novel approach, a single Walking Tours video remarkably becomes a strong competitor to ImageNet for several image and video downstream tasks."}, "primary_area": {"value": "unsupervised, self-supervised, semi-supervised, and supervised representation learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 oral"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/822b36f39680f189e99f3c34413c6b5c89d6b51a.pdf"}, "_bibtex": {"value": "@inproceedings{\nvenkataramanan2024is,\ntitle={Is ImageNet worth 1 video? Learning strong image encoders from 1 long unlabelled video},\nauthor={Shashanka Venkataramanan and Mamshad Nayeem Rizve and Joao Carreira and Yuki M Asano and Yannis Avrithis},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=Yen1lGns2o}\n}"}, "paperhash": {"value": "venkataramanan|is_imagenet_worth_1_video_learning_strong_image_encoders_from_1_long_unlabelled_video"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission2314/-/Revision", "ICLR.cc/2024/Conference/Submission2314/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission2314/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410844064, "version": 2, "details": {"replyCount": 26, "presentation": [{"name": "title", "order": 1}, {"name": "authors", "order": 3}, {"name": "code_of_ethics", "order": 3, "input": "checkbox", "value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "description": null}, {"name": "authorids", "order": 4}, {"name": "keywords", "order": 4}, {"name": "submission_guidelines", "order": 4, "input": "checkbox", "value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide.", "description": null}, {"name": "TLDR", "order": 5, "fieldName": "TL;DR"}, {"name": "abstract", "order": 6, "input": "textarea", "markdown": true}, {"name": "pdf", "order": 7}, {"name": "anonymous_url", "order": 7, "input": "checkbox", "value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "description": null}, {"name": "supplementary_material", "order": 8}, {"name": "no_acknowledgement_section", "order": 8, "input": "checkbox", "value": "I certify that there is no acknowledgement section in this submission for double blind review.", "description": null}, {"name": "primary_area", "order": 9, "input": "select", "value": "unsupervised, self-supervised, semi-supervised, and supervised representation learning", "description": null}, {"name": "resubmission"}, {"name": "student_author"}, {"name": "large_language_models"}, {"name": "other_comments_on_LLMs"}, {"name": "venue", "hidden": true}, {"name": "venueid", "hidden": true}, {"name": "_bibtex", "input": "textarea"}, {"name": "other_comments"}]}}, {"id": "T7YV5UZKBc", "forum": "T7YV5UZKBc", "number": 2290, "cdate": 1695190978238, "tcdate": 1695190978238, "mdate": 1709968751035, "tmdate": 1709968751035, "signatures": ["ICLR.cc/2024/Conference/Submission2290/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission2290/Authors"], "content": {"title": {"value": "Neural Fine-Tuning Search for Few-Shot Learning"}, "authors": {"value": ["Panagiotis Eustratiadis", "\u0141ukasz Dudziak", "Da Li", "Timothy Hospedales"]}, "authorids": {"value": ["~Panagiotis_Eustratiadis1", "~\u0141ukasz_Dudziak1", "~Da_Li3", "~Timothy_Hospedales1"]}, "keywords": {"value": ["stochastic", "neural", "architecture", "search", "few", "shot", "learning", "adapters"]}, "TLDR": {"value": "A stochastic neural architecture search algorithm that searches for the optimal configuration of layers in a pre-trained backbone architecture, to be adapted or fine-tuned."}, "abstract": {"value": "In few-shot recognition, a classifier that has been trained on one set of classes is required to rapidly adapt and generalize to a disjoint, novel set of classes. To that end, recent studies have shown the efficacy of fine-tuning with carefully-crafted adaptation architectures. However this raises the question of: How can one design the optimal adaptation strategy? In this paper, we study this question through the lens of neural architecture search (NAS). Given a pre-trained neural network, our algorithm discovers the optimal arrangement of adapters, which layers to keep frozen, and which to fine-tune. We demonstrate the generality of our NAS method by applying it to both residual networks and vision transformers and report state-of-the-art performance on Meta-Dataset and Meta-Album."}, "primary_area": {"value": "transfer learning, meta learning, and lifelong learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 oral"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/9878859cc4979dc1552ab1c206ff30122453346b.pdf"}, "_bibtex": {"value": "@inproceedings{\neustratiadis2024neural,\ntitle={Neural Fine-Tuning Search for Few-Shot Learning},\nauthor={Panagiotis Eustratiadis and {\\L}ukasz Dudziak and Da Li and Timothy Hospedales},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=T7YV5UZKBc}\n}"}, "paperhash": {"value": "eustratiadis|neural_finetuning_search_for_fewshot_learning"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission2290/-/Revision", "ICLR.cc/2024/Conference/Submission2290/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission2290/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410843567, "version": 2, "details": {"replyCount": 12, "presentation": [{"name": "title", "order": 1}, {"name": "authors", "order": 3}, {"name": "code_of_ethics", "order": 3, "input": "checkbox", "value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "description": null}, {"name": "authorids", "order": 4}, {"name": "keywords", "order": 4}, {"name": "submission_guidelines", "order": 4, "input": "checkbox", "value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide.", "description": null}, {"name": "TLDR", "order": 5, "fieldName": "TL;DR"}, {"name": "abstract", "order": 6, "input": "textarea", "markdown": true}, {"name": "pdf", "order": 7}, {"name": "anonymous_url", "order": 7, "input": "checkbox", "value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "description": null}, {"name": "supplementary_material", "order": 8}, {"name": "no_acknowledgement_section", "order": 8, "input": "checkbox", "value": "I certify that there is no acknowledgement section in this submission for double blind review.", "description": null}, {"name": "primary_area", "order": 9, "input": "select", "value": "transfer learning, meta learning, and lifelong learning", "description": null}, {"name": "resubmission"}, {"name": "student_author"}, {"name": "large_language_models"}, {"name": "other_comments_on_LLMs"}, {"name": "venue", "hidden": true}, {"name": "venueid", "hidden": true}, {"name": "_bibtex", "input": "textarea"}, {"name": "other_comments"}]}}, {"id": "bTMMNT7IdW", "forum": "bTMMNT7IdW", "number": 2147, "cdate": 1695173399331, "tcdate": 1695173399331, "mdate": 1710729274468, "tmdate": 1710729274468, "signatures": ["ICLR.cc/2024/Conference/Submission2147/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission2147/Authors"], "content": {"title": {"value": "Latent Trajectory Learning for Limited Timestamps under Distribution Shift over Time"}, "authors": {"value": ["QIUHAO Zeng", "Changjian Shui", "Long-Kai Huang", "Peng Liu", "Xi Chen", "Charles Ling", "Boyu Wang"]}, "authorids": {"value": ["~QIUHAO_Zeng1", "~Changjian_Shui2", "~Long-Kai_Huang1", "~Peng_Liu20", "~Xi_Chen32", "~Charles_Ling1", "~Boyu_Wang3"]}, "keywords": {"value": ["Distribution Shift", "Temporal Distribution Shift"]}, "TLDR": {"value": "Solving Distribution Shift over Time modelling with Stochastic Differential Equations"}, "abstract": {"value": "Distribution shifts over time are common in real-world machine-learning applications. This scenario is formulated as Evolving Domain Generalization (EDG), where models aim to generalize well to unseen target domains in a time-varying system by learning and leveraging the underlying evolving pattern of the distribution shifts across domains. However, existing methods encounter challenges due to the limited number of timestamps (every domain corresponds to a timestamp) in EDG datasets, leading to difficulties in capturing evolving dynamics and risking overfitting to the sparse timestamps, which hampers their generalization and adaptability to new tasks. To address this limitation, we propose a novel approach SDE-EDG that collects the Infinitely Fined-Grid Evolving Trajectory (IFGET) of the data distribution with continuous-interpolated samples to bridge temporal gaps (intervals between two successive timestamps). Furthermore, by leveraging the inherent capacity of Stochastic Differential Equations (SDEs) to capture continuous trajectories, we propose their use to align SDE-modeled trajectories with IFGET across domains, thus enabling the capture of evolving distribution trends. We evaluate our approach on several benchmark datasets and demonstrate that it can achieve superior performance compared to existing state-of-the-art methods."}, "primary_area": {"value": "transfer learning, meta learning, and lifelong learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 oral"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/2d6728dfffe50fd8e8627061ece7a1f07abc5462.pdf"}, "supplementary_material": {"value": "/attachment/8155991fb37a7092e341ebfd7cd77c43e1bdc508.zip"}, "_bibtex": {"value": "@inproceedings{\nzeng2024latent,\ntitle={Latent Trajectory Learning for Limited Timestamps under Distribution Shift over Time},\nauthor={QIUHAO Zeng and Changjian Shui and Long-Kai Huang and Peng Liu and Xi Chen and Charles Ling and Boyu Wang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=bTMMNT7IdW}\n}"}, "paperhash": {"value": "zeng|latent_trajectory_learning_for_limited_timestamps_under_distribution_shift_over_time"}}, "odate": 1697213872796, "pdate": 1705410840280, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission2147/-/Revision", "ICLR.cc/2024/Conference/Submission2147/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission2147/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "version": 2, "details": {"replyCount": 21, "presentation": [{"name": "title", "order": 1}, {"name": "authors", "order": 3}, {"name": "code_of_ethics", "order": 3, "input": "checkbox", "value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "description": null}, {"name": "authorids", "order": 4}, {"name": "keywords", "order": 4}, {"name": "submission_guidelines", "order": 4, "input": "checkbox", "value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide.", "description": null}, {"name": "TLDR", "order": 5, "fieldName": "TL;DR"}, {"name": "abstract", "order": 6, "input": "textarea", "markdown": true}, {"name": "pdf", "order": 7}, {"name": "anonymous_url", "order": 7, "input": "checkbox", "value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "description": null}, {"name": "supplementary_material", "order": 8}, {"name": "no_acknowledgement_section", "order": 8, "input": "checkbox", "value": "I certify that there is no acknowledgement section in this submission for double blind review.", "description": null}, {"name": "primary_area", "order": 9, "input": "select", "value": "transfer learning, meta learning, and lifelong learning", "description": null}, {"name": "resubmission"}, {"name": "student_author"}, {"name": "large_language_models"}, {"name": "other_comments_on_LLMs"}, {"name": "venue", "hidden": true}, {"name": "venueid", "hidden": true}, {"name": "_bibtex", "input": "textarea"}, {"name": "other_comments"}]}}, {"id": "jKTUlxo5zy", "forum": "jKTUlxo5zy", "number": 2053, "cdate": 1695156070624, "tcdate": 1695156070624, "mdate": 1709661484427, "tmdate": 1709661484427, "signatures": ["ICLR.cc/2024/Conference/Submission2053/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission2053/Authors"], "content": {"title": {"value": "Less is More: Fewer Interpretable Region via Submodular Subset Selection"}, "authors": {"value": ["Ruoyu Chen", "Hua Zhang", "Siyuan Liang", "Jingzhi Li", "Xiaochun Cao"]}, "authorids": {"value": ["~Ruoyu_Chen2", "~Hua_Zhang4", "~Siyuan_Liang1", "~Jingzhi_Li1", "~Xiaochun_Cao3"]}, "keywords": {"value": ["Interpretable AI", "Submodular subset selection", "Explainable AI", "Image Attribution"]}, "abstract": {"value": "Image attribution algorithms aim to identify important regions that are highly relevant to model decisions. Although existing attribution solutions can effectively assign importance to target elements, they still face the following challenges: 1) existing attribution methods generate inaccurate small regions thus misleading the direction of correct attribution, and 2) the model cannot produce good attribution results for samples with wrong predictions. To address the above challenges, this paper re-models the above image attribution problem as a submodular subset selection problem, aiming to enhance model interpretability using fewer regions. To address the lack of attention to local regions, we construct a novel submodular function to discover more accurate small interpretation regions. To enhance the attribution effect for all samples, we also impose four different constraints on the selection of sub-regions, i.e., confidence, effectiveness, consistency, and collaboration scores, to assess the importance of various subsets. Moreover, our theoretical analysis substantiates that the proposed function is in fact submodular. Extensive experiments show that the proposed method outperforms SOTA methods on two face datasets (Celeb-A and VGG-Face2) and one fine-grained dataset (CUB-200-2011). For correctly predicted samples, the proposed method improves the Deletion and Insertion scores with an average of 4.9\\% and 2.5\\% gain relative to HSIC-Attribution. For incorrectly predicted samples, our method achieves gains of 81.0\\% and 18.4\\% compared to the HSIC-Attribution algorithm in the average highest confidence and Insertion score respectively. The code is released at https://github.com/RuoyuChen10/SMDL-Attribution."}, "primary_area": {"value": "visualization or interpretation of learned representations"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 oral"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/ab53441cc4465bcbb3d2ffd4fc53dc1b27e76e6e.pdf"}, "supplementary_material": {"value": "/attachment/7d96ba920e8792bf85586f38994173fa647196c8.zip"}, "TLDR": {"value": "This paper re-models the image attribution problem as a submodular subset selection problem, aiming to enhance model interpretability using fewer regions."}, "_bibtex": {"value": "@inproceedings{\nchen2024less,\ntitle={Less is More: Fewer Interpretable Region via Submodular Subset Selection},\nauthor={Ruoyu Chen and Hua Zhang and Siyuan Liang and Jingzhi Li and Xiaochun Cao},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=jKTUlxo5zy}\n}"}, "paperhash": {"value": "chen|less_is_more_fewer_interpretable_region_via_submodular_subset_selection"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission2053/-/Revision", "ICLR.cc/2024/Conference/Submission2053/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission2053/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410837421, "version": 2, "details": {"replyCount": 26, "presentation": [{"name": "title", "order": 1}, {"name": "authors", "order": 3}, {"name": "code_of_ethics", "order": 3, "input": "checkbox", "value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "description": null}, {"name": "authorids", "order": 4}, {"name": "keywords", "order": 4}, {"name": "submission_guidelines", "order": 4, "input": "checkbox", "value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide.", "description": null}, {"name": "TLDR", "order": 5, "fieldName": "TL;DR"}, {"name": "abstract", "order": 6, "input": "textarea", "markdown": true}, {"name": "pdf", "order": 7}, {"name": "anonymous_url", "order": 7, "input": "checkbox", "value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "description": null}, {"name": "supplementary_material", "order": 8}, {"name": "no_acknowledgement_section", "order": 8, "input": "checkbox", "value": "I certify that there is no acknowledgement section in this submission for double blind review.", "description": null}, {"name": "primary_area", "order": 9, "input": "select", "value": "visualization or interpretation of learned representations", "description": null}, {"name": "resubmission"}, {"name": "student_author"}, {"name": "large_language_models"}, {"name": "other_comments_on_LLMs"}, {"name": "venue", "hidden": true}, {"name": "venueid", "hidden": true}, {"name": "_bibtex", "input": "textarea"}, {"name": "other_comments"}]}}, {"id": "EanCFCwAjM", "forum": "EanCFCwAjM", "number": 2052, "cdate": 1695156066326, "tcdate": 1695156066326, "mdate": 1713672853325, "tmdate": 1713672853325, "signatures": ["ICLR.cc/2024/Conference/Submission2052/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission2052/Authors"], "content": {"title": {"value": "Cameras as Rays: Pose Estimation via Ray Diffusion"}, "authors": {"value": ["Jason Y. Zhang", "Amy Lin", "Moneish Kumar", "Tzu-Hsuan Yang", "Deva Ramanan", "Shubham Tulsiani"]}, "authorids": {"value": ["~Jason_Y._Zhang1", "~Amy_Lin1", "~Moneish_Kumar1", "~Tzu-Hsuan_Yang1", "~Deva_Ramanan1", "~Shubham_Tulsiani1"]}, "keywords": {"value": ["3D Computer Vision", "Pose Estimation", "Diffusion"]}, "abstract": {"value": "Estimating camera poses is a fundamental task for 3D reconstruction and remains challenging given sparsely sampled views (<10). In contrast to existing approaches that pursue top-down prediction of global parametrizations of camera extrinsics, we propose a distributed representation of camera pose that treats a camera as a bundle of rays. This representation allows for a tight coupling with spatial image features improving pose precision. We observe that this representation is naturally suited for set-level transformers and develop a regression-based approach that maps image patches to corresponding rays. To capture the inherent uncertainties in sparse-view pose inference, we adapt this approach to learn a denoising diffusion model which allows us to sample plausible modes while improving performance. Our proposed methods, both regression- and diffusion-based, demonstrate state-of-the-art performance on camera pose estimation on CO3D while generalizing to unseen object categories and in-the-wild captures."}, "primary_area": {"value": "representation learning for computer vision, audio, language, and other modalities"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 oral"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/b94ec4f9e7354e38e14b5a0da4e4f829f20f381a.pdf"}, "supplementary_material": {"value": "/attachment/4d6ff352963f3403d5686060a2b2b473568c004b.zip"}, "TLDR": {"value": "Over-parameterize camera as a bundle of rays, which is a representation that can be predicted using a denoising diffusion model."}, "_bibtex": {"value": "@inproceedings{\nzhang2024cameras,\ntitle={Cameras as Rays: Pose Estimation via Ray Diffusion},\nauthor={Jason Y. Zhang and Amy Lin and Moneish Kumar and Tzu-Hsuan Yang and Deva Ramanan and Shubham Tulsiani},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=EanCFCwAjM}\n}"}, "paperhash": {"value": "zhang|cameras_as_rays_pose_estimation_via_ray_diffusion"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission2052/-/Revision", "ICLR.cc/2024/Conference/Submission2052/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission2052/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410837412, "version": 2, "details": {"replyCount": 21, "presentation": [{"name": "title", "order": 1}, {"name": "authors", "order": 3}, {"name": "code_of_ethics", "order": 3, "input": "checkbox", "value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "description": null}, {"name": "authorids", "order": 4}, {"name": "keywords", "order": 4}, {"name": "submission_guidelines", "order": 4, "input": "checkbox", "value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide.", "description": null}, {"name": "TLDR", "order": 5, "fieldName": "TL;DR"}, {"name": "abstract", "order": 6, "input": "textarea", "markdown": true}, {"name": "pdf", "order": 7}, {"name": "anonymous_url", "order": 7, "input": "checkbox", "value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "description": null}, {"name": "supplementary_material", "order": 8}, {"name": "no_acknowledgement_section", "order": 8, "input": "checkbox", "value": "I certify that there is no acknowledgement section in this submission for double blind review.", "description": null}, {"name": "primary_area", "order": 9, "input": "select", "value": "representation learning for computer vision, audio, language, and other modalities", "description": null}, {"name": "resubmission"}, {"name": "student_author"}, {"name": "large_language_models"}, {"name": "other_comments_on_LLMs"}, {"name": "venue", "hidden": true}, {"name": "venueid", "hidden": true}, {"name": "_bibtex", "input": "textarea"}, {"name": "other_comments"}]}}, {"id": "BV1PHbTJzd", "forum": "BV1PHbTJzd", "number": 2003, "cdate": 1695145534909, "tcdate": 1695145534909, "mdate": 1709661483850, "tmdate": 1709661483850, "signatures": ["ICLR.cc/2024/Conference/Submission2003/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission2003/Authors"], "content": {"title": {"value": "Accelerating Distributed Stochastic Optimization via Self-Repellent Random Walks"}, "authors": {"value": ["Jie Hu", "Vishwaraj Doshi", "Do Young Eun"]}, "authorids": {"value": ["~Jie_Hu7", "~Vishwaraj_Doshi1", "~Do_Young_Eun1"]}, "keywords": {"value": ["Distributed Learning", "Self-Repellent Random Walk", "Token Algorithm", "Central Limit Theorem", "Asymptotic Analysis"]}, "TLDR": {"value": "In distributed learning, we present SA-SRRW algorithm to prioritize lesser-visited nodes while discouraging frequently visited nodes in distributed learning, and show its performance improvement."}, "abstract": {"value": "We study a family of distributed stochastic optimization algorithms where gradients are sampled by a token traversing a network of agents in random-walk fashion. Typically, these random-walks are chosen to be Markov chains that asymptotically sample from a desired target distribution, and play a critical role in the convergence of the optimization iterates. In this paper, we take a novel approach by replacing the standard *linear* Markovian token by one which follows a *non-linear* Markov chain - namely the Self-Repellent Radom Walk (SRRW). Defined for any given 'base' Markov chain, the SRRW, parameterized by a positive scalar $\\\\alpha$, is less likely to transition to states that were highly visited in the past, thus the name. In the context of MCMC sampling on a graph, a recent breakthrough in Doshi et al. (2023) shows that the SRRW achieves $O(1/\\\\alpha)$ decrease in the asymptotic variance for sampling. We propose the use of a `generalized' version of the SRRW to drive token algorithms for distributed stochastic optimization in the form of stochastic approximation, termed SA-SRRW. We prove that the optimization iterate errors of the resulting SA-SRRW converge to zero almost surely and prove a central limit theorem, deriving the explicit form of the resulting asymptotic covariance matrix corresponding to iterate errors. This asymptotic covariance is always smaller than that of an algorithm driven by the base Markov chain and decreases at rate $O(1/\\\\alpha^2)$ - the performance benefit of using SRRW thereby *amplified* in the stochastic optimization context. Empirical results support our theoretical findings."}, "primary_area": {"value": "optimization"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 oral"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/64bc85abf6c1e89455cfa6d45b1c2c03c4e4ee54.pdf"}, "_bibtex": {"value": "@inproceedings{\nhu2024accelerating,\ntitle={Accelerating Distributed Stochastic Optimization via Self-Repellent Random Walks},\nauthor={Jie Hu and Vishwaraj Doshi and Do Young Eun},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=BV1PHbTJzd}\n}"}, "paperhash": {"value": "hu|accelerating_distributed_stochastic_optimization_via_selfrepellent_random_walks"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission2003/-/Revision", "ICLR.cc/2024/Conference/Submission2003/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission2003/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410836170, "version": 2, "details": {"replyCount": 16, "presentation": [{"name": "title", "order": 1}, {"name": "authors", "order": 3}, {"name": "code_of_ethics", "order": 3, "input": "checkbox", "value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "description": null}, {"name": "authorids", "order": 4}, {"name": "keywords", "order": 4}, {"name": "submission_guidelines", "order": 4, "input": "checkbox", "value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide.", "description": null}, {"name": "TLDR", "order": 5, "fieldName": "TL;DR"}, {"name": "abstract", "order": 6, "input": "textarea", "markdown": true}, {"name": "pdf", "order": 7}, {"name": "anonymous_url", "order": 7, "input": "checkbox", "value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "description": null}, {"name": "supplementary_material", "order": 8}, {"name": "no_acknowledgement_section", "order": 8, "input": "checkbox", "value": "I certify that there is no acknowledgement section in this submission for double blind review.", "description": null}, {"name": "primary_area", "order": 9, "input": "select", "value": "optimization", "description": null}, {"name": "resubmission"}, {"name": "student_author"}, {"name": "large_language_models"}, {"name": "other_comments_on_LLMs"}, {"name": "venue", "hidden": true}, {"name": "venueid", "hidden": true}, {"name": "_bibtex", "input": "textarea"}, {"name": "other_comments"}]}}, {"id": "84n3UwkH7b", "forum": "84n3UwkH7b", "number": 1933, "cdate": 1695135850252, "tcdate": 1695135850252, "mdate": 1710431986991, "tmdate": 1710431986991, "signatures": ["ICLR.cc/2024/Conference/Submission1933/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission1933/Authors"], "content": {"title": {"value": "Detecting, Explaining, and Mitigating Memorization in Diffusion Models"}, "authors": {"value": ["Yuxin Wen", "Yuchen Liu", "Chen Chen", "Lingjuan Lyu"]}, "authorids": {"value": ["~Yuxin_Wen2", "~Yuchen_Liu8", "~Chen_Chen20", "~Lingjuan_Lyu1"]}, "keywords": {"value": ["Diffusion Model", "Memorization"]}, "abstract": {"value": "Recent breakthroughs in diffusion models have exhibited exceptional image-generation capabilities. However, studies show that some outputs are merely replications of training data. Such replications present potential legal challenges for model owners, especially when the generated content contains proprietary information. In this work, we introduce a straightforward yet effective method for detecting memorized prompts by inspecting the magnitude of text-conditional predictions. Our proposed method seamlessly integrates without disrupting sampling algorithms, and delivers high accuracy even at the first generation step, with a single generation per prompt. Building on our detection strategy, we unveil an explainable approach that shows the contribution of individual words or tokens to memorization. This offers an interactive medium for users to adjust their prompts. Moreover, we propose two strategies i.e., to mitigate memorization by leveraging the magnitude of text-conditional predictions, either through minimization during inference or filtering during training. These proposed strategies effectively counteract memorization while maintaining high-generation quality. Code is available at https://github.com/YuxinWenRick/diffusion_memorization."}, "primary_area": {"value": "generative models"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 oral"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/f7cb8a4a7ba048a0d09bdea01774be1a0676504f.pdf"}, "supplementary_material": {"value": "/attachment/5a7cc8c3e384ae4896dc9e7840e66453f612bdb4.zip"}, "_bibtex": {"value": "@inproceedings{\nwen2024detecting,\ntitle={Detecting, Explaining, and Mitigating Memorization in Diffusion Models},\nauthor={Yuxin Wen and Yuchen Liu and Chen Chen and Lingjuan Lyu},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=84n3UwkH7b}\n}"}, "paperhash": {"value": "wen|detecting_explaining_and_mitigating_memorization_in_diffusion_models"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission1933/-/Revision", "ICLR.cc/2024/Conference/Submission1933/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission1933/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410834153, "version": 2, "details": {"replyCount": 12, "presentation": [{"name": "title", "order": 1}, {"name": "authors", "order": 3}, {"name": "code_of_ethics", "order": 3, "input": "checkbox", "value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "description": null}, {"name": "authorids", "order": 4}, {"name": "keywords", "order": 4}, {"name": "submission_guidelines", "order": 4, "input": "checkbox", "value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide.", "description": null}, {"name": "TLDR", "order": 5, "fieldName": "TL;DR"}, {"name": "abstract", "order": 6, "input": "textarea", "markdown": true}, {"name": "pdf", "order": 7}, {"name": "anonymous_url", "order": 7, "input": "checkbox", "value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "description": null}, {"name": "supplementary_material", "order": 8}, {"name": "no_acknowledgement_section", "order": 8, "input": "checkbox", "value": "I certify that there is no acknowledgement section in this submission for double blind review.", "description": null}, {"name": "primary_area", "order": 9, "input": "select", "value": "generative models", "description": null}, {"name": "resubmission"}, {"name": "student_author"}, {"name": "large_language_models"}, {"name": "other_comments_on_LLMs"}, {"name": "venue", "hidden": true}, {"name": "venueid", "hidden": true}, {"name": "_bibtex", "input": "textarea"}, {"name": "other_comments"}]}}, {"id": "tqh1zdXIra", "forum": "tqh1zdXIra", "number": 1690, "cdate": 1695106298712, "tcdate": 1695106298712, "mdate": 1709661480471, "tmdate": 1709661480471, "signatures": ["ICLR.cc/2024/Conference/Submission1690/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission1690/Authors"], "content": {"title": {"value": "Quick-Tune: Quickly Learning Which Pretrained Model to Finetune and How"}, "authors": {"value": ["Sebastian Pineda Arango", "Fabio Ferreira", "Arlind Kadra", "Frank Hutter", "Josif Grabocka"]}, "authorids": {"value": ["~Sebastian_Pineda_Arango1", "~Fabio_Ferreira1", "~Arlind_Kadra1", "~Frank_Hutter1", "~Josif_Grabocka1"]}, "keywords": {"value": ["Finetuning", "pretrained model hubs", "transfer learning", "hyperparameter optimization", "meta-learning"]}, "TLDR": {"value": "We learn to jointly and efficiently select pretrained models to finetune and their hyperparameters."}, "abstract": {"value": "With the ever-increasing number of pretrained models, machine learning practitioners are continuously faced with which pretrained model to use, and how to finetune it for a new dataset. In this paper, we propose a methodology that jointly searches for the optimal pretrained model and the hyperparameters for finetuning it. Our method transfers knowledge about the performance of many pretrained models with multiple hyperparameter configurations on a series of datasets. To this aim, we evaluated over 20k hyperparameter configurations for finetuning 24 pretrained image classification models on 87 datasets to generate a large-scale meta-dataset. We meta-learn a gray-box performance predictor on the learning curves of this meta-dataset and use it for fast hyperparameter optimization on new datasets. We empirically demonstrate that our resulting approach can quickly select an accurate pretrained model for a new dataset together with its optimal hyperparameters."}, "primary_area": {"value": "transfer learning, meta learning, and lifelong learning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 oral"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/0d50254746a68fad8be9e1216532dcd5924e2019.pdf"}, "supplementary_material": {"value": "/attachment/69571219ddfec93a6e9ab2526a853740706a9848.pdf"}, "_bibtex": {"value": "@inproceedings{\narango2024quicktune,\ntitle={Quick-Tune: Quickly Learning Which Pretrained Model to Finetune and How},\nauthor={Sebastian Pineda Arango and Fabio Ferreira and Arlind Kadra and Frank Hutter and Josif Grabocka},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=tqh1zdXIra}\n}"}, "paperhash": {"value": "arango|quicktune_quickly_learning_which_pretrained_model_to_finetune_and_how"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission1690/-/Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission1690/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410827360, "version": 2, "details": {"replyCount": 12, "presentation": [{"name": "title", "order": 1}, {"name": "authors", "order": 3}, {"name": "code_of_ethics", "order": 3, "input": "checkbox", "value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "description": null}, {"name": "authorids", "order": 4}, {"name": "keywords", "order": 4}, {"name": "submission_guidelines", "order": 4, "input": "checkbox", "value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide.", "description": null}, {"name": "TLDR", "order": 5, "fieldName": "TL;DR"}, {"name": "abstract", "order": 6, "input": "textarea", "markdown": true}, {"name": "pdf", "order": 7}, {"name": "anonymous_url", "order": 7, "input": "checkbox", "value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "description": null}, {"name": "supplementary_material", "order": 8}, {"name": "no_acknowledgement_section", "order": 8, "input": "checkbox", "value": "I certify that there is no acknowledgement section in this submission for double blind review.", "description": null}, {"name": "primary_area", "order": 9, "input": "select", "value": "transfer learning, meta learning, and lifelong learning", "description": null}, {"name": "resubmission"}, {"name": "student_author"}, {"name": "large_language_models"}, {"name": "other_comments_on_LLMs"}, {"name": "venue", "hidden": true}, {"name": "venueid", "hidden": true}, {"name": "_bibtex", "input": "textarea"}, {"name": "other_comments"}]}}, {"id": "6PmJoRfdaK", "forum": "6PmJoRfdaK", "number": 1602, "cdate": 1695092884278, "tcdate": 1695092884278, "mdate": 1709910976333, "tmdate": 1709910976333, "signatures": ["ICLR.cc/2024/Conference/Submission1602/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission1602/Authors"], "content": {"title": {"value": "LongLoRA: Efficient Fine-tuning of Long-Context Large Language Models"}, "authors": {"value": ["Yukang Chen", "Shengju Qian", "Haotian Tang", "Xin Lai", "Zhijian Liu", "Song Han", "Jiaya Jia"]}, "authorids": {"value": ["~Yukang_Chen1", "~Shengju_Qian1", "~Haotian_Tang1", "~Xin_Lai1", "~Zhijian_Liu1", "~Song_Han5", "~Jiaya_Jia1"]}, "keywords": {"value": ["Efficient fine-tuning", "Long context", "Large language model"]}, "abstract": {"value": "We present LongLoRA, an efficient fine-tuning approach that extends the context sizes of pre-trained large language models (LLMs), with limited computation cost.\nTypically, training LLMs with long context sizes is computationally expensive, requiring extensive training hours and GPU resources. For example, training on the context length of 8192 needs 16x computational costs in self-attention layers as that of 2048. In this paper, we speed up the context extension of LLMs in two aspects. On the one hand, although dense global attention is needed during inference, fine-tuning the model can be effectively and efficiently done by sparse local attention. The proposed shifted sparse attention effectively enables context extension, leading to non-trivial computation saving with similar performance to fine-tuning with vanilla attention. Particularly, it can be implemented with only two lines of code in training, while being optional in inference. On the other hand, we revisit the parameter-efficient fine-tuning regime for context expansion. Notably, we find that LoRA for context extension works well under the premise of trainable embedding and normalization. LongLoRA combines this improved LoRA with S^2-Attn. LongLoRA demonstrates strong empirical results on various tasks on Llama2 models from 7B/13B to 70B. LongLoRA extends Llama2 7B from 4k context to 100k, or Llama2 70B to 32k on a single 8x A100 machine. LongLoRA extends models' context while retaining their original architectures, and is compatible with most existing techniques, like Flash-Attention2. In addition, we further conduct supervised fine-tuning with LongLoRA and our long instruction-following LongAlpaca dataset. All our code, models, dataset, and demo are available at https://github.com/dvlab-research/LongLoRA."}, "primary_area": {"value": "representation learning for computer vision, audio, language, and other modalities"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 oral"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "TLDR": {"value": "LongLoRA is an efficient fine-tuning approach to extend the context lengths of pre-trained large language models."}, "pdf": {"value": "/pdf/c59a7d7e3b772a1cea62d9bac390273a26c26734.pdf"}, "_bibtex": {"value": "@inproceedings{\nchen2024longlora,\ntitle={LongLo{RA}: Efficient Fine-tuning of Long-Context Large Language Models},\nauthor={Yukang Chen and Shengju Qian and Haotian Tang and Xin Lai and Zhijian Liu and Song Han and Jiaya Jia},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=6PmJoRfdaK}\n}"}, "paperhash": {"value": "chen|longlora_efficient_finetuning_of_longcontext_large_language_models"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission1602/-/Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission1602/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/Submission1602/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410825299, "version": 2, "details": {"replyCount": 14, "presentation": [{"name": "title", "order": 1}, {"name": "authors", "order": 3}, {"name": "code_of_ethics", "order": 3, "input": "checkbox", "value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "description": null}, {"name": "authorids", "order": 4}, {"name": "keywords", "order": 4}, {"name": "submission_guidelines", "order": 4, "input": "checkbox", "value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide.", "description": null}, {"name": "TLDR", "order": 5, "fieldName": "TL;DR"}, {"name": "abstract", "order": 6, "input": "textarea", "markdown": true}, {"name": "pdf", "order": 7}, {"name": "anonymous_url", "order": 7, "input": "checkbox", "value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "description": null}, {"name": "supplementary_material", "order": 8}, {"name": "no_acknowledgement_section", "order": 8, "input": "checkbox", "value": "I certify that there is no acknowledgement section in this submission for double blind review.", "description": null}, {"name": "primary_area", "order": 9, "input": "select", "value": "representation learning for computer vision, audio, language, and other modalities", "description": null}, {"name": "resubmission"}, {"name": "student_author"}, {"name": "large_language_models"}, {"name": "other_comments_on_LLMs"}, {"name": "venue", "hidden": true}, {"name": "venueid", "hidden": true}, {"name": "_bibtex", "input": "textarea"}, {"name": "other_comments"}]}}, {"id": "Ouj6p4ca60", "forum": "Ouj6p4ca60", "number": 1391, "cdate": 1695050633117, "tcdate": 1695050633117, "mdate": 1709927318196, "tmdate": 1709927318196, "signatures": ["ICLR.cc/2024/Conference/Submission1391/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission1391/Authors"], "content": {"title": {"value": "Amortizing intractable inference in large language models"}, "authors": {"value": ["Edward J Hu", "Moksh Jain", "Eric Elmoznino", "Younesse Kaddar", "Guillaume Lajoie", "Yoshua Bengio", "Nikolay Malkin"]}, "authorids": {"value": ["~Edward_J_Hu1", "~Moksh_Jain1", "~Eric_Elmoznino1", "~Younesse_Kaddar1", "~Guillaume_Lajoie1", "~Yoshua_Bengio1", "~Nikolay_Malkin1"]}, "keywords": {"value": ["large language models", "LLMs", "Bayesian inference", "chain-of-thought reasoning", "latent variable models", "generative flow networks", "GFlowNets"]}, "abstract": {"value": "Autoregressive large language models (LLMs) compress knowledge from their training data through next-token conditional distributions. This limits tractable querying of this knowledge to start-to-end autoregressive sampling. However, many tasks of interest---including sequence continuation, infilling, and other forms of constrained generation---involve sampling from intractable posterior distributions. We address this limitation by using amortized Bayesian inference to sample from these intractable posteriors. Such amortization is algorithmically achieved by fine-tuning LLMs via diversity-seeking reinforcement learning algorithms: generative flow networks (GFlowNets). We empirically demonstrate that this distribution-matching paradigm of LLM fine-tuning can serve as an effective alternative to maximum-likelihood training and reward-maximizing policy optimization. As an important application, we interpret chain-of-thought reasoning as a latent variable modeling problem and demonstrate that our approach enables data-efficient adaptation of LLMs to tasks that require multi-step rationalization and tool use."}, "primary_area": {"value": "probabilistic methods (Bayesian methods, variational inference, sampling, UQ, etc.)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 oral"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "TLDR": {"value": "We fine-tune LLMs to sample from intractable posteriors for tasks such as infilling, chain-of-thought reasoning, and tool-augmented inference."}, "pdf": {"value": "/pdf/4636785df4e848cf95cee05d7314fcb50e2d4c3c.pdf"}, "supplementary_material": {"value": "/attachment/9bafb37d4a35901d97c44da14d1c222b5809c84f.zip"}, "_bibtex": {"value": "@inproceedings{\nhu2024amortizing,\ntitle={Amortizing intractable inference in large language models},\nauthor={Edward J Hu and Moksh Jain and Eric Elmoznino and Younesse Kaddar and Guillaume Lajoie and Yoshua Bengio and Nikolay Malkin},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=Ouj6p4ca60}\n}"}, "paperhash": {"value": "hu|amortizing_intractable_inference_in_large_language_models"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission1391/-/Revision", "ICLR.cc/2024/Conference/Submission1391/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission1391/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410819009, "version": 2, "details": {"replyCount": 23, "presentation": [{"name": "title", "order": 1}, {"name": "authors", "order": 3}, {"name": "code_of_ethics", "order": 3, "input": "checkbox", "value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "description": null}, {"name": "authorids", "order": 4}, {"name": "keywords", "order": 4}, {"name": "submission_guidelines", "order": 4, "input": "checkbox", "value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide.", "description": null}, {"name": "TLDR", "order": 5, "fieldName": "TL;DR"}, {"name": "abstract", "order": 6, "input": "textarea", "markdown": true}, {"name": "pdf", "order": 7}, {"name": "anonymous_url", "order": 7, "input": "checkbox", "value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "description": null}, {"name": "supplementary_material", "order": 8}, {"name": "no_acknowledgement_section", "order": 8, "input": "checkbox", "value": "I certify that there is no acknowledgement section in this submission for double blind review.", "description": null}, {"name": "primary_area", "order": 9, "input": "select", "value": "probabilistic methods (Bayesian methods, variational inference, sampling, UQ, etc.)", "description": null}, {"name": "resubmission"}, {"name": "student_author"}, {"name": "large_language_models"}, {"name": "other_comments_on_LLMs"}, {"name": "venue", "hidden": true}, {"name": "venueid", "hidden": true}, {"name": "_bibtex", "input": "textarea"}, {"name": "other_comments"}]}}, {"id": "aIok3ZD9to", "forum": "aIok3ZD9to", "number": 1387, "cdate": 1695050188312, "tcdate": 1695050188312, "mdate": 1710339036813, "tmdate": 1710339036813, "signatures": ["ICLR.cc/2024/Conference/Submission1387/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission1387/Authors"], "content": {"title": {"value": "LLMCarbon: Modeling the End-to-End Carbon Footprint of Large Language Models"}, "authors": {"value": ["Ahmad Faiz", "Sotaro Kaneda", "Ruhan Wang", "Rita Chukwunyere Osi", "Prateek Sharma", "Fan Chen", "Lei Jiang"]}, "authorids": {"value": ["~Ahmad_Faiz1", "~Sotaro_Kaneda1", "~Ruhan_Wang1", "~Rita_Chukwunyere_Osi1", "~Prateek_Sharma1", "~Fan_Chen2", "~Lei_Jiang1"]}, "keywords": {"value": ["carbon footprint modeling", "large lanaguage models"]}, "TLDR": {"value": "we propose a carbon footprint modeling tool for large language models."}, "abstract": {"value": "The carbon footprint associated with large language models (LLMs) is a significant concern, encompassing emissions from their training, inference, experimentation, and storage processes, including operational and embodied carbon emissions. An essential aspect is accurately estimating the carbon impact of emerging LLMs even before their training, which heavily relies on GPU usage. Existing studies have reported the carbon footprint of LLM training, but only one tool, mlco2, can predict the carbon footprint of new neural networks prior to physical training. However, mlco2 has several serious limitations. It cannot extend its estimation to dense or mixture-of-experts (MoE) LLMs, disregards critical architectural parameters, focuses solely on GPUs, and cannot model embodied carbon footprints. Addressing these gaps, we introduce \\textit{\\carb}, an end-to-end carbon footprint projection model designed for both dense and MoE LLMs. Compared to mlco2, \\carb~significantly enhances the accuracy of carbon footprint estimations for various LLMs. The source code is released at \\url{https://github.com/SotaroKaneda/MLCarbon}."}, "primary_area": {"value": "societal considerations including fairness, safety, privacy"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 oral"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/43015130fe7515c37278585d5e156acdb8bba5fb.pdf"}, "_bibtex": {"value": "@inproceedings{\nfaiz2024llmcarbon,\ntitle={{LLMC}arbon: Modeling the End-to-End Carbon Footprint of Large Language Models},\nauthor={Ahmad Faiz and Sotaro Kaneda and Ruhan Wang and Rita Chukwunyere Osi and Prateek Sharma and Fan Chen and Lei Jiang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=aIok3ZD9to}\n}"}, "paperhash": {"value": "faiz|llmcarbon_modeling_the_endtoend_carbon_footprint_of_large_language_models"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission1387/-/Revision", "ICLR.cc/2024/Conference/Submission1387/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission1387/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410818812, "version": 2, "details": {"replyCount": 18, "presentation": [{"name": "title", "order": 1}, {"name": "authors", "order": 3}, {"name": "code_of_ethics", "order": 3, "input": "checkbox", "value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "description": null}, {"name": "authorids", "order": 4}, {"name": "keywords", "order": 4}, {"name": "submission_guidelines", "order": 4, "input": "checkbox", "value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide.", "description": null}, {"name": "TLDR", "order": 5, "fieldName": "TL;DR"}, {"name": "abstract", "order": 6, "input": "textarea", "markdown": true}, {"name": "pdf", "order": 7}, {"name": "anonymous_url", "order": 7, "input": "checkbox", "value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "description": null}, {"name": "supplementary_material", "order": 8}, {"name": "no_acknowledgement_section", "order": 8, "input": "checkbox", "value": "I certify that there is no acknowledgement section in this submission for double blind review.", "description": null}, {"name": "primary_area", "order": 9, "input": "select", "value": "societal considerations including fairness, safety, privacy", "description": null}, {"name": "resubmission"}, {"name": "student_author"}, {"name": "large_language_models"}, {"name": "other_comments_on_LLMs"}, {"name": "venue", "hidden": true}, {"name": "venueid", "hidden": true}, {"name": "_bibtex", "input": "textarea"}, {"name": "other_comments"}]}}, {"id": "9JQtrumvg8", "forum": "9JQtrumvg8", "number": 1265, "cdate": 1695032743122, "tcdate": 1695032743122, "mdate": 1710415767055, "tmdate": 1710415767055, "signatures": ["ICLR.cc/2024/Conference/Submission1265/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission1265/Authors"], "content": {"title": {"value": "A Real-World WebAgent with Planning, Long Context Understanding, and Program Synthesis"}, "authors": {"value": ["Izzeddin Gur", "Hiroki Furuta", "Austin V Huang", "Mustafa Safdari", "Yutaka Matsuo", "Douglas Eck", "Aleksandra Faust"]}, "authorids": {"value": ["~Izzeddin_Gur1", "~Hiroki_Furuta1", "~Austin_V_Huang1", "~Mustafa_Safdari1", "~Yutaka_Matsuo1", "~Douglas_Eck1", "~Aleksandra_Faust1"]}, "keywords": {"value": ["Web Navigation", "Web Automation", "Large Language Models", "Language Model Agents", "Tool Use", "Program Synthesis"]}, "TLDR": {"value": "We propose a modular language model agents for real-world web automation by leveraging the capability of multi-step planning, long context understanding, and program synthesis in LLMs."}, "abstract": {"value": "Pre-trained large language models (LLMs) have recently achieved better generalization and sample efficiency in autonomous web automation.\nHowever, the performance on real-world websites has still suffered from (1) open domainness, (2) limited context length, and (3) lack of inductive bias on HTML.\nWe introduce WebAgent, an LLM-driven agent that learns from self-experience to complete tasks on real websites following natural language instructions.\nWebAgent plans ahead by decomposing instructions into canonical sub-instructions, summarizes long HTML documents into task-relevant snippets, and acts on websites via Python programs generated from those.\nWe design WebAgent with Flan-U-PaLM, for grounded code generation, and HTML-T5, new pre-trained LLMs for long HTML documents using local and global attention mechanisms and a mixture of long-span denoising objectives, for planning and summarization.\nWe empirically demonstrate that our modular recipe improves the success on real websites by over 50%, and that HTML-T5 is the best model to solve various HTML understanding tasks; achieving 18.7% higher success rate than the prior method on MiniWoB web automation benchmark, and SoTA performance on Mind2Web, an offline task planning evaluation."}, "primary_area": {"value": "applications to robotics, autonomy, planning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 oral"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/0b27823f96e3efd0ed6921aafc4fe4643d1aeec5.pdf"}, "_bibtex": {"value": "@inproceedings{\ngur2024a,\ntitle={A Real-World WebAgent with Planning, Long Context Understanding, and Program Synthesis},\nauthor={Izzeddin Gur and Hiroki Furuta and Austin V Huang and Mustafa Safdari and Yutaka Matsuo and Douglas Eck and Aleksandra Faust},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=9JQtrumvg8}\n}"}, "paperhash": {"value": "gur|a_realworld_webagent_with_planning_long_context_understanding_and_program_synthesis"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission1265/-/Revision", "ICLR.cc/2024/Conference/Submission1265/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission1265/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410815218, "version": 2, "details": {"replyCount": 17, "presentation": [{"name": "title", "order": 1}, {"name": "authors", "order": 3}, {"name": "code_of_ethics", "order": 3, "input": "checkbox", "value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "description": null}, {"name": "authorids", "order": 4}, {"name": "keywords", "order": 4}, {"name": "submission_guidelines", "order": 4, "input": "checkbox", "value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide.", "description": null}, {"name": "TLDR", "order": 5, "fieldName": "TL;DR"}, {"name": "abstract", "order": 6, "input": "textarea", "markdown": true}, {"name": "pdf", "order": 7}, {"name": "anonymous_url", "order": 7, "input": "checkbox", "value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "description": null}, {"name": "supplementary_material", "order": 8}, {"name": "no_acknowledgement_section", "order": 8, "input": "checkbox", "value": "I certify that there is no acknowledgement section in this submission for double blind review.", "description": null}, {"name": "primary_area", "order": 9, "input": "select", "value": "applications to robotics, autonomy, planning", "description": null}, {"name": "resubmission"}, {"name": "student_author"}, {"name": "large_language_models"}, {"name": "other_comments_on_LLMs"}, {"name": "venue", "hidden": true}, {"name": "venueid", "hidden": true}, {"name": "_bibtex", "input": "textarea"}, {"name": "other_comments"}]}}, {"id": "WNkW0cOwiz", "forum": "WNkW0cOwiz", "number": 1058, "cdate": 1695003042921, "tcdate": 1695003042921, "mdate": 1710220515366, "tmdate": 1710220515366, "signatures": ["ICLR.cc/2024/Conference/Submission1058/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission1058/Authors"], "content": {"title": {"value": "Lipschitz Singularities in Diffusion Models"}, "authors": {"value": ["Zhantao Yang", "Ruili Feng", "Han Zhang", "Yujun Shen", "Kai Zhu", "Lianghua Huang", "Yifei Zhang", "Yu Liu", "Deli Zhao", "Jingren Zhou", "Fan Cheng"]}, "authorids": {"value": ["~Zhantao_Yang1", "~Ruili_Feng1", "~Han_Zhang16", "~Yujun_Shen1", "~Kai_Zhu4", "~Lianghua_Huang2", "~Yifei_Zhang4", "~Yu_Liu23", "~Deli_Zhao1", "~Jingren_Zhou1", "~Fan_Cheng1"]}, "keywords": {"value": ["Image Generation", "Generative models", "Diffusion models"]}, "abstract": {"value": "Diffusion models, which employ stochastic differential equations to sample images through integrals, have emerged as a dominant class of generative models. However, the rationality of the diffusion process itself receives limited attention, leaving the question of whether the problem is well-posed and well-conditioned. In this paper, we uncover a vexing propensity of diffusion models: they frequently exhibit the infinite Lipschitz near the zero point of timesteps. We provide theoretical proofs to illustrate the presence of infinite Lipschitz constants and empirical results to confirm it. The Lipschitz singularities pose a threat to the stability and accuracy during both the training and inference processes of diffusion models. Therefore, the mitigation of Lipschitz singularities holds great potential for enhancing the performance of diffusion models. To address this challenge, we propose a novel approach, dubbed E-TSDM, which alleviates the Lipschitz singularities of the diffusion model near the zero point. Remarkably, our technique yields a substantial improvement in performance. Moreover, as a byproduct of our method, we achieve a dramatic reduction in the Fr\u00e9chet Inception Distance of acceleration methods relying on network Lipschitz, including DDIM and DPM-Solver, by over 33\\%. Extensive experiments on diverse datasets validate our theory and method. Our work may advance the understanding of the general diffusion process, and also provide insights for the design of diffusion models."}, "primary_area": {"value": "generative models"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 oral"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/79d5382f3723bab77cf1931fe0c461eb35d8218a.pdf"}, "supplementary_material": {"value": "/attachment/3d35d43c8b13c9365e0babf1d568a9e6e00fce61.zip"}, "TLDR": {"value": "We theoretically prove and empirically observe the presence of infinite Lipschitz constants near the zero point, and propose a simple but effective approach to address this challenge."}, "_bibtex": {"value": "@inproceedings{\nyang2024lipschitz,\ntitle={Lipschitz Singularities in Diffusion Models},\nauthor={Zhantao Yang and Ruili Feng and Han Zhang and Yujun Shen and Kai Zhu and Lianghua Huang and Yifei Zhang and Yu Liu and Deli Zhao and Jingren Zhou and Fan Cheng},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=WNkW0cOwiz}\n}"}, "paperhash": {"value": "yang|lipschitz_singularities_in_diffusion_models"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission1058/-/Revision", "ICLR.cc/2024/Conference/Submission1058/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission1058/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410809432, "version": 2, "details": {"replyCount": 20, "presentation": [{"name": "title", "order": 1}, {"name": "authors", "order": 3}, {"name": "code_of_ethics", "order": 3, "input": "checkbox", "value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "description": null}, {"name": "authorids", "order": 4}, {"name": "keywords", "order": 4}, {"name": "submission_guidelines", "order": 4, "input": "checkbox", "value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide.", "description": null}, {"name": "TLDR", "order": 5, "fieldName": "TL;DR"}, {"name": "abstract", "order": 6, "input": "textarea", "markdown": true}, {"name": "pdf", "order": 7}, {"name": "anonymous_url", "order": 7, "input": "checkbox", "value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "description": null}, {"name": "supplementary_material", "order": 8}, {"name": "no_acknowledgement_section", "order": 8, "input": "checkbox", "value": "I certify that there is no acknowledgement section in this submission for double blind review.", "description": null}, {"name": "primary_area", "order": 9, "input": "select", "value": "generative models", "description": null}, {"name": "resubmission"}, {"name": "student_author"}, {"name": "large_language_models"}, {"name": "other_comments_on_LLMs"}, {"name": "venue", "hidden": true}, {"name": "venueid", "hidden": true}, {"name": "_bibtex", "input": "textarea"}, {"name": "other_comments"}]}}, {"id": "5Ca9sSzuDp", "forum": "5Ca9sSzuDp", "number": 980, "cdate": 1694974317609, "tcdate": 1694974317609, "mdate": 1711397571360, "tmdate": 1711397571360, "signatures": ["ICLR.cc/2024/Conference/Submission980/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission980/Authors"], "content": {"title": {"value": "Interpreting CLIP's Image Representation via Text-Based Decomposition"}, "authors": {"value": ["Yossi Gandelsman", "Alexei A Efros", "Jacob Steinhardt"]}, "authorids": {"value": ["~Yossi_Gandelsman2", "~Alexei_A_Efros1", "~Jacob_Steinhardt1"]}, "keywords": {"value": ["CLIP", "interpretability", "explainability"]}, "abstract": {"value": "We investigate the CLIP image encoder by analyzing how individual model components affect the final representation. We decompose the image representation as a sum across individual image patches, model layers, and attention heads, and use CLIP's text representation to interpret the summands. Interpreting the attention heads, we characterize each head's role by automatically finding text representations that span its output space, which reveals property-specific roles for many heads (e.g. location or shape). Next, interpreting the image patches, we uncover an emergent spatial localization within CLIP. Finally, we use this understanding to remove spurious features from CLIP and to create a strong zero-shot image segmenter. Our results indicate that scalable understanding of transformer models is attainable and can be used to repair and improve models."}, "primary_area": {"value": "visualization or interpretation of learned representations"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 oral"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/8570a395fcdad9f81c89c604044a2406efb7dc7b.pdf"}, "TLDR": {"value": "We investigate the CLIP image encoder by analyzing how individual model components affect the final representation"}, "_bibtex": {"value": "@inproceedings{\ngandelsman2024interpreting,\ntitle={Interpreting {CLIP}'s Image Representation via Text-Based Decomposition},\nauthor={Yossi Gandelsman and Alexei A Efros and Jacob Steinhardt},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=5Ca9sSzuDp}\n}"}, "paperhash": {"value": "gandelsman|interpreting_clips_image_representation_via_textbased_decomposition"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission980/-/Revision", "ICLR.cc/2024/Conference/Submission980/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission980/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410807775, "version": 2, "details": {"replyCount": 16, "presentation": [{"name": "title", "order": 1}, {"name": "authors", "order": 3}, {"name": "code_of_ethics", "order": 3, "input": "checkbox", "value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "description": null}, {"name": "authorids", "order": 4}, {"name": "keywords", "order": 4}, {"name": "submission_guidelines", "order": 4, "input": "checkbox", "value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide.", "description": null}, {"name": "TLDR", "order": 5, "fieldName": "TL;DR"}, {"name": "abstract", "order": 6, "input": "textarea", "markdown": true}, {"name": "pdf", "order": 7}, {"name": "anonymous_url", "order": 7, "input": "checkbox", "value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "description": null}, {"name": "supplementary_material", "order": 8}, {"name": "no_acknowledgement_section", "order": 8, "input": "checkbox", "value": "I certify that there is no acknowledgement section in this submission for double blind review.", "description": null}, {"name": "primary_area", "order": 9, "input": "select", "value": "visualization or interpretation of learned representations", "description": null}, {"name": "resubmission"}, {"name": "student_author"}, {"name": "large_language_models"}, {"name": "other_comments_on_LLMs"}, {"name": "venue", "hidden": true}, {"name": "venueid", "hidden": true}, {"name": "_bibtex", "input": "textarea"}, {"name": "other_comments"}]}}, {"id": "FVhmnvqnsI", "forum": "FVhmnvqnsI", "number": 801, "cdate": 1694919998262, "tcdate": 1694919998262, "mdate": 1713024180203, "tmdate": 1713024180203, "signatures": ["ICLR.cc/2024/Conference/Submission801/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission801/Authors"], "content": {"title": {"value": "Multisize Dataset Condensation"}, "authors": {"value": ["Yang He", "Lingao Xiao", "Joey Tianyi Zhou", "Ivor Tsang"]}, "authorids": {"value": ["~Yang_He2", "~Lingao_Xiao1", "~Joey_Tianyi_Zhou1", "~Ivor_Tsang1"]}, "keywords": {"value": ["Dataset Condensation", "Dataset Distillation", "Image Classification"]}, "abstract": {"value": "While dataset condensation effectively enhances training efficiency, its application in on-device scenarios brings unique challenges. 1) Due to the fluctuating computational resources of these devices, there's a demand for a flexible dataset size that diverges from a predefined size. 2) The limited computational power on devices often prevents additional condensation operations. These two challenges connect to the \"subset degradation problem\" in traditional dataset condensation: a subset from a larger condensed dataset is often unrepresentative compared to directly condensing the whole dataset to that smaller size. In this paper, we propose Multisize Dataset Condensation (MDC) by **compressing $N$ condensation processes into a single condensation process to obtain datasets with multiple sizes.** Specifically, we introduce an \"adaptive subset loss\" on top of the basic condensation loss to mitigate the \"subset degradation problem\". Our MDC method offers several benefits: 1) No additional condensation process is required; 2) reduced storage requirement by reusing condensed images. Experiments validate our findings on networks including ConvNet, ResNet and DenseNet, and datasets including SVHN,  CIFAR-10, CIFAR-100 and ImageNet. For example, we achieved 5.22%-6.40% average accuracy gains on condensing CIFAR-10 to ten images per class. Code is available at: [https://github.com/he-y/Multisize-Dataset-Condensation](https://github.com/he-y/Multisize-Dataset-Condensation)."}, "primary_area": {"value": "general machine learning (i.e., none of the above)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 oral"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "TLDR": {"value": "Compress N condensation processes into one single condensation process to generate condensed datasets with various sizes."}, "pdf": {"value": "/pdf/316b7fa983b9fde383169e561c22722abd5b96fb.pdf"}, "supplementary_material": {"value": "/attachment/bf69019ab4256b6451e720650a077e557b0d8fbe.pdf"}, "_bibtex": {"value": "@inproceedings{\nhe2024multisize,\ntitle={Multisize Dataset Condensation},\nauthor={Yang He and Lingao Xiao and Joey Tianyi Zhou and Ivor Tsang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=FVhmnvqnsI}\n}"}, "paperhash": {"value": "he|multisize_dataset_condensation"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission801/-/Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission801/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410803984, "version": 2, "details": {"replyCount": 12, "presentation": [{"name": "title", "order": 1}, {"name": "authors", "order": 3}, {"name": "code_of_ethics", "order": 3, "input": "checkbox", "value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "description": null}, {"name": "authorids", "order": 4}, {"name": "keywords", "order": 4}, {"name": "submission_guidelines", "order": 4, "input": "checkbox", "value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide.", "description": null}, {"name": "TLDR", "order": 5, "fieldName": "TL;DR"}, {"name": "abstract", "order": 6, "input": "textarea", "markdown": true}, {"name": "pdf", "order": 7}, {"name": "anonymous_url", "order": 7, "input": "checkbox", "value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "description": null}, {"name": "supplementary_material", "order": 8}, {"name": "no_acknowledgement_section", "order": 8, "input": "checkbox", "value": "I certify that there is no acknowledgement section in this submission for double blind review.", "description": null}, {"name": "primary_area", "order": 9, "input": "select", "value": "general machine learning (i.e., none of the above)", "description": null}, {"name": "resubmission"}, {"name": "student_author"}, {"name": "large_language_models"}, {"name": "other_comments_on_LLMs"}, {"name": "venue", "hidden": true}, {"name": "venueid", "hidden": true}, {"name": "_bibtex", "input": "textarea"}, {"name": "other_comments"}]}}, {"id": "UyNXMqnN3c", "forum": "UyNXMqnN3c", "number": 789, "cdate": 1694914785467, "tcdate": 1694914785467, "mdate": 1710173073576, "tmdate": 1710173073576, "signatures": ["ICLR.cc/2024/Conference/Submission789/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission789/Authors"], "content": {"title": {"value": "DreamGaussian: Generative Gaussian Splatting for Efficient 3D Content Creation"}, "authors": {"value": ["Jiaxiang Tang", "Jiawei Ren", "Hang Zhou", "Ziwei Liu", "Gang Zeng"]}, "authorids": {"value": ["~Jiaxiang_Tang1", "~Jiawei_Ren1", "~Hang_Zhou4", "~Ziwei_Liu1", "~Gang_Zeng1"]}, "keywords": {"value": ["Text-to-3D", "Image-to-3D", "3D Generation", "Efficiency"]}, "abstract": {"value": "Recent advances in 3D content creation mostly leverage optimization-based 3D generation via score distillation sampling (SDS).\nThough promising results have been exhibited, these methods often suffer from slow per-sample optimization, limiting their practical usage. \nIn this paper, we propose DreamGaussian, a novel 3D content generation framework that achieves both efficiency and quality simultaneously. \nOur key insight is to design a generative 3D Gaussian Splatting model with companioned mesh extraction and texture refinement in UV space.\nIn contrast to the occupancy pruning used in Neural Radiance Fields, we demonstrate that the progressive densification of 3D Gaussians converges significantly faster for 3D generative tasks.\nTo further enhance the texture quality and facilitate downstream applications, we introduce an efficient algorithm to convert 3D Gaussians into textured meshes and apply a fine-tuning stage to refine the details.\nExtensive experiments demonstrate the superior efficiency and competitive generation quality of our proposed approach.\nNotably, DreamGaussian produces high-quality textured meshes in just 2 minutes from a single-view image, achieving approximately 10 times acceleration compared to existing methods."}, "primary_area": {"value": "generative models"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 oral"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/6070ff46264213801f0d925ab0af21f3c57d8c37.pdf"}, "supplementary_material": {"value": "/attachment/9bf656012f7bb6c82f5f9e3d48b55ccd3f11c53f.zip"}, "_bibtex": {"value": "@inproceedings{\ntang2024dreamgaussian,\ntitle={DreamGaussian: Generative Gaussian Splatting for Efficient 3D Content Creation},\nauthor={Jiaxiang Tang and Jiawei Ren and Hang Zhou and Ziwei Liu and Gang Zeng},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=UyNXMqnN3c}\n}"}, "paperhash": {"value": "tang|dreamgaussian_generative_gaussian_splatting_for_efficient_3d_content_creation"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission789/-/Revision", "ICLR.cc/2024/Conference/Submission789/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission789/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410803847, "version": 2, "details": {"replyCount": 16, "presentation": [{"name": "title", "order": 1}, {"name": "authors", "order": 3}, {"name": "code_of_ethics", "order": 3, "input": "checkbox", "value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "description": null}, {"name": "authorids", "order": 4}, {"name": "keywords", "order": 4}, {"name": "submission_guidelines", "order": 4, "input": "checkbox", "value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide.", "description": null}, {"name": "TLDR", "order": 5, "fieldName": "TL;DR"}, {"name": "abstract", "order": 6, "input": "textarea", "markdown": true}, {"name": "pdf", "order": 7}, {"name": "anonymous_url", "order": 7, "input": "checkbox", "value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "description": null}, {"name": "supplementary_material", "order": 8}, {"name": "no_acknowledgement_section", "order": 8, "input": "checkbox", "value": "I certify that there is no acknowledgement section in this submission for double blind review.", "description": null}, {"name": "primary_area", "order": 9, "input": "select", "value": "generative models", "description": null}, {"name": "resubmission"}, {"name": "student_author"}, {"name": "large_language_models"}, {"name": "other_comments_on_LLMs"}, {"name": "venue", "hidden": true}, {"name": "venueid", "hidden": true}, {"name": "_bibtex", "input": "textarea"}, {"name": "other_comments"}]}}, {"id": "sllU8vvsFF", "forum": "sllU8vvsFF", "number": 749, "cdate": 1694902089509, "tcdate": 1694902089509, "mdate": 1709979739038, "tmdate": 1709979739038, "signatures": ["ICLR.cc/2024/Conference/Submission749/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission749/Authors"], "content": {"title": {"value": "LRM: Large Reconstruction Model for Single Image to 3D"}, "authors": {"value": ["Yicong Hong", "Kai Zhang", "Jiuxiang Gu", "Sai Bi", "Yang Zhou", "Difan Liu", "Feng Liu", "Kalyan Sunkavalli", "Trung Bui", "Hao Tan"]}, "authorids": {"value": ["~Yicong_Hong1", "~Kai_Zhang7", "~Jiuxiang_Gu2", "~Sai_Bi1", "~Yang_Zhou10", "~Difan_Liu2", "~Feng_Liu6", "~Kalyan_Sunkavalli1", "~Trung_Bui1", "~Hao_Tan1"]}, "keywords": {"value": ["3D Reconstruction", "Large-Scale Training", "Transformers"]}, "abstract": {"value": "We propose the first Large Reconstruction Model (LRM) that predicts the 3D model of an object from a single input image within just 5 seconds. In contrast to many previous methods that are trained on small-scale datasets such as ShapeNet in a category-specific fashion, LRM adopts a highly scalable transformer-based architecture with 500 million learnable parameters to directly predict a neural radiance field (NeRF) from the input image. We train our model in an end-to-end manner on massive multi-view data containing around 1 million objects, including both synthetic renderings from Objaverse and real captures from MVImgNet. This combination of a high-capacity model and large-scale training data empowers our model to be highly generalizable and produce high-quality 3D reconstructions from various testing inputs, including real-world in-the-wild captures and images created by generative models. Video demos and interactable 3D meshes can be found on our LRM project webpage: https://yiconghong.me/LRM."}, "primary_area": {"value": "representation learning for computer vision, audio, language, and other modalities"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 oral"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/21831b2594b6b1378c517f290ba90103625d2d55.pdf"}, "TLDR": {"value": "A transformer-based Large Reconstruction Model (LRM) that predicts the 3D model of an object from a single image within just 5 seconds."}, "_bibtex": {"value": "@inproceedings{\nhong2024lrm,\ntitle={{LRM}: Large Reconstruction Model for Single Image to 3D},\nauthor={Yicong Hong and Kai Zhang and Jiuxiang Gu and Sai Bi and Yang Zhou and Difan Liu and Feng Liu and Kalyan Sunkavalli and Trung Bui and Hao Tan},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=sllU8vvsFF}\n}"}, "paperhash": {"value": "hong|lrm_large_reconstruction_model_for_single_image_to_3d"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission749/-/Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission749/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410802719, "version": 2, "details": {"replyCount": 16, "presentation": [{"name": "title", "order": 1}, {"name": "authors", "order": 3}, {"name": "code_of_ethics", "order": 3, "input": "checkbox", "value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "description": null}, {"name": "authorids", "order": 4}, {"name": "keywords", "order": 4}, {"name": "submission_guidelines", "order": 4, "input": "checkbox", "value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide.", "description": null}, {"name": "TLDR", "order": 5, "fieldName": "TL;DR"}, {"name": "abstract", "order": 6, "input": "textarea", "markdown": true}, {"name": "pdf", "order": 7}, {"name": "anonymous_url", "order": 7, "input": "checkbox", "value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "description": null}, {"name": "supplementary_material", "order": 8}, {"name": "no_acknowledgement_section", "order": 8, "input": "checkbox", "value": "I certify that there is no acknowledgement section in this submission for double blind review.", "description": null}, {"name": "primary_area", "order": 9, "input": "select", "value": "representation learning for computer vision, audio, language, and other modalities", "description": null}, {"name": "resubmission"}, {"name": "student_author"}, {"name": "large_language_models"}, {"name": "other_comments_on_LLMs"}, {"name": "venue", "hidden": true}, {"name": "venueid", "hidden": true}, {"name": "_bibtex", "input": "textarea"}, {"name": "other_comments"}]}}, {"id": "AhizIPytk4", "forum": "AhizIPytk4", "number": 742, "cdate": 1694898539138, "tcdate": 1694898539138, "mdate": 1713672922379, "tmdate": 1713672922379, "signatures": ["ICLR.cc/2024/Conference/Submission742/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission742/Authors"], "content": {"title": {"value": "How Well Do Supervised 3D Models Transfer to Medical Imaging Tasks?"}, "authors": {"value": ["Wenxuan Li", "Alan Yuille", "Zongwei Zhou"]}, "authorids": {"value": ["~Wenxuan_Li3", "~Alan_Yuille1", "~Zongwei_Zhou1"]}, "keywords": {"value": ["Transfer Learning", "Medical Image Analysis", "Organ Segmentation"]}, "abstract": {"value": "The pre-training and fine-tuning paradigm has become prominent in transfer learning. For example, if the model is pre-trained on ImageNet and then fine-tuned to PASCAL, it can significantly outperform that trained on PASCAL from scratch. While ImageNet pre-training has shown enormous success, it is formed in 2D, and the learned features are for classification tasks; when transferring to more diverse tasks, like 3D image segmentation, its performance is inevitably compromised due to the deviation from the original ImageNet context. A significant challenge lies in the lack of large, annotated 3D datasets rivaling the scale of ImageNet for model pre-training. To overcome this challenge, we make two contributions. Firstly, we construct AbdomenAtlas 1.1 that comprises **9,262** three-dimensional computed tomography (CT) volumes with high-quality, per-voxel annotations of 25 anatomical structures and pseudo annotations of seven tumor types. Secondly, we develop a suite of models that are pre-trained on our AbdomenAtlas 1.1 for transfer learning. Our preliminary analyses indicate that the model trained only with 21 CT volumes, 672 masks, and 40 GPU hours has a transfer learning ability similar to the model trained with 5,050 (unlabeled) CT volumes and 1,152 GPU hours. More importantly, the transfer learning ability of supervised models can further scale up with larger annotated datasets, achieving significantly better performance than preexisting pre-trained models, irrespective of their pre-training methodologies or data sources. We hope this study can facilitate collective efforts in constructing larger 3D medical datasets and more releases of supervised pre-trained models."}, "primary_area": {"value": "datasets and benchmarks"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 oral"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/08dee4fe8bfab20e8d683609d546d91345d8cd82.pdf"}, "_bibtex": {"value": "@inproceedings{\nli2024how,\ntitle={How Well Do Supervised 3D Models Transfer to Medical Imaging Tasks?},\nauthor={Wenxuan Li and Alan Yuille and Zongwei Zhou},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=AhizIPytk4}\n}"}, "paperhash": {"value": "li|how_well_do_supervised_3d_models_transfer_to_medical_imaging_tasks"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission742/-/Revision", "ICLR.cc/2024/Conference/Submission742/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission742/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410802409, "version": 2, "details": {"replyCount": 26, "presentation": [{"name": "title", "order": 1}, {"name": "authors", "order": 3}, {"name": "code_of_ethics", "order": 3, "input": "checkbox", "value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "description": null}, {"name": "authorids", "order": 4}, {"name": "keywords", "order": 4}, {"name": "submission_guidelines", "order": 4, "input": "checkbox", "value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide.", "description": null}, {"name": "TLDR", "order": 5, "fieldName": "TL;DR"}, {"name": "abstract", "order": 6, "input": "textarea", "markdown": true}, {"name": "pdf", "order": 7}, {"name": "anonymous_url", "order": 7, "input": "checkbox", "value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "description": null}, {"name": "supplementary_material", "order": 8}, {"name": "no_acknowledgement_section", "order": 8, "input": "checkbox", "value": "I certify that there is no acknowledgement section in this submission for double blind review.", "description": null}, {"name": "primary_area", "order": 9, "input": "select", "value": "datasets and benchmarks", "description": null}, {"name": "resubmission"}, {"name": "student_author"}, {"name": "large_language_models"}, {"name": "other_comments_on_LLMs"}, {"name": "venue", "hidden": true}, {"name": "venueid", "hidden": true}, {"name": "_bibtex", "input": "textarea"}, {"name": "other_comments"}]}}, {"id": "gFR4QwK53h", "forum": "gFR4QwK53h", "number": 489, "cdate": 1694825952428, "tcdate": 1694825952428, "mdate": 1713672382140, "tmdate": 1713672382140, "signatures": ["ICLR.cc/2024/Conference/Submission489/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission489/Authors"], "content": {"title": {"value": "Gene Regulatory Network Inference in the Presence of Dropouts: a Causal View"}, "authors": {"value": ["Haoyue Dai", "Ignavier Ng", "Gongxu Luo", "Peter Spirtes", "Petar Stojanov", "Kun Zhang"]}, "authorids": {"value": ["~Haoyue_Dai1", "~Ignavier_Ng1", "~Gongxu_Luo1", "~Peter_Spirtes1", "~Petar_Stojanov2", "~Kun_Zhang1"]}, "keywords": {"value": ["Gene regulatory network", "Single-cell RNA-sequencing", "Dropout", "Zero-inflated data", "Causal model", "Causal discovery", "Nonparametric"]}, "abstract": {"value": "Gene regulatory network inference (GRNI) is a challenging problem, particularly owing to the presence of zeros in single-cell RNA sequencing data: some are biological zeros representing no gene expression, while some others are technical zeros arising from the sequencing procedure (aka dropouts), which may bias GRNI by distorting the joint distribution of the measured gene expressions. Existing approaches typically handle dropout error via imputation, which may introduce spurious relations as the true joint distribution is generally unidentifiable. To tackle this issue, we introduce a causal graphical model to characterize the dropout mechanism, namely, Causal Dropout Model. We provide a simple yet effective theoretical result: interestingly, the conditional independence (CI) relations in the data with dropouts, after deleting the samples with zero values (regardless if technical or not) for the conditioned variables, are asymptotically identical to the CI relations in the original data without dropouts. This particular test-wise deletion procedure, in which we perform CI tests on the samples without zeros for the conditioned variables, can be seamlessly integrated with existing structure learning approaches including constraint-based and greedy score-based methods, thus giving rise to a principled framework for GRNI in the presence of dropouts. We further show that the causal dropout model can be validated from data, and many existing statistical models to handle dropouts fit into our model as specific parametric instances. Empirical evaluation on synthetic, curated, and real-world experimental transcriptomic data comprehensively demonstrate the efficacy of our method."}, "pdf": {"value": "/pdf/69813094585730931fce711a92e4bb53d955e2dd.pdf"}, "primary_area": {"value": "causal reasoning"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 oral"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "TLDR": {"value": "The conditional independence (CI) relations in the data with dropouts, after deleting the samples with zero values for conditioned variables, are identical to the CI relations in the original data without dropout."}, "_bibtex": {"value": "@inproceedings{\ndai2024gene,\ntitle={Gene Regulatory Network Inference in the Presence of Dropouts: a Causal View},\nauthor={Haoyue Dai and Ignavier Ng and Gongxu Luo and Peter Spirtes and Petar Stojanov and Kun Zhang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=gFR4QwK53h}\n}"}, "paperhash": {"value": "dai|gene_regulatory_network_inference_in_the_presence_of_dropouts_a_causal_view"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission489/-/Revision", "ICLR.cc/2024/Conference/Submission489/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission489/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410795922, "version": 2, "details": {"replyCount": 12, "presentation": [{"name": "title", "order": 1}, {"name": "authors", "order": 3}, {"name": "code_of_ethics", "order": 3, "input": "checkbox", "value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "description": null}, {"name": "authorids", "order": 4}, {"name": "keywords", "order": 4}, {"name": "submission_guidelines", "order": 4, "input": "checkbox", "value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide.", "description": null}, {"name": "TLDR", "order": 5, "fieldName": "TL;DR"}, {"name": "abstract", "order": 6, "input": "textarea", "markdown": true}, {"name": "pdf", "order": 7}, {"name": "anonymous_url", "order": 7, "input": "checkbox", "value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "description": null}, {"name": "supplementary_material", "order": 8}, {"name": "no_acknowledgement_section", "order": 8, "input": "checkbox", "value": "I certify that there is no acknowledgement section in this submission for double blind review.", "description": null}, {"name": "primary_area", "order": 9, "input": "select", "value": "causal reasoning", "description": null}, {"name": "resubmission"}, {"name": "student_author"}, {"name": "large_language_models"}, {"name": "other_comments_on_LLMs"}, {"name": "venue", "hidden": true}, {"name": "venueid", "hidden": true}, {"name": "_bibtex", "input": "textarea"}, {"name": "other_comments"}]}}, {"id": "v7ZPwoHU1j", "forum": "v7ZPwoHU1j", "number": 400, "cdate": 1694806701941, "tcdate": 1694806701941, "mdate": 1713374303361, "tmdate": 1713374303361, "signatures": ["ICLR.cc/2024/Conference/Submission400/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission400/Authors"], "content": {"title": {"value": "Statistically Optimal $K$-means Clustering via Nonnegative Low-rank Semidefinite Programming"}, "authors": {"value": ["Yubo Zhuang", "Xiaohui Chen", "Yun Yang", "Richard Y. Zhang"]}, "authorids": {"value": ["~Yubo_Zhuang1", "~Xiaohui_Chen3", "~Yun_Yang4", "~Richard_Y._Zhang1"]}, "keywords": {"value": ["clustering", "Burer-Monteiro", "semidefinite programming"]}, "abstract": {"value": "$K$-means clustering is a widely used machine learning method for identifying patterns in large datasets. Recently, semidefinite programming (SDP) relaxations have been proposed for solving the $K$-means optimization problem, which enjoy strong statistical optimality guarantees. However, the prohibitive cost of implementing an SDP solver renders these guarantees inaccessible to practical datasets. In contrast, nonnegative matrix factorization (NMF) is a simple clustering algorithm widely used by machine learning practitioners, but it lacks a solid statistical underpinning and theoretical guarantees. In this paper, we consider an NMF-like algorithm that solves a nonnegative low-rank restriction of the SDP-relaxed $K$-means formulation using a nonconvex Burer--Monteiro factorization approach. The resulting algorithm is as simple and scalable as state-of-the-art NMF algorithms while also enjoying the same strong statistical optimality guarantees as the SDP. In our experiments, we observe that our algorithm achieves significantly smaller mis-clustering errors compared to the existing state-of-the-art while maintaining scalability."}, "primary_area": {"value": "optimization"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 oral"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/4a224d33173cf3086a62083b5dda9cf8d1f4261a.pdf"}, "_bibtex": {"value": "@inproceedings{\nzhuang2024statistically,\ntitle={Statistically Optimal \\$K\\$-means Clustering via Nonnegative Low-rank Semidefinite Programming},\nauthor={Yubo Zhuang and Xiaohui Chen and Yun Yang and Richard Y. Zhang},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=v7ZPwoHU1j}\n}"}, "paperhash": {"value": "zhuang|statistically_optimal_kmeans_clustering_via_nonnegative_lowrank_semidefinite_programming"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission400/-/Revision", "ICLR.cc/2024/Conference/Submission400/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission400/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410793629, "version": 2, "details": {"replyCount": 13, "presentation": [{"name": "title", "order": 1}, {"name": "authors", "order": 3}, {"name": "code_of_ethics", "order": 3, "input": "checkbox", "value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "description": null}, {"name": "authorids", "order": 4}, {"name": "keywords", "order": 4}, {"name": "submission_guidelines", "order": 4, "input": "checkbox", "value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide.", "description": null}, {"name": "TLDR", "order": 5, "fieldName": "TL;DR"}, {"name": "abstract", "order": 6, "input": "textarea", "markdown": true}, {"name": "pdf", "order": 7}, {"name": "anonymous_url", "order": 7, "input": "checkbox", "value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "description": null}, {"name": "supplementary_material", "order": 8}, {"name": "no_acknowledgement_section", "order": 8, "input": "checkbox", "value": "I certify that there is no acknowledgement section in this submission for double blind review.", "description": null}, {"name": "primary_area", "order": 9, "input": "select", "value": "optimization", "description": null}, {"name": "resubmission"}, {"name": "student_author"}, {"name": "large_language_models"}, {"name": "other_comments_on_LLMs"}, {"name": "venue", "hidden": true}, {"name": "venueid", "hidden": true}, {"name": "_bibtex", "input": "textarea"}, {"name": "other_comments"}]}}, {"id": "jr03SfWsBS", "forum": "jr03SfWsBS", "number": 289, "cdate": 1694787033425, "tcdate": 1694787033425, "mdate": 1710517054374, "tmdate": 1710517054374, "signatures": ["ICLR.cc/2024/Conference/Submission289/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission289/Authors"], "content": {"title": {"value": "Unprocessing Seven Years of Algorithmic Fairness"}, "authors": {"value": ["Andr\u00e9 Cruz", "Moritz Hardt"]}, "authorids": {"value": ["~Andr\u00e9_Cruz1", "~Moritz_Hardt1"]}, "keywords": {"value": ["fairness", "algorithmic fairness", "social computing", "tabular data", "meta study"]}, "TLDR": {"value": "A large-scale meta study shows that the simple post-processing method to achieve error rate parity is Pareto-dominant."}, "abstract": {"value": "Seven years ago, researchers proposed a postprocessing method to equalize the error rates of a model across different demographic groups. The work launched hundreds of papers purporting to improve over the postprocessing baseline. We empirically evaluate these claims through thousands of model evaluations on several tabular datasets. We find that the fairness-accuracy Pareto frontier achieved by postprocessing contains all other methods we were feasibly able to evaluate. In doing so, we address two common methodological errors that have confounded previous observations. One relates to the comparison of methods with different unconstrained base models. The other concerns methods achieving different levels of constraint relaxation. At the heart of our study is a simple idea we call unprocessing that roughly corresponds to the inverse of postprocessing. Unprocessing allows for a direct comparison of methods using different underlying models and levels of relaxation."}, "primary_area": {"value": "societal considerations including fairness, safety, privacy"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 oral"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/cd3bf8642c6c69bd7fce176fc9e60e2ddc23c58e.pdf"}, "supplementary_material": {"value": "/attachment/395d0ac4ddf66d240d56a05ca7c0f3a185466b35.pdf"}, "_bibtex": {"value": "@inproceedings{\ncruz2024unprocessing,\ntitle={Unprocessing Seven Years of Algorithmic Fairness},\nauthor={Andr{\\'e} Cruz and Moritz Hardt},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=jr03SfWsBS}\n}"}, "paperhash": {"value": "cruz|unprocessing_seven_years_of_algorithmic_fairness"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission289/-/Revision", "ICLR.cc/2024/Conference/Submission289/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission289/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410790883, "version": 2, "details": {"replyCount": 18, "presentation": [{"name": "title", "order": 1}, {"name": "authors", "order": 3}, {"name": "code_of_ethics", "order": 3, "input": "checkbox", "value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "description": null}, {"name": "authorids", "order": 4}, {"name": "keywords", "order": 4}, {"name": "submission_guidelines", "order": 4, "input": "checkbox", "value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide.", "description": null}, {"name": "TLDR", "order": 5, "fieldName": "TL;DR"}, {"name": "abstract", "order": 6, "input": "textarea", "markdown": true}, {"name": "pdf", "order": 7}, {"name": "anonymous_url", "order": 7, "input": "checkbox", "value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "description": null}, {"name": "supplementary_material", "order": 8}, {"name": "no_acknowledgement_section", "order": 8, "input": "checkbox", "value": "I certify that there is no acknowledgement section in this submission for double blind review.", "description": null}, {"name": "primary_area", "order": 9, "input": "select", "value": "societal considerations including fairness, safety, privacy", "description": null}, {"name": "resubmission"}, {"name": "student_author"}, {"name": "large_language_models"}, {"name": "other_comments_on_LLMs"}, {"name": "venue", "hidden": true}, {"name": "venueid", "hidden": true}, {"name": "_bibtex", "input": "textarea"}, {"name": "other_comments"}]}}, {"id": "C61sk5LsK6", "forum": "C61sk5LsK6", "number": 247, "cdate": 1694782681300, "tcdate": 1694782681300, "mdate": 1710495120239, "tmdate": 1710495120239, "signatures": ["ICLR.cc/2024/Conference/Submission247/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission247/Authors"], "content": {"title": {"value": "InfoBatch: Lossless Training Speed Up by Unbiased Dynamic Data Pruning"}, "authors": {"value": ["Ziheng Qin", "Kai Wang", "Zangwei Zheng", "Jianyang Gu", "Xiangyu Peng", "xu Zhao Pan", "Daquan Zhou", "Lei Shang", "Baigui Sun", "Xuansong Xie", "Yang You"]}, "authorids": {"value": ["~Ziheng_Qin1", "~Kai_Wang8", "~Zangwei_Zheng1", "~Jianyang_Gu1", "~Xiangyu_Peng2", "~xu_Zhao_Pan1", "~Daquan_Zhou1", "~Lei_Shang1", "~Baigui_Sun1", "~Xuansong_Xie1", "~Yang_You1"]}, "keywords": {"value": ["Dynamic Data Pruning; Training acceleration"]}, "abstract": {"value": "Data pruning aims to obtain lossless performances with less overall cost. A common approach is to filter out samples that make less contribution to the training. This could lead to gradient expectation bias compared to the original data. To solve this problem, we propose InfoBatch, a novel framework aiming to achieve lossless training acceleration by unbiased dynamic data pruning. Specifically, InfoBatch\nrandomly prunes a portion of less informative samples based on the loss distribution and rescales the gradients of the remaining samples to approximate the original gradient. As a plug-and-play and architecture-agnostic framework, InfoBatch consistently obtains lossless training results on classification, semantic segmentation, vision pertaining, and instruction fine-tuning tasks. On CIFAR10/100, ImageNet-\n1K, and ADE20K, InfoBatch losslessly saves 40% overall cost. For pertaining MAE and diffusion model, InfoBatch can respectively save 24.8% and 27% cost. For LLaMA instruction fine-tuning, combining InfoBatch and the recent coreset selection method (DQ) can achieve 10 times acceleration. Our results encourage more exploration on the data efficiency aspect of large model training. Code is publicly available at NUS-HPC-AI-Lab/InfoBatch."}, "primary_area": {"value": "general machine learning (i.e., none of the above)"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 oral"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/9d5adb82a04bd07a7baace8a7f619a6d39a4d2a2.pdf"}, "supplementary_material": {"value": "/attachment/5e4cc27b7a5943ee13bcf8072cf75b21d07f018e.zip"}, "_bibtex": {"value": "@inproceedings{\nqin2024infobatch,\ntitle={InfoBatch: Lossless Training Speed Up by Unbiased Dynamic Data Pruning},\nauthor={Ziheng Qin and Kai Wang and Zangwei Zheng and Jianyang Gu and Xiangyu Peng and xu Zhao Pan and Daquan Zhou and Lei Shang and Baigui Sun and Xuansong Xie and Yang You},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=C61sk5LsK6}\n}"}, "paperhash": {"value": "qin|infobatch_lossless_training_speed_up_by_unbiased_dynamic_data_pruning"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission247/-/Revision", "ICLR.cc/2024/Conference/Submission247/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission247/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410789863, "version": 2, "details": {"replyCount": 30, "presentation": [{"name": "title", "order": 1}, {"name": "authors", "order": 3}, {"name": "code_of_ethics", "order": 3, "input": "checkbox", "value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "description": null}, {"name": "authorids", "order": 4}, {"name": "keywords", "order": 4}, {"name": "submission_guidelines", "order": 4, "input": "checkbox", "value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide.", "description": null}, {"name": "TLDR", "order": 5, "fieldName": "TL;DR"}, {"name": "abstract", "order": 6, "input": "textarea", "markdown": true}, {"name": "pdf", "order": 7}, {"name": "anonymous_url", "order": 7, "input": "checkbox", "value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "description": null}, {"name": "supplementary_material", "order": 8}, {"name": "no_acknowledgement_section", "order": 8, "input": "checkbox", "value": "I certify that there is no acknowledgement section in this submission for double blind review.", "description": null}, {"name": "primary_area", "order": 9, "input": "select", "value": "general machine learning (i.e., none of the above)", "description": null}, {"name": "resubmission"}, {"name": "student_author"}, {"name": "large_language_models"}, {"name": "other_comments_on_LLMs"}, {"name": "venue", "hidden": true}, {"name": "venueid", "hidden": true}, {"name": "_bibtex", "input": "textarea"}, {"name": "other_comments"}]}}, {"id": "9Cu8MRmhq2", "forum": "9Cu8MRmhq2", "number": 39, "cdate": 1694763719850, "tcdate": 1694763719850, "mdate": 1713672959881, "tmdate": 1713672959881, "signatures": ["ICLR.cc/2024/Conference/Submission39/Authors"], "readers": ["everyone"], "writers": ["ICLR.cc/2024/Conference", "ICLR.cc/2024/Conference/Submission39/Authors"], "content": {"title": {"value": "Multi-granularity Correspondence Learning from Long-term Noisy Videos"}, "authors": {"value": ["Yijie Lin", "Jie Zhang", "Zhenyu Huang", "Jia Liu", "zujie wen", "Xi Peng"]}, "authorids": {"value": ["~Yijie_Lin1", "~Jie_Zhang42", "~Zhenyu_Huang1", "~Jia_Liu4", "~zujie_wen1", "~Xi_Peng3"]}, "keywords": {"value": ["Video-language pre-training", "Noisy correspondence"]}, "abstract": {"value": "Existing video-language studies mainly focus on learning short video clips, leaving long-term temporal dependencies rarely explored due to over-high computational cost of modeling long videos. To address this issue, one feasible solution is learning the correspondence between video clips and captions, which however inevitably encounters the multi-granularity noisy correspondence (MNC) problem. To be specific, MNC refers to the clip-caption misalignment (coarse-grained) and frame-word misalignment (fine-grained), hindering temporal learning and video understanding. In this paper, we propose NOise Robust Temporal Optimal traNsport (Norton) that addresses MNC in a unified optimal transport (OT) framework. In brief, Norton employs video-paragraph and clip-caption contrastive losses to capture long-term dependencies based on OT. To address coarse-grained misalignment in video-paragraph contrast, Norton filters out the irrelevant clips and captions through an alignable prompt bucket and realigns asynchronous clip-caption pairs based on transport distance. To address the fine-grained misalignment, Norton incorporates a soft-maximum operator to identify crucial words and key frames. Additionally, Norton exploits the potential faulty negative samples in clip-caption contrast by rectifying the alignment target with OT assignment to ensure precise temporal modeling. Extensive experiments on video retrieval, videoQA, and action segmentation verify the effectiveness of our method. \nCode is available at https://lin-yijie.github.io/projects/Norton."}, "primary_area": {"value": "representation learning for computer vision, audio, language, and other modalities"}, "code_of_ethics": {"value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics."}, "submission_guidelines": {"value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide."}, "anonymous_url": {"value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity."}, "no_acknowledgement_section": {"value": "I certify that there is no acknowledgement section in this submission for double blind review."}, "venue": {"value": "ICLR 2024 oral"}, "venueid": {"value": "ICLR.cc/2024/Conference"}, "pdf": {"value": "/pdf/578b0930059c165430921bc67cd65b6a0657e518.pdf"}, "_bibtex": {"value": "@inproceedings{\nlin2024multigranularity,\ntitle={Multi-granularity Correspondence Learning from Long-term Noisy Videos},\nauthor={Yijie Lin and Jie Zhang and Zhenyu Huang and Jia Liu and zujie wen and Xi Peng},\nbooktitle={The Twelfth International Conference on Learning Representations},\nyear={2024},\nurl={https://openreview.net/forum?id=9Cu8MRmhq2}\n}"}, "paperhash": {"value": "lin|multigranularity_correspondence_learning_from_longterm_noisy_videos"}}, "odate": 1697213872796, "invitations": ["ICLR.cc/2024/Conference/-/Submission", "ICLR.cc/2024/Conference/-/Post_Submission", "ICLR.cc/2024/Conference/Submission39/-/Revision", "ICLR.cc/2024/Conference/Submission39/-/Rebuttal_Revision", "ICLR.cc/2024/Conference/-/Edit", "ICLR.cc/2024/Conference/Submission39/-/Camera_Ready_Revision"], "domain": "ICLR.cc/2024/Conference", "pdate": 1705410785085, "version": 2, "details": {"replyCount": 16, "presentation": [{"name": "title", "order": 1}, {"name": "authors", "order": 3}, {"name": "code_of_ethics", "order": 3, "input": "checkbox", "value": "I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.", "description": null}, {"name": "authorids", "order": 4}, {"name": "keywords", "order": 4}, {"name": "submission_guidelines", "order": 4, "input": "checkbox", "value": "I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide.", "description": null}, {"name": "TLDR", "order": 5, "fieldName": "TL;DR"}, {"name": "abstract", "order": 6, "input": "textarea", "markdown": true}, {"name": "pdf", "order": 7}, {"name": "anonymous_url", "order": 7, "input": "checkbox", "value": "I certify that there is no URL (e.g., github page) that could be used to find authors' identity.", "description": null}, {"name": "supplementary_material", "order": 8}, {"name": "no_acknowledgement_section", "order": 8, "input": "checkbox", "value": "I certify that there is no acknowledgement section in this submission for double blind review.", "description": null}, {"name": "primary_area", "order": 9, "input": "select", "value": "representation learning for computer vision, audio, language, and other modalities", "description": null}, {"name": "resubmission"}, {"name": "student_author"}, {"name": "large_language_models"}, {"name": "other_comments_on_LLMs"}, {"name": "venue", "hidden": true}, {"name": "venueid", "hidden": true}, {"name": "_bibtex", "input": "textarea"}, {"name": "other_comments"}]}}], "count": 86}