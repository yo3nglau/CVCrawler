{"notes": [{"id": "79zWncwO2p", "original": "QXT60aPDXOZx", "number": 3465, "cdate": 1621630306536, "mdate": null, "ddate": null, "tcdate": 1623678899491, "tmdate": 1683307771480, "tddate": null, "forum": "79zWncwO2p", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Collaborating with Humans without Human Data", "authorids": ["~DJ_Strouse1", "~Kevin_R._McKee1", "~Matthew_Botvinick1", "~Edward_Hughes1", "~Richard_Everett1"], "authors": ["DJ Strouse", "Kevin R. McKee", "Matthew Botvinick", "Edward Hughes", "Richard Everett"], "keywords": ["multi-agent", "zero-shot coordination", "collaboration", "cooperation", "common-payoff", "human-ai interaction", "reinforcement learning", "deep reinforcement learning"], "abstract": "Collaborating with humans requires rapidly adapting to their individual strengths, weaknesses, and preferences. Unfortunately, most standard multi-agent reinforcement learning techniques, such as self-play (SP) or population play (PP), produce agents that overfit to their training partners and do not generalize well to humans. Alternatively, researchers can collect human data, train a human model using behavioral cloning, and then use that model to train \"human-aware\" agents (\"behavioral cloning play\", or BCP). While such an approach can improve the generalization of agents to new human co-players, it involves the onerous and expensive step of collecting large amounts of human data first. Here, we study the problem of how to train agents that collaborate well with human partners without using human data. We argue that the crux of the problem is to produce a diverse set of training partners. Drawing inspiration from successful multi-agent approaches in competitive domains, we find that a surprisingly simple approach is highly effective. We train our agent partner as the best response to a population of self-play agents and their past checkpoints taken throughout training, a method we call Fictitious Co-Play (FCP). Our experiments focus on a two-player collaborative cooking simulator that has recently been proposed as a challenge problem for coordination with humans. We find that FCP agents score significantly higher than SP, PP, and BCP when paired with novel agent and human partners. Furthermore, humans also report a strong subjective preference to partnering with FCP agents over all baselines.", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "strouse|collaborating_with_humans_without_human_data", "TL;DR": "We train state-of-the-art agents for zero-shot coordination with humans without using human data in the training pipeline.", "pdf": "/pdf/7499f6f42069792cb6d87c1afa6c7aab422765c2.pdf", "checklist": "", "supplementary_material": "/attachment/185ae4cc8fe0cb6c015d750a68549de0ad422cb2.pdf", "thumbnail": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nstrouse2021collaborating,\ntitle={Collaborating with Humans without Human Data},\nauthor={DJ Strouse and Kevin R. McKee and Matthew Botvinick and Edward Hughes and Richard Everett},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=79zWncwO2p}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "pdate": 1636492728069, "odate": 1636492728025, "details": {"replyCount": 11}}, {"id": "27qon5Ut4PSl", "original": "BVlUEchMCXf", "number": 9562, "cdate": 1621630277668, "mdate": null, "ddate": null, "tcdate": 1623678863970, "tmdate": 1683307761616, "tddate": null, "forum": "27qon5Ut4PSl", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Sliced Mutual Information: A Scalable Measure of Statistical Dependence", "authorids": ["~Ziv_Goldfeld1", "~Kristjan_Greenewald1"], "authors": ["Ziv Goldfeld", "Kristjan Greenewald"], "keywords": ["mutual information", "sliced mutual information", "curse of dimensionality", "feature extraction", "independence tests"], "abstract": " Mutual information (MI) is a fundamental measure of statistical dependence, with a myriad of applications to information theory, statistics, and machine learning. While it possesses many desirable structural properties, the estimation of high-dimensional MI from samples suffers from the curse of dimensionality. Motivated by statistical scalability to high dimensions, this paper proposes sliced MI (SMI) as a surrogate measure of dependence. SMI is defined as an average of MI terms between one-dimensional random projections. We show that it preserves many of the structural properties of classic MI, while gaining scalable computation and efficient estimation from samples. Furthermore, and in contrast to classic MI, SMI can grow as a result of deterministic transformations. This enables leveraging SMI for feature extraction by optimizing it over processing functions of raw data to identify useful representations thereof. Our theory is supported by numerical studies of independence testing and feature extraction, which demonstrate the potential gains SMI offers over classic MI for high-dimensional inference.", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "goldfeld|sliced_mutual_information_a_scalable_measure_of_statistical_dependence", "pdf": "/pdf/1b9b6ef0da1009871d71f6bb347c7d3ce884aa58.pdf", "checklist": "", "supplementary_material": "/attachment/84d03c77af23826a3aa6e1e017649f4e63e99030.pdf", "thumbnail": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\ngoldfeld2021sliced,\ntitle={Sliced Mutual Information: A Scalable Measure of Statistical Dependence},\nauthor={Ziv Goldfeld and Kristjan Greenewald},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=27qon5Ut4PSl}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "pdate": 1636492779399, "odate": 1636492779359, "details": {"replyCount": 11}}, {"id": "LzwfcoEiB5O", "original": "q3YoATwF_3z", "number": 11602, "cdate": 1621630274802, "mdate": null, "ddate": null, "tcdate": 1623678860482, "tmdate": 1683307760599, "tddate": null, "forum": "LzwfcoEiB5O", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Forster Decomposition and Learning Halfspaces with Noise", "authorids": ["~Ilias_Diakonikolas1", "~Daniel_Kane1", "~Christos_Tzamos1"], "authors": ["Ilias Diakonikolas", "Daniel Kane", "Christos Tzamos"], "keywords": ["learning theory", "Forster transform", "halfspaces", "Massart noise"], "abstract": "A Forster transform is an operation that turns a multivariate distribution into one with good anti-concentration properties. While a Forster transform does not always exist, we show that any distribution can be efficiently decomposed as a disjoint mixture of few distributions for which a Forster transform exists and can be computed efficiently. As the main application of this result, we obtain the first polynomial-time algorithm for distribution-independent PAC learning of halfspaces in the Massart noise model with strongly polynomial sample complexity, i.e., independent of the bit complexity of the examples. Previous algorithms for this learning problem incurred sample complexity scaling polynomially with the bit complexity, even though such a dependence is not information-theoretically necessary.\n", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "diakonikolas|forster_decomposition_and_learning_halfspaces_with_noise", "TL;DR": "First efficient learning algorithm for Massart halfspaces with sample complexity independent of the bit complexity of the examples.", "pdf": "/pdf/afeeb9f3448feeadd0b373af7e2014eb8c8fb3ec.pdf", "checklist": "", "supplementary_material": "/attachment/6ad7018b0d90a657a23df430b906e0d186fc03d0.pdf", "thumbnail": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\ndiakonikolas2021forster,\ntitle={Forster Decomposition and Learning Halfspaces with Noise},\nauthor={Ilias Diakonikolas and Daniel Kane and Christos Tzamos},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=LzwfcoEiB5O}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "pdate": 1636492720297, "odate": 1636492720252, "details": {"replyCount": 12}}, {"id": "jNq-i1zd0t9", "original": "gdDcNnmeB8D", "number": 9536, "cdate": 1621630265705, "mdate": null, "ddate": null, "tcdate": 1623678847000, "tmdate": 1697937359026, "tddate": null, "forum": "jNq-i1zd0t9", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Generalized Depthwise-Separable Convolutions for Adversarially Robust and Efficient Neural Networks", "authorids": ["~Hassan_Dbouk1", "~Naresh_Shanbhag1"], "authors": ["Hassan Dbouk", "Naresh Shanbhag"], "keywords": ["adversarial robustness", "efficient inference", "generalized depthwise-seprarable", "convolutions", "neural networks"], "abstract": "Despite their tremendous successes, convolutional neural networks (CNNs) incur high computational/storage costs and are vulnerable to adversarial perturbations. Recent works on robust model compression address these challenges by combining model compression techniques with adversarial training. But these methods are unable to improve throughput (frames-per-second) on real-life hardware while simultaneously preserving robustness to adversarial perturbations. To overcome this problem, we propose the method of Generalized Depthwise-Separable (GDWS) convolution - an efficient, universal, post-training approximation of a standard 2D convolution. GDWS dramatically improves the throughput of a standard pre-trained network on real-life hardware while preserving its robustness. Lastly, GDWS is scalable to large problem sizes since it operates on pre-trained models and doesn't require any additional training. We establish the optimality of GDWS as a 2D convolution approximator and present exact algorithms for constructing optimal GDWS convolutions under complexity and error constraints. We demonstrate the effectiveness of GDWS via extensive experiments on CIFAR-10, SVHN, and ImageNet datasets. Our code can be found at https://github.com/hsndbk4/GDWS.", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "dbouk|generalized_depthwiseseparable_convolutions_for_adversarially_robust_and_efficient_neural_networks", "TL;DR": "We propose Generalized Depthwise-Separable convolutions as an efficient approximation of standard 2D convolutions that dramatically improve the throughput of an arbitrary pre-trained network on real-life hardware while preserving its robustness.", "pdf": "/pdf/d534bfc36a98b994d548d563a345b11771e29d46.pdf", "checklist": "", "supplementary_material": "/attachment/85f542db885d3c3305ebc6a68afee07cc5fd83aa.pdf", "code": "https://github.com/hsndbk4/GDWS", "thumbnail": "", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2110.14871/code)", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\ndbouk2021generalized,\ntitle={Generalized Depthwise-Separable Convolutions for Adversarially Robust and Efficient Neural Networks},\nauthor={Hassan Dbouk and Naresh Shanbhag},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=jNq-i1zd0t9}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "pdate": 1636492709198, "odate": 1636492709155, "details": {"replyCount": 7}}, {"id": "neRSyESg1GU", "original": "zvAsdtVukCEa", "number": 11543, "cdate": 1621630254072, "mdate": null, "ddate": null, "tcdate": 1623678819609, "tmdate": 1683307752987, "tddate": null, "forum": "neRSyESg1GU", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Statistical Query Lower Bounds for List-Decodable Linear Regression", "authorids": ["~Ilias_Diakonikolas1", "~Daniel_Kane1", "~Ankit_Pensia1", "~Thanasis_Pittas1", "~Alistair_Stewart1"], "authors": ["Ilias Diakonikolas", "Daniel Kane", "Ankit Pensia", "Thanasis Pittas", "Alistair Stewart"], "keywords": ["learning theory", "high-dimensional robust statistics", "statistical query model", "list-decodable learning", "linear regression"], "abstract": "We study the problem of list-decodable linear regression, where an adversary can corrupt a majority of the examples. Specifically, we are given a set $T$ of labeled examples $(x, y) \\in \\mathbb{R}^d \\times \\mathbb{R}$ and a parameter $0< \\alpha <1/2$ such that an $\\alpha$-fraction of the points in $T$ are i.i.d. samples from a linear regression model with Gaussian covariates, and the remaining $(1-\\alpha)$-fraction of the points are drawn from an arbitrary noise distribution. The goal is to output a small list of hypothesis vectors such that at least one of them is close to the target regression vector. Our main result is a Statistical Query (SQ) lower bound of $d^{\\mathrm{poly}(1/\\alpha)}$ for this problem. Our SQ lower bound qualitatively matches the performance of previously developed algorithms, providing evidence that current upper bounds for this task are nearly best possible.\n", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "diakonikolas|statistical_query_lower_bounds_for_listdecodable_linear_regression", "TL;DR": "We prove a superpolynomial statistical query lower bound for the problem of learning the regression vector of a Gaussian linear model when outliers constitute the majority of the dataset.", "pdf": "/pdf/79b7fba0b8f6074f6b14ad0c9f08674c46af27fe.pdf", "checklist": "", "supplementary_material": "/attachment/124e66bb902037b5e727f4f5c2c5e37589ae9ac5.pdf", "thumbnail": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\ndiakonikolas2021statistical,\ntitle={Statistical Query Lower Bounds for List-Decodable Linear Regression},\nauthor={Ilias Diakonikolas and Daniel Kane and Ankit Pensia and Thanasis Pittas and Alistair Stewart},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=neRSyESg1GU}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "pdate": 1636492736054, "odate": 1636492736010, "details": {"replyCount": 13}}, {"id": "rMKTq-ca0qu", "original": "pi4viFBDLQX", "number": 3245, "cdate": 1621630206404, "mdate": null, "ddate": null, "tcdate": 1623678748157, "tmdate": 1683307734366, "tddate": null, "forum": "rMKTq-ca0qu", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Early-stopped neural networks are consistent", "authorids": ["~Ziwei_Ji1", "~Justin_D._Li1", "~Matus_Telgarsky1"], "authors": ["Ziwei Ji", "Justin D. Li", "Matus Telgarsky"], "keywords": ["Neural Networks", "Deep Networks", "calibration", "consistency", "nonseparable", "gradient descent"], "TL;DR": "For general classification problems, including those with noise, gradient descent with early stopping on shallow ReLU networks achieves the optimal risk amongst all measurable predictors", "abstract": "This work studies the behavior of shallow ReLU networks trained with the logistic loss via gradient descent on binary classification data where the underlying data distribution is general, and the (optimal) Bayes risk is not necessarily zero.  In this setting, it is shown that gradient descent with early stopping achieves population risk arbitrarily close to optimal in terms of not just logistic and misclassification losses, but also in terms of calibration, meaning the sigmoid mapping of its outputs approximates the true underlying conditional distribution arbitrarily finely.  Moreover, the necessary iteration, sample, and architectural complexities of this analysis all scale naturally with a certain complexity measure of the true conditional model.  Lastly, while it is not shown that early stopping is necessary, it is shown that any classifier satisfying a basic local interpolation property is inconsistent.\n", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "ji|earlystopped_neural_networks_are_consistent", "pdf": "/pdf/9ebc9157cf020d6f0d38ca51766d1fcb105f3e5b.pdf", "checklist": "", "supplementary_material": "/attachment/2b49e1455496bbcce30d42e8969b51232b0032c7.pdf", "thumbnail": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nji2021earlystopped,\ntitle={Early-stopped neural networks are consistent},\nauthor={Ziwei Ji and Justin D. Li and Matus Telgarsky},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=rMKTq-ca0qu}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "pdate": 1636492724921, "odate": 1636492724867, "details": {"replyCount": 13}}, {"id": "oumDUrf2dAB", "original": "3POocZmn79o", "number": 1121, "cdate": 1621630160609, "mdate": null, "ddate": null, "tcdate": 1623678684450, "tmdate": 1683307719445, "tddate": null, "forum": "oumDUrf2dAB", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "On the Value of Infinite Gradients in Variational Autoencoder Models", "authorids": ["~Bin_Dai1", "~Li_Kevin_Wenliang1", "~David_Wipf1"], "authors": ["Bin Dai", "Li Kevin Wenliang", "David Wipf"], "keywords": ["variational autoencoders", "sparse representations", "latent variable models"], "TL;DR": "We demonstrate that infinite gradients, although perhaps at times difficult to address in practical, can serve a useful role in pruning the latent space of autoencoder-based models.", "abstract": "A number of recent studies of continuous variational autoencoder (VAE) models have noted, either directly or indirectly, the tendency of various parameter gradients to drift towards infinity during training.  Because such gradients could potentially contribute to numerical instabilities, and are often framed as a problematic phenomena to be avoided, it may be tempting to shift to alternative energy functions that guarantee bounded gradients.  But it remains an open question: What might the unintended consequences of such a restriction be?  To address this issue, we examine how unbounded gradients relate to the regularization of a broad class of autoencoder-based architectures, including VAE models, as applied to data lying on or near a low-dimensional manifold (e.g., natural images).  Our main finding is that, if the ultimate goal is to simultaneously avoid over-regularization (high reconstruction errors, sometimes referred to as posterior collapse) and under-regularization (excessive latent dimensions are not pruned from the model), then an autoencoder-based energy function with infinite gradients around optimal representations is provably required per a certain technical sense which we carefully detail.  Given that both over- and under-regularization can directly lead to poor generated sample quality or suboptimal feature selection, this result suggests that heuristic modifications to or constraints on the VAE energy function may at times be ill-advised, and large gradients should be accommodated to the extent possible.", "submission_history": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "dai|on_the_value_of_infinite_gradients_in_variational_autoencoder_models", "pdf": "/pdf/6a387334ef970d6cfe3c743383352e40ca208c6b.pdf", "checklist": "", "supplementary_material": "/attachment/a817ccf0ba840c2bcd20040688b28ed1e7dd5f22.pdf", "thumbnail": "", "_bibtex": "@inproceedings{\ndai2021on,\ntitle={On the Value of Infinite Gradients in Variational Autoencoder Models},\nauthor={Bin Dai and Li Kevin Wenliang and David Wipf},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=oumDUrf2dAB}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "pdate": 1636492731901, "odate": 1636492731857, "details": {"replyCount": 12}}, {"id": "TZPidZS3r_z", "original": "x4pxVRd4Zt", "number": 9254, "cdate": 1621630133175, "mdate": null, "ddate": null, "tcdate": 1623678641116, "tmdate": 1683307709431, "tddate": null, "forum": "TZPidZS3r_z", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "On the Power of Differentiable Learning versus PAC and SQ Learning", "authorids": ["~Emmanuel_Abbe1", "~Pritish_Kamath2", "~eran_malach1", "~Colin_Sandon1", "~Nathan_Srebro1"], "authors": ["Emmanuel Abbe", "Pritish Kamath", "eran malach", "Colin Sandon", "Nathan Srebro"], "keywords": ["Differentiable Learning", "PAC Learning", "Statistical Query Learning", "mini-batch SGD"], "abstract": "We study the power of learning via mini-batch stochastic gradient descent (SGD) on the loss of a differentiable model or neural network, and ask what learning problems can be learnt using this paradigm. We show that SGD can always simulate\u00a0learning with statistical queries (SQ), but its ability to go beyond that depends on the precision $\\rho$ of the gradients and the minibatch size $b$. With fine enough precision relative to minibatch size, namely when $b \\rho$ is small enough, SGD can go beyond SQ learning and simulate any sample-based learning algorithm and thus its learning power is equivalent to that of PAC learning;\u00a0this extends prior work that achieved this result for $b=1$.\u00a0Moreover,\u00a0with polynomially many bits of precision (i.e. when $\\rho$ is exponentially small), SGD can simulate PAC learning regardless of the batch size. On the other hand, when $b \\rho^2$ is large enough, the power of SGD is equivalent to that of SQ learning.", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "abbe|on_the_power_of_differentiable_learning_versus_pac_and_sq_learning", "pdf": "/pdf/5d42fa810057548adfff4fe5ea3e6717ffd5d6a3.pdf", "supplementary_material": "/attachment/c10c65ab22310a97ca3ddc4ae79a77e0af41d2fd.pdf", "checklist": "", "TL;DR": "Identifies regimes of mini-batch size and gradient precision in gradient-based learning on differentiable models under which it becomes as powerful as sample based learning, or collapses to learning in the statistical query model.", "thumbnail": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nabbe2021on,\ntitle={On the Power of Differentiable Learning versus {PAC} and {SQ} Learning},\nauthor={Emmanuel Abbe and Pritish Kamath and eran malach and Colin Sandon and Nathan Srebro},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=TZPidZS3r_z}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "pdate": 1636492728453, "odate": 1636492728409, "details": {"replyCount": 5}}, {"id": "I2pS-Lg7Xl", "original": "VRntuV9mPpm", "number": 9221, "cdate": 1621630119095, "mdate": null, "ddate": null, "tcdate": 1623678614581, "tmdate": 1683307704335, "tddate": null, "forum": "I2pS-Lg7Xl", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Learning Disentangled Behavior Embeddings", "authorids": ["~Changhao_Shi1", "~Sivan_Schwartz1", "~Shahar_Levy1", "~Shay_Achvat1", "~Maisan_Abboud1", "~Amir_Ghanayim1", "~Jackie_Schiller1", "~Gal_Mishne1"], "authors": ["Changhao Shi", "Sivan Schwartz", "Shahar Levy", "Shay Achvat", "Maisan Abboud", "Amir Ghanayim", "Jackie Schiller", "Gal Mishne"], "keywords": ["Neuroscience", "Animal Behavior", "Behavioral Videos", "Generative Models"], "abstract": "To understand the relationship between behavior and neural activity, experiments in neuroscience often include an animal performing a repeated behavior such as a motor task. Recent progress in computer vision and deep learning has shown great potential in the automated analysis of behavior by leveraging large and high-quality video datasets. In this paper, we design Disentangled Behavior Embedding (DBE) to learn robust behavioral embeddings from unlabeled, multi-view, high-resolution behavioral videos across different animals and multiple sessions. We further combine DBE with a stochastic temporal model to propose Variational Disentangled Behavior Embedding (VDBE), an end-to-end approach that learns meaningful discrete behavior representations and generates interpretable behavioral videos. Our models learn consistent behavior representations by explicitly disentangling the dynamic behavioral factors (pose) from time-invariant, non-behavioral nuisance factors (context) in a deep autoencoder, and exploit the temporal structures of pose dynamics. Compared to competing approaches, DBE and VDBE enjoy superior performance on downstream tasks such as fine-grained behavioral motif generation and behavior decoding.", "pdf": "/pdf/e1e68e0afaed7486ffbd91ed1e878bcc0baa6167.pdf", "supplementary_material": "/attachment/54a492d0a2a54a0bf0217365c124e88333520eb8.zip", "submission_history": "", "checklist": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "shi|learning_disentangled_behavior_embeddings", "code": "https://github.com/Mishne-Lab/DBE-Disentangled-Behavior-Embedding", "thumbnail": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nshi2021learning,\ntitle={Learning Disentangled Behavior Embeddings},\nauthor={Changhao Shi and Sivan Schwartz and Shahar Levy and Shay Achvat and Maisan Abboud and Amir Ghanayim and Jackie Schiller and Gal Mishne},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=I2pS-Lg7Xl}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "pdate": 1636492749589, "odate": 1636492749548, "details": {"replyCount": 12}}, {"id": "sri2nuQC4Y", "original": "JdHcx-LB1e", "number": 7055, "cdate": 1621630080348, "mdate": null, "ddate": null, "tcdate": 1623678545951, "tmdate": 1697937473563, "tddate": null, "forum": "sri2nuQC4Y", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Learning Generalized Gumbel-max Causal Mechanisms", "authorids": ["~Guy_Lorberbom1", "~Daniel_D._Johnson1", "~Chris_J._Maddison1", "~Daniel_Tarlow1", "~Tamir_Hazan1"], "authors": ["Guy Lorberbom", "Daniel D. Johnson", "Chris J. Maddison", "Daniel Tarlow", "Tamir Hazan"], "keywords": ["Gumbel max", "reparameterization trick", "structural causal model"], "TL;DR": "Learn a causal mechanism that minimizes a quantitative criteria (such as variance) when used in a counterfactual context.", "abstract": "To perform counterfactual reasoning in Structural Causal Models (SCMs), one needs to know the causal mechanisms, which provide factorizations of conditional distributions into noise sources and deterministic functions mapping realizations of noise to samples. Unfortunately, the causal mechanism is not uniquely identified by data that can be gathered by observing and interacting with the world, so there remains the question of how to choose causal mechanisms. In recent work, Oberst & Sontag (2019) propose Gumbel-max SCMs, which use Gumbel-max reparameterizations as the causal mechanism due to an appealing  counterfactual stability property. However, the justification requires appealing to intuition. In this work, we instead argue for choosing a causal mechanism that is best under a quantitative criteria such as minimizing variance when estimating counterfactual treatment effects. We propose a parameterized family of causal mechanisms that generalize Gumbel-max. We show that they can be trained to minimize counterfactual effect variance and other losses on a distribution of queries of interest, yielding lower variance estimates of counterfactual treatment effect than fixed alternatives, also generalizing to queries not seen at training time.", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "lorberbom|learning_generalized_gumbelmax_causal_mechanisms", "pdf": "/pdf/ab8f78632111077a50132193913c15a64e4b00e8.pdf", "supplementary_material": "/attachment/0dfe920228dd5cbdedbb46b85dc68d9954d287fb.pdf", "checklist": "", "code": "https://github.com/google-research/google-research/tree/master/gumbel_max_causal_gadgets", "thumbnail": "", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2111.06888/code)", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nlorberbom2021learning,\ntitle={Learning Generalized Gumbel-max Causal Mechanisms},\nauthor={Guy Lorberbom and Daniel D. Johnson and Chris J. Maddison and Daniel Tarlow and Tamir Hazan},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=sri2nuQC4Y}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "pdate": 1636492719440, "odate": 1636492719390, "details": {"replyCount": 17}}, {"id": "w6iVxEdh6bi", "original": "MGwowvUg3SD", "number": 6741, "cdate": 1621629942646, "mdate": null, "ddate": null, "tcdate": 1623678317984, "tmdate": 1697937566991, "tddate": null, "forum": "w6iVxEdh6bi", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Offline RL Without Off-Policy Evaluation", "authorids": ["~David_Brandfonbrener1", "~William_F_Whitney1", "~Rajesh_Ranganath2", "~Joan_Bruna1"], "authors": ["David Brandfonbrener", "William F Whitney", "Rajesh Ranganath", "Joan Bruna"], "keywords": ["Offline reinforcement learning", "reinforcement learning"], "abstract": "Most prior approaches to offline reinforcement learning (RL) have taken an iterative actor-critic approach involving off-policy evaluation. In this paper we show that simply doing one step of constrained/regularized policy improvement using an on-policy Q estimate of the behavior policy performs surprisingly well. This one-step algorithm beats the previously reported results of iterative algorithms on a large portion of the D4RL benchmark. The one-step baseline achieves this strong performance while being notably simpler and more robust to hyperparameters than previously proposed iterative algorithms. We argue that the relatively poor performance of iterative approaches is a result of the high variance inherent in doing off-policy evaluation and magnified by the repeated optimization of policies against those estimates. In addition, we hypothesize that the strong performance of the one-step algorithm is due to a combination of favorable structure in the environment and behavior policy.", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "brandfonbrener|offline_rl_without_offpolicy_evaluation", "pdf": "/pdf/7431019b4f1abb7b086fde48b4f19e12449f7739.pdf", "checklist": "", "supplementary_material": "/attachment/cd88de24d8371ce51a0e43af296c0c16e4f707a1.pdf", "TL;DR": "Performing one step of policy iteration provides a strong baseline for offline RL.", "code": "https://github.com/davidbrandfonbrener/onestep-rl", "thumbnail": "", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2106.08909/code)", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nbrandfonbrener2021offline,\ntitle={Offline {RL} Without Off-Policy Evaluation},\nauthor={David Brandfonbrener and William F Whitney and Rajesh Ranganath and Joan Bruna},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=w6iVxEdh6bi}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "pdate": 1636492763712, "odate": 1636492763671, "details": {"replyCount": 12}}, {"id": "zcrC_XDUFd", "original": "mWqA_Y43PaO", "number": 10820, "cdate": 1621629935477, "mdate": null, "ddate": null, "tcdate": 1623678302968, "tmdate": 1697937571732, "tddate": null, "forum": "zcrC_XDUFd", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Learning with Holographic Reduced Representations", "authorids": ["~Ashwinkumar_Ganesan1", "~Hang_Gao3", "~Sunil_Gandhi1", "~Edward_Raff1", "~Tim_Oates2", "~James_Holt1", "mrmclea@lps.umd.edu"], "authors": ["Ashwinkumar Ganesan", "Hang Gao", "Sunil Gandhi", "Edward Raff", "Tim Oates", "James Holt", "Mark McLean"], "keywords": ["Holographic Reduced Representations", "binding", "neuro-symbolic"], "TL;DR": "An approach to do symbolic AI using vectors from the 90s has been long neglected by ML ressearches, but some careful updates make it applicable to modern use.", "abstract": "Holographic Reduced Representations (HRR) are a method for performing symbolic AI on top of real-valued vectors by associating each vector with an abstract concept, and providing mathematical operations to manipulate vectors as if they were classic symbolic objects. This method has seen little use outside of older symbolic AI work and cognitive science. Our goal is to revisit this approach to understand if it is viable for enabling a hybrid neural-symbolic  approach to learning as a differential component of a deep learning architecture. HRRs today are not effective in a differential solution due to numerical instability, a problem we solve by introducing a projection step that forces the vectors to exist in a well behaved point in space. In doing so we improve the concept retrieval efficacy of HRRs by over $100\\times$. Using multi-label classification we demonstrate how to leverage the symbolic HRR properties to develop a output layer and loss function that is able to learn effectively, and allows us to investigate some of the pros and cons of an HRR neuro-symbolic learning approach. ", "submission_history": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "ganesan|learning_with_holographic_reduced_representations", "pdf": "/pdf/0ce1c221b0cf3953a1e3f354bd01944ac9441cb6.pdf", "supplementary_material": "/attachment/d23cc8c27770dab0d8936b58fcce0d4200a51f2b.pdf", "checklist": "", "code": "https://github.com/NeuromorphicComputationResearchProgram/Learning-with-Holographic-Reduced-Representations", "thumbnail": "", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2109.02157/code)", "_bibtex": "@inproceedings{\nganesan2021learning,\ntitle={Learning with Holographic Reduced Representations},\nauthor={Ashwinkumar Ganesan and Hang Gao and Sunil Gandhi and Edward Raff and Tim Oates and James Holt and Mark McLean},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=zcrC_XDUFd}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "pdate": 1636492719573, "odate": 1636492719530, "details": {"replyCount": 13}}, {"id": "9PBxTCg0F6m", "original": "BF8Hh_EKfa6", "number": 8685, "cdate": 1621629891677, "mdate": null, "ddate": null, "tcdate": 1623678227897, "tmdate": 1683307606521, "tddate": null, "forum": "9PBxTCg0F6m", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Variational Inference for Continuous-Time Switching Dynamical Systems", "authorids": ["~Lukas_K\u00f6hs1", "~Bastian_Alt1", "~Heinz_Koeppl1"], "authors": ["Lukas K\u00f6hs", "Bastian Alt", "Heinz Koeppl"], "keywords": ["variational inference", "hybrid processes", "stochastic processes", "continuous time", "stochastic differential equations", "Markov jump processes"], "abstract": "Switching dynamical systems provide a powerful, interpretable modeling framework for inference in time-series data in, e.g., the natural sciences or engineering applications. Since many areas, such as biology or discrete-event systems, are naturally described in continuous time, we present a model based on a Markov jump process modulating a subordinated diffusion process. We provide the exact evolution equations for the prior and posterior marginal densities, the direct solutions of which are however computationally intractable. Therefore, we develop a new continuous-time variational inference algorithm, combining a Gaussian process approximation on the diffusion level with posterior inference for Markov jump processes. By minimizing the path-wise Kullback-Leibler divergence we obtain (i) Bayesian latent state estimates for arbitrary points on the real axis and (ii) point estimates of unknown system parameters, utilizing variational expectation maximization. We extensively evaluate our algorithm under the model assumption and for real-world examples.", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "k\u00f6hs|variational_inference_for_continuoustime_switching_dynamical_systems", "pdf": "/pdf/c4224d7d543d85e63ba4228630d6d46a4fa350ec.pdf", "checklist": "", "supplementary_material": "/attachment/fb07ea37b64a4715ddd667fb5f178bcebd8293bc.pdf", "thumbnail": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nk{\\\"o}hs2021variational,\ntitle={Variational Inference for Continuous-Time Switching Dynamical Systems},\nauthor={Lukas K{\\\"o}hs and Bastian Alt and Heinz Koeppl},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=9PBxTCg0F6m}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "pdate": 1636492769974, "odate": 1636492769931, "details": {"replyCount": 13}}, {"id": "5ga5mfbGsRM", "original": "pKHjch3rN4P", "number": 482, "cdate": 1621629888393, "mdate": null, "ddate": null, "tcdate": 1623678222045, "tmdate": 1683307604855, "tddate": null, "forum": "5ga5mfbGsRM", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Clustering Effect of Adversarial Robust Models", "authorids": ["~Yang_Bai1", "~Xin_Yan2", "~Yong_Jiang3", "~Shu-Tao_Xia1", "~Yisen_Wang1"], "authors": ["Yang Bai", "Xin Yan", "Yong Jiang", "Shu-Tao Xia", "Yisen Wang"], "keywords": ["Adversarial robust models", "hierarchical clustering effect", "domain adaption tasks"], "abstract": "Adversarial robustness has received increasing attention along with the study of adversarial examples. So far, existing works show that robust models not only obtain robustness against various adversarial attacks but also boost the performance in some downstream tasks. However, the underlying mechanism of adversarial robustness is still not clear. In this paper, we interpret adversarial robustness from the perspective of linear components, and find that there exist some statistical properties for comprehensively robust models. Specifically, robust models show obvious hierarchical clustering effect on their linearized sub-networks, when removing or replacing all non-linear components (e.g., batch normalization, maximum pooling, or activation layers). Based on these observations, we propose a novel understanding of adversarial robustness and apply it on more tasks including domain adaption and robustness boosting. Experimental evaluations demonstrate the rationality and superiority of our proposed clustering strategy. Our code is available at https://github.com/bymavis/Adv_Weight_NeurIPS2021.", "submission_history": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "checklist": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "bai|clustering_effect_of_adversarial_robust_models", "pdf": "/pdf/a2ca93698d4980274afcb77eb99177cd419d965a.pdf", "supplementary_material": "/attachment/5c5aef608050666af9fd339b58cf99054e38b71a.pdf", "TL;DR": "Clustering Effect of (Linearized) Adversarial Robust Models", "code": "https://github.com/bymavis/Adv_Weight_NeurIPS2021", "thumbnail": "", "_bibtex": "@inproceedings{\nbai2021clustering,\ntitle={Clustering Effect of Adversarial Robust Models},\nauthor={Yang Bai and Xin Yan and Yong Jiang and Shu-Tao Xia and Yisen Wang},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=5ga5mfbGsRM}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "pdate": 1636492736355, "odate": 1636492736312, "details": {"replyCount": 12}}, {"id": "yNzF41lHYV", "original": "kzVVB5s1_J", "number": 444, "cdate": 1621629872647, "mdate": null, "ddate": null, "tcdate": 1623678190540, "tmdate": 1683307598195, "tddate": null, "forum": "yNzF41lHYV", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Believe What You See: Implicit Constraint Approach for Offline Multi-Agent Reinforcement Learning", "authorids": ["~Yiqin_Yang1", "~Xiaoteng_Ma1", "~Chenghao_Li1", "~Zewu_Zheng2", "~Qiyuan_Zhang1", "~Gao_Huang1", "~Jun_Yang6", "~Qianchuan_Zhao1"], "authors": ["Yiqin Yang", "Xiaoteng Ma", "Chenghao Li", "Zewu Zheng", "Qiyuan Zhang", "Gao Huang", "Jun Yang", "Qianchuan Zhao"], "keywords": ["Extrapolation Error", "Offline Reinforcement Learning", "Multi-Agent Reinforcement Learning"], "TL;DR": "The first study analyzing and addressing the extrapolation error in multi-agent reinforcement learning.", "abstract": "Learning from datasets without interaction with environments (Offline Learning) is an essential step to apply Reinforcement Learning (RL) algorithms in real-world scenarios.\tHowever, compared with the single-agent counterpart, offline multi-agent RL introduces more agents with the larger state and action space, which is more challenging but attracts little attention. We demonstrate current offline RL algorithms are ineffective in multi-agent systems due to the accumulated extrapolation error. In this paper, we propose a novel offline RL algorithm, named Implicit Constraint Q-learning (ICQ), which effectively alleviates the extrapolation error by only trusting the state-action pairs given in the dataset for value estimation.  Moreover, we extend ICQ to multi-agent tasks by decomposing the joint-policy under the implicit constraint.  Experimental results demonstrate that the extrapolation error is successfully controlled within a reasonable range and insensitive to the number of agents. We further show that ICQ achieves the state-of-the-art performance in the challenging multi-agent offline tasks (StarCraft II). Our code is public online at https://github.com/YiqinYang/ICQ.", "submission_history": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "yang|believe_what_you_see_implicit_constraint_approach_for_offline_multiagent_reinforcement_learning", "pdf": "/pdf/1abfb071e9c1450e756c38da0ae48674fd96fc07.pdf", "checklist": "", "supplementary_material": "/attachment/175cd46b1adf549a36e2aa1cdc3daeebbd5a0394.zip", "thumbnail": "", "_bibtex": "@inproceedings{\nyang2021believe,\ntitle={Believe What You See: Implicit Constraint Approach for Offline Multi-Agent Reinforcement Learning},\nauthor={Yiqin Yang and Xiaoteng Ma and Chenghao Li and Zewu Zheng and Qiyuan Zhang and Gao Huang and Jun Yang and Qianchuan Zhao},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=yNzF41lHYV}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "pdate": 1636492684441, "odate": 1636492684394, "details": {"replyCount": 28}}, {"id": "ehzq1YQrucI", "original": "NCLMn-3jx3M", "number": 365, "cdate": 1621629845937, "mdate": null, "ddate": null, "tcdate": 1623678134359, "tmdate": 1683307585691, "tddate": null, "forum": "ehzq1YQrucI", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "An Infinite-Feature Extension for Bayesian ReLU Nets That Fixes Their Asymptotic Overconfidence", "authorids": ["~Agustinus_Kristiadi1", "~Matthias_Hein2", "~Philipp_Hennig1"], "authors": ["Agustinus Kristiadi", "Matthias Hein", "Philipp Hennig"], "keywords": ["bayesian deep learning", "uncertainty quantification", "overconfidence", "gaussian processes"], "abstract": "A Bayesian treatment can mitigate overconfidence in ReLU nets around the training data. But far away from them, ReLU Bayesian neural networks (BNNs) can still underestimate uncertainty and thus be asymptotically overconfident. This issue arises since the output variance of a BNN with finitely many features is quadratic in the distance from the data region. Meanwhile, Bayesian linear models with ReLU features converge, in the infinite-width limit, to a particular Gaussian process (GP) with a variance that grows cubically so that no asymptotic overconfidence can occur. While this may seem of mostly theoretical interest, in this work, we show that it can be used in practice to the benefit of BNNs. We extend finite ReLU BNNs with infinite ReLU features via the GP and show that the resulting model is asymptotically maximally uncertain far away from the data while the BNNs' predictive power is unaffected near the data. Although the resulting model approximates a full GP posterior, thanks to its structure, it can be applied post-hoc to any pre-trained ReLU BNN at a low cost.", "submission_history": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "kristiadi|an_infinitefeature_extension_for_bayesian_relu_nets_that_fixes_their_asymptotic_overconfidence", "TL;DR": "We propose a post-hoc extension, constructed by considering infinitely many ReLU features, for standard ReLU BNNs. This extension effectively fixes ReLU BNNs' overconfidence far away from the training data.", "pdf": "/pdf/59c37faebe54cf2a53b3b465fe8549636d76489c.pdf", "checklist": "", "supplementary_material": "/attachment/4396959396bd2d5f42d3133fe7e4a12c02da9577.pdf", "code": "https://github.com/wiseodd/rgpr", "thumbnail": "", "_bibtex": "@inproceedings{\nkristiadi2021an,\ntitle={An Infinite-Feature Extension for Bayesian Re{LU} Nets That Fixes Their Asymptotic Overconfidence},\nauthor={Agustinus Kristiadi and Matthias Hein and Philipp Hennig},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=ehzq1YQrucI}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "pdate": 1636492740969, "odate": 1636492740919, "details": {"replyCount": 16}}, {"id": "QwNLVId9Df", "original": "Lo3jgP0sP46", "number": 2364, "cdate": 1621629821922, "mdate": null, "ddate": null, "tcdate": 1623678096904, "tmdate": 1683307577094, "tddate": null, "forum": "QwNLVId9Df", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Program Synthesis Guided Reinforcement Learning for Partially Observed Environments", "authorids": ["~Yichen_Yang1", "~Jeevana_Priya_Inala1", "~Osbert_Bastani1", "~Yewen_Pu1", "~Armando_Solar-Lezama1", "~Martin_Rinard1"], "authors": ["Yichen Yang", "Jeevana Priya Inala", "Osbert Bastani", "Yewen Pu", "Armando Solar-Lezama", "Martin Rinard"], "keywords": ["program synthesis", "reinforcement learning", "partial observation"], "abstract": "A key challenge for reinforcement learning is solving long-horizon planning problems. Recent work has leveraged programs to guide reinforcement learning in these settings. However, these approaches impose a high manual burden on the user since they must provide a guiding program for every new task. Partially observed environments further complicate the programming task because the program must implement a strategy that correctly, and ideally optimally, handles every possible configuration of the hidden regions of the environment. We propose a new approach, model predictive program synthesis (MPPS), that uses program synthesis to automatically generate the guiding programs. It trains a generative model to predict the unobserved portions of the world, and then synthesizes a program based on samples from this model in a way that is robust to its uncertainty. In our experiments, we show that our approach significantly outperforms non-program-guided approaches on a set of challenging benchmarks, including a 2D Minecraft-inspired environment where the agent must complete a complex sequence of subtasks to achieve its goal, and achieves a similar performance as using handcrafted programs to guide the agent. Our results demonstrate that our approach can obtain the benefits of program-guided reinforcement learning without requiring the user to provide a new guiding program for every new task.", "submission_history": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "yang|program_synthesis_guided_reinforcement_learning_for_partially_observed_environments", "pdf": "/pdf/ceb607c2bb76cb6de648533b9c54cf91a3baa6eb.pdf", "supplementary_material": "/attachment/c76c2a71fb04026bc8e4814404d299ccb9aeba6b.pdf", "checklist": "", "code": "https://github.com/yycdavid/program-synthesis-guided-RL", "thumbnail": "", "_bibtex": "@inproceedings{\nyang2021program,\ntitle={Program Synthesis Guided Reinforcement Learning for Partially Observed Environments},\nauthor={Yichen Yang and Jeevana Priya Inala and Osbert Bastani and Yewen Pu and Armando Solar-Lezama and Martin Rinard},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=QwNLVId9Df}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "pdate": 1636492705775, "odate": 1636492705732, "details": {"replyCount": 23}}, {"id": "pbfAgoc_l2w", "original": "v9NdayjHfHa", "number": 10234, "cdate": 1621629811273, "mdate": null, "ddate": null, "tcdate": 1623678079354, "tmdate": 1697937664814, "tddate": null, "forum": "pbfAgoc_l2w", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Sequence-to-Sequence Learning with Latent Neural Grammars", "authorids": ["~Yoon_Kim1"], "authors": ["Yoon Kim"], "keywords": ["sequence-to-sequence learning", "compositional generalization", "synchronous grammars"], "abstract": "Sequence-to-sequence learning with neural networks has become the de facto standard for sequence modeling. This approach typically models the local distribution over the next element with a powerful neural network that can condition on arbitrary context. While flexible and performant, these models often require large datasets for training and can fail spectacularly on benchmarks designed to test for compositional generalization. This work explores an alternative, hierarchical approach to sequence-to-sequence learning with synchronous grammars, where each node in the target tree is transduced by a subset of nodes in the source tree. The source and target trees are treated as fully latent and marginalized out during training. We develop a neural parameterization of the grammar which enables parameter sharing over combinatorial structures without the need for manual feature engineering. We apply this latent neural grammar to various domains---a diagnostic language navigation task designed to test for compositional generalization (SCAN), style transfer, and small-scale machine translation---and find that it performs respectably compared to standard baselines.", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "kim|sequencetosequence_learning_with_latent_neural_grammars", "pdf": "/pdf/b3dc1d866e1ca0a79b93f0b7f76c61cc8eabba4f.pdf", "supplementary_material": "/attachment/571c3340c4790e8888ddd593163bb71da2c79dbf.pdf", "checklist": "", "code": "https://github.com/yoonkim/neural-qcfg", "thumbnail": "", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 3 code implementations](https://www.catalyzex.com/paper/arxiv:2109.01135/code)", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nkim2021sequencetosequence,\ntitle={Sequence-to-Sequence Learning with Latent Neural Grammars},\nauthor={Yoon Kim},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=pbfAgoc_l2w}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "pdate": 1636492682494, "odate": 1636492682448, "details": {"replyCount": 12}}, {"id": "7_M2f2DEIEK", "original": "84_3H6S-r3L", "number": 267, "cdate": 1621629802491, "mdate": null, "ddate": null, "tcdate": 1623678066931, "tmdate": 1683307567788, "tddate": null, "forum": "7_M2f2DEIEK", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Beyond Tikhonov: faster learning with self-concordant losses, via iterative regularization", "authorids": ["~Gaspard_Beugnot1", "~Julien_Mairal1", "~Alessandro_Rudi1"], "authors": ["Gaspard Beugnot", "Julien Mairal", "Alessandro Rudi"], "keywords": ["Kernel methods", "learning theory", "self concordance", "iterated tikhonov", "proximal point"], "TL;DR": "The iterative Thikonov regularization scheme achieves optimal sample complexity on self concordant losses. ", "abstract": "The theory of spectral filtering is a remarkable tool to understand the statistical properties of learning with kernels. For least squares, it allows to derive various regularization schemes that yield faster convergence rates of the excess risk than with Tikhonov regularization. This is typically achieved by leveraging classical assumptions called source and capacity conditions, which characterize the difficulty of the learning task. In order to understand estimators derived from other loss functions, Marteau-Ferey et al. have extended the theory of Tikhonov regularization to generalized self concordant loss functions (GSC), which contain, e.g., the logistic loss. In this paper, we go a step further and show that fast and optimal rates can be achieved for GSC by using the iterated Tikhonov regularization scheme, which is intrinsically related to the proximal point method in optimization, and overcomes the limitation of the classical Tikhonov regularization.", "submission_history": "", "checklist": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "beugnot|beyond_tikhonov_faster_learning_with_selfconcordant_losses_via_iterative_regularization", "pdf": "/pdf/f5a1917aebd2bfa6d9a100a36ba84eeb512f7205.pdf", "supplementary_material": "/attachment/d83be0a7f6119ffb0e72261ef03921807a51a5f1.pdf", "code": "/attachment/b1e5281a0f8e8c7ecb9ad40d3cb25936f672b4ef.zip", "thumbnail": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nbeugnot2021beyond,\ntitle={Beyond Tikhonov: faster learning with self-concordant losses, via iterative regularization},\nauthor={Gaspard Beugnot and Julien Mairal and Alessandro Rudi},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=7_M2f2DEIEK}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "pdate": 1636492765519, "odate": 1636492765478, "details": {"replyCount": 10}}, {"id": "r6cNUjS8cm0", "original": "z_lIx0_CsLV", "number": 6379, "cdate": 1621629788951, "mdate": null, "ddate": null, "tcdate": 1623678046398, "tmdate": 1683307563390, "tddate": null, "forum": "r6cNUjS8cm0", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Closing the Gap: Tighter Analysis of Alternating Stochastic Gradient Methods for Bilevel Problems", "authorids": ["~Tianyi_Chen5", "~Yuejiao_Sun1", "~Wotao_Yin1"], "authors": ["Tianyi Chen", "Yuejiao Sun", "Wotao Yin"], "keywords": ["Stochastic bilevel optimization", "min-max optimization", "compositional optimization", "convergence analysis"], "TL;DR": "Our results explain why simple SGD-type algorithms all work very well in practical bilevel problems without the need for further modifications. ", "abstract": "Stochastic nested optimization, including stochastic compositional, min-max, and bilevel optimization, is gaining popularity in many machine learning applications. \nWhile the three problems share a nested structure, existing works often treat them separately, thus developing problem-specific algorithms and analyses. \nAmong various exciting developments, simple SGD-type updates (potentially on multiple variables) are still prevalent in solving this class of nested problems, but they are believed to have a slower convergence rate than non-nested problems. \nThis paper unifies several SGD-type updates for stochastic nested problems into a single SGD approach that we term ALternating Stochastic gradient dEscenT (ALSET) method. By leveraging the hidden smoothness of the problem, this paper presents a tighter analysis of ALSET for stochastic nested problems. \nUnder the new analysis, to achieve an $\\epsilon$-stationary point of the nested problem, it requires ${\\cal O}(\\epsilon^{-2})$ samples in total. \nUnder certain regularity conditions, applying our results to stochastic compositional, min-max, and reinforcement learning problems either improves or matches the best-known sample complexity in the respective cases. \nOur results explain why simple SGD-type algorithms in stochastic nested problems all work very well in practice without the need for further modifications. ", "pdf": "/pdf/73ab2738d167100d1ec6b33c2f518db5b403da63.pdf", "supplementary_material": "/attachment/3f4b9b2fcba9cd8ae65c2122a52078cbf622aeb1.pdf", "submission_history": "", "checklist": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "chen|closing_the_gap_tighter_analysis_of_alternating_stochastic_gradient_methods_for_bilevel_problems", "thumbnail": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nchen2021closing,\ntitle={Closing the Gap: Tighter Analysis of Alternating Stochastic Gradient Methods for Bilevel Problems},\nauthor={Tianyi Chen and Yuejiao Sun and Wotao Yin},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=r6cNUjS8cm0}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "pdate": 1636492670354, "odate": 1636492670308, "details": {"replyCount": 11}}, {"id": "4JHdr4lgpVT", "original": "9f6mEy8JDL5", "number": 2279, "cdate": 1621629786921, "mdate": null, "ddate": null, "tcdate": 1623678040246, "tmdate": 1697937679818, "tddate": null, "forum": "4JHdr4lgpVT", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Coresets for Decision Trees of Signals", "authorids": ["~Ibrahim_Jubran1", "~Ernesto_Evgeniy_Sanches_Shayda1", "ilan@cs.haifa.ac.il", "~Dan_Feldman1"], "authors": ["Ibrahim Jubran", "Ernesto Evgeniy Sanches Shayda", "Ilan Newman", "Dan Feldman"], "keywords": ["Coresets", "Machine Learning", "Decision Trees", "Random Forests"], "abstract": "A $k$-decision tree $t$ (or $k$-tree) is a recursive partition of a matrix (2D-signal) into $k\\geq 1$ block matrices (axis-parallel rectangles, leaves) where each rectangle is assigned a real label. Its regression or classification loss to a given matrix $D$ of $N$ entries (labels) is the sum of squared differences over every label in $D$ and its assigned label by $t$.\nGiven an error parameter $\\varepsilon\\in(0,1)$, a $(k,\\varepsilon)$-coreset $C$ of $D$ is a small summarization that provably approximates this loss to \\emph{every} such tree, up to a multiplicative factor of $1\\pm\\varepsilon$. In particular, the optimal $k$-tree of $C$ is a $(1+\\varepsilon)$-approximation to the optimal $k$-tree of $D$.\n\nWe provide the first algorithm that outputs such a $(k,\\varepsilon)$-coreset for \\emph{every} such matrix $D$. The size $|C|$ of the coreset is polynomial in $k\\log(N)/\\varepsilon$, and its construction takes $O(Nk)$ time.\nThis is by forging a link between decision trees from machine learning -- to partition trees in computational geometry. \n\nExperimental results on \\texttt{sklearn} and \\texttt{lightGBM} show that applying our coresets on real-world data-sets boosts the computation time of random forests and their parameter tuning by up to x$10$, while keeping similar accuracy. Full open source code is provided.", "submission_history": "", "checklist": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "jubran|coresets_for_decision_trees_of_signals", "pdf": "/pdf/76d15a9db13a84df21f931a588e24ba4cba2fc4e.pdf", "supplementary_material": "/attachment/06339e0688c9c981eb68c89cb35ca83cfbd53131.pdf", "TL;DR": "Coresets for Decision Trees of Signals", "code": "https://github.com/ernestosanches/Decision-Trees-Coreset", "thumbnail": "", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2110.03195/code)", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\njubran2021coresets,\ntitle={Coresets for Decision Trees of Signals},\nauthor={Ibrahim Jubran and Ernesto Evgeniy Sanches Shayda and Ilan Newman and Dan Feldman},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=4JHdr4lgpVT}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "pdate": 1636492774873, "odate": 1636492774827, "details": {"replyCount": 10}}, {"id": "kLJjmSrRB3S", "original": "WFJ_8mzfJHM", "number": 204, "cdate": 1621629771383, "mdate": null, "ddate": null, "tcdate": 1623678019474, "tmdate": 1697937688976, "tddate": null, "forum": "kLJjmSrRB3S", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Continuous vs. Discrete Optimization of Deep Neural Networks", "authorids": ["~Omer_Elkabetz1", "~Nadav_Cohen1"], "authors": ["Omer Elkabetz", "Nadav Cohen"], "keywords": ["Deep Learning", "Non-Convex Optimization", "Gradient Flow", "Gradient Descent"], "TL;DR": "We present a theory quantifying the discrepancy between gradient flow and gradient descent over deep neural networks, and use it to translate an analysis of gradient flow into a new convergence guarantee for gradient descent.", "abstract": "Existing analyses of optimization in deep learning are either continuous, focusing on (variants of) gradient flow, or discrete, directly treating (variants of) gradient descent.  Gradient flow is amenable to theoretical analysis, but is stylized and disregards computational efficiency.  The extent to which it represents gradient descent is an open question in the theory of deep learning.  The current paper studies this question.  Viewing gradient descent as an approximate numerical solution to the initial value problem of gradient flow, we find that the degree of approximation depends on the curvature around the gradient flow trajectory.  We then show that over deep neural networks with homogeneous activations, gradient flow trajectories enjoy favorable curvature, suggesting they are well approximated by gradient descent.  This finding allows us to translate an analysis of gradient flow over deep linear neural networks into a guarantee that gradient descent efficiently converges to global minimum almost surely under random initialization.  Experiments suggest that over simple deep neural networks, gradient descent with conventional step size is indeed close to gradient flow.  We hypothesize that the theory of gradient flows will unravel mysteries behind deep learning.", "pdf": "/pdf/7a7346bdd1e5412513909a45e624886c4d81a82c.pdf", "submission_history": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "checklist": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "elkabetz|continuous_vs_discrete_optimization_of_deep_neural_networks", "supplementary_material": "/attachment/e0a002db2f0b2c38bcf3b457f04f2019254befc1.pdf", "code": "https://github.com/elkabzo/cont_disc_opt_dnn", "thumbnail": "", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2107.06608/code)", "_bibtex": "@inproceedings{\nelkabetz2021continuous,\ntitle={Continuous vs. Discrete Optimization of Deep Neural Networks},\nauthor={Omer Elkabetz and Nadav Cohen},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=kLJjmSrRB3S}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "pdate": 1636492668121, "odate": 1636492668070, "details": {"replyCount": 12}}, {"id": "OU98jZWS3x_", "original": "GvWVaxotcNl", "number": 8389, "cdate": 1621629767342, "mdate": null, "ddate": null, "tcdate": 1623678013435, "tmdate": 1697937692209, "tddate": null, "forum": "OU98jZWS3x_", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Diffusion Models Beat GANs on Image Synthesis", "authorids": ["~Prafulla_Dhariwal1", "~Alexander_Quinn_Nichol1"], "authors": ["Prafulla Dhariwal", "Alexander Quinn Nichol"], "keywords": ["generative models", "diffusion models", "score-based models", "denoising diffusion probabilistic models", "image generation", "neural networks", "attention"], "TL;DR": "We achieve state-of-the-art image generation on ImageNet and several LSUN classes with diffusion models.", "abstract": "We show that diffusion models can achieve image sample quality superior to the current state-of-the-art generative models. We achieve this on unconditional image synthesis by finding a better architecture through a series of ablations. For conditional image synthesis, we further improve sample quality with classifier guidance: a simple, compute-efficient method for trading off diversity for fidelity using gradients from a classifier. We achieve an FID of 2.97 on ImageNet 128$\\times$128, 4.59 on ImageNet 256$\\times$256, and 7.72 on ImageNet 512$\\times$512, and we match BigGAN-deep even with as few as 25 forward passes per sample, all while maintaining better coverage of the distribution. Finally, we find that classifier guidance combines well with upsampling diffusion models, further improving FID to 3.94 on ImageNet 256$\\times$256 and 3.85 on ImageNet 512$\\times$512.", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "dhariwal|diffusion_models_beat_gans_on_image_synthesis", "pdf": "/pdf/fac47484c51c0a9ca609c04dfef93927c49cea18.pdf", "supplementary_material": "/attachment/c47d3fa2b246d4d640583c0ee3166c25b0eaef15.pdf", "checklist": "", "code": "https://github.com/openai/guided-diffusion", "thumbnail": "", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2105.05233/code)", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\ndhariwal2021diffusion,\ntitle={Diffusion Models Beat {GAN}s on Image Synthesis},\nauthor={Prafulla Dhariwal and Alexander Quinn Nichol},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=OU98jZWS3x_}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "pdate": 1636492779528, "odate": 1636492779487, "details": {"replyCount": 9}}, {"id": "o4t543Oon5G", "original": "5MIG13WXliN", "number": 10319, "cdate": 1621629695416, "mdate": null, "ddate": null, "tcdate": 1623677902797, "tmdate": 1683307522035, "tddate": null, "forum": "o4t543Oon5G", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Aligned Structured Sparsity Learning for Efficient Image Super-Resolution", "authorids": ["~Yulun_Zhang1", "~Huan_Wang3", "~Can_Qin1", "~Yun_Fu1"], "authors": ["Yulun Zhang", "Huan Wang", "Can Qin", "Yun Fu"], "keywords": ["Neural Network Pruning", "Lightweight Image Super-Resolution", "Aligned Structured Sparsity Learning"], "abstract": "Lightweight image super-resolution (SR) networks have obtained promising results with moderate model size. Many SR methods have focused on designing lightweight architectures, which neglect to further reduce the redundancy of network parameters. On the other hand, model compression techniques, like neural architecture search and knowledge distillation, typically consume considerable memory and computation resources. In contrast, network pruning is a cheap and effective model compression technique. However, it is hard to be applied to SR networks directly, because filter pruning for residual blocks is well-known tricky. To address the above issues, we propose aligned structured sparsity learning (ASSL), which introduces a weight normalization layer and applies $L_2$ regularization to the scale parameters for sparsity. To align the pruned locations across different layers, we propose a \\emph{sparsity structure alignment} penalty term, which minimizes the norm of soft mask gram matrix. We apply aligned structured sparsity learning strategy to train efficient image SR network, named as ASSLN, with smaller model size and lower computation than state-of-the-art methods. We conduct extensive comparisons with lightweight SR networks. Our ASSLN achieves superior performance gains over recent methods quantitatively and visually.", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "zhang|aligned_structured_sparsity_learning_for_efficient_image_superresolution", "TL;DR": "Optimize image SR networks with network pruning simultaneously and achieve SOTA results", "pdf": "/pdf/e913bbc7caee9b11a9a70c1d1094df9563ffaa17.pdf", "checklist": "", "supplementary_material": "/attachment/5c4711c1c6e821b0ea607dcad2fdd7da6717080d.pdf", "code": "https://github.com/MingSun-Tse/ASSL", "thumbnail": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nzhang2021aligned,\ntitle={Aligned Structured Sparsity Learning for Efficient Image Super-Resolution},\nauthor={Yulun Zhang and Huan Wang and Can Qin and Yun Fu},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=o4t543Oon5G}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "pdate": 1636492706077, "odate": 1636492706022, "details": {"replyCount": 10}}, {"id": "5-GXHFNbq_U", "original": "a8AvaqOlnCz", "number": 59, "cdate": 1621629683304, "mdate": null, "ddate": null, "tcdate": 1623677889974, "tmdate": 1683307519040, "tddate": null, "forum": "5-GXHFNbq_U", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Prototypical Cross-Attention Networks for Multiple Object Tracking and Segmentation", "authorids": ["~Lei_Ke1", "~Xia_Li3", "~Martin_Danelljan4", "~Yu-Wing_Tai2", "~Chi-Keung_Tang1", "~Fisher_Yu2"], "authors": ["Lei Ke", "Xia Li", "Martin Danelljan", "Yu-Wing Tai", "Chi-Keung Tang", "Fisher Yu"], "keywords": ["multiple object tracking and segmentation", "video instance segmentation", "efficient cross-attention networks", "space-time memory"], "abstract": "Multiple object tracking and segmentation requires detecting, tracking, and segmenting objects belonging to a set of given classes. Most approaches only exploit the temporal dimension to address the association problem, while relying on single frame predictions for the segmentation mask itself. We propose Prototypical Cross-Attention Network (PCAN), capable of leveraging rich spatio-temporal information for online multiple object tracking and segmentation. PCAN first distills a space-time memory into a set of prototypes and then employs cross-attention to retrieve rich information from the past frames. To segment each object, PCAN adopts a prototypical appearance module to learn a set of contrastive foreground and background prototypes, which are then propagated over time. Extensive experiments demonstrate that PCAN outperforms current video instance tracking and segmentation competition winners on both Youtube-VIS and BDD100K datasets, and shows efficacy to both one-stage and two-stage segmentation frameworks. Code and video resources are available at http://vis.xyz/pub/pcan.", "submission_history": "", "checklist": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "ke|prototypical_crossattention_networks_for_multiple_object_tracking_and_segmentation", "pdf": "/pdf/c5cb01ad4f3f209cee2fb4bfccc8e3cb1d1ec7b4.pdf", "supplementary_material": "/attachment/acdf5ecd0d24df872985030342ded6ed80e660fe.pdf", "TL;DR": "We design efficient cross-attention networks (PCAN) for multiple object tracking and segmentation.", "code": "https://github.com/SysCV/pcan", "thumbnail": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nke2021prototypical,\ntitle={Prototypical Cross-Attention Networks for Multiple Object Tracking and Segmentation},\nauthor={Lei Ke and Xia Li and Martin Danelljan and Yu-Wing Tai and Chi-Keung Tang and Fisher Yu},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=5-GXHFNbq_U}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "pdate": 1636492672837, "odate": 1636492672792, "details": {"replyCount": 11}}, {"id": "GPwmbxtG9Ow", "original": "KFKdOTayJcP", "number": 11689, "cdate": 1621630355349, "ddate": null, "tcdate": 1621630355349, "tmdate": 1683307782723, "tddate": null, "forum": "GPwmbxtG9Ow", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Bootstrapping the Error of Oja's Algorithm ", "authorids": ["~Robert_Lunde1", "~Purnamrita_Sarkar1", "~Rachel_Ward1"], "authors": ["Robert Lunde", "Purnamrita Sarkar", "Rachel Ward"], "keywords": ["Gaussian approximation", "bootstrap", "Streaming PCA"], "abstract": "We consider the problem of quantifying uncertainty for the estimation error of the leading eigenvector from Oja's algorithm for streaming principal component analysis, where the data are generated IID from some unknown distribution.  By combining classical tools from the U-statistics literature with recent results on high-dimensional central limit theorems for quadratic forms of random vectors and concentration of matrix products, we establish a weighted $\\chi^2$ approximation result for the $\\sin^2$ error between the population eigenvector and the output of Oja\u2019s algorithm. Since estimating the covariance matrix associated with the approximating distribution requires knowledge of unknown model parameters, we propose a multiplier bootstrap algorithm that may be updated in an online manner.  We establish conditions under which the bootstrap distribution is close to the corresponding sampling distribution with high probability, thereby establishing the bootstrap as a consistent inferential method in an appropriate asymptotic regime. ", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "lunde|bootstrapping_the_error_of_ojas_algorithm", "TL;DR": "We establish a high-dimensional central limit theorem and online bootstrap procedure for inferring the error of Oja's algorithm, which is a widely used method in Streaming PCA", "pdf": "/pdf/abc3ae02f98c370a857911d2fdd4312682be2bad.pdf", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "checklist": "", "supplementary_material": "/attachment/5a17cb5c02e2246e834ac6eb9e55faff09438107.pdf", "thumbnail": "", "_bibtex": "@inproceedings{\nlunde2021bootstrapping,\ntitle={Bootstrapping the Error of Oja's Algorithm },\nauthor={Robert Lunde and Purnamrita Sarkar and Rachel Ward},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=GPwmbxtG9Ow}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492702801, "odate": 1636492702801, "details": {"replyCount": 13}}, {"id": "8RnRLP4SHe0", "original": "8B6TC-MtSGk", "number": 11603, "cdate": 1621630350174, "ddate": null, "tcdate": 1621630350174, "tmdate": 1683307781438, "tddate": null, "forum": "8RnRLP4SHe0", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Regulating algorithmic filtering on social media", "authorids": ["~Sarah_Cen1", "~Devavrat_Shah1"], "authors": ["Sarah Cen", "Devavrat Shah"], "keywords": ["social media", "regulation", "audit", "filtering algorithm", "performance cost", "content diversity", "counterfactual", "hypothesis testing", "minimum-variance unbiased estimator"], "abstract": "By filtering the content that users see, social media platforms have the ability to influence users' perceptions and decisions, from their dining choices to their voting preferences. This influence has drawn scrutiny, with many calling for regulations on filtering algorithms, but designing and enforcing regulations remains challenging. In this work, we examine three questions. First, given a regulation, how would one design an audit to enforce it? Second, does the audit impose a performance cost on the platform? Third, how does the audit affect the content that the platform is incentivized to filter? In response to these questions, we propose a method such that, given a regulation, an auditor can test whether that regulation is met with only black-box access to the filtering algorithm. We then turn to the platform's perspective. The platform's goal is to maximize an objective function while meeting regulation. We find that there are conditions under which the regulation does not place a high performance cost on the platform and, notably, that content diversity can play a key role in aligning the interests of the platform and regulators.", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "cen|regulating_algorithmic_filtering_on_social_media", "pdf": "/pdf/3522e18c2e38a2f7e74f52525f86eec64cf216de.pdf", "checklist": "", "supplementary_material": "/attachment/4d3b666ece6ff7c315a19da537c093cbbb1aa89e.pdf", "TL;DR": "We propose an auditing procedure for enforcing social media regulations, provide theoretical guarantees on the audit, study whether there is a performance-regulation tradeoff, and find that content diversity plays a key role.", "thumbnail": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\ncen2021regulating,\ntitle={Regulating algorithmic filtering on social media},\nauthor={Sarah Cen and Devavrat Shah},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=8RnRLP4SHe0}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492683120, "odate": 1636492683120, "details": {"replyCount": 15}}, {"id": "SFLSOd_hv-4", "original": "qM7GYj6NNW", "number": 11587, "cdate": 1621630349207, "ddate": null, "tcdate": 1621630349207, "tmdate": 1697937323079, "tddate": null, "forum": "SFLSOd_hv-4", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Robust Predictable Control", "authorids": ["~Benjamin_Eysenbach1", "~Ruslan_Salakhutdinov1", "~Sergey_Levine1"], "authors": ["Benjamin Eysenbach", "Ruslan Salakhutdinov", "Sergey Levine"], "keywords": ["reinforcement learning", "information bottleneck"], "TL;DR": "We propose a method for learning robust and predictable policies in RL using ideas from compression.", "abstract": "Many of the challenges facing today's reinforcement learning (RL) algorithms, such as robustness, generalization, transfer, and computational efficiency are closely related to compression.  Prior work has convincingly argued why minimizing information is useful in the supervised learning setting, but standard RL algorithms lack an explicit mechanism for compression. The RL setting is unique because (1) its sequential nature allows an agent to use past information to avoid looking at future observations and (2) the agent can optimize its behavior to prefer states where decision making requires few bits. We take advantage of these properties to propose a method (RPC) for learning simple policies. This method brings together ideas from information bottlenecks, model-based RL, and bits-back coding into a simple and theoretically-justified algorithm. Our method jointly optimizes a latent-space model and policy to be self-consistent, such that the policy avoids states where the model is inaccurate. We demonstrate that our method achieves much tighter compression than prior methods, achieving up to 5$\\times$ higher reward than a standard information bottleneck when constrained to use just 0.3 bits per observation. We also demonstrate that our method learns policies that are more robust and generalize better to new tasks.", "submission_history": "", "checklist": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "eysenbach|robust_predictable_control", "pdf": "/pdf/d7c95080cd81c780f403cc17925cf4ea0f5465b8.pdf", "supplementary_material": "/attachment/668fd55c2d4554677c79ba39f46f986af6751158.pdf", "code": "https://github.com/google-research/google-research/tree/master/rpc", "thumbnail": "", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 2 code implementations](https://www.catalyzex.com/paper/arxiv:2109.03214/code)", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\neysenbach2021robust,\ntitle={Robust Predictable Control},\nauthor={Benjamin Eysenbach and Ruslan Salakhutdinov and Sergey Levine},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=SFLSOd_hv-4}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492716287, "odate": 1636492716287, "details": {"replyCount": 14}}, {"id": "K5YKjaMjbja", "original": "iuNByH0-Dpz", "number": 11515, "cdate": 1621630344704, "ddate": null, "tcdate": 1621630344704, "tmdate": 1697937324305, "tddate": null, "forum": "K5YKjaMjbja", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Neural Algorithmic Reasoners are Implicit Planners", "authorids": ["~Andreea_Deac1", "~Petar_Veli\u010dkovi\u01071", "~Ognjen_Milinkovi\u01071", "~Pierre-Luc_Bacon1", "~Jian_Tang1", "~Mladen_Nikolic1"], "authors": ["Andreea Deac", "Petar Veli\u010dkovi\u0107", "Ognjen Milinkovi\u0107", "Pierre-Luc Bacon", "Jian Tang", "Mladen Nikolic"], "keywords": ["graph neural networks", "value iteration", "implicit planning", "algorithmic bottleneck"], "TL;DR": "We study value iteration-based implicit planning methods, discover an algorithmic bottleneck which leaves them vulnerable in low-data scenarios. By performing value iteration-style planing in the latent space, we successfully break this bottleneck.", "abstract": "Implicit planning has emerged as an elegant technique for combining learned models of the world with end-to-end model-free reinforcement learning. We study the class of implicit planners inspired by value iteration, an algorithm that is guaranteed to yield perfect policies in fully-specified tabular environments. We find that prior approaches either assume that the environment is provided in such a tabular form---which is highly restrictive---or infer \"local neighbourhoods\" of states to run value iteration over---for which we discover an algorithmic bottleneck effect. This effect is caused by explicitly running the planning algorithm based on scalar predictions in every state, which can be harmful to data efficiency if such scalars are improperly predicted. We propose eXecuted Latent Value Iteration Networks (XLVINs), which alleviate the above limitations. Our method performs all planning computations in a high-dimensional latent space, breaking the algorithmic bottleneck. It maintains alignment with value iteration by carefully leveraging neural graph-algorithmic reasoning and contrastive self-supervised learning. Across seven low-data settings---including classical control, navigation and Atari---XLVINs provide significant improvements to data efficiency against value iteration-based implicit planners, as well as relevant model-free baselines. Lastly, we empirically verify that XLVINs can closely align with value iteration.", "submission_history": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "deac|neural_algorithmic_reasoners_are_implicit_planners", "pdf": "/pdf/319c3b390202c9f8cc7967096432c1dd2664a627.pdf", "checklist": "", "supplementary_material": "/attachment/b58918f3bdf0d682374874e36853cc9f37834c3e.pdf", "thumbnail": "", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 2 code implementations](https://www.catalyzex.com/paper/arxiv:2110.05442/code)", "_bibtex": "@inproceedings{\ndeac2021neural,\ntitle={Neural Algorithmic Reasoners are Implicit Planners},\nauthor={Andreea Deac and Petar Veli{\\v{c}}kovi{\\'c} and Ognjen Milinkovi{\\'c} and Pierre-Luc Bacon and Jian Tang and Mladen Nikolic},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=K5YKjaMjbja}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492787474, "odate": 1636492787474, "details": {"replyCount": 14}}, {"id": "cCQAzuT5q4", "original": "D0q6t5rVm_5", "number": 11413, "cdate": 1621630338478, "ddate": null, "tcdate": 1621630338478, "tmdate": 1697937326004, "tddate": null, "forum": "cCQAzuT5q4", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Online Selective Classification with Limited Feedback", "authorids": ["~Aditya_Gangrade1", "~Anil_Kag1", "~Ashok_Cutkosky1", "~Venkatesh_Saligrama1"], "authors": ["Aditya Gangrade", "Anil Kag", "Ashok Cutkosky", "Venkatesh Saligrama"], "keywords": ["Selective Classification", "Online Learning"], "abstract": "Motivated by applications to resource-limited and safety-critical domains, we study selective classification in the online learning model, wherein a predictor may abstain from classifying an instance. For example, this may model an adaptive decision to invoke more resources on this instance. Two salient aspects of the setting we consider are that the data may be non-realisable, due to which abstention may be a valid long-term action, and that feedback is only received when the learner abstains, which models the fact that reliable labels are only available when the resource intensive processing is invoked.\nWithin this framework, we explore strategies that make few mistakes, while not abstaining too many times more than the best-in-hindsight error-free classifier from a given class. That is, the one that makes no mistakes, while abstaining the fewest number of times. We construct simple versioning-based schemes for any $\\mu \\in (0,1],$ that make most $T^\\mu$ mistakes while incurring $\\tilde{O}(T^{1-\\mu})$ excess abstention against adaptive adversaries. We further show that this dependence on $T$ is tight, and provide illustrative experiments on realistic datasets.", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "gangrade|online_selective_classification_with_limited_feedback", "pdf": "/pdf/04ede82d511df0ea966189284a7558ee102fc2a9.pdf", "supplementary_material": "/attachment/066a47d46c8a741446031ff5962dbcc8449bce70.pdf", "checklist": "", "thumbnail": "", "code": "https://github.com/anilkagak2/Online-Selective-Classification", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 2 code implementations](https://www.catalyzex.com/paper/arxiv:2110.14243/code)", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\ngangrade2021online,\ntitle={Online Selective Classification with Limited Feedback},\nauthor={Aditya Gangrade and Anil Kag and Ashok Cutkosky and Venkatesh Saligrama},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=cCQAzuT5q4}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492716382, "odate": 1636492716382, "details": {"replyCount": 15}}, {"id": "bXehDYUjjXi", "original": "xXxWOdIw3e87", "number": 11401, "cdate": 1621630337720, "ddate": null, "tcdate": 1621630337720, "tmdate": 1683307779157, "tddate": null, "forum": "bXehDYUjjXi", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "A Variational Perspective on Diffusion-Based Generative Models and Score Matching", "authorids": ["~Chin-Wei_Huang1", "~Jae_Hyun_Lim1", "~Aaron_Courville3"], "authors": ["Chin-Wei Huang", "Jae Hyun Lim", "Aaron Courville"], "keywords": ["Diffusion model", "Neural SDE", "Neural ODE", "normalizing flows", "score matching", "hierarchical VAE", "generative modelling", "maximum likelihood", "variational lower bound"], "abstract": "Discrete-time diffusion-based generative models and score matching methods have shown promising results in modeling high-dimensional image data. Recently, Song et al. (2021) show that diffusion processes that transform data into noise can be reversed via learning the score function, i.e. the gradient of the log-density of the perturbed data. They propose to plug the learned score function into an inverse formula to define a generative diffusion process. Despite the empirical success, a theoretical underpinning of this procedure is still lacking. In this work, we approach the (continuous-time) generative diffusion directly and derive a variational framework for likelihood estimation, which includes continuous-time normalizing flows as a special case, and can be seen as an infinitely deep variational autoencoder. Under this framework, we show that minimizing the score-matching loss is equivalent to maximizing a lower bound of the likelihood of the plug-in reverse SDE proposed by Song et al. (2021), bridging the theoretical gap.", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "huang|a_variational_perspective_on_diffusionbased_generative_models_and_score_matching", "pdf": "/pdf/00242204adbef5e8350ca7ec1295e37a516ed6c5.pdf", "supplementary_material": "/attachment/aee836ece97d0e4cfbd72be7307809714b751f22.pdf", "checklist": "", "TL;DR": "We derived an ELBO for continuous-time diffusion models using stochastic calculus, and made connection to continuous-time normalizing flows, hierarchical VAE, and score-based generative models. ", "code": "https://github.com/CW-Huang/sdeflow-light", "thumbnail": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nhuang2021a,\ntitle={A Variational Perspective on Diffusion-Based Generative Models and Score Matching},\nauthor={Chin-Wei Huang and Jae Hyun Lim and Aaron Courville},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=bXehDYUjjXi}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492777806, "odate": 1636492777806, "details": {"replyCount": 14}}, {"id": "LBhruMnhgIB", "original": "zVvirR272e", "number": 11361, "cdate": 1621630335288, "ddate": null, "tcdate": 1621630335288, "tmdate": 1683307777299, "tddate": null, "forum": "LBhruMnhgIB", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Unintended Selection: Persistent Qualification Rate Disparities and Interventions", "authorids": ["~Reilly_Raab1", "~Yang_Liu3"], "authors": ["Reilly Raab", "Yang Liu"], "keywords": ["Fairness", "Evolution", "Qualification Rate Disparity", "Intervention", "Replicator Dynamics", "Feedback Control"], "TL;DR": "Careless deployment of machine learning classifiers can induce social changes that maintain existing disparities between structurally equivalent groups.", "abstract": "Realistically---and equitably---modeling the dynamics of group-level disparities in machine learning remains an open problem. In particular, we desire models that do not suppose inherent differences between artificial groups of people---but rather endogenize disparities by appeal to unequal initial conditions of insular subpopulations. In this paper, agents each have a real-valued feature $X$ (e.g., credit score) informed by a ``true'' binary label $Y$ representing qualification (e.g., for a loan). Each agent alternately (1) receives a binary classification label $\\hat{Y}$ (e.g., loan approval) from a Bayes-optimal machine learning classifier observing $X$ and (2) may update their qualification $Y$ by imitating successful strategies (e.g., seek a raise) within an isolated group $G$ of agents to which they belong. We consider the disparity of qualification rates $\\Pr(Y=1)$ between different groups and how this disparity changes subject to a sequence of Bayes-optimal classifiers repeatedly retrained on the global population. We model the evolving qualification rates of each subpopulation (group) using the replicator equation, which derives from a class of imitation processes. We show that differences in qualification rates between subpopulations can persist indefinitely for a set of non-trivial equilibrium states due to uniformed classifier deployments, even when groups are identical in all aspects except initial qualification densities. We next simulate the effects of commonly proposed fairness interventions on this dynamical system along with a new feedback control mechanism capable of permanently eliminating group-level qualification rate disparities. We conclude by discussing the limitations of our model and findings and by outlining potential future work.", "pdf": "/pdf/43be3729d8989f4582ffccdfa1a4e0d08472517f.pdf", "supplementary_material": "/attachment/937f8dbfc4d30cbd16035bd4ebcb755f24c369ea.pdf", "submission_history": "", "checklist": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "raab|unintended_selection_persistent_qualification_rate_disparities_and_interventions", "code": "/attachment/b9a9c319c9a4a04a7e2a9f5b0d4f0e22e3193db1.zip", "thumbnail": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nraab2021unintended,\ntitle={Unintended Selection: Persistent Qualification Rate Disparities and Interventions},\nauthor={Reilly Raab and Yang Liu},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=LBhruMnhgIB}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492683758, "odate": 1636492683758, "details": {"replyCount": 12}}, {"id": "HnLDt9v6Q-j", "original": "3YtxxlAvvHy", "number": 11333, "cdate": 1621630333599, "ddate": null, "tcdate": 1621630333599, "tmdate": 1697937328514, "tddate": null, "forum": "HnLDt9v6Q-j", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Two steps to risk sensitivity", "authorids": ["~Christopher_Gagne1", "~Peter_Dayan1"], "authors": ["Christopher Gagne", "Peter Dayan"], "keywords": ["Risk measures", "Conditional value-at-risk", "Two-step task", "Time-consistency", "Distributional reinforcement learning", "Anxiety"], "abstract": "Distributional reinforcement learning (RL) \u2013 in which agents learn about all the possible long-term consequences of their actions, and not just the expected value \u2013 is of great recent interest. One of the most important affordances of a distributional view is facilitating a modern, measured, approach to risk when outcomes are not completely certain. By contrast, psychological and neuroscientific investigations into decision making under risk have utilized a variety of more venerable theoretical models such as prospect theory that lack axiomatically desirable properties such as coherence. Here, we consider a particularly relevant risk measure for modeling human and animal planning, called conditional value-at-risk (CVaR), which quantifies worst-case outcomes (e.g., vehicle accidents or predation). We first adopt a conventional distributional approach to CVaR in a sequential setting and reanalyze the choices of human decision-makers in the well-known two-step task, revealing substantial risk aversion that had been lurking under stickiness and perseveration. We then consider a further critical property of risk sensitivity, namely time consistency, showing alternatives to this form of CVaR that enjoy this desirable characteristic. We use simulations to examine settings in which the various forms differ in ways that have implications for human and animal planning and behavior.", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "gagne|two_steps_to_risk_sensitivity", "TL;DR": "We use a conditional value-at-risk (CVaR) measure to show that many human subjects are highly risk averse in the popular two-step task; and use simulations in a novel domain to suggest how to distinguish time-consistent/inconsistent CVaRiants.", "pdf": "/pdf/e4557754aa084979b86bd331e6bf1cf6d6f5afc8.pdf", "checklist": "", "supplementary_material": "/attachment/869bf68b7abcedd9429c2ac2106c4c1eb635815c.pdf", "thumbnail": "", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2111.06803/code)", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\ngagne2021two,\ntitle={Two steps to risk sensitivity},\nauthor={Christopher Gagne and Peter Dayan},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=HnLDt9v6Q-j}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492778542, "odate": 1636492778542, "details": {"replyCount": 11}}, {"id": "bJz3cFePTna", "original": "xiULwiGoWCj", "number": 11279, "cdate": 1621630330292, "ddate": null, "tcdate": 1621630330292, "tmdate": 1683307776688, "tddate": null, "forum": "bJz3cFePTna", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Mixture Proportion Estimation and PU Learning:A Modern Approach", "authorids": ["~Saurabh_Garg3", "~Yifan_Wu1", "~Alex_Smola1", "~Sivaraman_Balakrishnan1", "~Zachary_Chase_Lipton1"], "authors": ["Saurabh Garg", "Yifan Wu", "Alex Smola", "Sivaraman Balakrishnan", "Zachary Chase Lipton"], "keywords": ["PU learning", "Mixture Proportion Estimation"], "abstract": "Given only positive examples and unlabeled examples (from both positive and negative classes), we might hope nevertheless to estimate an accurate positive-versus-negative classifier. Formally, this task is broken down into two subtasks: (i) Mixture Proportion Estimation (MPE)---determining the fraction of positive examples in the unlabeled data; and (ii) PU-learning---given such an estimate, learning the desired positive-versus-negative classifier. Unfortunately, classical methods for both problems break down in high-dimensional settings. Meanwhile, recently proposed heuristics lack theoretical coherence and depend precariously on hyperparameter tuning. In this paper, we propose two simple techniques: Best Bin Estimation (BBE) (for MPE); and Conditional Value Ignoring Risk (CVIR), a simple objective for PU-learning. Both methods dominate previous approaches empirically, and for BBE, we establish formal guarantees that hold whenever we can train a model to cleanly separate out a small subset of positive examples. Our final algorithm (TED)$^n$, alternates between the two procedures, significantly improving both our mixture proportion estimator and classifier", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "garg|mixture_proportion_estimation_and_pu_learninga_modern_approach", "TL;DR": "Given only Positive (P) and Unlabeled (U) data, containing both P and Negative (N) samples, we propose new approaches to estimate fraction of P in U and learn P vs N classifier.", "pdf": "/pdf/e3f798f5d82138de928114ab2e0317a73322a3d8.pdf", "checklist": "", "supplementary_material": "/attachment/f430fbc0af87765df12378f0978b6d740667ec33.pdf", "code": "https://github.com/acmi-lab/PU_learning", "thumbnail": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\ngarg2021mixture,\ntitle={Mixture Proportion Estimation and {PU} Learning:A Modern Approach},\nauthor={Saurabh Garg and Yifan Wu and Alex Smola and Sivaraman Balakrishnan and Zachary Chase Lipton},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=bJz3cFePTna}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492686446, "odate": 1636492686446, "details": {"replyCount": 13}}, {"id": "GEKTIKvslP", "original": "FCxanB_qjl2", "number": 11188, "cdate": 1621630324647, "ddate": null, "tcdate": 1621630324647, "tmdate": 1683307776003, "tddate": null, "forum": "GEKTIKvslP", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Fair Exploration via Axiomatic Bargaining", "authorids": ["~Jackie_Baek1", "~Vivek_Farias1"], "authors": ["Jackie Baek", "Vivek Farias"], "keywords": ["bandits", "fairness", "exploration", "Nash bargaining"], "TL;DR": "We study how to fairly allocate the burden of exploration for multi-armed bandits with groups using the Nash bargaining framework.", "abstract": "Motivated by the consideration of fairly sharing the cost of exploration between multiple groups in learning problems, we develop the Nash bargaining solution in the context of multi-armed bandits. Specifically, the 'grouped' bandit associated with any multi-armed bandit problem associates, with each time step, a single group from some finite set of groups. The utility gained by a given group under some learning policy is naturally viewed as the reduction in that group's regret relative to the regret that group would have incurred 'on its own'. We derive policies that yield the Nash bargaining solution relative to the set of incremental utilities possible under any policy. We show that on the one hand, the 'price of fairness' under such policies is limited, while on the other hand, regret optimal policies are arbitrarily unfair under generic conditions. Our theoretical development is complemented by a case study on contextual bandits for warfarin dosing where we are concerned with the cost of exploration across multiple races and age groups. ", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "baek|fair_exploration_via_axiomatic_bargaining", "pdf": "/pdf/87e00094fce5a3bd35d25cab960cdf814aae84f1.pdf", "checklist": "", "supplementary_material": "/attachment/1f5ba217ef60d018d4b65ba7222c17487d575d91.zip", "thumbnail": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nbaek2021fair,\ntitle={Fair Exploration via Axiomatic Bargaining},\nauthor={Jackie Baek and Vivek Farias},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=GEKTIKvslP}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492729126, "odate": 1636492729126, "details": {"replyCount": 10}}, {"id": "yaksQCYcRs", "original": "9-VESZh6Q1M", "number": 10989, "cdate": 1621630312845, "ddate": null, "tcdate": 1621630312845, "tmdate": 1697937335657, "tddate": null, "forum": "yaksQCYcRs", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Neural Program Generation Modulo Static Analysis", "authorids": ["~Rohan_Mukherjee1", "~Yeming_Wen1", "~Dipak_Chaudhari1", "~Thomas_Reps1", "~Swarat_Chaudhuri1", "~Chris_Jermaine1"], "authors": ["Rohan Mukherjee", "Yeming Wen", "Dipak Chaudhari", "Thomas Reps", "Swarat Chaudhuri", "Chris Jermaine"], "keywords": ["Program generation", "neurosymbolic learning", "attribute grammars", "program synthesis"], "TL;DR": "We proposed to tackle the long-horizon code generation challenge using weak supervision from a static program analyzer.", "abstract": "State-of-the-art neural models of source code tend to be evaluated on the generation of individual expressions and lines of code, and commonly fail on long-horizon tasks such as the generation of entire method bodies. We propose to address this deficiency using weak supervision from a static program analyzer. Our neurosymbolic method allows a deep generative model to symbolically compute, using calls to a static analysis tool, long-distance semantic relationships in the code that it has already generated. During training, the model observes these relationships and learns to generate programs conditioned on them. We apply our approach to the problem of generating entire Java methods given the remainder of the class that contains the method. Our experiments show that the approach substantially outperforms a state-of-the-art transformer and a model that explicitly tries to learn program semantics on this task, both in terms of producing programs free of basic semantic errors and in terms of syntactically matching the ground truth. ", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "mukherjee|neural_program_generation_modulo_static_analysis", "pdf": "/pdf/d5004beda194492ba2417ae619f57dbfa11a22fe.pdf", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "checklist": "", "supplementary_material": "/attachment/0ebbbffabc8b0eec32bd7e2f48151e2da30c997f.pdf", "code": "https://github.com/rohanmukh/nsg", "thumbnail": "", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 2 code implementations](https://www.catalyzex.com/paper/arxiv:2111.01633/code)", "_bibtex": "@inproceedings{\nmukherjee2021neural,\ntitle={Neural Program Generation Modulo Static Analysis},\nauthor={Rohan Mukherjee and Yeming Wen and Dipak Chaudhari and Thomas Reps and Swarat Chaudhuri and Chris Jermaine},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=yaksQCYcRs}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492670401, "odate": 1636492670401, "details": {"replyCount": 14}}, {"id": "XL9DWRG7mJn", "original": "oKXVLpfn_X6", "number": 10919, "cdate": 1621630308643, "ddate": null, "tcdate": 1621630308643, "tmdate": 1697937337233, "tddate": null, "forum": "XL9DWRG7mJn", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Rethinking gradient sparsification as total error minimization", "authorids": ["~Atal_Narayan_Sahu1", "~Aritra_Dutta1", "~Ahmed_M._Abdelmoniem1", "~Trambak_Banerjee1", "~Marco_Canini1", "~Panos_Kalnis1"], "authors": ["Atal Narayan Sahu", "Aritra Dutta", "Ahmed M. Abdelmoniem", "Trambak Banerjee", "Marco Canini", "Panos Kalnis"], "keywords": ["Gradient compression", "Distributed optimization"], "abstract": "Gradient compression is a widely-established remedy to tackle the communication bottleneck in distributed training of large deep neural networks (DNNs). Under the error-feedback framework, Top-$k$ sparsification, sometimes with $k$ as little as 0.1% of the gradient size, enables training to the same model quality as the uncompressed case for a similar iteration count. From the optimization perspective, we find that Top-$k$ is the communication-optimal sparsifier given a per-iteration $k$ element budget.\nWe argue that to further the benefits of gradient sparsification, especially for DNNs, a different perspective is necessary \u2014 one that moves from per-iteration optimality to consider optimality for the entire training.\n\nWe identify that the total error \u2014 the sum of the compression errors for all iterations \u2014 encapsulates sparsification throughout training. Then, we propose a communication complexity model that minimizes the total error under a communication budget for the entire training. We find that the hard-threshold sparsifier, a variant of the Top-$k$ sparsifier with $k$ determined by a constant hard-threshold, is the optimal sparsifier for this model. Motivated by this, we provide convex and non-convex convergence analyses for the hard-threshold sparsifier with error-feedback. We show that hard-threshold has the same asymptotic convergence and linear speedup property as SGD in both the case, and unlike with Top-$k$ sparsifier, has no impact due to data-heterogeneity. Our diverse experiments on various DNNs and a logistic regression model demonstrate that the hard-threshold sparsifier is more communication-efficient than Top-$k$.", "pdf": "/pdf/10d180a533e69f26b10bcb560e6ff4c1b1f70e9d.pdf", "supplementary_material": "/attachment/d8f888a10918ff2fd66060d27ef1e74f846c1fcf.pdf", "submission_history": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "checklist": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "sahu|rethinking_gradient_sparsification_as_total_error_minimization", "code": "https://github.com/sands-lab/rethinking-sparsification", "thumbnail": "", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 3 code implementations](https://www.catalyzex.com/paper/arxiv:2108.00951/code)", "_bibtex": "@inproceedings{\nsahu2021rethinking,\ntitle={Rethinking gradient sparsification as total error minimization},\nauthor={Atal Narayan Sahu and Aritra Dutta and Ahmed M. Abdelmoniem and Trambak Banerjee and Marco Canini and Panos Kalnis},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=XL9DWRG7mJn}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492667146, "odate": 1636492667146, "details": {"replyCount": 11}}, {"id": "1Kof-nkmQB8", "original": "QXT60aPDXOZx", "number": 10884, "cdate": 1621630306536, "ddate": null, "tcdate": 1621630306536, "tmdate": 1683307771480, "tddate": null, "forum": "1Kof-nkmQB8", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Collaborating with Humans without Human Data", "authorids": ["~DJ_Strouse1", "~Kevin_R._McKee1", "~Matthew_Botvinick1", "~Edward_Hughes1", "~Richard_Everett1"], "authors": ["DJ Strouse", "Kevin R. McKee", "Matthew Botvinick", "Edward Hughes", "Richard Everett"], "keywords": ["multi-agent", "zero-shot coordination", "collaboration", "cooperation", "common-payoff", "human-ai interaction", "reinforcement learning", "deep reinforcement learning"], "abstract": "Collaborating with humans requires rapidly adapting to their individual strengths, weaknesses, and preferences. Unfortunately, most standard multi-agent reinforcement learning techniques, such as self-play (SP) or population play (PP), produce agents that overfit to their training partners and do not generalize well to humans. Alternatively, researchers can collect human data, train a human model using behavioral cloning, and then use that model to train \"human-aware\" agents (\"behavioral cloning play\", or BCP). While such an approach can improve the generalization of agents to new human co-players, it involves the onerous and expensive step of collecting large amounts of human data first. Here, we study the problem of how to train agents that collaborate well with human partners without using human data. We argue that the crux of the problem is to produce a diverse set of training partners. Drawing inspiration from successful multi-agent approaches in competitive domains, we find that a surprisingly simple approach is highly effective. We train our agent partner as the best response to a population of self-play agents and their past checkpoints taken throughout training, a method we call Fictitious Co-Play (FCP). Our experiments focus on a two-player collaborative cooking simulator that has recently been proposed as a challenge problem for coordination with humans. We find that FCP agents score significantly higher than SP, PP, and BCP when paired with novel agent and human partners. Furthermore, humans also report a strong subjective preference to partnering with FCP agents over all baselines.", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "strouse|collaborating_with_humans_without_human_data", "TL;DR": "We train state-of-the-art agents for zero-shot coordination with humans without using human data in the training pipeline.", "pdf": "/pdf/7499f6f42069792cb6d87c1afa6c7aab422765c2.pdf", "checklist": "", "supplementary_material": "/attachment/185ae4cc8fe0cb6c015d750a68549de0ad422cb2.pdf", "thumbnail": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nstrouse2021collaborating,\ntitle={Collaborating with Humans without Human Data},\nauthor={DJ Strouse and Kevin R. McKee and Matthew Botvinick and Edward Hughes and Richard Everett},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=1Kof-nkmQB8}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492728069, "odate": 1636492728025, "details": {"replyCount": 17}}, {"id": "L5vbEVIePyb", "original": "KFnz-AZXmgC", "number": 10841, "cdate": 1621630303922, "ddate": null, "tcdate": 1621630303922, "tmdate": 1697937339609, "tddate": null, "forum": "L5vbEVIePyb", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Flexible Option Learning", "authorids": ["~Martin_Klissarov1", "~Doina_Precup1"], "authors": ["Martin Klissarov", "Doina Precup"], "keywords": ["temporal abstraction", "options", "hierarchical reinforcement learning", "deep reinforcement learning", "reinforcement learning"], "TL;DR": "We propose updates that allow for learning all relevant options simulteneously without introducing additional estimators. We verify that our approach can improve sample efficiency and can open the door to more flexibility when learning options.", "abstract": "Temporal abstraction in reinforcement learning (RL), offers the promise of improving generalization and knowledge transfer in complex environments, by propagating information more efficiently over time. Although option learning was initially formulated in a way that allows updating many options simultaneously, using off-policy, intra-option learning (Sutton, Precup & Singh, 1999) , many of the recent hierarchical reinforcement learning approaches only update a single option at a time: the option currently executing. We revisit and extend intra-option learning in the context of deep reinforcement learning, in order to enable updating all options consistent with current primitive action choices, without introducing any additional estimates. Our method can therefore be naturally adopted in most hierarchical RL frameworks. When we combine our approach with the option-critic algorithm for option discovery, we obtain significant improvements in performance and data-efficiency across a wide variety of domains. ", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "klissarov|flexible_option_learning", "pdf": "/pdf/cfc80653b11a2cb2122f4a55901e2fd2116ffc4e.pdf", "checklist": "", "supplementary_material": "/attachment/b3622060f6d4b53f8e9d13af1082cbfe33694937.pdf", "code": "https://github.com/mklissa/MOC", "thumbnail": "", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2112.03097/code)", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nklissarov2021flexible,\ntitle={Flexible Option Learning},\nauthor={Martin Klissarov and Doina Precup},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=L5vbEVIePyb}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492692678, "odate": 1636492692678, "details": {"replyCount": 8}}, {"id": "mSuBvrUJFsF", "original": "SlASQwEdx8", "number": 10716, "cdate": 1621630296567, "ddate": null, "tcdate": 1621630296567, "tmdate": 1683307768429, "tddate": null, "forum": "mSuBvrUJFsF", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Double Machine Learning Density Estimation for Local Treatment Effects with Instruments", "authorids": ["~Yonghan_Jung1", "~Jin_Tian1", "~Elias_Bareinboim2"], "authors": ["Yonghan Jung", "Jin Tian", "Elias Bareinboim"], "keywords": ["instrumental variables", "local treatment effect", "complier average causal effects", "density estimation", "double/debiased machine learning", "semiparametric inference"], "TL;DR": "We develop double/debiased machine learning (DML) density estimators for treatment effects among compliers in the presence of instruments.", "abstract": "Local treatment effects are a common quantity found throughout the empirical sciences that measure the treatment effect among those who comply with what they are assigned. Most of the literature is focused on estimating the average of such quantity, which is called the ``local average treatment effect (LATE)'' [Imbens and Angrist, 1994]). In this work, we study how to estimate the density of the local treatment effect, which is naturally more informative than its average. Specifically, we develop two families of methods for this task, namely, kernel-smoothing and model-based approaches. The kernel-smoothing-based approach estimates the density through some smooth kernel functions. The model-based approach estimates the density by projecting it onto a finite-dimensional density class. For both approaches, we derive the corresponding double/debiased machine learning-based estimators [Chernozhukov et al., 2018]. We further study the asymptotic convergence rates of the estimators and show that they are robust to the biases in nuisance function estimation. The use of the proposed methods is illustrated through both synthetic and a real dataset called 401(k).", "pdf": "/pdf/a84bfde89e18789cc718ba83743a22534c420874.pdf", "supplementary_material": "/attachment/9db8bd366d36ea72521988e659a6f3a51797a4da.pdf", "submission_history": "", "checklist": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "jung|double_machine_learning_density_estimation_for_local_treatment_effects_with_instruments", "thumbnail": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\njung2021double,\ntitle={Double Machine Learning Density Estimation for Local Treatment Effects with Instruments},\nauthor={Yonghan Jung and Jin Tian and Elias Bareinboim},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=mSuBvrUJFsF}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492698945, "odate": 1636492698945, "details": {"replyCount": 9}}, {"id": "KpKWDyXq17d", "original": "wbptkgiB4SM", "number": 10592, "cdate": 1621630289104, "ddate": null, "tcdate": 1621630289104, "tmdate": 1697937348099, "tddate": null, "forum": "KpKWDyXq17d", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "SLOE: A Faster Method for Statistical Inference in High-Dimensional Logistic Regression", "authorids": ["~Steve_Yadlowsky1", "~Taedong_Yun1", "~Cory_Y_McLean1", "~Alexander_D'Amour1"], "authors": ["Steve Yadlowsky", "Taedong Yun", "Cory Y McLean", "Alexander D'Amour"], "keywords": ["high dimensional", "logistic regression", "statistical inference"], "TL;DR": "Simpler corrections for logistic regression in high dimensions", "abstract": "Logistic regression remains one of the most widely used tools in applied statistics, machine learning and data science. However, in moderately high-dimensional problems, where the number of features $d$ is a non-negligible fraction of the sample size $n$, the logistic regression maximum likelihood estimator (MLE), and statistical procedures based the large-sample approximation of its distribution, behave poorly. Recently, Sur and Cand\u00e8s (2019) showed that these issues can be corrected by applying a new approximation of the MLE's sampling distribution in this high-dimensional regime. Unfortunately, these corrections are difficult to implement in practice, because they require an estimate of the \\emph{signal strength}, which is a function of the underlying parameters $\\beta$ of the logistic regression. To address this issue, we propose SLOE, a fast and straightforward approach to estimate the signal strength in logistic regression. The key insight of SLOE is that the Sur and Cand\u00e8s (2019) correction can be reparameterized in terms of the corrupted signal strength, which is only a function of the estimated parameters $\\widehat \\beta$. We propose an estimator for this quantity, prove that it is consistent in the relevant high-dimensional regime, and show that dimensionality correction using SLOE is accurate in finite samples. Compared to the existing ProbeFrontier heuristic, SLOE is conceptually simpler and orders of magnitude faster, making it suitable for routine use. We demonstrate the importance of routine dimensionality correction in the Heart Disease dataset from the UCI repository, and a genomics application using data from the UK Biobank.", "submission_history": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "yadlowsky|sloe_a_faster_method_for_statistical_inference_in_highdimensional_logistic_regression", "pdf": "/pdf/a1a79ce561a47d098e823fe52bf09ccfcb76b1df.pdf", "checklist": "", "supplementary_material": "/attachment/1509789ad5b5351f363332f2d6a29d07396de799.pdf", "code": "https://github.com/google-research/sloe-logistic", "thumbnail": "", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2103.12725/code)", "_bibtex": "@inproceedings{\nyadlowsky2021sloe,\ntitle={{SLOE}: A Faster Method for Statistical Inference in High-Dimensional Logistic Regression},\nauthor={Steve Yadlowsky and Taedong Yun and Cory Y McLean and Alexander D'Amour},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=KpKWDyXq17d}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492751074, "odate": 1636492751074, "details": {"replyCount": 9}}, {"id": "Nfbe1usrgx4", "original": "ZM-DCBKA5k", "number": 10507, "cdate": 1621630284065, "ddate": null, "tcdate": 1621630284065, "tmdate": 1683307763459, "tddate": null, "forum": "Nfbe1usrgx4", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Differential Privacy Dynamics of Langevin Diffusion and Noisy Gradient Descent", "authorids": ["~Rishav_Chourasia1", "~Jiayuan_Ye1", "~Reza_Shokri1"], "authors": ["Rishav Chourasia", "Jiayuan Ye", "Reza Shokri"], "keywords": ["Differential Privacy", "Noisy Gradient Descent"], "abstract": "What is the information leakage of an iterative randomized learning algorithm about its training data, when the internal state of the algorithm is \\emph{private}? How much is the contribution of each specific training epoch to the information leakage through the released model? We study this problem for noisy gradient descent algorithms, and model the \\emph{dynamics} of R\\'enyi differential privacy loss throughout the training process.  Our analysis traces a provably \\emph{tight} bound on the R\\'enyi divergence between the pair of probability distributions over parameters of models trained on neighboring datasets.  We prove that the privacy loss converges exponentially fast, for smooth and strongly convex loss functions, which is a significant improvement over composition theorems (which over-estimate the privacy loss by upper-bounding its total value over all intermediate gradient computations). For Lipschitz, smooth, and strongly convex loss functions, we prove optimal utility with a small gradient complexity for noisy gradient descent algorithms.", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "chourasia|differential_privacy_dynamics_of_langevin_diffusion_and_noisy_gradient_descent", "pdf": "/pdf/bce5ca796174582c8a9300f1d074f18050104dd1.pdf", "supplementary_material": "/attachment/f7d85963c49ed427f86632086e3d2c1c254ae069.zip", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "checklist": "", "TL;DR": "Tight converging differential privacy analysis for noisy gradient descent when only last iterate model is released.", "thumbnail": "", "_bibtex": "@inproceedings{\nchourasia2021differential,\ntitle={Differential Privacy Dynamics of Langevin Diffusion and Noisy Gradient Descent},\nauthor={Rishav Chourasia and Jiayuan Ye and Reza Shokri},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=Nfbe1usrgx4}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492736401, "odate": 1636492736401, "details": {"replyCount": 15}}, {"id": "fIn4wLS2XzU", "original": "ljmxSwfpIAH", "number": 10477, "cdate": 1621630282225, "ddate": null, "tcdate": 1621630282225, "tmdate": 1697937351337, "tddate": null, "forum": "fIn4wLS2XzU", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Behavior From the Void: Unsupervised Active Pre-Training", "authorids": ["~Hao_Liu1", "~Pieter_Abbeel2"], "authors": ["Hao Liu", "Pieter Abbeel"], "keywords": ["unsupervised exploration", "unsupervised pretraining", "reinforcement learning"], "TL;DR": "We present an unsupervised pre-training RL method that is based on particle-based state entropy maximization and it outperforms canonical RL methods.", "abstract": "We introduce a new unsupervised pre-training method for reinforcement learning called APT, which stands for Active Pre-Training. APT learns behaviors and representations by actively searching for novel states in reward-free environments. The key novel idea is to explore the environment by maximizing a non-parametric entropy computed in an abstract representation space, which avoids challenging density modeling and consequently allows our approach to scale much better in environments that have high-dimensional observations (e.g., image observations). We empirically evaluate APT by exposing task-specific reward after a long unsupervised pre-training phase. In Atari games, APT achieves human-level performance on 12 games and obtains highly competitive performance compared to canonical fully supervised RL algorithms. On DMControl suite, APT beats all baselines in terms of asymptotic performance and data efficiency and dramatically improves performance on tasks that are extremely difficult to train from scratch. ", "submission_history": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "checklist": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "liu|behavior_from_the_void_unsupervised_active_pretraining", "pdf": "/pdf/bdf592ef5b7480c5c732c89e1c2984f9e2f53110.pdf", "supplementary_material": "/attachment/b21c6ce60043377ad0fe459439136610546dd885.pdf", "thumbnail": "", "code": "https://github.com/rll-research/url_benchmark", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2103.04551/code)", "_bibtex": "@inproceedings{\nliu2021behavior,\ntitle={Behavior From the Void: Unsupervised Active Pre-Training},\nauthor={Hao Liu and Pieter Abbeel},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=fIn4wLS2XzU}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492692092, "odate": 1636492692092, "details": {"replyCount": 12}}, {"id": "4c1EiEvivpx", "original": "pSCadSDDqi5u", "number": 10465, "cdate": 1621630281510, "ddate": null, "tcdate": 1621630281510, "tmdate": 1697937351563, "tddate": null, "forum": "4c1EiEvivpx", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Neural Scene Flow Prior", "authorids": ["~Xueqian_Li1", "~Jhony_Kaesemodel_Pontes1", "~Simon_Lucey2"], "authors": ["Xueqian Li", "Jhony Kaesemodel Pontes", "Simon Lucey"], "keywords": ["neural prior", "scene flow", "implicit regularizer"], "TL;DR": "We estimate scene flow through runtime optimization with a neural prior, which utilizes the architecture of neural networks as an implicit regularizer.", "abstract": "Before the deep learning revolution, many perception algorithms were based on runtime optimization in conjunction with a strong prior/regularization penalty. A prime example of this in computer vision is optical and scene flow. Supervised learning has largely displaced the need for explicit regularization. Instead, they rely on large amounts of labeled data to capture prior statistics, which are not always readily available for many problems. Although optimization is employed to learn the neural network, at runtime, the weights of this network are frozen. As a result, these learning solutions are domain-specific and do not generalize well to other statistically different scenarios. This paper revisits the scene flow problem that relies predominantly on runtime optimization and strong regularization. A central innovation here is the inclusion of a neural scene flow prior, which utilizes the architecture of neural networks as a new type of implicit regularizer. Unlike learning-based scene flow methods, optimization occurs at runtime, and our approach needs no offline datasets---making it ideal for deployment in new environments such as autonomous driving. We show that an architecture based exclusively on multilayer perceptrons (MLPs) can be used as a scene flow prior.  Our method attains competitive---if not better---results on scene flow benchmarks. Also, our neural prior's implicit and continuous scene flow representation allows us to estimate dense long-term correspondences across a sequence of point clouds. The dense motion information is represented by scene flow fields where points can be propagated through time by integrating motion vectors. We demonstrate such a capability by accumulating a sequence of lidar point clouds.", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "li|neural_scene_flow_prior", "pdf": "/pdf/e52c26421bd22aeb6bee6b6dd19f0ca3572881d8.pdf", "supplementary_material": "/attachment/5efbdb7661e78f042b7159a1fc2a66d382fe36e0.zip", "code": "https://github.com/Lilac-Lee/Neural_Scene_Flow_Prior", "thumbnail": "", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 2 code implementations](https://www.catalyzex.com/paper/arxiv:2111.01253/code)", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "checklist": "", "_bibtex": "@inproceedings{\nli2021neural,\ntitle={Neural Scene Flow Prior},\nauthor={Xueqian Li and Jhony Kaesemodel Pontes and Simon Lucey},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=4c1EiEvivpx}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492705376, "odate": 1636492705376, "details": {"replyCount": 19}}, {"id": "SvrYl-FDq2", "original": "BVlUEchMCXf", "number": 10402, "cdate": 1621630277668, "ddate": null, "tcdate": 1621630277668, "tmdate": 1683307761616, "tddate": null, "forum": "SvrYl-FDq2", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Sliced Mutual Information: A Scalable Measure of Statistical Dependence", "authorids": ["~Ziv_Goldfeld1", "~Kristjan_Greenewald1"], "authors": ["Ziv Goldfeld", "Kristjan Greenewald"], "keywords": ["mutual information", "sliced mutual information", "curse of dimensionality", "feature extraction", "independence tests"], "abstract": " Mutual information (MI) is a fundamental measure of statistical dependence, with a myriad of applications to information theory, statistics, and machine learning. While it possesses many desirable structural properties, the estimation of high-dimensional MI from samples suffers from the curse of dimensionality. Motivated by statistical scalability to high dimensions, this paper proposes sliced MI (SMI) as a surrogate measure of dependence. SMI is defined as an average of MI terms between one-dimensional random projections. We show that it preserves many of the structural properties of classic MI, while gaining scalable computation and efficient estimation from samples. Furthermore, and in contrast to classic MI, SMI can grow as a result of deterministic transformations. This enables leveraging SMI for feature extraction by optimizing it over processing functions of raw data to identify useful representations thereof. Our theory is supported by numerical studies of independence testing and feature extraction, which demonstrate the potential gains SMI offers over classic MI for high-dimensional inference.", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "goldfeld|sliced_mutual_information_a_scalable_measure_of_statistical_dependence", "pdf": "/pdf/1b9b6ef0da1009871d71f6bb347c7d3ce884aa58.pdf", "checklist": "", "supplementary_material": "/attachment/84d03c77af23826a3aa6e1e017649f4e63e99030.pdf", "thumbnail": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\ngoldfeld2021sliced,\ntitle={Sliced Mutual Information: A Scalable Measure of Statistical Dependence},\nauthor={Ziv Goldfeld and Kristjan Greenewald},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=SvrYl-FDq2}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492779399, "odate": 1636492779359, "details": {"replyCount": 11}}, {"id": "lVmIjQiJJSr", "original": "vVJo81JrZus", "number": 10400, "cdate": 1621630277549, "ddate": null, "tcdate": 1621630277549, "tmdate": 1683307761460, "tddate": null, "forum": "lVmIjQiJJSr", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Removing Inter-Experimental Variability from Functional Data in Systems Neuroscience", "authorids": ["~Dominic_Gonschorek2", "~Larissa_H\u00f6fling1", "~Klaudia_P._Szatko1", "~Katrin_Franke1", "~Timm_Schubert1", "~Benjamin_Adric_Dunn1", "~Philipp_Berens1", "~David_A._Klindt1", "~Thomas_Euler1"], "authors": ["Dominic Gonschorek", "Larissa H\u00f6fling", "Klaudia P. Szatko", "Katrin Franke", "Timm Schubert", "Benjamin Adric Dunn", "Philipp Berens", "David A. Klindt", "Thomas Euler"], "keywords": ["systems neuroscience", "inter-experimental variability", "cell type classification", "retina", "domain adaptation", "autoencoder", "adversarial optimization"], "TL;DR": "We offer a flexible approach to remove inter-experimental variability and integrate datasets across experiments in systems neuroscience.", "abstract": "Integrating data from multiple experiments is common practice in systems neuroscience but it requires inter-experimental variability to be negligible compared to the biological signal of interest. This requirement is rarely fulfilled; systematic changes between experiments can drastically affect the outcome of complex analysis pipelines. Modern machine learning approaches designed to adapt models across multiple data domains offer flexible ways of removing inter-experimental variability where classical statistical methods often fail. While applications of these methods have been mostly limited to single-cell genomics, in this work, we develop a theoretical framework for domain adaptation in systems neuroscience. We implement this in an adversarial optimization scheme that removes inter-experimental variability while preserving the biological signal. We compare our method to previous approaches on a large-scale dataset of two-photon imaging recordings of retinal bipolar cell responses to visual stimuli. This dataset provides a unique benchmark as it contains biological signal from well-defined cell types that is obscured by large inter-experimental variability. In a supervised setting, we compare the generalization performance of cell type classifiers across experiments, which we validate with anatomical cell type distributions from electron microscopy data. In an unsupervised setting, we remove inter-experimental variability from the data which can then be fed into arbitrary downstream analyses. In both settings, we find that our method achieves the best trade-off between removing inter-experimental variability and preserving biological signal. Thus, we offer a flexible approach to remove inter-experimental variability and integrate datasets across experiments in systems neuroscience. Code available at https://github.com/eulerlab/rave.", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "gonschorek|removing_interexperimental_variability_from_functional_data_in_systems_neuroscience", "pdf": "/pdf/0cb21e5542996679989b8dfd64ddaa977b112f09.pdf", "checklist": "", "supplementary_material": "/attachment/dd258accadf56610a9386b4588a7c71dfa2612be.pdf", "code": "https://github.com/eulerlab/rave", "thumbnail": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\ngonschorek2021removing,\ntitle={Removing Inter-Experimental Variability from Functional Data in Systems Neuroscience},\nauthor={Dominic Gonschorek and Larissa H{\\\"o}fling and Klaudia P. Szatko and Katrin Franke and Timm Schubert and Benjamin Adric Dunn and Philipp Berens and David A. Klindt and Thomas Euler},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=lVmIjQiJJSr}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492670501, "odate": 1636492670501, "details": {"replyCount": 13}}, {"id": "P9_gOq5w7Eb", "original": "E_FJ4caTlgk", "number": 10360, "cdate": 1621630275147, "ddate": null, "tcdate": 1621630275147, "tmdate": 1683307761083, "tddate": null, "forum": "P9_gOq5w7Eb", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Towards optimally abstaining from prediction with OOD test examples", "authorids": ["~Adam_Tauman_Kalai1", "~Varun_Kanade1"], "authors": ["Adam Tauman Kalai", "Varun Kanade"], "keywords": ["Selective classification", "covariate shift", "classification with a reject option"], "TL;DR": "Near-optimal guarantees for selective classification (with the option to abstain at a cost), with extreme covariate shift where train and test distributions do not even fully overlap", "abstract": "A common challenge across all areas of machine learning is that training data is not distributed like test data, due to natural shifts or adversarial examples; such examples are referred to as out-of-distribution (OOD) test examples. We consider a model where one may abstain from predicting, at a fixed cost. In particular, our transductive abstention algorithm takes labeled training examples and unlabeled test examples as input, and provides predictions with optimal prediction loss guarantees. The loss bounds match standard generalization bounds when test examples are i.i.d. from the training distribution, but add an additional term that is the cost of abstaining times the statistical distance between the train and test distribution (or the fraction of adversarial examples). For linear regression, we give a polynomial-time algorithm based on Celis-Dennis-Tapia optimization algorithms. For binary classification, we show how to efficiently implement it using a proper agnostic learner (i.e., an Empirical Risk Minimizer) for the class of interest. Our work builds on recent work of Goldwasser, Kalais, and Montasser (2020) who gave error and abstention guarantees for transductive binary classification.", "pdf": "/pdf/3f23d88b8c3255a32dd2cf4c9fd5dbdbae56c810.pdf", "supplementary_material": "/attachment/318c524090aa4322edea9ea4e655cb274a5ab116.pdf", "submission_history": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "checklist": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "kalai|towards_optimally_abstaining_from_prediction_with_ood_test_examples", "thumbnail": "", "_bibtex": "@inproceedings{\nkalai2021towards,\ntitle={Towards optimally abstaining from prediction with {OOD} test examples},\nauthor={Adam Tauman Kalai and Varun Kanade},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=P9_gOq5w7Eb}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492762584, "odate": 1636492762584, "details": {"replyCount": 10}}, {"id": "7rYDxRb1eSa", "original": "NWu1pisF_L_", "number": 10356, "cdate": 1621630274921, "ddate": null, "tcdate": 1621630274921, "tmdate": 1683307760921, "tddate": null, "forum": "7rYDxRb1eSa", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Bias and variance of the Bayesian-mean decoder", "authorids": ["~Arthur_Prat-Carrabin1", "~Michael_Woodford1"], "authors": ["Arthur Prat-Carrabin", "Michael Woodford"], "keywords": ["neuroscience", "perception", "encoding-decoding models", "efficient coding", "Bayesian inference", "Bayesian mean", "perceptual biases"], "TL;DR": "We present an analytical approximation to the mean of the Bayesian posterior, as a function of the prior and of the encoding Fisher information, and study the resulting perceptual biases under different encoding strategies.", "abstract": "Perception, in theoretical neuroscience, has been modeled as the encoding of external stimuli into internal signals, which are then decoded. The Bayesian mean is an important decoder, as it is optimal for purposes of both estimation and discrimination. We present widely-applicable approximations to the bias and to the variance of the Bayesian mean, obtained under the minimal and biologically-relevant assumption that the encoding results from a series of independent, though not necessarily identically-distributed, signals. Simulations substantiate the accuracy of our approximations in the small-noise regime. The bias of the Bayesian mean comprises two components: one driven by the prior, and one driven by the precision of the encoding. If the encoding is 'efficient', the two components have opposite effects; their relative strengths are determined by the objective that the encoding optimizes. The experimental literature on perception reports both 'Bayesian' biases directed towards prior expectations, and opposite, 'anti-Bayesian' biases. We show that different tasks are indeed predicted to yield such contradictory biases, under a consistently-optimal encoding-decoding model. Moreover, we recover Wei and Stocker's \"law of human perception\", a relation between the bias of the Bayesian mean and the derivative of its variance, and show how the coefficient of proportionality in this law depends on the task at hand. Our results provide a parsimonious theory of optimal perception under constraints, in which encoding and decoding are adapted both to the prior and to the task faced by the observer.", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "pratcarrabin|bias_and_variance_of_the_bayesianmean_decoder", "pdf": "/pdf/a0e736ba84064206f899600bc1c8e6b4f1ab5f64.pdf", "supplementary_material": "/attachment/4bba5d0c20f6dd71f97fedf1f69c6fff437e07a1.pdf", "checklist": "", "thumbnail": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nprat-carrabin2021bias,\ntitle={Bias and variance of the Bayesian-mean decoder},\nauthor={Arthur Prat-Carrabin and Michael Woodford},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=7rYDxRb1eSa}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492768277, "odate": 1636492768277, "details": {"replyCount": 9}}, {"id": "l4DQWgjbZg", "original": "q3YoATwF_3z", "number": 10354, "cdate": 1621630274802, "ddate": null, "tcdate": 1621630274802, "tmdate": 1683307760599, "tddate": null, "forum": "l4DQWgjbZg", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Forster Decomposition and Learning Halfspaces with Noise", "authorids": ["~Ilias_Diakonikolas1", "~Daniel_Kane1", "~Christos_Tzamos1"], "authors": ["Ilias Diakonikolas", "Daniel Kane", "Christos Tzamos"], "keywords": ["learning theory", "Forster transform", "halfspaces", "Massart noise"], "abstract": "A Forster transform is an operation that turns a multivariate distribution into one with good anti-concentration properties. While a Forster transform does not always exist, we show that any distribution can be efficiently decomposed as a disjoint mixture of few distributions for which a Forster transform exists and can be computed efficiently. As the main application of this result, we obtain the first polynomial-time algorithm for distribution-independent PAC learning of halfspaces in the Massart noise model with strongly polynomial sample complexity, i.e., independent of the bit complexity of the examples. Previous algorithms for this learning problem incurred sample complexity scaling polynomially with the bit complexity, even though such a dependence is not information-theoretically necessary.\n", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "diakonikolas|forster_decomposition_and_learning_halfspaces_with_noise", "TL;DR": "First efficient learning algorithm for Massart halfspaces with sample complexity independent of the bit complexity of the examples.", "pdf": "/pdf/afeeb9f3448feeadd0b373af7e2014eb8c8fb3ec.pdf", "checklist": "", "supplementary_material": "/attachment/6ad7018b0d90a657a23df430b906e0d186fc03d0.pdf", "thumbnail": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\ndiakonikolas2021forster,\ntitle={Forster Decomposition and Learning Halfspaces with Noise},\nauthor={Ilias Diakonikolas and Daniel Kane and Christos Tzamos},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=l4DQWgjbZg}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492720297, "odate": 1636492720252, "details": {"replyCount": 12}}, {"id": "e2gqGkFjDHg", "original": "r-3eMMJE4vK", "number": 10344, "cdate": 1621630274197, "ddate": null, "tcdate": 1621630274197, "tmdate": 1683307760503, "tddate": null, "forum": "e2gqGkFjDHg", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Redesigning the Transformer Architecture with Insights from Multi-particle Dynamical Systems", "authorids": ["~Subhabrata_Dutta1", "~Tanya_Gautam1", "~Soumen_Chakrabarti1", "~Tanmoy_Chakraborty1"], "authors": ["Subhabrata Dutta", "Tanya Gautam", "Soumen Chakrabarti", "Tanmoy Chakraborty"], "keywords": ["Transformers", "Dynamical systems", "Time-evolution", "Self-attention"], "abstract": "The Transformer and its variants have been proven to be efficient sequence learners in many different domains. Despite their staggering success, a critical issue has been the enormous number of parameters that must be trained (ranging from $10^7$ to $10^{11}$) along with the quadratic complexity of dot-product attention. In this work, we investigate the problem of approximating the two central components of the Transformer --- multi-head self-attention and point-wise feed-forward transformation, with reduced parameter space and computational complexity. We build upon recent developments in analyzing deep neural networks as numerical solvers of ordinary differential equations. Taking advantage of an analogy between Transformer stages and the evolution of a dynamical system of multiple interacting particles, we formulate a temporal evolution scheme, \\name, to bypass costly dot-product attention over multiple stacked layers.  We perform exhaustive experiments with \\name\\ on well-known encoder-decoder as well as encoder-only tasks. We observe that the degree of approximation (or inversely, the degree of parameter reduction) has different effects on the performance, depending on the task. While in the encoder-decoder regime, \\name\\ delivers performances comparable to the original Transformer, in encoder-only tasks it consistently outperforms Transformer along with several subsequent variants.", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "dutta|redesigning_the_transformer_architecture_with_insights_from_multiparticle_dynamical_systems", "pdf": "/pdf/47f4f2c76dfb82eb0065c80df4efd28f0a61421a.pdf", "checklist": "", "supplementary_material": "/attachment/947370b81c875b6bda0f309a75d2b223bdf1c5a0.pdf", "TL;DR": "A dynamical system motivated Transformer-variant that can achieves state-of-the-art performance with astoundingly fewer parameters.", "code": "https://github.com/LCS2-IIITD/TransEvolve", "thumbnail": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\ndutta2021redesigning,\ntitle={Redesigning the Transformer Architecture with Insights from Multi-particle Dynamical Systems},\nauthor={Subhabrata Dutta and Tanya Gautam and Soumen Chakrabarti and Tanmoy Chakraborty},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=e2gqGkFjDHg}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492723100, "odate": 1636492723100, "details": {"replyCount": 15}}, {"id": "1bBF5Zq1YHz", "original": "fy4XHSmg9tA", "number": 10341, "cdate": 1621630274006, "ddate": null, "tcdate": 1621630274006, "tmdate": 1683307760280, "tddate": null, "forum": "1bBF5Zq1YHz", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Probabilistic Tensor Decomposition of Neural Population Spiking Activity", "authorids": ["~Hugo_Soulat2", "~Sepiedeh_Keshavarzi1", "~Troy_William_Margrie1", "~Maneesh_Sahani1"], "authors": ["Hugo Soulat", "Sepiedeh Keshavarzi", "Troy William Margrie", "Maneesh Sahani"], "keywords": ["Probabilistic", "Tensor Decomposition", "Neuroscience", "Spike", "Population Activity", "Count"], "abstract": "The firing of neural populations is coordinated across cells, in time, and across experimental\nconditions or repeated experimental trials; and so a full understanding of the computational\nsignificance of neural responses must be based on a separation of these different contributions to\nstructured activity.\n\nTensor decomposition is an approach to untangling the influence of multiple factors in data that is\ncommon in many fields.  However, despite some recent interest in neuroscience, wider applicability\nof the approach is hampered by the lack of a full probabilistic treatment allowing principled\ninference of a decomposition from non-Gaussian spike-count data.\nHere, we extend the P\u00f3lya-Gamma (PG) augmentation, previously used in sampling-based Bayesian\ninference, to implement scalable variational inference in non-conjugate spike-count models.\n\nUsing this new approach, we develop techniques related to automatic relevance determination to infer\nthe most appropriate tensor rank, as well as to incorporate priors based on known brain anatomy such\nas the segregation of cell response properties by brain area.\n\nWe apply the model to neural recordings taken under conditions of visual-vestibular sensory\nintegration, revealing how the encoding of self- and visual-motion signals is modulated by the\nsensory information available to the animal.", "submission_history": "", "checklist": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "soulat|probabilistic_tensor_decomposition_of_neural_population_spiking_activity", "pdf": "/pdf/0219c0b63bfa2e8fa16570221cd68bdf09c41ea0.pdf", "supplementary_material": "/attachment/7b9cdd61fe10c89a6ff8e32c5f1bb6c97baecdf9.pdf", "code": "https://github.com/hugosou/vbgcp", "thumbnail": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nsoulat2021probabilistic,\ntitle={Probabilistic Tensor Decomposition of Neural Population Spiking Activity},\nauthor={Hugo Soulat and Sepiedeh Keshavarzi and Troy William Margrie and Maneesh Sahani},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=1bBF5Zq1YHz}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492676903, "odate": 1636492676903, "details": {"replyCount": 10}}, {"id": "usxt30HpW66", "original": "D1mYxt531sL", "number": 10299, "cdate": 1621630271522, "ddate": null, "tcdate": 1621630271522, "tmdate": 1683307759692, "tddate": null, "forum": "usxt30HpW66", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "What\u2019s a good imputation to predict with missing values?", "authorids": ["~Marine_Le_Morvan2", "~Julie_Josse1", "~Erwan_Scornet1", "~Gael_Varoquaux1"], "authors": ["Marine Le Morvan", "Julie Josse", "Erwan Scornet", "Gael Varoquaux"], "keywords": ["missing values", "neural networks", "Bayes optimality", "consistency"], "abstract": "How to learn a good predictor on data with missing values? Most efforts focus on first imputing as well as possible and second learning on the completed data to predict the outcome. Yet, this widespread practice has no theoretical grounding. Here we show that for almost all imputation functions, an impute-then-regress procedure with a powerful learner is Bayes optimal. This result holds for all missing-values mechanisms, in contrast with the classic statistical results that require missing-at-random settings to use imputation in probabilistic modeling. Moreover, it implies that perfect conditional imputation is not needed for good prediction asymptotically. In fact, we show that on perfectly imputed data the best regression function will generally be discontinuous, which makes it hard to learn. Crafting instead the imputation so as to leave the regression function unchanged simply shifts the problem to learning discontinuous imputations. Rather, we suggest that it is easier to learn imputation and regression jointly. We propose such a procedure, adapting NeuMiss, a neural network capturing the conditional links across observed and unobserved variables whatever the missing-value pattern. Our experiments confirm that joint imputation and regression through NeuMiss is better than various two step procedures in a finite-sample regime.  ", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "morvan|whats_a_good_imputation_to_predict_with_missing_values", "pdf": "/pdf/5594c28c4c2528d1438238a5675f64dba43f948d.pdf", "supplementary_material": "/attachment/36d1879473a634cdc3ff257e8f390bf2ad75423c.pdf", "checklist": "", "code": "https://github.com/marineLM/Impute_then_Regress", "thumbnail": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nmorvan2021whats,\ntitle={What{\\textquoteright}s a good imputation to predict with missing values?},\nauthor={Marine Le Morvan and Julie Josse and Erwan Scornet and Gael Varoquaux},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=usxt30HpW66}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492688763, "odate": 1636492688763, "details": {"replyCount": 10}}, {"id": "sNw3VBPL7rg", "original": "LgPM4xLExNl", "number": 10283, "cdate": 1621630270523, "ddate": null, "tcdate": 1621630270523, "tmdate": 1683307759206, "tddate": null, "forum": "sNw3VBPL7rg", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Calibration and Consistency of Adversarial Surrogate Losses", "authorids": ["~Pranjal_Awasthi3", "~Natalie_Frank1", "~Anqi_Mao1", "~Mehryar_Mohri2", "~Yutao_Zhong1"], "authors": ["Pranjal Awasthi", "Natalie Frank", "Anqi Mao", "Mehryar Mohri", "Yutao Zhong"], "keywords": ["Adversarial Robustness", "Learning Theory", "Consistency", "Calibration", "Statistical learning", "Classification."], "abstract": "Adversarial robustness is an increasingly critical property of classifiers in applications. The design of robust algorithms relies on surrogate losses since the optimization of the adversarial loss with most hypothesis sets is NP-hard. But, which surrogate losses should be used and when do they benefit from theoretical guarantees? We present an extensive study of this question, including a detailed analysis of the $\\mathcal{H}$-calibration and $\\mathcal{H}$-consistency of adversarial surrogate losses. We show that convex loss functions, or the supremum-based convex losses often used in applications, are not $\\mathcal{H}$-calibrated for common hypothesis sets used in machine learning. We then give a characterization of $\\mathcal{H}$-calibration and prove that some surrogate losses are indeed $\\mathcal{H}$-calibrated for the adversarial zero-one loss, with common hypothesis sets. In particular, we fix some calibration results presented in prior work for a family of linear models and significantly generalize the results to the nonlinear hypothesis sets. Next, we show that $\\mathcal{H}$-calibration is not sufficient to guarantee consistency and prove that, in the absence of any distributional assumption, no continuous surrogate loss is consistent in the adversarial setting. This, in particular, proves that a claim made in prior work is inaccurate. Next, we identify natural conditions under which some surrogate losses that we describe in detail are $\\mathcal{H}$-consistent. We also report a series of empirical results which show that many $\\mathcal{H}$-calibrated surrogate losses are indeed not $\\mathcal{H}$-consistent, and validate our theoretical assumptions. Our adversarial $\\mathcal{H}$-consistency results are novel, even for the case where $\\mathcal{H}$ is the family of all measurable functions.", "submission_history": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "awasthi|calibration_and_consistency_of_adversarial_surrogate_losses", "pdf": "/pdf/b41be5fff4203186f87daff7519ee9e44918bdfc.pdf", "supplementary_material": "/attachment/dcf18954ae356f2799aa05b54ca88db90f11d052.pdf", "checklist": "", "thumbnail": "", "_bibtex": "@inproceedings{\nawasthi2021calibration,\ntitle={Calibration and Consistency of Adversarial Surrogate Losses},\nauthor={Pranjal Awasthi and Natalie Frank and Anqi Mao and Mehryar Mohri and Yutao Zhong},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=sNw3VBPL7rg}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492732086, "odate": 1636492732086, "details": {"replyCount": 16}}, {"id": "hzioAx8g9x", "original": "0c9fVp19niO", "number": 10265, "cdate": 1621630269478, "ddate": null, "tcdate": 1621630269478, "tmdate": 1697937357108, "tddate": null, "forum": "hzioAx8g9x", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Neural optimal feedback control with local learning rules", "authorids": ["~Johannes_Friedrich1", "~Siavash_Golkar1", "~Shiva_Farashahi1", "~Alexander_Genkin1", "~Anirvan_M._Sengupta2", "~Dmitri_Chklovskii1"], "authors": ["Johannes Friedrich", "Siavash Golkar", "Shiva Farashahi", "Alexander Genkin", "Anirvan M. Sengupta", "Dmitri Chklovskii"], "keywords": ["optimal feedback control", "Kalman filter", "motor control", "neural circuit"], "abstract": "A major problem in motor control is understanding how the brain plans and executes proper movements in the face of delayed and noisy stimuli. A prominent framework for addressing such control problems is Optimal Feedback Control (OFC). OFC generates control actions that optimize behaviorally relevant criteria by integrating noisy sensory stimuli and the predictions of an internal model using the Kalman filter or its extensions. However, a satisfactory neural model of Kalman filtering and control is lacking because existing proposals have the following  limitations: not considering the delay of sensory feedback, training in alternating phases, requiring knowledge of the noise covariance matrices, as well as that of systems dynamics. Moreover, the majority of these studies considered Kalman filtering in isolation, and not jointly with control. To address these shortcomings, we introduce a novel online algorithm which combines adaptive Kalman filtering with a model free control approach  (i.e., policy gradient algorithm). We implement this algorithm in a biologically plausible neural network with local synaptic plasticity rules. This network, with local synaptic plasticity rules, performs system identification, Kalman filtering and control with delayed noisy sensory feedback. This network performs system identification and Kalman filtering, without the need for multiple phases with distinct update rules or the knowledge of the noise covariances. It can perform state estimation  with delayed sensory feedback, with the help of an internal model. It learns the control policy without requiring any knowledge of the dynamics, thus avoiding the need for weight transport. In this way, our implementation of OFC solves the credit assignment problem needed to produce the appropriate sensory-motor control in the presence of stimulus delay.", "submission_history": "", "checklist": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "friedrich|neural_optimal_feedback_control_with_local_learning_rules", "pdf": "/pdf/d82466435d9e63d4133d2da4e3aadce0ae1e67ce.pdf", "supplementary_material": "/attachment/19fec8c16e7771f56365887aa242a3d03d43e8cd.pdf", "TL;DR": "The paper introduces a biologically plausible neural implementation of optimal feedback control, which considers that sensory feedback is delayed, and combines adaptive Kalman filtering and model free control.", "code": "https://github.com/j-friedrich/neuralOFC", "thumbnail": "", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 2 code implementations](https://www.catalyzex.com/paper/arxiv:2111.06920/code)", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nfriedrich2021neural,\ntitle={Neural optimal feedback control with local learning rules},\nauthor={Johannes Friedrich and Siavash Golkar and Shiva Farashahi and Alexander Genkin and Anirvan M. Sengupta and Dmitri Chklovskii},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=hzioAx8g9x}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492679556, "odate": 1636492679556, "details": {"replyCount": 13}}, {"id": "tjdHCnPqoo", "original": "SCsoaw0ur82H", "number": 10209, "cdate": 1621630266098, "ddate": null, "tcdate": 1621630266098, "tmdate": 1683307758135, "tddate": null, "forum": "tjdHCnPqoo", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Is Automated Topic Model Evaluation Broken? The Incoherence of Coherence", "authorids": ["~Alexander_Hoyle1", "~Pranav_Goel1", "~Andrew_Hian-Cheong1", "~Denis_Peskov1", "~Jordan_Lee_Boyd-Graber1", "~Philip_Resnik1"], "authors": ["Alexander Hoyle", "Pranav Goel", "Andrew Hian-Cheong", "Denis Peskov", "Jordan Lee Boyd-Graber", "Philip Resnik"], "keywords": ["topic model", "topic model evaluation", "npmi", "topic coherence", "human evaluation", "metric", "evaluation", "validation", "crowdsourcing", "model comparison", "automatic metric", "automated metric"], "abstract": "Topic model evaluation, like evaluation of other unsupervised methods, can be contentious. However, the field has coalesced around automated estimates of topic coherence, which rely on the frequency of word co-occurrences in a reference corpus. Contemporary neural topic models surpass classical ones according to these metrics. At the same time, topic model evaluation suffers from a validation gap: automated coherence, developed for classical models, has not been validated using human experimentation for neural models. In addition, a meta-analysis of topic modeling literature reveals a substantial standardization gap in automated topic modeling benchmarks. To address the validation gap, we compare automated coherence with the two most widely accepted human judgment tasks: topic rating and word intrusion. To address the standardization gap, we systematically evaluate a dominant classical model and two state-of-the-art neural models on two commonly used datasets. Automated evaluations declare a winning model when corresponding human evaluations do not, calling into question the validity of fully automatic evaluations independent of human judgments.", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "hoyle|is_automated_topic_model_evaluation_broken_the_incoherence_of_coherence", "TL;DR": "Yes, automated topic evaluation is broken.", "pdf": "/pdf/96eaa5e2e00db5cc7ab8c585f16b3c4374379ef6.pdf", "checklist": "", "supplementary_material": "/attachment/99104fbe89a37caa081f42a6d0943be61625ffc0.pdf", "code": "https://www.github.com/ahoho/topics", "thumbnail": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nhoyle2021is,\ntitle={Is Automated Topic Model Evaluation Broken? The Incoherence of Coherence},\nauthor={Alexander Hoyle and Pranav Goel and Andrew Hian-Cheong and Denis Peskov and Jordan Lee Boyd-Graber and Philip Resnik},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=tjdHCnPqoo}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492707431, "odate": 1636492707431, "details": {"replyCount": 13}}, {"id": "bXTxva_xx6r", "original": "gdDcNnmeB8D", "number": 10203, "cdate": 1621630265705, "ddate": null, "tcdate": 1621630265705, "tmdate": 1697937359026, "tddate": null, "forum": "bXTxva_xx6r", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Generalized Depthwise-Separable Convolutions for Adversarially Robust and Efficient Neural Networks", "authorids": ["~Hassan_Dbouk1", "~Naresh_Shanbhag1"], "authors": ["Hassan Dbouk", "Naresh Shanbhag"], "keywords": ["adversarial robustness", "efficient inference", "generalized depthwise-seprarable", "convolutions", "neural networks"], "abstract": "Despite their tremendous successes, convolutional neural networks (CNNs) incur high computational/storage costs and are vulnerable to adversarial perturbations. Recent works on robust model compression address these challenges by combining model compression techniques with adversarial training. But these methods are unable to improve throughput (frames-per-second) on real-life hardware while simultaneously preserving robustness to adversarial perturbations. To overcome this problem, we propose the method of Generalized Depthwise-Separable (GDWS) convolution - an efficient, universal, post-training approximation of a standard 2D convolution. GDWS dramatically improves the throughput of a standard pre-trained network on real-life hardware while preserving its robustness. Lastly, GDWS is scalable to large problem sizes since it operates on pre-trained models and doesn't require any additional training. We establish the optimality of GDWS as a 2D convolution approximator and present exact algorithms for constructing optimal GDWS convolutions under complexity and error constraints. We demonstrate the effectiveness of GDWS via extensive experiments on CIFAR-10, SVHN, and ImageNet datasets. Our code can be found at https://github.com/hsndbk4/GDWS.", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "dbouk|generalized_depthwiseseparable_convolutions_for_adversarially_robust_and_efficient_neural_networks", "TL;DR": "We propose Generalized Depthwise-Separable convolutions as an efficient approximation of standard 2D convolutions that dramatically improve the throughput of an arbitrary pre-trained network on real-life hardware while preserving its robustness.", "pdf": "/pdf/d534bfc36a98b994d548d563a345b11771e29d46.pdf", "checklist": "", "supplementary_material": "/attachment/85f542db885d3c3305ebc6a68afee07cc5fd83aa.pdf", "code": "https://github.com/hsndbk4/GDWS", "thumbnail": "", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2110.14871/code)", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\ndbouk2021generalized,\ntitle={Generalized Depthwise-Separable Convolutions for Adversarially Robust and Efficient Neural Networks},\nauthor={Hassan Dbouk and Naresh Shanbhag},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=bXTxva_xx6r}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492709198, "odate": 1636492709155, "details": {"replyCount": 13}}, {"id": "6fmgB38rLI1", "original": "SsJGIRNayXUf", "number": 10119, "cdate": 1621630260792, "ddate": null, "tcdate": 1621630260792, "tmdate": 1683307756001, "tddate": null, "forum": "6fmgB38rLI1", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Multimodal and Multilingual Embeddings for Large-Scale Speech Mining", "authorids": ["~Paul-Ambroise_Duquenne1", "~Hongyu_Gong1", "~Holger_Schwenk1"], "authors": ["Paul-Ambroise Duquenne", "Hongyu Gong", "Holger Schwenk"], "keywords": ["Speech Mining", "Large-scale mining", "Speech Translation"], "abstract": "We present an approach to encode a speech signal into a fixed-size representation which minimizes the cosine loss with the existing massively multilingual LASER text embedding space. Sentences are close in this embedding space, independently of their language and modality, either text or audio. Using a similarity metric in that multimodal embedding space, we perform mining of audio in German, French, Spanish and English from Librivox against billions of sentences from Common Crawl. This yielded more than twenty thousand hours of aligned speech translations.  To evaluate the automatically mined speech/text corpora, we train neural speech translation systems for several languages pairs. Adding the mined data, achieves significant improvements in the BLEU score on the CoVoST2 and the MUST-C test sets with respect to a very competitive baseline. Our approach can also be used to directly perform speech-to-speech mining, without the need to first transcribe or translate the data. We obtain more than one thousand three hundred hours of aligned speech in French, German, Spanish and English. This speech corpus has the potential to boost research in speech-to-speech translation which suffers from scarcity of natural end-to-end training data. All the mined multimodal corpora will be made freely available.", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "duquenne|multimodal_and_multilingual_embeddings_for_largescale_speech_mining", "TL;DR": "We train a fixed-size speech embedding which is compatible with LASER text embedding. More than 20000h of mined speech translations, significant improvement of SOTA S2T system on CoVoST2. Proof of concept of direct speech-to-speech mining.", "pdf": "/pdf/323b06b17e9d64aff536c9cfd341f591d7f21139.pdf", "checklist": "", "supplementary_material": "/attachment/611541caf56f3997351fd7136e3f55c22a3f5e16.pdf", "thumbnail": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nduquenne2021multimodal,\ntitle={Multimodal and Multilingual Embeddings for Large-Scale Speech Mining},\nauthor={Paul-Ambroise Duquenne and Hongyu Gong and Holger Schwenk},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=6fmgB38rLI1}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492730704, "odate": 1636492730704, "details": {"replyCount": 12}}, {"id": "af_hng9tuNj", "original": "mq2DfmiyMtj", "number": 10081, "cdate": 1621630258506, "ddate": null, "tcdate": 1621630258506, "tmdate": 1683307755140, "tddate": null, "forum": "af_hng9tuNj", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "GeoMol: Torsional Geometric Generation of Molecular 3D Conformer Ensembles", "authorids": ["~Octavian-Eugen_Ganea1", "~Lagnajit_Pattanaik1", "~Connor_W._Coley1", "~Regina_Barzilay1", "~Klavs_Jensen1", "~William_Green1", "~Tommi_S._Jaakkola1"], "authors": ["Octavian-Eugen Ganea", "Lagnajit Pattanaik", "Connor W. Coley", "Regina Barzilay", "Klavs Jensen", "William Green", "Tommi S. Jaakkola"], "keywords": ["molecular conformer generation", "molecular geometry", "molecular generative models", "message passing neural networks", "3D generation", "molecular conformations"], "TL;DR": "We generate ensembles of molecular 3D conformers from the input molecular graph in an end-to-end fashion by explicitly modeling local atomic 3D structures, torsion angles, chirality, and other geometric elements. ", "abstract": "Prediction of a molecule\u2019s 3D conformer ensemble from the molecular graph holds a key role in areas of cheminformatics and drug discovery. Existing generative models have several drawbacks including lack of modeling important molecular geometry elements (e.g., torsion angles), separate optimization stages prone to error accumulation, and the need for structure fine-tuning based on approximate classical force-fields or computationally expensive methods. We propose GEOMOL --- an end-to-end, non-autoregressive, and SE(3)-invariant machine learning approach to generate distributions of low-energy molecular 3D conformers. Leveraging the power of message passing neural networks (MPNNs) to capture local and global graph information, we predict local atomic 3D structures and torsion angles, avoid- ing unnecessary over-parameterization of the geometric degrees of freedom (e.g., one angle per non-terminal bond). Such local predictions suffice both for both the training loss computation and for the full deterministic conformer assembly (at test time). We devise a non-adversarial optimal transport based loss function to promote diverse conformer generation. GEOMOL predominantly outperforms popular open-source, commercial, or state-of-the-art machine learning (ML) models, while achieving significant speed-ups. We expect such differentiable 3D structure generators to significantly impact molecular modeling and related applications.", "submission_history": "", "checklist": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "ganea|geomol_torsional_geometric_generation_of_molecular_3d_conformer_ensembles", "pdf": "/pdf/60d0a45d080911f2c4b597a0681841557860f69c.pdf", "supplementary_material": "/attachment/b96c79f28e2d6819d2525dab378104c20a07142e.pdf", "code": "https://github.com/PattanaikL/GeoMol", "thumbnail": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nganea2021geomol,\ntitle={GeoMol: Torsional Geometric Generation of Molecular 3D Conformer Ensembles},\nauthor={Octavian-Eugen Ganea and Lagnajit Pattanaik and Connor W. Coley and Regina Barzilay and Klavs Jensen and William Green and Tommi S. Jaakkola},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=af_hng9tuNj}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492701508, "odate": 1636492701508, "details": {"replyCount": 9}}, {"id": "tMFTT3BDEK9", "original": "fd2H4TQJ-Ut", "number": 10067, "cdate": 1621630257683, "ddate": null, "tcdate": 1621630257683, "tmdate": 1683307754894, "tddate": null, "forum": "tMFTT3BDEK9", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Look at What I\u2019m Doing: Self-Supervised Spatial Grounding of Narrations in Instructional Videos", "authorids": ["~Reuben_Tan1", "~Bryan_A._Plummer1", "~Kate_Saenko1", "~Hailin_Jin1", "~Bryan_Russell1"], "authors": ["Reuben Tan", "Bryan A. Plummer", "Kate Saenko", "Hailin Jin", "Bryan Russell"], "keywords": ["Self-supervision", "video understanding", "natural language"], "TL;DR": "Self-supervised interaction grounding in videos", "abstract": "We introduce the task of spatially localizing narrated interactions in videos. Key to our approach is the ability to learn to spatially localize interactions with self-supervision on a large corpus of videos with accompanying transcribed narrations. \nTo achieve this goal, we propose a multilayer cross-modal attention network that enables effective optimization of a contrastive loss during training. We introduce a divided strategy that alternates between computing inter- and intra-modal attention across the visual and natural language modalities, which allows effective training via directly contrasting the two modalities' representations. We demonstrate the effectiveness of our approach by self-training on the HowTo100M instructional video dataset and evaluating on a newly collected dataset of localized described interactions in the YouCook2 dataset. We show that our approach outperforms alternative baselines, including shallow co-attention and full cross-modal attention. We also apply our approach to grounding phrases in images with weak supervision on Flickr30K and show that stacking multiple attention layers is effective and, when combined with a word-to-region loss, achieves state of the art on recall-at-one and pointing hand accuracies.", "pdf": "/pdf/85b05c73c8fd9d818f0ae4ffc03f1cf7c64848ef.pdf", "supplementary_material": "/attachment/5614aa0c4cb251e4e07ebb3d984abfb4662195c6.pdf", "submission_history": "", "checklist": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "tan|look_at_what_im_doing_selfsupervised_spatial_grounding_of_narrations_in_instructional_videos", "code": "https://cs-people.bu.edu/rxtan/projects/grounding_narrations", "thumbnail": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\ntan2021look,\ntitle={Look at What I{\\textquoteright}m Doing: Self-Supervised Spatial Grounding of Narrations in Instructional Videos},\nauthor={Reuben Tan and Bryan A. Plummer and Kate Saenko and Hailin Jin and Bryan Russell},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=tMFTT3BDEK9}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492667739, "odate": 1636492667739, "details": {"replyCount": 14}}, {"id": "dsmxf7FKiaY", "original": "GZggB22ufr", "number": 10054, "cdate": 1621630256972, "ddate": null, "tcdate": 1621630256972, "tmdate": 1697937364782, "tddate": null, "forum": "dsmxf7FKiaY", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Revisiting ResNets: Improved Training and Scaling Strategies", "authorids": ["~Irwan_Bello1", "~William_Fedus2", "~Xianzhi_Du4", "~Ekin_Dogus_Cubuk1", "~Aravind_Srinivas1", "~Tsung-Yi_Lin4", "~Jonathon_Shlens1", "~Barret_Zoph2"], "authors": ["Irwan Bello", "William Fedus", "Xianzhi Du", "Ekin Dogus Cubuk", "Aravind Srinivas", "Tsung-Yi Lin", "Jonathon Shlens", "Barret Zoph"], "keywords": ["Scaling", "Architectures", "ResNet", "EfficientNet", "ViT", "Image Classification", "Vision", "ImageNet"], "TL;DR": "Improved training and scaling strategies make ResNet architectures competitive on image/video classification, suggesting that proper training and scaling matters more than architectural changes", "abstract": "Novel computer vision architectures monopolize the spotlight, but the impact of the model architecture is often conflated with simultaneous changes to training methodology and scaling strategies.\nOur work revisits the canonical ResNet and studies these three aspects in an effort to disentangle them. Perhaps surprisingly, we find that training and scaling strategies may matter more than architectural changes, and further, that the resulting ResNets match recent state-of-the-art models. We show that the best performing scaling strategy depends on the training regime and offer two new scaling strategies: (1) scale model depth in regimes where overfitting can occur (width scaling is preferable otherwise); (2) increase image resolution more slowly than previously recommended.\nUsing improved training and scaling strategies, we design a family of ResNet architectures, ResNet-RS, which are 1.7x - 2.7x faster than EfficientNets on TPUs, while achieving similar accuracies on ImageNet. In a large-scale semi-supervised learning setup, ResNet-RS achieves 86.2% top-1 ImageNet accuracy, while being 4.7x faster than EfficientNet-NoisyStudent. The training techniques improve transfer performance on a suite of downstream tasks (rivaling state-of-the-art self-supervised algorithms) and extend to video classification on Kinetics-400. We recommend practitioners use these simple revised ResNets as baselines for future research.", "pdf": "/pdf/9ae1782c039721cebad2c29ad33690234bffad98.pdf", "supplementary_material": "/attachment/8483bc7be5b3c7f32d64e49f1fe7f6d5b73aef46.pdf", "submission_history": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "checklist": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "bello|revisiting_resnets_improved_training_and_scaling_strategies", "thumbnail": "", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 2 code implementations](https://www.catalyzex.com/paper/arxiv:2103.07579/code)", "_bibtex": "@inproceedings{\nbello2021revisiting,\ntitle={Revisiting ResNets: Improved Training and Scaling Strategies},\nauthor={Irwan Bello and William Fedus and Xianzhi Du and Ekin Dogus Cubuk and Aravind Srinivas and Tsung-Yi Lin and Jonathon Shlens and Barret Zoph},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=dsmxf7FKiaY}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492775783, "odate": 1636492775783, "details": {"replyCount": 12}}, {"id": "7pU_P1IbePx", "original": "zvAsdtVukCEa", "number": 10006, "cdate": 1621630254072, "ddate": null, "tcdate": 1621630254072, "tmdate": 1683307752987, "tddate": null, "forum": "7pU_P1IbePx", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Statistical Query Lower Bounds for List-Decodable Linear Regression", "authorids": ["~Ilias_Diakonikolas1", "~Daniel_Kane1", "~Ankit_Pensia1", "~Thanasis_Pittas1", "~Alistair_Stewart1"], "authors": ["Ilias Diakonikolas", "Daniel Kane", "Ankit Pensia", "Thanasis Pittas", "Alistair Stewart"], "keywords": ["learning theory", "high-dimensional robust statistics", "statistical query model", "list-decodable learning", "linear regression"], "abstract": "We study the problem of list-decodable linear regression, where an adversary can corrupt a majority of the examples. Specifically, we are given a set $T$ of labeled examples $(x, y) \\in \\mathbb{R}^d \\times \\mathbb{R}$ and a parameter $0< \\alpha <1/2$ such that an $\\alpha$-fraction of the points in $T$ are i.i.d. samples from a linear regression model with Gaussian covariates, and the remaining $(1-\\alpha)$-fraction of the points are drawn from an arbitrary noise distribution. The goal is to output a small list of hypothesis vectors such that at least one of them is close to the target regression vector. Our main result is a Statistical Query (SQ) lower bound of $d^{\\mathrm{poly}(1/\\alpha)}$ for this problem. Our SQ lower bound qualitatively matches the performance of previously developed algorithms, providing evidence that current upper bounds for this task are nearly best possible.\n", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "diakonikolas|statistical_query_lower_bounds_for_listdecodable_linear_regression", "TL;DR": "We prove a superpolynomial statistical query lower bound for the problem of learning the regression vector of a Gaussian linear model when outliers constitute the majority of the dataset.", "pdf": "/pdf/79b7fba0b8f6074f6b14ad0c9f08674c46af27fe.pdf", "checklist": "", "supplementary_material": "/attachment/124e66bb902037b5e727f4f5c2c5e37589ae9ac5.pdf", "thumbnail": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\ndiakonikolas2021statistical,\ntitle={Statistical Query Lower Bounds for List-Decodable Linear Regression},\nauthor={Ilias Diakonikolas and Daniel Kane and Ankit Pensia and Thanasis Pittas and Alistair Stewart},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=7pU_P1IbePx}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492736054, "odate": 1636492736010, "details": {"replyCount": 10}}, {"id": "OSLVL-tIBei", "original": "iooMhOiJliS", "number": 9896, "cdate": 1621630247498, "ddate": null, "tcdate": 1621630247498, "tmdate": 1683307750937, "tddate": null, "forum": "OSLVL-tIBei", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Exploration-Exploitation in Multi-Agent Competition: Convergence with Bounded Rationality", "authorids": ["~Stefanos_Leonardos1", "~Georgios_Piliouras1", "~Kelly_Spendlove1"], "authors": ["Stefanos Leonardos", "Georgios Piliouras", "Kelly Spendlove"], "keywords": ["Exploration-Exploitation", "Q-learning", "Zero-Sum Polymatrix Games", "Quantal Response Equilibria", "Bounded Rationality"], "TL;DR": "Complementing recent results about convergence in weighted potential games, we show that Q-learning converges both in competitive as well as cooperative settings, regardless of the number of agents and without any need for parameter fine-tuning.", "abstract": "The interplay between exploration and exploitation in competitive multi-agent learning is still far from being well understood. Motivated by this, we study smooth Q-learning, a prototypical learning model that explicitly captures the balance between game rewards and exploration costs. We show that Q-learning always converges to the unique quantal-response equilibrium (QRE), the standard solution concept for games under bounded rationality, in weighted zero-sum polymatrix games with heterogeneous learning agents using positive exploration rates. Complementing recent results about convergence in weighted potential games [16,34], we show that fast convergence of Q-learning in competitive settings obtains regardless of the number of agents and without any need for parameter fine-tuning. As showcased by our experiments in network zero-sum games, these theoretical results provide the necessary guarantees for an algorithmic approach to the currently open problem of equilibrium selection in competitive multi-agent settings.", "submission_history": "", "checklist": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "leonardos|explorationexploitation_in_multiagent_competition_convergence_with_bounded_rationality", "pdf": "/pdf/e6afb63d3c73d493f3a8b82cbdc933f2cf642203.pdf", "supplementary_material": "/attachment/c6671246df415bf4eab7cb5d5863efff2146dbc5.pdf", "code": "/attachment/ddcbb1d459d47e9fc87a1e9da3e3637403219019.zip", "thumbnail": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nleonardos2021explorationexploitation,\ntitle={Exploration-Exploitation in Multi-Agent Competition: Convergence with Bounded Rationality},\nauthor={Stefanos Leonardos and Georgios Piliouras and Kelly Spendlove},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=OSLVL-tIBei}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492747259, "odate": 1636492747259, "details": {"replyCount": 9}}, {"id": "Dzy8YEm5dX", "original": "DoJ6fqMlDnq", "number": 9862, "cdate": 1621630245525, "ddate": null, "tcdate": 1621630245525, "tmdate": 1683307750258, "tddate": null, "forum": "Dzy8YEm5dX", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Towards a Unified Information-Theoretic Framework for Generalization", "authorids": ["~MAHDI_HAGHIFAM1", "~Gintare_Karolina_Dziugaite1", "~Shay_Moran1", "~Daniel_M._Roy1"], "authors": ["MAHDI HAGHIFAM", "Gintare Karolina Dziugaite", "Shay Moran", "Daniel M. Roy"], "keywords": ["information-theoretic generalization", "conditional mutual information", "leave-one-out", "sample compression schemes", "SVM"], "TL;DR": "We show that the CMI framework can be used to obtain optimal or near-optimal bounds for the expected excess risk for a wide range of algorithms.", "abstract": "In this work, we investigate the expressiveness of the \"conditional mutual information\" (CMI)  framework of Steinke and Zakynthinou (2020)  and the prospect of using it to provide a unified framework for proving generalization bounds in the realizable setting.  We first demonstrate that one can use this framework to express non-trivial (but sub-optimal) bounds for any learning algorithm that outputs hypotheses from a class of bounded VC dimension.  We then explore two directions of strengthening this bound: (i) Can the CMI framework express optimal bounds for VC classes? (ii) Can the CMI framework be used to analyze algorithms whose output hypothesis space is unrestricted (i.e. has an unbounded VC dimension)?\n    \nWith respect to Item (i) we prove that the CMI framework yields the optimal bound on the expected risk  of Support Vector Machines (SVMs) for learning halfspaces. This result is an application of our general result showing that stable compression schemes Bousquet al. (2020) of size $k$ have uniformly bounded CMI of order $O(k)$. We further show that an inherent limitation of proper learning of VC classes contradicts the existence of a proper learner with constant CMI, and it implies a negative resolution to an open problem of Steinke and Zakynthinou (2020).  We further study the CMI of empirical risk minimizers (ERMs) of class $H$ and show that it is possible to output all  consistent classifiers (version space) with bounded CMI if and only if $H$ has a bounded star number (Hanneke and Yang (2015)). With respect to Item (ii) we prove a general reduction showing that \"leave-one-out\" analysis is expressible via the CMI framework. As a corollary we investigate the CMI of the one-inclusion-graph algorithm proposed by Haussler et al. (1994). More generally, we  show that the CMI framework is universal in the sense that for every consistent algorithm and data distribution, the expected risk vanishes as the number of  samples diverges if and only if its evaluated CMI has sublinear growth with the number of samples.", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "haghifam|towards_a_unified_informationtheoretic_framework_for_generalization", "pdf": "/pdf/92e60241b750bf848f377d6e45a9f03485d94db5.pdf", "checklist": "", "supplementary_material": "/attachment/745c07477d4b8f55520a041d4f32b289be0c8fbc.pdf", "thumbnail": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nhaghifam2021towards,\ntitle={Towards a Unified Information-Theoretic Framework for Generalization},\nauthor={MAHDI HAGHIFAM and Gintare Karolina Dziugaite and Shay Moran and Daniel M. Roy},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=Dzy8YEm5dX}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492669648, "odate": 1636492669648, "details": {"replyCount": 8}}, {"id": "ZAOrF0mYSYU", "original": "ptM-O0vygCK", "number": 9847, "cdate": 1621630244608, "ddate": null, "tcdate": 1621630244608, "tmdate": 1683307750090, "tddate": null, "forum": "ZAOrF0mYSYU", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Agnostic Reinforcement Learning with Low-Rank MDPs and Rich Observations", "authorids": ["~Ayush_Sekhari1", "~Christoph_Dann1", "~Mehryar_Mohri2", "~Yishay_Mansour2", "~Karthik_Sridharan1"], "authors": ["Ayush Sekhari", "Christoph Dann", "Mehryar Mohri", "Yishay Mansour", "Karthik Sridharan"], "keywords": ["Sample complexity", "Agnostic learning", "low rank MDP", "RL theory"], "abstract": "There have been many recent advances on provably efficient Reinforcement Learning (RL) in problems with rich observation spaces. However, all these works share a strong realizability assumption about the optimal value function of the true MDP. Such realizability assumptions are often too strong to hold in practice. In this work, we consider the more realistic setting of agnostic RL with rich observation spaces and a fixed class of policies $\\Pi$ that may not contain any near-optimal policy. We provide an algorithm for this setting whose error is bounded in terms of the rank $d$ of the underlying MDP.  Specifically, our algorithm enjoys a sample complexity bound of $\\widetilde{O}\\left((H^{4d} K^{3d} \\log |\\Pi|)/\\epsilon^2\\right)$ where $H$ is the length of episodes, $K$ is the number of actions and $\\epsilon>0$ is the desired sub-optimality.  We also provide a nearly matching lower bound for this agnostic setting that shows that the exponential dependence on rank is unavoidable, without further assumptions. ", "submission_history": "", "submission_history_-_venue_and_year": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "sekhari|agnostic_reinforcement_learning_with_lowrank_mdps_and_rich_observations", "pdf": "/pdf/d292d7645c28655e430f40c87a4ada9e7e31fbb1.pdf", "submission_history_-_improvements_made": "", "checklist": "", "supplementary_material": "/attachment/ef73b2fa439d9db2774b478525fb28611067c3e3.pdf", "TL;DR": "Provide algorithms for low rank MDPs with rich observations that do not require a realizable value function class, and instead focus on completing with a given policy class. ", "thumbnail": "", "_bibtex": "@inproceedings{\nsekhari2021agnostic,\ntitle={Agnostic Reinforcement Learning with Low-Rank {MDP}s and Rich Observations},\nauthor={Ayush Sekhari and Christoph Dann and Mehryar Mohri and Yishay Mansour and Karthik Sridharan},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=ZAOrF0mYSYU}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492700316, "odate": 1636492700316, "details": {"replyCount": 11}}, {"id": "oAxm0Wz7Bv", "original": "5Kn6dpMMUclD", "number": 9716, "cdate": 1621630236840, "ddate": null, "tcdate": 1621630236840, "tmdate": 1683307747409, "tddate": null, "forum": "oAxm0Wz7Bv", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Make Sure You're Unsure: A Framework for Verifying Probabilistic Specifications", "authorids": ["~Leonard_Berrada1", "~Sumanth_Dathathri1", "~Krishnamurthy_Dj_Dvijotham1", "~Robert_Stanforth1", "~Rudy_R_Bunel1", "~Jonathan_Uesato1", "~Sven_Gowal2", "~M._Pawan_Kumar1"], "authors": ["Leonard Berrada", "Sumanth Dathathri", "Krishnamurthy Dj Dvijotham", "Robert Stanforth", "Rudy R Bunel", "Jonathan Uesato", "Sven Gowal", "M. Pawan Kumar"], "keywords": ["Verification", "Safety", "Optimization"], "TL;DR": "Verification of probabilistic specifications", "abstract": "Most real world applications require dealing with stochasticity like sensor noise or predictive uncertainty, where formal specifications of desired behavior are inherently probabilistic.  Despite the promise of formal verification in ensuring the reliability of neural networks, progress in the direction of probabilistic specifications has been limited. In this direction, we first introduce a general formulation of probabilistic specifications for neural networks, which captures both probabilistic networks (e.g., Bayesian neural networks, MC-Dropout networks) and uncertain inputs (distributions over inputs arising from sensor noise or other perturbations). We then propose a general technique to verify such specifications by generalizing the notion of Lagrangian duality, replacing standard Lagrangian multipliers with \"functional multipliers\" that can be arbitrary functions of the activations at a given layer. We show that an optimal choice of functional multipliers leads to exact verification (i.e.,  sound and complete verification),  and for specific forms of multipliers, we develop tractable practical verification algorithms.\n \nWe empirically validate our algorithms by applying them to Bayesian Neural Networks (BNNs) and MC Dropout Networks, and certifying properties such as adversarial robustness and robust detection of out-of-distribution (OOD) data. On these tasks we are able to provide significantly stronger guarantees when compared to prior work -- for instance, for a VGG-64 MC-Dropout CNN trained on CIFAR-10 in a verification-agnostic manner,  we improve the certified AUC (a verified lower bound on the true AUC) for robust OOD detection (on CIFAR-100) from $0 \\% \\rightarrow 29\\%$. Similarly, for a BNN trained on MNIST, we improve on the $\\ell_\\infty$ robust accuracy from $60.2 \\% \\rightarrow 74.6\\%$. Further, on a novel specification -- distributionally robust OOD detection -- we improve on the certified AUC from $5\\% \\rightarrow 23\\%$.", "submission_history": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "berrada|make_sure_youre_unsure_a_framework_for_verifying_probabilistic_specifications", "pdf": "/pdf/7f059b450871889baa05409c6a07b34a3a696037.pdf", "checklist": "", "supplementary_material": "/attachment/082546c393978e43a0917e56d4682f4057258d4c.pdf", "code": "https://github.com/deepmind/jax_verify", "thumbnail": "", "_bibtex": "@inproceedings{\nberrada2021make,\ntitle={Make Sure You're Unsure: A Framework for Verifying Probabilistic Specifications},\nauthor={Leonard Berrada and Sumanth Dathathri and Krishnamurthy Dj Dvijotham and Robert Stanforth and Rudy R Bunel and Jonathan Uesato and Sven Gowal and M. Pawan Kumar},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=oAxm0Wz7Bv}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492698112, "odate": 1636492698112, "details": {"replyCount": 11}}, {"id": "fpQojkIV5q8", "original": "YcwFMaYd-ih", "number": 9676, "cdate": 1621630234461, "ddate": null, "tcdate": 1621630234461, "tmdate": 1683307746856, "tddate": null, "forum": "fpQojkIV5q8", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "DropGNN: Random Dropouts Increase the Expressiveness of Graph Neural Networks", "authorids": ["~P\u00e1l_Andr\u00e1s_Papp1", "~Karolis_Martinkus1", "~Lukas_Faber1", "~Roger_Wattenhofer1"], "authors": ["P\u00e1l Andr\u00e1s Papp", "Karolis Martinkus", "Lukas Faber", "Roger Wattenhofer"], "keywords": ["graph neural networks", "GNN", "expressivity", "WL", "molecular graphs"], "TL;DR": "We devise a new GNN variant (DropGNN) with larger expressive power in both theory and practice", "abstract": "This paper studies Dropout Graph Neural Networks (DropGNNs), a new approach that aims to overcome the limitations of standard GNN frameworks. In DropGNNs, we execute multiple runs of a GNN on the input graph, with some of the nodes randomly and independently dropped in each of these runs. Then, we combine the results of these runs to obtain the final result. We prove that DropGNNs can distinguish various graph neighborhoods that cannot be separated by message passing GNNs. We derive theoretical bounds for the number of runs required to ensure a reliable distribution of dropouts, and we prove several properties regarding the expressive capabilities and limits of DropGNNs. We experimentally validate our theoretical findings on expressiveness. Furthermore, we show that DropGNNs perform competitively on established GNN benchmarks.", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "papp|dropgnn_random_dropouts_increase_the_expressiveness_of_graph_neural_networks", "pdf": "/pdf/296332c5e1a63cf70db199bbc44fd0b2f3ee51ca.pdf", "checklist": "", "supplementary_material": "/attachment/3bfb21ab74f95fb65156d87a6eec4862d4b64ab4.pdf", "thumbnail": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\npapp2021dropgnn,\ntitle={Drop{GNN}: Random Dropouts Increase the Expressiveness of Graph Neural Networks},\nauthor={P{\\'a}l Andr{\\'a}s Papp and Karolis Martinkus and Lukas Faber and Roger Wattenhofer},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=fpQojkIV5q8}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492674129, "odate": 1636492674129, "details": {"replyCount": 13}}, {"id": "YscYPF8bU13", "original": "xsoj-hODcL0", "number": 9649, "cdate": 1621630232908, "ddate": null, "tcdate": 1621630232908, "tmdate": 1683307746335, "tddate": null, "forum": "YscYPF8bU13", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "A Central Limit Theorem for Differentially Private Query Answering", "authorids": ["~Jinshuo_Dong1", "~Weijie_J_Su1", "~Linjun_Zhang1"], "authors": ["Jinshuo Dong", "Weijie J Su", "Linjun Zhang"], "keywords": ["differential privacy", "central limit theorem", "uncertainty principle", "Cramer-Rao lower bound"], "TL;DR": "Adding even highly correlated noise to a high-dimensional query yields Gaussian Differential Privacy. Privacy-accuracy trade-off is related to Cramer-Rao lower bound.", "abstract": "Perhaps the single most important use case for differential privacy is to privately answer numerical queries, which is usually achieved by adding noise to the answer vector. The central question is, therefore, to understand which noise distribution optimizes the privacy-accuracy trade-off, especially when the dimension of the answer vector is high. Accordingly, an extensive literature has been dedicated to the question and the upper and lower bounds have been successfully matched up to constant factors (Bun et al.,\n2018; Steinke & Ullman, 2017). In this paper, we take a novel approach to address this important optimality question. We first demonstrate an intriguing central limit theorem phenomenon in the high-dimensional regime. More precisely, we prove that a mechanism is approximately Gaussian Differentially Private (Dong et al., 2021) if the added noise satisfies certain conditions. In particular, densities proportional to $\\mathrm{e}^{-\\|x\\|_p^\\alpha}$, where $\\|x\\|_p$ is the standard $\\ell_p$-norm, satisfies the conditions. Taking this perspective, we make use of the Cramer--Rao inequality and show an \"uncertainty principle\"-style result: the product of privacy parameter and the $\\ell_2$-loss of the mechanism is lower bounded by the dimension. Furthermore, the Gaussian mechanism achieves the constant-sharp optimal privacy-accuracy trade-off among all such noises. Our findings are corroborated by numerical experiments.", "supplementary_material": "/attachment/9b7cdf216ab3995e45783477ed26ce58f0cce376.pdf", "submission_history": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "checklist": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "dong|a_central_limit_theorem_for_differentially_private_query_answering", "pdf": "/pdf/d9c02b68f98b3b8a5a16e2019cea4a91c5d4931f.pdf", "thumbnail": "", "code": "/attachment/fa894cc03518b334595ec0d8e2cf8c3f42a745d3.zip", "_bibtex": "@inproceedings{\ndong2021a,\ntitle={A Central Limit Theorem for Differentially Private Query Answering},\nauthor={Jinshuo Dong and Weijie J Su and Linjun Zhang},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=YscYPF8bU13}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492706211, "odate": 1636492706211, "details": {"replyCount": 11}}, {"id": "73OmmrCfSyy", "original": "MCMD2A5zZWn", "number": 9628, "cdate": 1621630231613, "ddate": null, "tcdate": 1621630231613, "tmdate": 1683307745645, "tddate": null, "forum": "73OmmrCfSyy", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Mind the Gap: Assessing Temporal Generalization in Neural Language Models", "authorids": ["~Angeliki_Lazaridou1", "~Adhiguna_Kuncoro2", "~Elena_Gribovskaya1", "~Devang_Agrawal2", "~Adam_Liska1", "~Tayfun_Terzi1", "maigimenez@google.com", "~Cyprien_de_Masson_d'Autume1", "~Tom\u00e1\u0161_Ko\u010disk\u00fd1", "~Sebastian_Ruder2", "~Dani_Yogatama2", "~Kris_Cao2", "~Susannah_Young1", "~Phil_Blunsom1"], "authors": ["Angeliki Lazaridou", "Adhiguna Kuncoro", "Elena Gribovskaya", "Devang Agrawal", "Adam Liska", "Tayfun Terzi", "Mai Gimenez", "Cyprien de Masson d'Autume", "Tom\u00e1\u0161 Ko\u010disk\u00fd", "Sebastian Ruder", "Dani Yogatama", "Kris Cao", "Susannah Young", "Phil Blunsom"], "keywords": ["language modelling", "temporal splits", "model analysis"], "abstract": "Our world is open-ended, non-stationary, and constantly evolving; thus what we talk about and how we talk about it change over time. This inherent dynamic nature of language contrasts with the current static language modelling paradigm, which trains and evaluates models on utterances from overlapping time periods. Despite impressive recent progress, we demonstrate that Transformer-XL language models perform worse in the realistic setup of predicting future utterances from beyond their training period, and that model performance becomes increasingly worse with time. We find that, while increasing model size alone\u2014a key driver behind recent progress\u2014does not solve this problem, having models that continually update their knowledge with new information can indeed mitigate this performance degradation over time. Hence, given the compilation of ever-larger language modelling datasets, combined with the growing list of language-model-based NLP applications that require up-to-date factual knowledge about the world, we argue that now is the right time to rethink the static way in which we currently train and evaluate our language models, and develop adaptive language models that can remain up-to-date with respect to our ever-changing and non-stationary world. We publicly release our dynamic, streaming language modelling benchmarks for WMT and arXiv to facilitate language model evaluation that takes temporal dynamics into account.", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "lazaridou|mind_the_gap_assessing_temporal_generalization_in_neural_language_models", "TL;DR": "We test and analyze temporal generalization capabilities of neural language models using time-stratified datasets.", "pdf": "/pdf/8377536cb8a0618c81b1ffa8a01497b6a19f85f7.pdf", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "checklist": "", "supplementary_material": "/attachment/bb5191b7b9b051d97fa59c5f1f4d65b37d92847f.pdf", "thumbnail": "", "_bibtex": "@inproceedings{\nlazaridou2021mind,\ntitle={Mind the Gap: Assessing Temporal Generalization in Neural Language Models},\nauthor={Angeliki Lazaridou and Adhiguna Kuncoro and Elena Gribovskaya and Devang Agrawal and Adam Liska and Tayfun Terzi and Mai Gimenez and Cyprien de Masson d'Autume and Tom{\\'a}{\\v{s}} Ko{\\v{c}}isk{\\'y} and Sebastian Ruder and Dani Yogatama and Kris Cao and Susannah Young and Phil Blunsom},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=73OmmrCfSyy}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492728965, "odate": 1636492728965, "details": {"replyCount": 13}}, {"id": "1yeYYtLqq7K", "original": "a4rzsbeNe4", "number": 9524, "cdate": 1621630225432, "ddate": null, "tcdate": 1621630225432, "tmdate": 1683307743808, "tddate": null, "forum": "1yeYYtLqq7K", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "A flow-based latent state generative model of neural population responses to natural images", "authorids": ["~Mohammad_Bashiri3", "~Edgar_Y._Walker1", "~Konstantin-Klemens_Lurz1", "~Akshay_Kumar_Jagadish1", "~Taliah_Muhammad1", "~Zhiwei_Ding1", "~Zhuokun_Ding1", "~Andreas_S._Tolias1", "~Fabian_H._Sinz1"], "authors": ["Mohammad Bashiri", "Edgar Y. Walker", "Konstantin-Klemens Lurz", "Akshay Kumar Jagadish", "Taliah Muhammad", "Zhiwei Ding", "Zhuokun Ding", "Andreas S. Tolias", "Fabian H. Sinz"], "keywords": ["mouse visual cortex", "neural system identification", "latent variable models", "normalizing flow", "generative models", "noise correlations"], "TL;DR": "We present a simple-to-train, yet flexible, flow-based generative model of neural population responses that successfully accounts for stimulus-driven responses and noise correlations.", "abstract": "We present a joint deep neural system identification model for two major sources of neural variability: stimulus-driven and stimulus-conditioned fluctuations. To this end, we combine (1) state-of-the-art deep networks for stimulus-driven activity and (2) a flexible, normalizing flow-based generative model to capture the stimulus-conditioned variability including noise correlations. This allows us to train the model end-to-end without the need for sophisticated probabilistic approximations associated with many latent state models for stimulus-conditioned fluctuations. We train the model on the responses of thousands of neurons from multiple areas of the mouse visual cortex to natural images. We show that our model outperforms previous state-of-the-art models in predicting the distribution of neural population responses to novel stimuli, including shared stimulus-conditioned variability. Furthermore, it successfully learns known latent factors of the population responses that are related to behavioral variables such as pupil dilation, and other factors that vary systematically with brain area or retinotopic location. Overall, our model accurately accounts for two critical sources of neural variability while avoiding several complexities associated with many existing latent state models. It thus provides a useful tool for uncovering the interplay between different factors that contribute to variability in neural activity.", "pdf": "/pdf/4a677fb99d14450a3ed48bcf67829e4ad7965d8f.pdf", "supplementary_material": "/attachment/b0912f1aca19e05c142653fa5750a0e01b679c9d.pdf", "submission_history": "", "checklist": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "bashiri|a_flowbased_latent_state_generative_model_of_neural_population_responses_to_natural_images", "code": "https://github.com/sinzlab/bashiri-et-al-2021", "thumbnail": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nbashiri2021a,\ntitle={A flow-based latent state generative model of neural population responses to natural images},\nauthor={Mohammad Bashiri and Edgar Y. Walker and Konstantin-Klemens Lurz and Akshay Kumar Jagadish and Taliah Muhammad and Zhiwei Ding and Zhuokun Ding and Andreas S. Tolias and Fabian H. Sinz},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=1yeYYtLqq7K}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492733039, "odate": 1636492733039, "details": {"replyCount": 20}}, {"id": "_OPHJ7nkZoC", "original": "8iYdCqkrhMN", "number": 9410, "cdate": 1621630218567, "ddate": null, "tcdate": 1621630218567, "tmdate": 1683307742449, "tddate": null, "forum": "_OPHJ7nkZoC", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Sample Complexity of Tree Search Configuration: Cutting Planes and Beyond", "authorids": ["~Nina_Balcan1", "~Siddharth_Prasad1", "~Tuomas_Sandholm1", "~Ellen_Vitercik1"], "authors": ["Nina Balcan", "Siddharth Prasad", "Tuomas Sandholm", "Ellen Vitercik"], "keywords": ["Automated algorithm configuration", "automated algorithm design", "data-driven algorithm design", "integer programming", "tree search", "branch-and-bound", "branch-and-cut", "cutting planes", "Chv\u00e1tal-Gomory cuts", "machine learning theory", "sample complexity", "generalization guarantees"], "abstract": "Cutting-plane methods have enabled remarkable successes in integer programming over the last few decades. State-of-the-art solvers integrate a myriad of cutting-plane techniques to speed up the underlying tree-search algorithm used to find optimal solutions. In this paper we provide sample complexity bounds for cut-selection in branch-and-cut (B&C). Given a training set of integer programs sampled from an application-specific input distribution and a family of cut selection policies, these guarantees bound the number of samples sufficient to ensure that using any policy in the family, the size of the tree B&C builds on average over the training set is close to the expected size of the tree B&C builds. We first bound the sample complexity of learning cutting planes from the canonical family of Chv\u00e1tal-Gomory cuts. Our bounds handle any number of waves of any number of cuts and are fine tuned to the magnitudes of the constraint coefficients. Next, we prove sample complexity bounds for more sophisticated cut selection policies that use a combination of scoring rules to choose from a family of cuts. Finally, beyond the realm of cutting planes for integer programming, we develop a general abstraction of tree search that captures key components such as node selection and variable selection. For this abstraction, we bound the sample complexity of learning a good policy for building the search tree.", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "balcan|sample_complexity_of_tree_search_configuration_cutting_planes_and_beyond", "pdf": "/pdf/10fdb2624630733e4c404ac43eaec127ff80b3b9.pdf", "supplementary_material": "/attachment/b07ac947ee9c04da8ea6f5df4fec67c5cdc42528.pdf", "checklist": "", "thumbnail": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nbalcan2021sample,\ntitle={Sample Complexity of Tree Search Configuration: Cutting Planes and Beyond},\nauthor={Nina Balcan and Siddharth Prasad and Tuomas Sandholm and Ellen Vitercik},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=_OPHJ7nkZoC}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492717291, "odate": 1636492717291, "details": {"replyCount": 10}}, {"id": "e_yvNqkJKAW", "original": "dNYyQs26Ssf", "number": 9393, "cdate": 1621630217544, "ddate": null, "tcdate": 1621630217544, "tmdate": 1683307741810, "tddate": null, "forum": "e_yvNqkJKAW", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Test-Time Classifier Adjustment Module for Model-Agnostic Domain Generalization", "authorids": ["~Yusuke_Iwasawa1", "~Yutaka_Matsuo1"], "authors": ["Yusuke Iwasawa", "Yutaka Matsuo"], "keywords": ["domain generalization", "test time adaptation", "prototypical classifier"], "abstract": "This paper presents a new algorithm for domain generalization (DG), \\textit{test-time template adjuster (T3A)}, aiming to robustify a model to unknown distribution shift. Unlike existing methods that focus on \\textit{training phase}, our method focuses \\textit{test phase}, i.e., correcting its prediction by itself during test time. Specifically, T3A adjusts a trained linear classifier (the last layer of deep neural networks) with the following procedure:  (1) compute a pseudo-prototype representation for each class using online unlabeled data augmented by the base classifier trained in the source domains, (2) and then classify each sample based on its distance to the pseudo-prototypes. T3A is back-propagation-free and modifies only the linear layer; therefore, the increase in computational cost during inference is negligible and avoids the catastrophic failure might caused by stochastic optimization. Despite its simplicity, T3A can leverage knowledge about the target domain by using off-the-shelf test-time data and improve performance. We tested our method on four domain generalization benchmarks, namely PACS, VLCS, OfficeHome, and TerraIncognita, along with various backbone networks including ResNet18, ResNet50, Big Transfer (BiT), Vision Transformers (ViT), and MLP-Mixer. The results show T3A stably improves performance on unseen domains across choices of backbone networks, and outperforms existing domain generalization methods. ", "submission_history": "", "checklist": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "iwasawa|testtime_classifier_adjustment_module_for_modelagnostic_domain_generalization", "TL;DR": "This paper presents a new algorithm for domain generalization (DG), \\textit{test-time template adjuster (T3A)}, which correct its prediction by itself during test time. ", "pdf": "/pdf/22a5d6cf8f5a37e348c03a005c67203022e78ed2.pdf", "supplementary_material": "/attachment/dd40f726cc5cf4cffd99fbd6f43751249f29734c.pdf", "thumbnail": "", "code": "https://github.com/matsuolab/T3A", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\niwasawa2021testtime,\ntitle={Test-Time Classifier Adjustment Module for Model-Agnostic Domain Generalization},\nauthor={Yusuke Iwasawa and Yutaka Matsuo},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=e_yvNqkJKAW}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492747342, "odate": 1636492747342, "details": {"replyCount": 13}}, {"id": "ALvt7nXa2q", "original": "lZyep4REy1S", "number": 9373, "cdate": 1621630216362, "ddate": null, "tcdate": 1621630216362, "tmdate": 1697937386221, "tddate": null, "forum": "ALvt7nXa2q", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Overcoming Catastrophic Forgetting in Incremental Few-Shot Learning by Finding Flat Minima", "authorids": ["~Guangyuan_SHI1", "~Jiaxin_Chen1", "~Wenlong_Zhang3", "~Li-Ming_Zhan1", "~Xiao-Ming_Wu1"], "authors": ["Guangyuan SHI", "Jiaxin Chen", "Wenlong Zhang", "Li-Ming Zhan", "Xiao-Ming Wu"], "keywords": ["incremental few-shot learning", "catastrophic forgetting", "flat minima"], "abstract": "This paper considers incremental few-shot learning, which requires a model to continually recognize new categories with only a few examples provided. Our study shows that existing methods severely suffer from catastrophic forgetting, a well-known problem in incremental learning, which is aggravated due to data scarcity and imbalance in the few-shot setting. Our analysis further suggests that to prevent catastrophic forgetting, actions need to be taken in the primitive stage -- the training of base classes instead of later few-shot learning sessions. Therefore, we propose to search for flat local minima of the base training objective function and then fine-tune the model parameters within the flat region on new tasks. In this way, the model can efficiently learn new classes while preserving the old ones. Comprehensive experimental results demonstrate that our approach outperforms all prior state-of-the-art methods and is very close to the approximate upper bound. The source code is available at https://github.com/moukamisama/F2M.", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "shi|overcoming_catastrophic_forgetting_in_incremental_fewshot_learning_by_finding_flat_minima", "TL;DR": "We propose to overcome catastrophic forgetting in incremental few-shot learning by finding flat minima in the base training stage.", "pdf": "/pdf/30198a83e95ba8db176e9307af2d6d957591f9c7.pdf", "checklist": "", "supplementary_material": "/attachment/d7c967c98c4c649871763490b9efbe897bc269f8.pdf", "code": "https://github.com/moukamisama/F2M", "thumbnail": "", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2111.01549/code)", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nshi2021overcoming,\ntitle={Overcoming Catastrophic Forgetting in Incremental Few-Shot Learning by Finding Flat Minima},\nauthor={Guangyuan SHI and Jiaxin Chen and Wenlong Zhang and Li-Ming Zhan and Xiao-Ming Wu},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=ALvt7nXa2q}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492678512, "odate": 1636492678512, "details": {"replyCount": 18}}, {"id": "9FREJhzo1q", "original": "cP8BV20UXqE", "number": 9345, "cdate": 1621630214657, "ddate": null, "tcdate": 1621630214657, "tmdate": 1683307740789, "tddate": null, "forum": "9FREJhzo1q", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "A sampling-based circuit for optimal decision making", "authorids": ["~Camille_E._Rull\u00e1n_Bux\u00f31", "~Cristina_Savin1"], "authors": ["Camille E. Rull\u00e1n Bux\u00f3", "Cristina Savin"], "keywords": ["computational neuroscience", "neural sampling", "spiking network", "optimal decision making"], "abstract": "Many features of human and animal behavior can be understood in the framework of Bayesian inference and optimal decision making, but the biological substrate of such processes is not fully understood. Neural sampling provides a flexible code for probabilistic inference in high dimensions and explains key features of sensory responses under experimental manipulations of uncertainty. However, since it encodes uncertainty implicitly, across time and neurons, it remains unclear how such representations can be used for decision making. Here we propose a spiking network model that maps neural samples of a task-specific marginal distribution into an instantaneous representation of uncertainty via a procedure inspired by online  kernel density estimation, so that its output can be readily used for decision making. Our model is consistent with experimental results at the level of single neurons and populations, and makes predictions for how neural responses and decisions could be modulated by uncertainty and prior biases. More generally, our work brings together conflicting perspectives on probabilistic brain computation.", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "bux\u00f3|a_samplingbased_circuit_for_optimal_decision_making", "TL;DR": "We describe a spiking neural circuit that performs approximately optimal decision making and analyze its computational and representational properties.", "pdf": "/pdf/69cc1d51827abe975aa8c111368a77a07538d39f.pdf", "checklist": "", "supplementary_material": "/attachment/cd0966c8e822b258ae68a7b063c16cf788ee3930.pdf", "code": "https://github.com/camillerb/RullanSavin2021", "thumbnail": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nbux{\\'o}2021a,\ntitle={A sampling-based circuit for optimal decision making},\nauthor={Camille E. Rull{\\'a}n Bux{\\'o} and Cristina Savin},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=9FREJhzo1q}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492764700, "odate": 1636492764700, "details": {"replyCount": 11}}, {"id": "jar9C-V8GH", "original": "N7-wt1Imp1m", "number": 9329, "cdate": 1621630213685, "ddate": null, "tcdate": 1621630213685, "tmdate": 1683307740095, "tddate": null, "forum": "jar9C-V8GH", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Coresets for Time Series Clustering", "authorids": ["~Lingxiao_Huang2", "~K._Sudhir1", "~Nisheeth_K_Vishnoi1"], "authors": ["Lingxiao Huang", "K. Sudhir", "Nisheeth K Vishnoi"], "keywords": ["coresets", "clustering", "time series data", "Gaussian mixture model", "autocorrelation"], "TL;DR": "We present an efficient algorithm to construct coresets for clustering  Gaussian mixture time series data.", "abstract": "We study the problem of constructing coresets for clustering problems with time series data.  This problem has gained importance across many fields including biology, medicine, and economics due to the proliferation of sensors facilitating real-time measurement and rapid drop in storage costs.  In particular, we consider the setting where the time series data on $N$ entities is generated from a Gaussian mixture model with autocorrelations over $k$ clusters in $\\mathbb{R}^d$. Our main contribution is an algorithm to construct coresets for the maximum likelihood objective for this mixture model. Our algorithm is efficient, and under a mild boundedness assumption on the covariance matrices of the underlying Gaussians, the size of the coreset is independent of the number of entities $N$ and the number of observations for each entity, and depends only polynomially on $k$, $d$ and $1/\\varepsilon$, where $\\varepsilon$ is the error parameter.  We empirically assess the performance of our coreset with synthetic data. ", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "huang|coresets_for_time_series_clustering", "pdf": "/pdf/4350f19ae7a244fe2cce71f091b96f1e8ab09b13.pdf", "supplementary_material": "/attachment/5454aa9f9078d11074fd2e6aae6dcc44109088f7.pdf", "checklist": "", "code": "/attachment/86009bb8b12a53ed1a20cc06a483f4f110375bc1.zip", "thumbnail": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nhuang2021coresets,\ntitle={Coresets for Time Series Clustering},\nauthor={Lingxiao Huang and K. Sudhir and Nisheeth K Vishnoi},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=jar9C-V8GH}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492760808, "odate": 1636492760808, "details": {"replyCount": 14}}, {"id": "vPVTsuJtGky", "original": "pi4viFBDLQX", "number": 9206, "cdate": 1621630206404, "ddate": null, "tcdate": 1621630206404, "tmdate": 1683307734366, "tddate": null, "forum": "vPVTsuJtGky", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Early-stopped neural networks are consistent", "authorids": ["~Ziwei_Ji1", "~Justin_D._Li1", "~Matus_Telgarsky1"], "authors": ["Ziwei Ji", "Justin D. Li", "Matus Telgarsky"], "keywords": ["Neural Networks", "Deep Networks", "calibration", "consistency", "nonseparable", "gradient descent"], "TL;DR": "For general classification problems, including those with noise, gradient descent with early stopping on shallow ReLU networks achieves the optimal risk amongst all measurable predictors", "abstract": "This work studies the behavior of shallow ReLU networks trained with the logistic loss via gradient descent on binary classification data where the underlying data distribution is general, and the (optimal) Bayes risk is not necessarily zero.  In this setting, it is shown that gradient descent with early stopping achieves population risk arbitrarily close to optimal in terms of not just logistic and misclassification losses, but also in terms of calibration, meaning the sigmoid mapping of its outputs approximates the true underlying conditional distribution arbitrarily finely.  Moreover, the necessary iteration, sample, and architectural complexities of this analysis all scale naturally with a certain complexity measure of the true conditional model.  Lastly, while it is not shown that early stopping is necessary, it is shown that any classifier satisfying a basic local interpolation property is inconsistent.\n", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "ji|earlystopped_neural_networks_are_consistent", "pdf": "/pdf/9ebc9157cf020d6f0d38ca51766d1fcb105f3e5b.pdf", "checklist": "", "supplementary_material": "/attachment/2b49e1455496bbcce30d42e8969b51232b0032c7.pdf", "thumbnail": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nji2021earlystopped,\ntitle={Early-stopped neural networks are consistent},\nauthor={Ziwei Ji and Justin D. Li and Matus Telgarsky},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=vPVTsuJtGky}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492724921, "odate": 1636492724867, "details": {"replyCount": 16}}, {"id": "we8d1FjibAc", "original": "xDtuT0S5qG", "number": 9070, "cdate": 1621630198223, "ddate": null, "tcdate": 1621630198223, "tmdate": 1683307731545, "tddate": null, "forum": "we8d1FjibAc", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Robust and Fully-Dynamic Coreset for Continuous-and-Bounded Learning (With Outliers) Problems", "authorids": ["~Zixiu_Wang1", "~Yiwen_Guo1", "~Hu_Ding1"], "authors": ["Zixiu Wang", "Yiwen Guo", "Hu Ding"], "keywords": ["coreset", "Continuous-and-Bounded learning", "outliers", "dynamic setting"], "TL;DR": "We provide a robust coreset construction method for continuous-and-bounded optimization problems", "abstract": "In many machine learning tasks, a common approach for dealing with large-scale data is to build a small summary, {\\em e.g.,} coreset,  that can efficiently represent the original input. However, real-world datasets usually contain outliers and most existing coreset construction methods are not resilient against outliers (in particular, an outlier can be located arbitrarily in the space by an adversarial attacker). In this paper, we propose a novel robust coreset method for the {\\em continuous-and-bounded learning} problems (with outliers) which includes a broad range of popular optimization objectives in machine learning, {\\em e.g.,} logistic regression and $ k $-means clustering. Moreover, our robust coreset  can be efficiently maintained in fully-dynamic environment. To the best of our knowledge, this is the first robust and fully-dynamic coreset construction method for these optimization problems. Another highlight is that our coreset size can depend on the doubling dimension of the parameter space, rather than the VC dimension of the objective function which could be very large or even challenging to compute. Finally, we conduct the experiments on real-world datasets to evaluate the effectiveness of our proposed robust coreset method.", "pdf": "/pdf/e2c51c700937752918b31fdddee45858b66e0c09.pdf", "supplementary_material": "", "submission_history": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "checklist": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "wang|robust_and_fullydynamic_coreset_for_continuousandbounded_learning_with_outliers_problems", "thumbnail": "", "_bibtex": "@inproceedings{\nwang2021robust,\ntitle={Robust and Fully-Dynamic Coreset for Continuous-and-Bounded Learning (With Outliers) Problems},\nauthor={Zixiu Wang and Yiwen Guo and Hu Ding},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=we8d1FjibAc}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492737464, "odate": 1636492737464, "details": {"replyCount": 18}}, {"id": "_RSgXL8gNnx", "original": "QG_lnGqjJA", "number": 8850, "cdate": 1621630185305, "ddate": null, "tcdate": 1621630185305, "tmdate": 1683307727995, "tddate": null, "forum": "_RSgXL8gNnx", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Batch Normalization Orthogonalizes Representations in Deep Random Networks", "authorids": ["~Hadi_Daneshmand1", "~Amir_Joudaki1", "~Francis_Bach1"], "authors": ["Hadi Daneshmand", "Amir Joudaki", "Francis Bach"], "keywords": ["Batch normalization", "Theory of deep neural networks", "Markov chains", "Random Neural Networks", "Optimization for neural networks"], "TL;DR": "We prove that successive batch normalizations, together with random linear layers, incrementally orthogonalize representations of samples.", "abstract": "This paper underlines an elegant property of batch-normalization (BN): Successive batch normalizations with random linear updates make samples increasingly orthogonal. We establish a non-asymptotic characterization of the interplay between depth, width, and the orthogonality of deep representations. More precisely, we prove, under a mild assumption, the deviation of the representations from orthogonality rapidly decays with depth up to a term inversely proportional to the network width. This result has two main theoretical and practical implications: 1) Theoretically, as the depth grows, the distribution of the outputs contracts to a Wasserstein-2 ball around an isotropic normal distribution. Furthermore, the radius of this Wasserstein ball shrinks with the width of the network. 2) Practically, the orthogonality of the representations directly influences the performance of stochastic gradient descent (SGD). When representations are initially aligned, we observe SGD wastes many iterations to disentangle representations before the classification. Nevertheless, we experimentally show that starting optimization from orthogonal representations is sufficient to accelerate SGD, with no need for BN.", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "daneshmand|batch_normalization_orthogonalizes_representations_in_deep_random_networks", "pdf": "/pdf/25c304f8a27f5a32f91c5cc504b510508b1142d4.pdf", "checklist": "", "supplementary_material": "/attachment/c9eebd1cf3ea1a0ebacccd9fe433925d77092efd.pdf", "code": "https://github.com/hadidaneshmand/batchnorm21", "thumbnail": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\ndaneshmand2021batch,\ntitle={Batch Normalization Orthogonalizes Representations in Deep Random Networks},\nauthor={Hadi Daneshmand and Amir Joudaki and Francis Bach},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=_RSgXL8gNnx}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492748662, "odate": 1636492748662, "details": {"replyCount": 14}}, {"id": "vMWHOumNj5", "original": "EGGoGSpAZs5", "number": 8801, "cdate": 1621630182424, "ddate": null, "tcdate": 1621630182424, "tmdate": 1683307726785, "tddate": null, "forum": "vMWHOumNj5", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "A Unified Approach to Fair Online Learning via Blackwell Approachability", "authorids": ["~Evgenii_E_Chzhen1", "~Christophe_Giraud1", "~Gilles_Stoltz1"], "authors": ["Evgenii E Chzhen", "Christophe Giraud", "Gilles Stoltz"], "keywords": ["online learning", "fairness", "Blackwell approachability", "calibration"], "abstract": "We provide a setting and a general approach to fair online learning with stochastic sensitive and non-sensitive contexts.\nThe setting is a repeated game between the Player and Nature, where at each stage both pick actions based on the contexts. Inspired by the notion of unawareness, we assume that the Player can only access the non-sensitive context before making a decision, while we discuss both cases of Nature accessing the sensitive contexts and Nature unaware of the sensitive contexts. Adapting Blackwell's approachability theory to handle the case of an unknown contexts' distribution, we provide a general necessary and sufficient condition for learning objectives to be compatible with some fairness constraints. This condition is instantiated on (group-wise) no-regret and (group-wise) calibration objectives, and on demographic parity as an additional constraint. When the objective is not compatible with the constraint, the provided framework permits to characterise the optimal trade-off between the two.", "submission_history": "", "checklist": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "chzhen|a_unified_approach_to_fair_online_learning_via_blackwell_approachability", "TL;DR": "We provide a general approachability-theorem based tool to tacke faire online adversarial learning (with stochastic contexts) and illustrate its application by working out several examples.", "pdf": "/pdf/e1c3a1247684c8ebf221df7502d3c4e2cde16e25.pdf", "supplementary_material": "/attachment/dc0d36113bf872feaa3b91a52783cefc221d2bc2.pdf", "thumbnail": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nchzhen2021a,\ntitle={A Unified Approach to Fair Online Learning via Blackwell Approachability},\nauthor={Evgenii E Chzhen and Christophe Giraud and Gilles Stoltz},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=vMWHOumNj5}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492786178, "odate": 1636492786178, "details": {"replyCount": 11}}, {"id": "wgeK563QgSw", "original": "UnsVlFbAdv4", "number": 8655, "cdate": 1621630173628, "ddate": null, "tcdate": 1621630173628, "tmdate": 1683307724637, "tddate": null, "forum": "wgeK563QgSw", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Offline Reinforcement Learning as One Big Sequence Modeling Problem", "authorids": ["~Michael_Janner1", "~Qiyang_Li1", "~Sergey_Levine1"], "authors": ["Michael Janner", "Qiyang Li", "Sergey Levine"], "keywords": ["Reinforcement learning", "transformers"], "abstract": "Reinforcement learning (RL) is typically viewed as the problem of estimating single-step policies (for model-free RL) or single-step models (for model-based RL), leveraging the Markov property to factorize the problem in time. However, we can also view RL as a sequence modeling problem: predict a sequence of actions that leads to a sequence of high rewards. Viewed in this way, it is tempting to consider whether powerful, high-capacity sequence prediction models that work well in other supervised learning domains, such as natural-language processing, can also provide simple and effective solutions to the RL problem. To this end, we explore how RL can be reframed as \"one big sequence modeling\" problem, using state-of-the-art Transformer architectures to model distributions over sequences of states, actions, and rewards. Addressing RL as a sequence modeling problem significantly simplifies a range of design decisions: we no longer require separate behavior policy constraints, as is common in prior work on offline model-free RL, and we no longer require ensembles or other epistemic uncertainty estimators, as is common in prior work on model-based RL. All of these roles are filled by the same Transformer sequence model. In our experiments, we demonstrate the flexibility of this approach across imitation learning, goal-conditioned RL, and offline RL.", "pdf": "/pdf/9a21c00b4244193d92af33159000f19f364b15b1.pdf", "supplementary_material": "/attachment/68fa23fc603f81dceab05e43ca194762dcf72599.pdf", "submission_history": "", "checklist": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "janner|offline_reinforcement_learning_as_one_big_sequence_modeling_problem", "code": "https://github.com/JannerM/trajectory-transformer", "thumbnail": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\njanner2021offline,\ntitle={Offline Reinforcement Learning as One Big Sequence Modeling Problem},\nauthor={Michael Janner and Qiyang Li and Sergey Levine},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=wgeK563QgSw}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492666465, "odate": 1636492666465, "details": {"replyCount": 16}}, {"id": "AklttWFnxS9", "original": "fPIbEF4P-j7", "number": 8646, "cdate": 1621630173095, "ddate": null, "tcdate": 1621630173095, "tmdate": 1683307724323, "tddate": null, "forum": "AklttWFnxS9", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Maximum Likelihood Training of Score-Based Diffusion Models", "authorids": ["~Yang_Song1", "~Conor_Durkan1", "~Iain_Murray1", "~Stefano_Ermon1"], "authors": ["Yang Song", "Conor Durkan", "Iain Murray", "Stefano Ermon"], "keywords": ["generative models", "density estimation", "score matching", "score-based generative models", "diffusion models", "stochastic differential equations", "normalizing flows", "neural ODEs", "likelihood", "continuous normalizing flows"], "abstract": "Score-based diffusion models synthesize samples by reversing a stochastic process that diffuses data to noise, and are trained by minimizing a weighted combination of score matching losses. The log-likelihood of score-based diffusion models can be tractably computed through a connection to continuous normalizing flows, but log-likelihood is not directly optimized by the weighted combination of score matching losses. We show that for a specific weighting scheme, the objective upper bounds the negative log-likelihood, thus enabling approximate maximum likelihood training of score-based diffusion models. We empirically observe that maximum likelihood training consistently improves the likelihood of score-based diffusion models across multiple datasets, stochastic processes, and model architectures. Our best models achieve negative log-likelihoods of 2.83 and 3.76 bits/dim on CIFAR-10 and ImageNet $32\\times 32$ without any data augmentation, on a par with state-of-the-art autoregressive models on these tasks. ", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "song|maximum_likelihood_training_of_scorebased_diffusion_models", "TL;DR": "Score-based generative models can achieve state-of-the-art likelihoods when re-weighting the training objective.", "pdf": "/pdf/756ca91c16908b457e64e0f988e3fb8c54fc9f6e.pdf", "checklist": "", "supplementary_material": "/attachment/6af838866a73ba3a58c84ca787a7df7bfc92409b.pdf", "code": "https://github.com/yang-song/score_flow", "thumbnail": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nsong2021maximum,\ntitle={Maximum Likelihood Training of Score-Based Diffusion Models},\nauthor={Yang Song and Conor Durkan and Iain Murray and Stefano Ermon},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=AklttWFnxS9}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492774355, "odate": 1636492774355, "details": {"replyCount": 14}}, {"id": "4bKbEP9b65v", "original": "o6iuM29dTBU", "number": 8629, "cdate": 1621630172073, "ddate": null, "tcdate": 1621630172073, "tmdate": 1683307723876, "tddate": null, "forum": "4bKbEP9b65v", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Littlestone Classes are Privately Online Learnable", "authorids": ["~Noah_Golowich1", "~Roi_Livni1"], "authors": ["Noah Golowich", "Roi Livni"], "keywords": ["differential privacy", "online classification", "online learning"], "TL;DR": "We provide a differentially private online learning algorithm for Littlestone classes with finite mistake bound.", "abstract": "    We consider the problem of online classification under a privacy constraint. In this setting a learner observes sequentially a stream of labelled examples $(x_t, y_t)$, for $1 \\leq t \\leq T$, and returns at each iteration $t$ a hypothesis $h_t$ which is used to predict the label of each new example $x_t$. The learner's performance is measured by her regret against a known hypothesis class $\\mathcal{H}$. We require that the algorithm satisfies the following privacy constraint: the sequence $h_1, \\ldots, h_T$ of hypotheses output by the algorithm needs to be an $(\\epsilon, \\delta)$-differentially private function of the whole input sequence $(x_1, y_1), \\ldots, (x_T, y_T)$.\n\nWe provide the first non-trivial regret bound for the realizable setting. Specifically, we show that if the class $\\mathcal{H}$ has constant Littlestone dimension then, given an oblivious sequence of labelled examples, there is a private learner that makes in expectation at most $O(\\log T)$ mistakes -- comparable to the optimal mistake bound in the non-private case, up to a logarithmic factor. Moreover, for general values of the Littlestone dimension $d$, the same mistake bound holds but with a doubly-exponential in $d$ factor. \n\n    A recent line of work has demonstrated a strong connection between classes that are online learnable and those that are differentially-private learnable. Our results strengthen this connection and show that an online learning algorithm can in fact be directly privatized (in the realizable setting).\n\nWe also discuss an adaptive setting and provide a sublinear regret bound of $O(\\sqrt{T})$.", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "golowich|littlestone_classes_are_privately_online_learnable", "pdf": "/pdf/2871b2b3c8b1fd8399efa0d616bb91724493dbce.pdf", "checklist": "", "supplementary_material": "/attachment/3c22579bb799f28b2d583e0101584bea2f64b494.pdf", "thumbnail": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\ngolowich2021littlestone,\ntitle={Littlestone Classes are Privately Online Learnable},\nauthor={Noah Golowich and Roi Livni},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=4bKbEP9b65v}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492757150, "odate": 1636492757150, "details": {"replyCount": 9}}, {"id": "ejmqyWW0MK6", "original": "QMaWOCSDMt", "number": 8596, "cdate": 1621630170120, "ddate": null, "tcdate": 1621630170120, "tmdate": 1683307723402, "tddate": null, "forum": "ejmqyWW0MK6", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Mixability made efficient: Fast online multiclass logistic regression", "authorids": ["~R\u00e9mi_J\u00e9z\u00e9quel1", "~Pierre_Gaillard1", "~Alessandro_Rudi1"], "authors": ["R\u00e9mi J\u00e9z\u00e9quel", "Pierre Gaillard", "Alessandro Rudi"], "keywords": ["Online learning", "Logistic regression"], "abstract": "Mixability has been shown to be a powerful tool to obtain algorithms with optimal regret. However, the resulting methods often suffer from high computational complexity which has reduced their practical applicability. For example, in the case of multiclass logistic regression, the aggregating forecaster (see Foster et al. 2018) achieves a regret of $O(\\log(Bn))$ whereas Online Newton Step achieves $O(e^B\\log(n))$ obtaining a double exponential gain in $B$ (a bound on the norm of comparative functions). However, this high statistical performance is at the price of a prohibitive computational complexity $O(n^{37})$.\nIn this paper, we use quadratic surrogates to make aggregating forecasters more efficient. We show that the resulting algorithm has still high statistical performance for a large class of losses. In particular, we derive an algorithm for multiclass regression with a regret bounded by $O(B\\log(n))$ and computational complexity of only $O(n^4)$.", "pdf": "/pdf/d8e5de4b7e8d21a1c38f1ee3ef8e59eb8ec15990.pdf", "supplementary_material": "/attachment/3d00ec560997121002b40539629e9e7314fb1e17.pdf", "submission_history": "", "checklist": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "j\u00e9z\u00e9quel|mixability_made_efficient_fast_online_multiclass_logistic_regression", "code": "/attachment/f9823dabc2621f4c12fc2d7ebb0f56bfc4697caa.zip", "thumbnail": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nj{\\'e}z{\\'e}quel2021mixability,\ntitle={Mixability made efficient: Fast online multiclass logistic regression},\nauthor={R{\\'e}mi J{\\'e}z{\\'e}quel and Pierre Gaillard and Alessandro Rudi},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=ejmqyWW0MK6}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492742485, "odate": 1636492742485, "details": {"replyCount": 12}}, {"id": "REXvo_lsQS9", "original": "nFIBfVhH2zB", "number": 8501, "cdate": 1621630164518, "ddate": null, "tcdate": 1621630164518, "tmdate": 1697937413217, "tddate": null, "forum": "REXvo_lsQS9", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Credit Assignment in Neural Networks through Deep Feedback Control", "authorids": ["~Alexander_Meulemans1", "~Matilde_Tristany_Farinha1", "~Javier_Garcia_Ordonez1", "~Pau_Vilimelis_Aceituno1", "~Joao_Sacramento1", "~Benjamin_F_Grewe1"], "authors": ["Alexander Meulemans", "Matilde Tristany Farinha", "Javier Garcia Ordonez", "Pau Vilimelis Aceituno", "Joao Sacramento", "Benjamin F Grewe"], "keywords": ["Biologically-plausible Deep Learning", "Neuroscience", "Deep Learning", "Control theory", "Optimization theory"], "abstract": "The success of deep learning sparked interest in whether the brain learns by using similar techniques for assigning credit to each synaptic weight for its contribution to the network output. However, the majority of current attempts at biologically-plausible learning methods are either non-local in time, require highly specific connectivity motifs, or have no clear link to any known mathematical optimization method. Here, we introduce Deep Feedback Control (DFC), a new learning method that uses a feedback controller to drive a deep neural network to match a desired output target and whose control signal can be used for credit assignment. The resulting learning rule is fully local in space and time and approximates Gauss-Newton optimization for a wide range of feedback connectivity patterns. To further underline its biological plausibility, we relate DFC to a multi-compartment model of cortical pyramidal neurons with a local voltage-dependent synaptic plasticity rule, consistent with recent theories of dendritic processing. By combining dynamical system theory with mathematical optimization theory, we provide a strong theoretical foundation for DFC that we corroborate with detailed results on toy experiments and standard computer-vision benchmarks.", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "meulemans|credit_assignment_in_neural_networks_through_deep_feedback_control", "TL;DR": "We introduce Deep Feedback Control, a new bio-plausible learning method that uses a feedback controller to drive a deep neural network to match a desired output target and which approximates Gauss-Newton optimization.", "pdf": "/pdf/9d0ab63395985e29e1ac0236a796ad79bd5d2ed1.pdf", "checklist": "", "supplementary_material": "/attachment/edcee8c37b5e477f808a5ba05111e5df48f5c199.pdf", "code": "https://github.com/meulemansalex/deep_feedback_control", "thumbnail": "", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 2 code implementations](https://www.catalyzex.com/paper/arxiv:2106.07887/code)", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nmeulemans2021credit,\ntitle={Credit Assignment in Neural Networks through Deep Feedback Control},\nauthor={Alexander Meulemans and Matilde Tristany Farinha and Javier Garcia Ordonez and Pau Vilimelis Aceituno and Joao Sacramento and Benjamin F Grewe},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=REXvo_lsQS9}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492727589, "odate": 1636492727589, "details": {"replyCount": 16}}, {"id": "DTA7Bgrai-Q", "original": "PEFh9knkm5r", "number": 8491, "cdate": 1621630163984, "ddate": null, "tcdate": 1621630163984, "tmdate": 1683307720736, "tddate": null, "forum": "DTA7Bgrai-Q", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Precise characterization of the prior predictive distribution of deep ReLU networks", "authorids": ["~Lorenzo_Noci1", "~Gregor_Bachmann1", "~Kevin_Roth1", "~Sebastian_Nowozin1", "~Thomas_Hofmann1"], "authors": ["Lorenzo Noci", "Gregor Bachmann", "Kevin Roth", "Sebastian Nowozin", "Thomas Hofmann"], "keywords": ["Bayesian Neural Networks", "Priors", "Meijer-G", "NNGP", "finite width corrections"], "TL;DR": "We derive a precise characterization of the prior predictive distribution of deep ReLU networks using Meijer-G functions.", "abstract": "Recent works on Bayesian neural networks (BNNs) have highlighted the need to better understand the implications of using Gaussian priors in combination with the compositional structure of the network architecture. \nSimilar in spirit to the kind of analysis that has been developed to devise better initialization schemes for neural networks (cf. He- or Xavier initialization), we derive a precise characterization of the prior predictive distribution of finite-width ReLU networks with Gaussian weights.\nWhile theoretical results have been obtained for their heavy-tailedness,\nthe full characterization of the prior predictive distribution (i.e. its density, CDF and moments), remained unknown prior to this work. Our analysis, based on the Meijer-G function, allows us to quantify the influence of architectural choices such as the width or depth of the network on the resulting shape of the prior predictive distribution. \nWe also formally connect our results to previous work in the infinite width setting, demonstrating that the moments of the distribution converge to those of a normal log-normal mixture in the infinite depth limit. \nFinally, our results provide valuable guidance on prior design: \nfor instance, controlling the predictive variance with depth- and width-informed priors on the weights of the network.", "pdf": "/pdf/286e5deb612ee7013131c11e3c276ea35537c681.pdf", "supplementary_material": "/attachment/9ed9d6fb8009186f197c96f6088d736112adbe97.pdf", "submission_history": "", "checklist": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "noci|precise_characterization_of_the_prior_predictive_distribution_of_deep_relu_networks", "thumbnail": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nnoci2021precise,\ntitle={Precise characterization of the prior predictive distribution of deep Re{LU} networks},\nauthor={Lorenzo Noci and Gregor Bachmann and Kevin Roth and Sebastian Nowozin and Thomas Hofmann},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=DTA7Bgrai-Q}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492731539, "odate": 1636492731539, "details": {"replyCount": 8}}, {"id": "2zCRcTafea", "original": "KI2wzaP-nr", "number": 8461, "cdate": 1621630162220, "ddate": null, "tcdate": 1621630162220, "tmdate": 1683307720008, "tddate": null, "forum": "2zCRcTafea", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Focal Attention for Long-Range Interactions in Vision Transformers", "authorids": ["~Jianwei_Yang1", "~Chunyuan_Li1", "~Pengchuan_Zhang1", "~Xiyang_Dai2", "~Bin_Xiao2", "~Lu_Yuan1", "~Jianfeng_Gao1"], "authors": ["Jianwei Yang", "Chunyuan Li", "Pengchuan Zhang", "Xiyang Dai", "Bin Xiao", "Lu Yuan", "Jianfeng Gao"], "keywords": ["Focal Attention", "Self-Attention", "Long-range Interactions", "Local-Global Interactions", "Vision Transformer", "Image Classification", "Object Detection"], "TL;DR": "An effective focal attention mechanism for modeling short- and long-range visual dependencies in Vision Transformers", "abstract": "Recently, Vision Transformer and its variants have shown great promise on various computer vision tasks. The ability to capture local and global visual dependencies through self-attention is the key to its success. But it also brings challenges due to quadratic computational overhead, especially for the high-resolution vision tasks(e.g., object detection). Many recent works have attempted to reduce the cost and improve model performance by applying either coarse-grained global attention or fine-grained local attention. However, both approaches cripple the modeling power of the original self-attention mechanism of multi-layer Transformers, leading to sub-optimal solutions.  In this paper, we present focal attention, a new attention mechanism that incorporates both fine-grained local and coarse-grained global interactions.  In this new mechanism, each token attends its closest surrounding tokens at the fine granularity and the tokens far away at a coarse granularity and thus can capture both short- and long-range visual dependencies efficiently and effectively. With focal attention, we propose a new variant of Vision Transformer models, called Focal Transformers, which achieve superior performance over the state-of-the-art (SoTA) Vision Transformers on a range of public image classification and object detection benchmarks.  In particular, our Focal Transformer models with a moderate size of 51.1M and a large size of 89.8M achieve 83.6% and 84.0%Top-1 accuracy, respectively, on ImageNet classification at 224\u00d7224.  When employed as the backbones, Focal Transformers achieve consistent and substantial improvements over the current SoTA Swin Transformers [44] across 6 different object detection methods.  Our largest Focal Transformer yields58.7/59.0boxmAPs and50.9/51.3mask mAPs on COCO mini-val/test-dev, and55.4mIoU onADE20K for semantic segmentation, creating new SoTA on three of the most challenging computer vision tasks. ", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "yang|focal_attention_for_longrange_interactions_in_vision_transformers", "pdf": "/pdf/8001ec0a98490fb528c428ec20a79fdf7416855d.pdf", "checklist": "", "supplementary_material": "/attachment/9cd2a41b9bea84f37b629849dbc48b0dba7d95b0.zip", "code": "https://github.com/microsoft/Focal-Transformer", "thumbnail": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nyang2021focal,\ntitle={Focal Attention for Long-Range Interactions in Vision Transformers},\nauthor={Jianwei Yang and Chunyuan Li and Pengchuan Zhang and Xiyang Dai and Bin Xiao and Lu Yuan and Jianfeng Gao},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=2zCRcTafea}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492666351, "odate": 1636492666351, "details": {"replyCount": 12}}, {"id": "YAv9enSDW-a", "original": "3POocZmn79o", "number": 8434, "cdate": 1621630160609, "ddate": null, "tcdate": 1621630160609, "tmdate": 1683307719445, "tddate": null, "forum": "YAv9enSDW-a", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "On the Value of Infinite Gradients in Variational Autoencoder Models", "authorids": ["~Bin_Dai1", "~Li_Kevin_Wenliang1", "~David_Wipf1"], "authors": ["Bin Dai", "Li Kevin Wenliang", "David Wipf"], "keywords": ["variational autoencoders", "sparse representations", "latent variable models"], "TL;DR": "We demonstrate that infinite gradients, although perhaps at times difficult to address in practical, can serve a useful role in pruning the latent space of autoencoder-based models.", "abstract": "A number of recent studies of continuous variational autoencoder (VAE) models have noted, either directly or indirectly, the tendency of various parameter gradients to drift towards infinity during training.  Because such gradients could potentially contribute to numerical instabilities, and are often framed as a problematic phenomena to be avoided, it may be tempting to shift to alternative energy functions that guarantee bounded gradients.  But it remains an open question: What might the unintended consequences of such a restriction be?  To address this issue, we examine how unbounded gradients relate to the regularization of a broad class of autoencoder-based architectures, including VAE models, as applied to data lying on or near a low-dimensional manifold (e.g., natural images).  Our main finding is that, if the ultimate goal is to simultaneously avoid over-regularization (high reconstruction errors, sometimes referred to as posterior collapse) and under-regularization (excessive latent dimensions are not pruned from the model), then an autoencoder-based energy function with infinite gradients around optimal representations is provably required per a certain technical sense which we carefully detail.  Given that both over- and under-regularization can directly lead to poor generated sample quality or suboptimal feature selection, this result suggests that heuristic modifications to or constraints on the VAE energy function may at times be ill-advised, and large gradients should be accommodated to the extent possible.", "submission_history": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "dai|on_the_value_of_infinite_gradients_in_variational_autoencoder_models", "pdf": "/pdf/6a387334ef970d6cfe3c743383352e40ca208c6b.pdf", "checklist": "", "supplementary_material": "/attachment/a817ccf0ba840c2bcd20040688b28ed1e7dd5f22.pdf", "thumbnail": "", "_bibtex": "@inproceedings{\ndai2021on,\ntitle={On the Value of Infinite Gradients in Variational Autoencoder Models},\nauthor={Bin Dai and Li Kevin Wenliang and David Wipf},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=YAv9enSDW-a}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492731901, "odate": 1636492731857, "details": {"replyCount": 20}}, {"id": "AnJUTpZiiWD", "original": "jvsG6wdO5aK", "number": 8421, "cdate": 1621630159859, "ddate": null, "tcdate": 1621630159859, "tmdate": 1697937416778, "tddate": null, "forum": "AnJUTpZiiWD", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Instance-Dependent Partial Label Learning", "authorids": ["~Ning_Xu5", "~Congyu_Qiao3", "~Xin_Geng1", "~Min-Ling_Zhang2"], "authors": ["Ning Xu", "Congyu Qiao", "Xin Geng", "Min-Ling Zhang"], "keywords": ["partial label learning", "label enhancement", "label distribution", "pseudo label"], "TL;DR": "We consider instance-dependent PLL and assume that each example is associated with a latent label distribution.", "abstract": "Partial label learning (PLL) is a typical weakly supervised learning problem, where each training example is associated with a set of candidate labels among which only one is true. Most existing PLL approaches assume that the incorrect labels in each training example are randomly picked as the candidate labels. However, this assumption is not realistic since the candidate labels are always instance-dependent. In this paper, we consider instance-dependent PLL and assume that each example is associated with a latent label distribution constituted by the real number of each label, representing the degree to each label describing the feature. The incorrect label with a high degree is more likely to be annotated as the candidate label. Therefore, the latent label distribution is the essential labeling information in partially labeled examples and worth being leveraged for predictive model training. Motivated by this consideration, we propose a novel PLL method that recovers the label distribution as a label enhancement (LE) process and trains the predictive model iteratively in every epoch. Specifically, we assume the true posterior density of the latent label distribution takes on the variational approximate Dirichlet density parameterized by an inference model. Then the evidence lower bound is deduced for optimizing the inference model and the label distributions generated from the variational posterior are utilized for training the predictive model. Experiments on benchmark and real-world datasets validate the effectiveness of the proposed method. Source code is available at https://github.com/palm-ml/valen.", "pdf": "/pdf/5b1ecb14325914eee49b1a64eea570cb75486a40.pdf", "supplementary_material": "/attachment/7883fad16a4809881d1cc070f7cc048e2a02af31.pdf", "submission_history": "", "checklist": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "xu|instancedependent_partial_label_learning", "code": "https://github.com/palm-ml/valen", "thumbnail": "", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2110.12911/code)", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nxu2021instancedependent,\ntitle={Instance-Dependent Partial Label Learning},\nauthor={Ning Xu and Congyu Qiao and Xin Geng and Min-Ling Zhang},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=AnJUTpZiiWD}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492697324, "odate": 1636492697324, "details": {"replyCount": 7}}, {"id": "Jyxmk4wUoQV", "original": "dF5i8bI7DuV", "number": 8261, "cdate": 1621630150235, "ddate": null, "tcdate": 1621630150235, "tmdate": 1697937423014, "tddate": null, "forum": "Jyxmk4wUoQV", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Foundations of Symbolic Languages for Model Interpretability", "authorids": ["~Marcelo_Arenas1", "~Daniel_B\u00e1ez1", "~Pablo_Barcelo1", "~Jorge_P\u00e9rez2", "~Bernardo_Subercaseaux1"], "authors": ["Marcelo Arenas", "Daniel B\u00e1ez", "Pablo Barcelo", "Jorge P\u00e9rez", "Bernardo Subercaseaux"], "keywords": ["language", "interpretability", "logic", "complexity", "decision trees", "explainability"], "TL;DR": "We propose a systematic study of model interpretability by considering a minimalistic symbolic query language tailored for interpretability, studying its complexity of evaluation and presenting a prototype with high-level syntax.", "abstract": "Several queries and scores have recently been proposed to explain individual predictions over ML models. Examples include queries based on \u201canchors\u201d, which are parts of an instance that are sufficient to justify its classification, and \u201cfeature-perturbation\u201d scores such as SHAP. Given the need for flexible, reliable, and easy-to-apply interpretability methods for ML models, we foresee the need for developing declarative languages to naturally specify different explainability queries. We do this in a principled way by rooting such a language in a logic called FOIL, which allows for expressing many simple but important explainability queries, and might serve as a core for more expressive interpretability languages. We study the computational complexity of FOIL queries over two classes of ML models often deemed to be easily interpretable: decision trees and more general decision diagrams. Since the number of possible inputs for an ML model is exponential in its dimension, tractability of the FOIL evaluation problem is delicate but can be achieved by either restricting the structure of the models, or the fragment of FOIL being evaluated.  We also present a prototype implementation of FOIL wrapped in a high-level declarative language and perform experiments showing that such a language can be used in practice.", "submission_history": "", "checklist": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "arenas|foundations_of_symbolic_languages_for_model_interpretability", "pdf": "/pdf/74d25cdc220156cda122af7ace9a36dc9a127d35.pdf", "supplementary_material": "/attachment/957fe5b2e3569a7690bf28338f6afee5c21f6634.pdf", "code": "https://github.com/AngrySeal/FOIL-Prototype", "thumbnail": "", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2110.02376/code)", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\narenas2021foundations,\ntitle={Foundations of Symbolic Languages for Model Interpretability},\nauthor={Marcelo Arenas and Daniel B{\\'a}ez and Pablo Barcelo and Jorge P{\\'e}rez and Bernardo Subercaseaux},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=Jyxmk4wUoQV}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492683616, "odate": 1636492683616, "details": {"replyCount": 10}}, {"id": "LZDiWaC9CGL", "original": "CInda96aWTb", "number": 8245, "cdate": 1621630149275, "ddate": null, "tcdate": 1621630149275, "tmdate": 1697937423310, "tddate": null, "forum": "LZDiWaC9CGL", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Multiwavelet-based Operator Learning for Differential Equations", "authorids": ["~Gaurav_Gupta2", "~Xiongye_Xiao1", "~Paul_Bogdan1"], "authors": ["Gaurav Gupta", "Xiongye Xiao", "Paul Bogdan"], "keywords": ["Neural operators", "multiwavelet transform", "partial differential equations"], "abstract": "The solution of a partial differential equation can be obtained by computing the inverse operator map between the input and the solution space. Towards this end, we introduce a $\\textit{multiwavelet-based neural operator learning scheme}$ that compresses the associated operator's kernel using fine-grained wavelets. By explicitly embedding the inverse multiwavelet filters, we learn the projection of the kernel onto fixed multiwavelet polynomial bases. The projected kernel is trained at multiple scales derived from using repeated computation of multiwavelet transform. This allows learning the complex dependencies at various scales and results in a resolution-independent scheme. Compare to the prior works, we exploit the fundamental properties of the operator's kernel which enable numerically efficient representation. We perform experiments on the Korteweg-de Vries (KdV) equation, Burgers' equation, Darcy Flow, and Navier-Stokes equation. Compared with the existing neural operator approaches, our model shows significantly higher accuracy and achieves state-of-the-art in a range of datasets. For the time-varying equations, the proposed method exhibits a ($2X-10X$) improvement ($0.0018$ ($0.0033$) relative $L2$ error for Burgers' (KdV) equation). By learning the mappings between function spaces, the proposed method has the ability to find the solution of a high-resolution input after learning from lower-resolution data.", "submission_history": "", "checklist": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "gupta|multiwaveletbased_operator_learning_for_differential_equations", "TL;DR": "We propose a novel multiwavelet-based Neural Operator scheme for learning partial differential equations, where the fundamental property of kernel smoothness enables efficient learning by multiwavelets.", "pdf": "/pdf/ce397728c11717a97c7fd98a9edc32fc2034fc9b.pdf", "supplementary_material": "/attachment/2c863eda2a47f8924f2693dc255656ed07346c38.pdf", "code": "https://github.com/gaurav71531/mwt-operator", "thumbnail": "", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2109.13459/code)", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\ngupta2021multiwaveletbased,\ntitle={Multiwavelet-based Operator Learning for Differential Equations},\nauthor={Gaurav Gupta and Xiongye Xiao and Paul Bogdan},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=LZDiWaC9CGL}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492777332, "odate": 1636492777332, "details": {"replyCount": 20}}, {"id": "MQQeeDiO5vv", "original": "2wYuAFv63n", "number": 8230, "cdate": 1621630148349, "ddate": null, "tcdate": 1621630148349, "tmdate": 1697937424430, "tddate": null, "forum": "MQQeeDiO5vv", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Combiner: Full Attention Transformer with Sparse Computation Cost", "authorids": ["~Hongyu_Ren1", "~Hanjun_Dai1", "~Zihang_Dai1", "~Mengjiao_Yang1", "~Jure_Leskovec1", "~Dale_Schuurmans1", "~Bo_Dai1"], "authors": ["Hongyu Ren", "Hanjun Dai", "Zihang Dai", "Mengjiao Yang", "Jure Leskovec", "Dale Schuurmans", "Bo Dai"], "keywords": ["Transformer", "long sequence modeling", "conditional expectation factorization", "full attention"], "TL;DR": "We propose Combiner, a drop-in replacement of attention, achieving the  full attention with sub-quadratic cost using structured factorization. The proposed Combiner achieves SOTA on variety of tasks.", "abstract": "Transformers provide a class of expressive architectures that are extremely effective for sequence modeling. However, the key limitation of transformers is their quadratic memory and time complexity $\\mathcal{O}(L^2)$ with respect to the sequence length in attention layers, which restricts application in extremely long sequences. Most existing approaches leverage sparsity or low-rank assumptions in the attention matrix to reduce cost, but sacrifice expressiveness. Instead, we propose Combiner, which provides full attention capability in each attention head while maintaining low computation and memory complexity. The key idea is to treat the self-attention mechanism as a conditional expectation over embeddings at each location, and approximate the conditional distribution with a structured factorization. Each location can attend to all other locations, either via direct attention, or through indirect attention to abstractions, which are again conditional expectations of embeddings from corresponding local regions. We show that most sparse attention patterns used in existing sparse transformers are able to inspire the design of such factorization for full attention, resulting in the same sub-quadratic cost ($\\mathcal{O}(L\\log(L))$ or $\\mathcal{O}(L\\sqrt{L})$). Combiner is a drop-in replacement for attention layers in existing transformers and can be easily implemented in common frameworks. An experimental evaluation on both autoregressive and bidirectional sequence tasks demonstrates the effectiveness of this approach, yielding state-of-the-art results on several image and text modeling tasks.", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "ren|combiner_full_attention_transformer_with_sparse_computation_cost", "pdf": "/pdf/a3497d367f138973e0bf532b0a2ccccb1f9e370f.pdf", "checklist": "", "supplementary_material": "/attachment/e92e5dcfb8f8b30355647ba4d07eb3a04ccf3b13.pdf", "code": "https://github.com/google-research/google-research/tree/master/combiner", "thumbnail": "", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 2 code implementations](https://www.catalyzex.com/paper/arxiv:2107.05768/code)", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nren2021combiner,\ntitle={Combiner: Full Attention Transformer with Sparse Computation Cost},\nauthor={Hongyu Ren and Hanjun Dai and Zihang Dai and Mengjiao Yang and Jure Leskovec and Dale Schuurmans and Bo Dai},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=MQQeeDiO5vv}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492722522, "odate": 1636492722522, "details": {"replyCount": 20}}, {"id": "3GpcwM1slH8", "original": "yqKnrTUz2zo", "number": 8213, "cdate": 1621630147302, "ddate": null, "tcdate": 1621630147302, "tmdate": 1697937424605, "tddate": null, "forum": "3GpcwM1slH8", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Uniform Sampling over Episode Difficulty", "authorids": ["~Sebastien_Arnold1", "~Guneet_Singh_Dhillon1", "~Avinash_Ravichandran1", "~Stefano_Soatto1"], "authors": ["Sebastien Arnold", "Guneet Singh Dhillon", "Avinash Ravichandran", "Stefano Soatto"], "keywords": ["episode sampling", "few-shot learning", "meta-learning"], "TL;DR": "How should we sample episodes to improve generalization? Our empirical study suggests that sampling uniformly over episode difficulty outperforms curriculum learning, easy, and hard mining.", "abstract": "Episodic training is a core ingredient of few-shot learning to train models on tasks with limited labelled data. Despite its success, episodic training remains largely understudied, prompting us to ask the question: what is the best way to sample episodes? In this paper, we first propose a method to approximate episode sampling distributions based on their difficulty. Building on this method, we perform an extensive analysis and find that sampling uniformly over episode difficulty outperforms other sampling schemes, including curriculum and easy-/hard-mining. As the proposed sampling method is algorithm agnostic, we can leverage these insights to improve few-shot learning accuracies across many episodic training algorithms. We demonstrate the efficacy of our method across popular few-shot learning datasets, algorithms, network architectures, and protocols.\n", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "arnold|uniform_sampling_over_episode_difficulty", "pdf": "/pdf/bc0bc5f9e36f18e9bfbb12f39248209be6ff2c32.pdf", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "checklist": "", "supplementary_material": "/attachment/b42137702eb8d2381877bfa6b535337f5cc54c37.pdf", "code": "http://seba1511.net/projects/eis/", "thumbnail": "", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 2 code implementations](https://www.catalyzex.com/paper/arxiv:2108.01662/code)", "_bibtex": "@inproceedings{\narnold2021uniform,\ntitle={Uniform Sampling over Episode Difficulty},\nauthor={Sebastien Arnold and Guneet Singh Dhillon and Avinash Ravichandran and Stefano Soatto},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=3GpcwM1slH8}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492685820, "odate": 1636492685820, "details": {"replyCount": 14}}, {"id": "-1rrzmJCp4", "original": "1qDPJF9-3Q5", "number": 8181, "cdate": 1621630145364, "ddate": null, "tcdate": 1621630145364, "tmdate": 1683307714413, "tddate": null, "forum": "-1rrzmJCp4", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "SPANN: Highly-efficient Billion-scale Approximate Nearest Neighborhood Search", "authorids": ["~Qi_Chen2", "~Bing_Zhao3", "~Haidong_Wang2", "~Mingqin_Li1", "chuanli@microsoft.com", "~Zengzhong_Li1", "~Mao_Yang1", "~Jingdong_Wang1"], "authors": ["Qi Chen", "Bing Zhao", "Haidong Wang", "Mingqin Li", "Chuanjie Liu", "Zengzhong Li", "Mao Yang", "Jingdong Wang"], "keywords": ["billion-scale", "vector search", "inverted index solution"], "abstract": "The in-memory algorithms for approximate nearest neighbor search (ANNS) have achieved great success for fast high-recall search, but are extremely expensive when handling very large scale database. Thus, there is an increasing request for the hybrid ANNS solutions with small memory and inexpensive solid-state drive (SSD). In this paper, we present a simple but efficient memory-disk hybrid indexing and search system, named SPANN, that follows the inverted index methodology. It stores the centroid points of the posting lists in the memory and the large posting lists in the disk. We guarantee both disk-access efficiency (low  latency) and high recall by effectively reducing the disk-access number and retrieving high-quality posting lists. In the index-building stage, we adopt a hierarchical balanced clustering algorithm to balance the length of posting lists and augment the posting list by adding the points in the closure of the corresponding clusters. In the search stage, we use a query-aware scheme to dynamically prune the access of unnecessary posting lists.  Experiment results demonstrate that SPANN is 2X faster than the state-of-the-art ANNS solution DiskANN to reach the same recall quality 90% with same memory cost in three billion-scale datasets. It can reach 90% recall@1 and recall@10 in just around one millisecond with only about 10% of original memory cost.  Code is available at: https://github.com/microsoft/SPTAG.\n", "submission_history": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "chen|spann_highlyefficient_billionscale_approximate_nearest_neighborhood_search", "pdf": "/pdf/6affdf6824ec740a0e00cd471601ba19212762d0.pdf", "checklist": "", "TL;DR": "SPANN: Highly-efficient Billion-scale Approximate Nearest Neighbor Search", "code": "https://github.com/microsoft/SPTAG", "thumbnail": "", "_bibtex": "@inproceedings{\nchen2021spann,\ntitle={{SPANN}: Highly-efficient Billion-scale Approximate Nearest Neighborhood Search},\nauthor={Qi Chen and Bing Zhao and Haidong Wang and Mingqin Li and Chuanjie Liu and Zengzhong Li and Mao Yang and Jingdong Wang},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=-1rrzmJCp4}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492737937, "odate": 1636492737937, "details": {"replyCount": 11}}, {"id": "o2mbl-Hmfgd", "original": "CKWmi-xCGie", "number": 8129, "cdate": 1621630142331, "ddate": null, "tcdate": 1621630142331, "tmdate": 1697937428207, "tddate": null, "forum": "o2mbl-Hmfgd", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Intriguing Properties of Vision Transformers", "authorids": ["~Muzammal_Naseer1", "~Kanchana_Ranasinghe1", "~Salman_Khan4", "~Munawar_Hayat2", "~Fahad_Khan1", "~Ming-Hsuan_Yang1"], "authors": ["Muzammal Naseer", "Kanchana Ranasinghe", "Salman Khan", "Munawar Hayat", "Fahad Khan", "Ming-Hsuan Yang"], "keywords": ["Vision Transformers", "Auto-segmentation", "Off-the-shelf-features", "Robustness", "Shape-Modeling"], "abstract": "Vision transformers (ViT) have demonstrated impressive performance across numerous machine vision tasks. These models are based on multi-head self-attention mechanisms that can flexibly attend to a sequence of image patches to encode contextual cues. An important question is how such flexibility (in attending image-wide context conditioned on a given patch) can facilitate handling nuisances in natural images e.g., severe occlusions, domain shifts, spatial permutations, adversarial and natural perturbations. We systematically study this question via an extensive set of experiments encompassing three ViT families and provide comparisons with a high-performing convolutional neural network (CNN). We show and analyze the following intriguing properties of ViT: (a)Transformers are highly robust to severe occlusions, perturbations and domain shifts, e.g., retain as high as 60% top-1 accuracy on ImageNet even after randomly occluding 80% of the image content. (b)The robustness towards occlusions is not due to texture bias, instead we show that ViTs are significantly less biased towards local textures, compared to CNNs. When properly trained to encode shape-based features, ViTs demonstrate shape recognition capability comparable to that of human visual system, previously unmatched in the literature. (c)Using ViTs to encode shape representation leads to an interesting consequence of accurate semantic segmentation without pixel-level supervision. (d)Off-the-shelf features from a single ViT model can be combined to create a feature ensemble,  leading to high accuracy rates across a range of classification datasets in both traditional and few-shot learning paradigms.  We show effective features of ViTs are due to flexible and dynamic receptive fields possible via self-attention mechanisms. Our code will be publicly released.", "submission_history": "", "checklist": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "naseer|intriguing_properties_of_vision_transformers", "pdf": "/pdf/0140d23fc2b190ea54786be5346158ec0c332da4.pdf", "supplementary_material": "/attachment/b95a4c06add42b50237d3ccb8645da5add49a35d.pdf", "TL;DR": "Analysis of content-dependent long-range interaction modeling capabilities of Vision Transformers in terms of robustness against image nuisances such as severe occlusions, domain shifts, spatial permutations, adversarial and natural perturbations.", "code": "https://github.com/Muzammal-Naseer/Intriguing-Properties-of-Vision-Transformers", "thumbnail": "", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 2 code implementations](https://www.catalyzex.com/paper/arxiv:2105.10497/code)", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nnaseer2021intriguing,\ntitle={Intriguing Properties of Vision Transformers},\nauthor={Muzammal Naseer and Kanchana Ranasinghe and Salman Khan and Munawar Hayat and Fahad Khan and Ming-Hsuan Yang},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=o2mbl-Hmfgd}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492690072, "odate": 1636492690072, "details": {"replyCount": 13}}, {"id": "iQICgKcrGpE", "original": "qwK7GKzh6Xm", "number": 8088, "cdate": 1621630139826, "ddate": null, "tcdate": 1621630139826, "tmdate": 1683307712424, "tddate": null, "forum": "iQICgKcrGpE", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "On the Existence of The Adversarial Bayes Classifier", "authorids": ["~Pranjal_Awasthi3", "~Natalie_Frank1", "~Mehryar_Mohri2"], "authors": ["Pranjal Awasthi", "Natalie Frank", "Mehryar Mohri"], "keywords": ["Adversarial Learning", "Learning Theory", "Consistency", "Calibration", "Bayes classifiers"], "TL;DR": "We prove that in many typical adversarial learning scenarios, there exists a classifier that minimizes the adversarial loss", "abstract": "Adversarial robustness is a critical property in a variety of modern machine learning applications. While it has been the subject of several recent theoretical studies, many important questions related to adversarial robustness are still open.  In this work, we study a fundamental question regarding Bayes optimality for adversarial robustness. We provide general sufficient conditions under which the existence of a Bayes optimal classifier can be guaranteed for adversarial robustness. Our results can provide a useful tool for a subsequent study of surrogate losses in adversarial robustness and their consistency properties.", "submission_history": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "awasthi|on_the_existence_of_the_adversarial_bayes_classifier", "pdf": "/pdf/f6b538a624347b3715a7b4f261f3fe536106f811.pdf", "supplementary_material": "/attachment/30b4cd66e3419143ba08f657d5edff575630f836.pdf", "checklist": "", "thumbnail": "", "_bibtex": "@inproceedings{\nawasthi2021on,\ntitle={On the Existence of The Adversarial Bayes Classifier},\nauthor={Pranjal Awasthi and Natalie Frank and Mehryar Mohri},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=iQICgKcrGpE}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492743954, "odate": 1636492743954, "details": {"replyCount": 14}}, {"id": "4h4oqp-ATxb", "original": "SYHHXn5JViO", "number": 8066, "cdate": 1621630138537, "ddate": null, "tcdate": 1621630138537, "tmdate": 1683307711585, "tddate": null, "forum": "4h4oqp-ATxb", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Neural Symplectic Form: Learning Hamiltonian Equations on General Coordinate Systems", "authorids": ["~Yuhan_Chen1", "~Takashi_Matsubara1", "~Takaharu_Yaguchi1"], "authors": ["Yuhan Chen", "Takashi Matsubara", "Takaharu Yaguchi"], "keywords": ["Hamiltonian Neural Networks", "Hamiltonian Mechanics", "Symplectic Geometry"], "TL;DR": "We propose an efficient method for learning Hamiltonian equations in general coordinate systems by using a coordinate-free representation used in symplectic geometry.", "abstract": "In recent years, substantial research on the methods for learning Hamiltonian equations has been conducted. Although these approaches are very promising, the commonly used representation of the Hamilton equation uses the generalized momenta, which are generally unknown. Therefore, the training data must be represented in this unknown coordinate system, and this causes difficulty in applying the model to real data. Meanwhile, Hamiltonian equations also have a coordinate-free expression that is expressed by using the symplectic 2-form. In this study, we propose a model that learns the symplectic form from data using neural networks, thereby providing a method for learning Hamiltonian equations from data represented in general coordinate systems, which are not limited to the generalized coordinates and the generalized momenta. Consequently, the proposed method is capable not only of modeling target equations of both Hamiltonian and Lagrangian formalisms but also of extracting unknown Hamiltonian structures hidden in the data. For example, many polynomial ordinary differential equations such as the Lotka-Volterra equation are known to admit non-trivial Hamiltonian structures, and our numerical experiments show that such structures can be certainly learned from data. Technically, each symplectic 2-form is associated with a skew-symmetric matrix, but not all skew-symmetric matrices define the symplectic 2-form. In the proposed method, using the fact that symplectic 2-forms are derived as the exterior derivative of certain differential 1-forms, we model the differential 1-form by neural networks, thereby improving the efficiency of learning.", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "chen|neural_symplectic_form_learning_hamiltonian_equations_on_general_coordinate_systems", "pdf": "/pdf/426244b37a22c3f273db4ccb51d3e27d8ecdf6e4.pdf", "checklist": "", "supplementary_material": "/attachment/9a1eb66c3c9afeaa2f57b558740725916779a17b.pdf", "code": "https://github.com/YuhanChen0805/neural_symplectic_form", "thumbnail": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nchen2021neural,\ntitle={Neural Symplectic Form: Learning Hamiltonian Equations on General Coordinate Systems},\nauthor={Yuhan Chen and Takashi Matsubara and Takaharu Yaguchi},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=4h4oqp-ATxb}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492674308, "odate": 1636492674308, "details": {"replyCount": 21}}, {"id": "WYrC0Aentah", "original": "x4pxVRd4Zt", "number": 7971, "cdate": 1621630133175, "ddate": null, "tcdate": 1621630133175, "tmdate": 1683307709431, "tddate": null, "forum": "WYrC0Aentah", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "On the Power of Differentiable Learning versus PAC and SQ Learning", "authorids": ["~Emmanuel_Abbe1", "~Pritish_Kamath2", "~eran_malach1", "~Colin_Sandon1", "~Nathan_Srebro1"], "authors": ["Emmanuel Abbe", "Pritish Kamath", "eran malach", "Colin Sandon", "Nathan Srebro"], "keywords": ["Differentiable Learning", "PAC Learning", "Statistical Query Learning", "mini-batch SGD"], "abstract": "We study the power of learning via mini-batch stochastic gradient descent (SGD) on the loss of a differentiable model or neural network, and ask what learning problems can be learnt using this paradigm. We show that SGD can always simulate\u00a0learning with statistical queries (SQ), but its ability to go beyond that depends on the precision $\\rho$ of the gradients and the minibatch size $b$. With fine enough precision relative to minibatch size, namely when $b \\rho$ is small enough, SGD can go beyond SQ learning and simulate any sample-based learning algorithm and thus its learning power is equivalent to that of PAC learning;\u00a0this extends prior work that achieved this result for $b=1$.\u00a0Moreover,\u00a0with polynomially many bits of precision (i.e. when $\\rho$ is exponentially small), SGD can simulate PAC learning regardless of the batch size. On the other hand, when $b \\rho^2$ is large enough, the power of SGD is equivalent to that of SQ learning.", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "abbe|on_the_power_of_differentiable_learning_versus_pac_and_sq_learning", "pdf": "/pdf/5d42fa810057548adfff4fe5ea3e6717ffd5d6a3.pdf", "supplementary_material": "/attachment/c10c65ab22310a97ca3ddc4ae79a77e0af41d2fd.pdf", "checklist": "", "TL;DR": "Identifies regimes of mini-batch size and gradient precision in gradient-based learning on differentiable models under which it becomes as powerful as sample based learning, or collapses to learning in the statistical query model.", "thumbnail": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nabbe2021on,\ntitle={On the Power of Differentiable Learning versus {PAC} and {SQ} Learning},\nauthor={Emmanuel Abbe and Pritish Kamath and eran malach and Colin Sandon and Nathan Srebro},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=WYrC0Aentah}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492728453, "odate": 1636492728409, "details": {"replyCount": 9}}, {"id": "-mGv2KxQ43D", "original": "EYUZ4Pl_tjV", "number": 7910, "cdate": 1621630129568, "ddate": null, "tcdate": 1621630129568, "tmdate": 1683307707962, "tddate": null, "forum": "-mGv2KxQ43D", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Learning MDPs from Features: Predict-Then-Optimize for Sequential Decision Making by Reinforcement Learning", "authorids": ["~Kai_Wang5", "~Sanket_Shah2", "~Haipeng_Chen1", "~Andrew_Perrault1", "~Finale_Doshi-Velez1", "~Milind_Tambe1"], "authors": ["Kai Wang", "Sanket Shah", "Haipeng Chen", "Andrew Perrault", "Finale Doshi-Velez", "Milind Tambe"], "keywords": ["Optimization", "predict-then-optimize", "decision-focused learning", "differentiable optimization", "reinforcement learning", "MDP", "low-rank approximation", "Woodbury matrix identity", "KKT conditions", "optimality conditions", "sequential decision problems"], "abstract": "In the predict-then-optimize framework, the objective is to train a predictive model, mapping from environment features to parameters of an optimization problem, which maximizes decision quality when the optimization is subsequently solved. Recent work on decision-focused learning shows that embedding the optimization problem in the training pipeline can improve decision quality and help generalize better to unseen tasks compared to relying on an intermediate loss function for evaluating prediction quality. We study the predict-then-optimize framework in the context of sequential decision problems (formulated as MDPs) that are solved via reinforcement learning. In particular, we are given environment features and a set of trajectories from training MDPs, which we use to train a predictive model that generalizes to unseen test MDPs without trajectories. Two significant computational challenges arise in applying decision-focused learning to MDPs: (i) large state and action spaces make it infeasible for existing techniques to differentiate through MDP problems, and (ii) the high-dimensional policy space, as parameterized by a neural network, makes differentiating through a policy expensive. We resolve the first challenge by sampling provably unbiased derivatives to approximate and differentiate through optimality conditions, and the second challenge by using a low-rank approximation to the high-dimensional sample-based derivatives. We implement both Bellman-based and policy gradient-based decision-focused learning on three different MDP problems with missing parameters, and show that decision-focused learning performs better in generalization to unseen tasks.", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "wang|learning_mdps_from_features_predictthenoptimize_for_sequential_decision_making_by_reinforcement_learning", "TL;DR": "We extend decision-focused learning to MDPs with missing parameters. The key novelty is to approximate Hessian to address the high computational cost of differentiating through MDP layers, which arises from large state-action and policy spaces.", "pdf": "/pdf/2b6c4caeb0af13353d32935ad0dd98ea20dd2060.pdf", "checklist": "", "supplementary_material": "/attachment/bdec4219139ac63b1a3b3f59f91b7f28614beab8.pdf", "code": "https://github.com/guaguakai/decision-focused-RL", "thumbnail": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nwang2021learning,\ntitle={Learning {MDP}s from Features: Predict-Then-Optimize for Sequential Decision Making by Reinforcement Learning},\nauthor={Kai Wang and Sanket Shah and Haipeng Chen and Andrew Perrault and Finale Doshi-Velez and Milind Tambe},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=-mGv2KxQ43D}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492728834, "odate": 1636492728834, "details": {"replyCount": 13}}, {"id": "VJ7u6SbqorK", "original": "l7W2WP9-Lq4", "number": 7849, "cdate": 1621630126025, "ddate": null, "tcdate": 1621630126025, "tmdate": 1697937438323, "tddate": null, "forum": "VJ7u6SbqorK", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "MEST: Accurate and Fast Memory-Economic Sparse Training Framework on the Edge", "authorids": ["~Geng_Yuan1", "~Xiaolong_Ma2", "~Wei_Niu3", "~Zhengang_Li2", "~Zhenglun_Kong1", "~Ning_Liu4", "~Yifan_Gong2", "~Zheng_Zhan3", "~Chaoyang_He1", "~Qing_Jin1", "~Siyue_Wang1", "~Minghai_Qin1", "~Bin_Ren1", "~Yanzhi_Wang3", "~Sijia_Liu1", "~Xue_Lin1"], "authors": ["Geng Yuan", "Xiaolong Ma", "Wei Niu", "Zhengang Li", "Zhenglun Kong", "Ning Liu", "Yifan Gong", "Zheng Zhan", "Chaoyang He", "Qing Jin", "Siyue Wang", "Minghai Qin", "Bin Ren", "Yanzhi Wang", "Sijia Liu", "Xue Lin"], "keywords": ["dynamic sparse training", "memory-economic training", "edge device training", "mobile training acceleration"], "abstract": "Recently, a new trend of exploring sparsity for accelerating neural network training has emerged, embracing the paradigm of training on the edge. This paper proposes a novel Memory-Economic Sparse Training (MEST) framework targeting for accurate and fast execution on edge devices. The proposed MEST framework consists of enhancements by Elastic Mutation (EM) and Soft Memory Bound (&S) that ensure superior accuracy at high sparsity ratios. Different from the existing works for sparse training, this current work reveals the importance of sparsity schemes on the performance of sparse training in terms of accuracy as well as training speed on real edge devices. On top of that, the paper proposes to employ data efficiency for further acceleration of sparse training. Our results suggest that unforgettable examples can be identified in-situ even during the dynamic exploration of sparsity masks in the sparse training process, and therefore can be removed for further training speedup on edge devices. Comparing with state-of-the-art (SOTA) works on accuracy, our MEST increases Top-1 accuracy significantly on ImageNet when using the same unstructured sparsity scheme. Systematical evaluation on accuracy, training speed, and memory footprint are conducted, where the proposed MEST framework consistently outperforms representative SOTA works. A reviewer strongly against our work based on his false assumptions and misunderstandings. On top of the previous submission, we employ data efficiency for further acceleration of sparse training. And we explore the impact of model sparsity, sparsity schemes, and sparse training algorithms on the number of removable training examples. Our codes are publicly available at: https://github.com/boone891214/MEST.", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "yuan|mest_accurate_and_fast_memoryeconomic_sparse_training_framework_on_the_edge", "pdf": "/pdf/76b030f2d80ecc8c2dbb385dadc6cbb2247101ab.pdf", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "checklist": "", "supplementary_material": "/attachment/547955a19a38c6214d6fe9c0a21896439a9374fe.pdf", "code": "https://github.com/boone891214/MEST", "thumbnail": "", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2110.14032/code)", "_bibtex": "@inproceedings{\nyuan2021mest,\ntitle={{MEST}: Accurate and Fast Memory-Economic Sparse Training Framework on the Edge},\nauthor={Geng Yuan and Xiaolong Ma and Wei Niu and Zhengang Li and Zhenglun Kong and Ning Liu and Yifan Gong and Zheng Zhan and Chaoyang He and Qing Jin and Siyue Wang and Minghai Qin and Bin Ren and Yanzhi Wang and Sijia Liu and Xue Lin},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=VJ7u6SbqorK}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492701964, "odate": 1636492701964, "details": {"replyCount": 17}}, {"id": "rm0I5y2zkG8", "original": "3OgPCewG0LN", "number": 7840, "cdate": 1621630125469, "ddate": null, "tcdate": 1621630125469, "tmdate": 1697937438561, "tddate": null, "forum": "rm0I5y2zkG8", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Learning to delegate for large-scale vehicle routing", "authorids": ["~Sirui_Li1", "~Zhongxia_Yan1", "~Cathy_Wu1"], "authors": ["Sirui Li", "Zhongxia Yan", "Cathy Wu"], "keywords": ["machine learning", "combinatorial optimization", "vehicle routing", "decomposition"], "abstract": "Vehicle routing problems (VRPs) form a class of combinatorial problems with wide practical applications. While previous heuristic or learning-based works achieve decent solutions on small problem instances, their performance deteriorates in large problems. This article presents a novel learning-augmented local search framework to solve large-scale VRP. The method iteratively improves the solution by identifying appropriate subproblems and $delegating$ their improvement to a black box subsolver. At each step, we leverage spatial locality to consider only a linear number of subproblems, rather than exponential. We frame subproblem selection as regression and train a Transformer on a generated training set of problem instances. Our method accelerates state-of-the-art VRP solvers by 10x to 100x while achieving competitive solution qualities for VRPs with sizes ranging from 500 to 3000. Learned subproblem selection offers a 1.5x to 2x speedup over heuristic or random selection. Our results generalize to a variety of VRP distributions, variants, and solvers.", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "li|learning_to_delegate_for_largescale_vehicle_routing", "pdf": "/pdf/602468bca527d068a48808961d5e9c1ae765fb9e.pdf", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "checklist": "", "supplementary_material": "/attachment/df4085ee67177624eaf9c16bf3c81e61a33da199.pdf", "code": "https://github.com/mit-wu-lab/learning-to-delegate", "thumbnail": "", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 4 code implementations](https://www.catalyzex.com/paper/arxiv:2107.04139/code)", "_bibtex": "@inproceedings{\nli2021learning,\ntitle={Learning to delegate for large-scale vehicle routing},\nauthor={Sirui Li and Zhongxia Yan and Cathy Wu},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=rm0I5y2zkG8}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492690503, "odate": 1636492690503, "details": {"replyCount": 21}}, {"id": "l-0rLXvctI", "original": "jLmsz6TYiOm", "number": 7805, "cdate": 1621630123338, "ddate": null, "tcdate": 1621630123338, "tmdate": 1683307706006, "tddate": null, "forum": "l-0rLXvctI", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Fair Sparse Regression with Clustering: An Invex Relaxation for a Combinatorial Problem", "authorids": ["~Adarsh_Barik1", "~Jean_Honorio1"], "authors": ["Adarsh Barik", "Jean Honorio"], "keywords": ["Fairness", "Invexity", "Combinatorial Optimization", "Primal Dual Witness Method"], "TL;DR": "We provide an invex relaxation with provable theoretical guarantees for a combinatorial problem while ensuring fairness.", "abstract": "In this paper, we study the problem of fair sparse regression on a biased dataset where bias depends upon a hidden binary attribute. The presence of a hidden attribute adds an extra layer of complexity to the problem by combining sparse regression and clustering with unknown binary labels. The corresponding optimization problem is combinatorial, but we propose a novel relaxation of it as an invex optimization problem. To the best of our knowledge, this is the first invex relaxation for a combinatorial problem. We show that the inclusion of the debiasing/fairness constraint in our model has no adverse effect on the performance. Rather, it enables the recovery of the hidden attribute. The support of our recovered regression parameter vector matches exactly with the true parameter vector. Moreover, we simultaneously solve the clustering problem by recovering the exact value of the hidden attribute for each sample. Our method uses carefully constructed primal dual witnesses to provide theoretical guarantees for the combinatorial problem. To that end, we show that the sample complexity of our method is logarithmic in terms of the dimension of the regression parameter vector.", "submission_history": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "barik|fair_sparse_regression_with_clustering_an_invex_relaxation_for_a_combinatorial_problem", "pdf": "/pdf/60a8d2baa231d6b4f5fa857caf4200a66a62d57d.pdf", "supplementary_material": "/attachment/3b71a687a962487e0518dc8be9ce6ad3f4294519.pdf", "checklist": "", "thumbnail": "", "_bibtex": "@inproceedings{\nbarik2021fair,\ntitle={Fair Sparse Regression with Clustering: An Invex Relaxation for a Combinatorial Problem},\nauthor={Adarsh Barik and Jean Honorio},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=l-0rLXvctI}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492763100, "odate": 1636492763100, "details": {"replyCount": 18}}, {"id": "iKYO63MOWwi", "original": "8kEAnShXoIy", "number": 7774, "cdate": 1621630121456, "ddate": null, "tcdate": 1621630121456, "tmdate": 1683307705245, "tddate": null, "forum": "iKYO63MOWwi", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Online Active Learning with Surrogate Loss Functions", "authorids": ["~Giulia_DeSalvo1", "~Claudio_Gentile1", "~Tobias_Sommer_Thune1"], "authors": ["Giulia DeSalvo", "Claudio Gentile", "Tobias Sommer Thune"], "keywords": ["active learning", "streaming", "weak labels"], "TL;DR": "We introduce a novel active learning algorithm with provable guarantees that works with surrogate loss functions and achieving compelling experimental performances", "abstract": "We derive a novel active learning algorithm in the streaming setting for binary classification tasks. The algorithm leverages \nweak labels to minimize the number of label requests, and trains a model to optimize a surrogate loss on a resulting set of labeled and \nweak-labeled points. Our algorithm jointly admits two crucial properties: theoretical guarantees in the general agnostic setting and a strong empirical performance. Our theoretical analysis shows that the algorithm attains favorable generalization and label complexity bounds, while our empirical study on 18 real-world datasets demonstrate that the algorithm outperforms standard baselines, including the Margin Algorithm, or  Uncertainty Sampling, a high-performing active learning algorithm favored by practitioners.", "submission_history": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "checklist": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "desalvo|online_active_learning_with_surrogate_loss_functions", "pdf": "/pdf/b84d4bc5c1236f380455ca5e3a4d15b8f2932a94.pdf", "supplementary_material": "/attachment/e6e4e4a1f8c9b0891a4d2ad3d14b494764cb7f9e.pdf", "thumbnail": "", "_bibtex": "@inproceedings{\ndesalvo2021online,\ntitle={Online Active Learning with Surrogate Loss Functions},\nauthor={Giulia DeSalvo and Claudio Gentile and Tobias Sommer Thune},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=iKYO63MOWwi}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492735380, "odate": 1636492735380, "details": {"replyCount": 13}}, {"id": "ThbM9_6DNU", "original": "VRntuV9mPpm", "number": 7734, "cdate": 1621630119095, "ddate": null, "tcdate": 1621630119095, "tmdate": 1683307704335, "tddate": null, "forum": "ThbM9_6DNU", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Learning Disentangled Behavior Embeddings", "authorids": ["~Changhao_Shi1", "~Sivan_Schwartz1", "~Shahar_Levy1", "~Shay_Achvat1", "~Maisan_Abboud1", "~Amir_Ghanayim1", "~Jackie_Schiller1", "~Gal_Mishne1"], "authors": ["Changhao Shi", "Sivan Schwartz", "Shahar Levy", "Shay Achvat", "Maisan Abboud", "Amir Ghanayim", "Jackie Schiller", "Gal Mishne"], "keywords": ["Neuroscience", "Animal Behavior", "Behavioral Videos", "Generative Models"], "abstract": "To understand the relationship between behavior and neural activity, experiments in neuroscience often include an animal performing a repeated behavior such as a motor task. Recent progress in computer vision and deep learning has shown great potential in the automated analysis of behavior by leveraging large and high-quality video datasets. In this paper, we design Disentangled Behavior Embedding (DBE) to learn robust behavioral embeddings from unlabeled, multi-view, high-resolution behavioral videos across different animals and multiple sessions. We further combine DBE with a stochastic temporal model to propose Variational Disentangled Behavior Embedding (VDBE), an end-to-end approach that learns meaningful discrete behavior representations and generates interpretable behavioral videos. Our models learn consistent behavior representations by explicitly disentangling the dynamic behavioral factors (pose) from time-invariant, non-behavioral nuisance factors (context) in a deep autoencoder, and exploit the temporal structures of pose dynamics. Compared to competing approaches, DBE and VDBE enjoy superior performance on downstream tasks such as fine-grained behavioral motif generation and behavior decoding.", "pdf": "/pdf/e1e68e0afaed7486ffbd91ed1e878bcc0baa6167.pdf", "supplementary_material": "/attachment/54a492d0a2a54a0bf0217365c124e88333520eb8.zip", "submission_history": "", "checklist": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "shi|learning_disentangled_behavior_embeddings", "code": "https://github.com/Mishne-Lab/DBE-Disentangled-Behavior-Embedding", "thumbnail": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nshi2021learning,\ntitle={Learning Disentangled Behavior Embeddings},\nauthor={Changhao Shi and Sivan Schwartz and Shahar Levy and Shay Achvat and Maisan Abboud and Amir Ghanayim and Jackie Schiller and Gal Mishne},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=ThbM9_6DNU}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492749589, "odate": 1636492749548, "details": {"replyCount": 11}}, {"id": "Wkq4hKpGxWv", "original": "_-MHQUBae5r", "number": 7696, "cdate": 1621630116813, "ddate": null, "tcdate": 1621630116813, "tmdate": 1683307703267, "tddate": null, "forum": "Wkq4hKpGxWv", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Auditing Black-Box Prediction Models for Data Minimization Compliance", "authorids": ["~Bashir_Rastegarpanah1", "~Krishna_P._Gummadi1", "~Mark_Crovella1"], "authors": ["Bashir Rastegarpanah", "Krishna P. Gummadi", "Mark Crovella"], "keywords": ["Responsible ML", "Privacy", "Data Minimization"], "TL;DR": "This paper proposes a new operational definition of the data minimization principle (eg, from GDPR) that is appropriate for auditing black-box prediction models, and develops efficient algorithms for that setting.", "abstract": "In this paper, we focus on auditing black-box prediction models for compliance with the GDPR\u2019s data minimization principle. This principle restricts prediction models to use the minimal information that is necessary for performing the task at hand. Given the challenge of the black-box setting, our key idea is to check if each of the prediction model\u2019s input features is individually necessary by assigning it some constant value (i.e., applying a simple imputation) across all prediction instances, and measuring the extent to which the model outcomes would change. We introduce a metric for data minimization that is based on model instability under simple imputations. We extend the applicability of this metric from a finite sample model to a distributional setting by introducing a probabilistic data minimization guarantee, which we derive using a Bayesian approach. Furthermore, we address the auditing problem under a constraint on the number of queries to the prediction system. We formulate the problem of allocating a budget of system queries to feasible simple imputations (for investigating model instability) as a multi-armed bandit framework with probabilistic success metrics. We define two bandit problems for providing a probabilistic data minimization guarantee at a given confidence level: a decision problem given a data minimization level, and a measurement problem given a fixed query budget. We design efficient algorithms for these auditing problems using novel exploration strategies that expand classical bandit strategies. Our experiments with real-world prediction systems show that our auditing algorithms significantly outperform simpler benchmarks in both measurement and decision problems.", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "rastegarpanah|auditing_blackbox_prediction_models_for_data_minimization_compliance", "pdf": "/pdf/ad4a4d5635bcf4babe9a55cae0721b2716f6072e.pdf", "checklist": "", "supplementary_material": "/attachment/3b887cf19e9ff75e90e4a7060e99076ddb018ace.pdf", "code": "https://github.com/rastegarpanah/Data-Minimization-Auditor", "thumbnail": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nrastegarpanah2021auditing,\ntitle={Auditing Black-Box Prediction Models for Data Minimization Compliance},\nauthor={Bashir Rastegarpanah and Krishna P. Gummadi and Mark Crovella},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=Wkq4hKpGxWv}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492697050, "odate": 1636492697050, "details": {"replyCount": 8}}, {"id": "hqDb8d65Vfh", "original": "Zv1nDj5GSeH", "number": 7658, "cdate": 1621630114568, "ddate": null, "tcdate": 1621630114568, "tmdate": 1697937446708, "tddate": null, "forum": "hqDb8d65Vfh", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Efficiently Identifying Task Groupings for Multi-Task Learning", "authorids": ["~Christopher_Fifty2", "~Ehsan_Amid1", "~Zhe_Zhao3", "~Tianhe_Yu1", "~Rohan_Anil1", "~Chelsea_Finn1"], "authors": ["Christopher Fifty", "Ehsan Amid", "Zhe Zhao", "Tianhe Yu", "Rohan Anil", "Chelsea Finn"], "keywords": ["multi-task learning", "task groupings", "which tasks should train together"], "abstract": "Multi-task learning can leverage information learned by one task to benefit the training of other tasks. Despite this capacity, naively training all tasks together in one model often degrades performance, and exhaustively searching through combinations of task groupings can be prohibitively expensive. As a result, efficiently identifying the tasks that would benefit from training together remains a challenging design question without a clear solution. In this paper, we suggest an approach to select which tasks should train together in multi-task learning models. Our method determines task groupings in a single run by training all tasks together and quantifying the effect to which one task's gradient would affect another task's loss. On the large-scale Taskonomy computer vision dataset, we find this method can decrease test loss by 10.0% compared to simply training all tasks together while operating 11.6 times faster than a state-of-the-art task grouping method. ", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "fifty|efficiently_identifying_task_groupings_for_multitask_learning", "pdf": "/pdf/d079a9de1b1a9279d1f36b1f812ece4a3a863a36.pdf", "checklist": "", "supplementary_material": "/attachment/173cef99ea0467fd9358d9a0049b347364725c6d.pdf", "TL;DR": "An efficient approach to determine which tasks should train together in multi-task learning networks. ", "code": "https://github.com/google-research/google-research/tree/master/tag", "thumbnail": "", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2109.04617/code)", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nfifty2021efficiently,\ntitle={Efficiently Identifying Task Groupings for Multi-Task Learning},\nauthor={Christopher Fifty and Ehsan Amid and Zhe Zhao and Tianhe Yu and Rohan Anil and Chelsea Finn},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=hqDb8d65Vfh}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492764230, "odate": 1636492764230, "details": {"replyCount": 13}}, {"id": "S2-j0ZegyrE", "original": "0Ikt4GKDrF", "number": 7628, "cdate": 1621630112785, "ddate": null, "tcdate": 1621630112785, "tmdate": 1683307701945, "tddate": null, "forum": "S2-j0ZegyrE", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Profiling Pareto Front With Multi-Objective Stein Variational  Gradient Descent", "authorids": ["~Xingchao_Liu1", "~Xin_Tong6", "~qiang_liu4"], "authors": ["Xingchao Liu", "Xin Tong", "qiang liu"], "keywords": ["Pareto Front", "Sampling", "Multi-objective Learning"], "TL;DR": "We design Multi-objective Stein Variational Gradient Descent that can profile the whole Pareto front with particles.", "abstract": "Finding diverse and representative Pareto solutions from the Pareto front is a key challenge in multi-objective optimization (MOO). In this work, we propose a novel gradient-based algorithm for profiling Pareto front by using Stein variational gradient descent (SVGD). We also provide a counterpart of our method based on Langevin dynamics. Our methods iteratively update a set of points in a parallel fashion to push them towards the Pareto front using multiple gradient descent, while encouraging the diversity between the particles by using the repulsive force mechanism in SVGD, or diffusion noise in Langevin dynamics. Compared with existing gradient-based methods that require predefined preference functions, our method can work efficiently in high dimensional problems, and can obtain more diverse solutions evenly distributed in the Pareto front. Moreover, our methods are theoretically guaranteed to converge to the Pareto front. We demonstrate the effectiveness of our method, especially the SVGD algorithm, through extensive experiments, showing its superiority over existing gradient-based algorithms.", "submission_history": "", "checklist": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "liu|profiling_pareto_front_with_multiobjective_stein_variational_gradient_descent", "pdf": "/pdf/15dede5d790cb8218fe1d3a57f54d4b7eabcfb5f.pdf", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "supplementary_material": "/attachment/f103a1776d098e813ef61a959ecb4f5dd70700cb.pdf", "code": "https://github.com/gnobitab/MultiObjectiveSampling", "thumbnail": "", "_bibtex": "@inproceedings{\nliu2021profiling,\ntitle={Profiling Pareto Front With Multi-Objective Stein Variational  Gradient Descent},\nauthor={Xingchao Liu and Xin Tong and qiang liu},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=S2-j0ZegyrE}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492736975, "odate": 1636492736975, "details": {"replyCount": 18}}, {"id": "10anajdGZm", "original": "0runyowCTUk", "number": 7452, "cdate": 1621630102291, "ddate": null, "tcdate": 1621630102291, "tmdate": 1697937455540, "tddate": null, "forum": "10anajdGZm", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Provably Faster Algorithms for Bilevel Optimization", "authorids": ["~Junjie_Yang2", "~Kaiyi_Ji1", "~Yingbin_Liang1"], "authors": ["Junjie Yang", "Kaiyi Ji", "Yingbin Liang"], "keywords": ["Bilevel Optimization", "Momentum", "Recursive Gradient Estimator", "Hessian Vector Computation"], "TL;DR": "This paper proposes two bilevel optimizers that provably outperform all existing algorithms by the order of magnitude.", "abstract": "Bilevel optimization has been widely applied in many important machine learning applications such as hyperparameter optimization and meta-learning. Recently, several momentum-based algorithms have been proposed to solve bilevel optimization problems faster. However, those momentum-based algorithms do not achieve provably better computational complexity than $\\mathcal{\\widetilde O}(\\epsilon^{-2})$ of the SGD-based algorithm. In this paper, we propose two new algorithms for bilevel optimization, where the first algorithm adopts momentum-based recursive iterations, and the second algorithm adopts recursive gradient estimations in nested loops to decrease the variance. We show that both algorithms achieve the complexity of $\\mathcal{\\widetilde O}(\\epsilon^{-1.5})$, which outperforms all existing algorithms by the order of magnitude. Our experiments validate our theoretical results and demonstrate the superior empirical performance of our algorithms in hyperparameter applications.", "submission_history": "", "checklist": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "yang|provably_faster_algorithms_for_bilevel_optimization", "pdf": "/pdf/b15dcd28a719407a19b257966a3cc63311527b26.pdf", "supplementary_material": "/attachment/7fdb81b96b6da41b2ac1f94019e888974389ef9c.pdf", "code": "https://github.com/JunjieYang97/MRVRBO", "thumbnail": "", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2106.04692/code)", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nyang2021provably,\ntitle={Provably Faster Algorithms for Bilevel Optimization},\nauthor={Junjie Yang and Kaiyi Ji and Yingbin Liang},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=10anajdGZm}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492734743, "odate": 1636492734743, "details": {"replyCount": 12}}, {"id": "b83ibRX55T", "original": "uT4xoKeM5Xh", "number": 7432, "cdate": 1621630101183, "ddate": null, "tcdate": 1621630101183, "tmdate": 1683307696687, "tddate": null, "forum": "b83ibRX55T", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Towards Gradient-based Bilevel Optimization with Non-convex Followers and Beyond", "authorids": ["~Risheng_Liu1", "~Yaohua_Liu1", "~Shangzhi_Zeng1", "~Jin_Zhang8"], "authors": ["Risheng Liu", "Yaohua Liu", "Shangzhi Zeng", "Jin Zhang"], "keywords": ["Bi-level programming", "gradient-based method", "asymptotic convergence", "few-shot classification", "data hyper-cleaning"], "abstract": "In recent years, Bi-Level Optimization (BLO) techniques have received extensive attentions from both learning and vision communities. A variety of BLO models in complex and practical tasks are of non-convex follower structure in nature (a.k.a., without Lower-Level Convexity, LLC for short). However, this challenging class of BLOs is lack of developments on both efficient solution strategies and solid theoretical guarantees. In this work, we propose a new algorithmic framework, named Initialization Auxiliary and Pessimistic Trajectory Truncated Gradient Method (IAPTT-GM), to partially address the above issues. In particular, by introducing an auxiliary as initialization to guide the optimization dynamics and designing a pessimistic trajectory truncation operation, we construct a reliable approximate version of the original BLO in the absence of LLC hypothesis. Our theoretical investigations establish the convergence of solutions returned by IAPTT-GM towards those of the original BLO without LLC. As an additional bonus, we also theoretically justify the quality of our IAPTT-GM embedded with Nesterov's accelerated dynamics under LLC. The experimental results confirm both the convergence of our algorithm without LLC, and the theoretical findings under LLC.", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "liu|towards_gradientbased_bilevel_optimization_with_nonconvex_followers_and_beyond", "pdf": "/pdf/f5881690f5e11da7aa342dd28ecda526fe4c99d8.pdf", "checklist": "", "supplementary_material": "/attachment/7901c18573bdc5d514f6b18dd10e2e822054d0e2.pdf", "code": "https://github.com/vis-opt-group/IAPTT-GM", "thumbnail": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nliu2021towards,\ntitle={Towards Gradient-based Bilevel Optimization with Non-convex Followers and Beyond},\nauthor={Risheng Liu and Yaohua Liu and Shangzhi Zeng and Jin Zhang},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=b83ibRX55T}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492761863, "odate": 1636492761863, "details": {"replyCount": 14}}, {"id": "YV3uoawS5KK", "original": "OhruurQIJ14", "number": 7421, "cdate": 1621630100542, "ddate": null, "tcdate": 1621630100542, "tmdate": 1683307696271, "tddate": null, "forum": "YV3uoawS5KK", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Averaging on the Bures-Wasserstein manifold: dimension-free convergence of gradient descent", "authorids": ["~Jason_Altschuler1", "~Sinho_Chewi1", "~Patrik_Robert_Gerber1", "~Austin_J_Stromme1"], "authors": ["Jason Altschuler", "Sinho Chewi", "Patrik Robert Gerber", "Austin J Stromme"], "keywords": ["Bures-Wasserstein barycenter", "dimension-free convergence", "entropic regularization", "first-order optimization", "geometric median", "non-convex optimization", "Riemannian optimization"], "TL;DR": "We improve state-of-the-art convergence guarantees for Riemannian gradient descent for computing geometric averages of Gaussians.", "abstract": "We study first-order optimization algorithms for computing the barycenter of Gaussian distributions with respect to the optimal transport metric. Although the objective is geodesically non-convex, Riemannian gradient descent empirically converges rapidly, in fact faster than off-the-shelf methods such as Euclidean gradient descent and SDP solvers. This stands in stark contrast to the best-known theoretical results, which depend exponentially on the dimension. In this work, we prove new geodesic convexity results which provide stronger control of the iterates, yielding a dimension-free convergence rate. Our techniques also enable the analysis of two related notions of averaging, the entropically-regularized barycenter and the geometric median, providing the first convergence guarantees for these problems.", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "altschuler|averaging_on_the_bureswasserstein_manifold_dimensionfree_convergence_of_gradient_descent", "pdf": "/pdf/c82a80020e3d04b12dc1645988600e59927a2d6d.pdf", "checklist": "", "supplementary_material": "/attachment/fefc81c3075caf8d4b1c46878b59bf8e172d12ce.pdf", "thumbnail": "", "code": "https://github.com/PatrikGerber/Bures-Barycenters", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\naltschuler2021averaging,\ntitle={Averaging on the Bures-Wasserstein manifold: dimension-free convergence of gradient descent},\nauthor={Jason Altschuler and Sinho Chewi and Patrik Robert Gerber and Austin J Stromme},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=YV3uoawS5KK}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492759347, "odate": 1636492759347, "details": {"replyCount": 11}}, {"id": "NE0YlkgRo9x", "original": "GSt76_YFI16", "number": 7355, "cdate": 1621630096723, "ddate": null, "tcdate": 1621630096723, "tmdate": 1683307693591, "tddate": null, "forum": "NE0YlkgRo9x", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "A single gradient step finds adversarial examples on random two-layers neural networks", "authorids": ["~Sebastien_Bubeck1", "~Yeshwanth_Cherapanamjeri1", "~Gauthier_Gidel1", "~Remi_Tachet_des_Combes1"], "authors": ["Sebastien Bubeck", "Yeshwanth Cherapanamjeri", "Gauthier Gidel", "Remi Tachet des Combes"], "keywords": ["adversarial examples", "random neural networks", "deep-learning theory"], "TL;DR": "We prove that a single gradient step finds adversarial examples on random two-layers neural networks.", "abstract": "Daniely and Schacham recently showed that gradient descent finds adversarial examples on random undercomplete two-layers ReLU neural networks. The term \u201cundercomplete\u201d refers to the fact that their proof only holds when the number of neurons is a vanishing fraction of the ambient dimension. We extend their result to the overcomplete case, where the number of neurons is larger than the dimension (yet also subexponential in the dimension). In fact we prove that a single step of gradient descent suffices. We also show this result for any subexponential width random neural network with smooth activation function.", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "bubeck|a_single_gradient_step_finds_adversarial_examples_on_random_twolayers_neural_networks", "pdf": "/pdf/2aa9b316475ebfbbdd6384576c2a301f2bd7847e.pdf", "supplementary_material": "/attachment/c970a4315586b5901d962afc5654579a7039e435.pdf", "checklist": "", "thumbnail": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nbubeck2021a,\ntitle={A single gradient step finds adversarial examples on random two-layers neural networks},\nauthor={Sebastien Bubeck and Yeshwanth Cherapanamjeri and Gauthier Gidel and Remi Tachet des Combes},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=NE0YlkgRo9x}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492698714, "odate": 1636492698714, "details": {"replyCount": 9}}, {"id": "qb0qTdxPWzY", "original": "ge1ReUqqW3N", "number": 7354, "cdate": 1621630096665, "ddate": null, "tcdate": 1621630096665, "tmdate": 1683307693540, "tddate": null, "forum": "qb0qTdxPWzY", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "List-Decodable Mean Estimation in Nearly-PCA Time", "authorids": ["~Ilias_Diakonikolas1", "~Daniel_Kane1", "~Daniel_Kongsgaard1", "~Jerry_Li1", "~Kevin_Tian1"], "authors": ["Ilias Diakonikolas", "Daniel Kane", "Daniel Kongsgaard", "Jerry Li", "Kevin Tian"], "keywords": ["robust statistics", "learning theory", "mixture models", "semidefinite programming", "list-decodable learning"], "TL;DR": "We give a state-of-the-art algorithm for list-decodable mean estimation, the robust generalization of learning mixture models, attaining optimal error in polylogarithmic calls to approximate PCA.", "abstract": "Robust statistics has traditionally focused on designing estimators tolerant to a minority of contaminated data. {\\em List-decodable learning}~\\cite{CharikarSV17} studies the more challenging regime where only a minority $\\tfrac 1 k$ fraction of the dataset, $k \\geq 2$, is drawn from the distribution of interest, and no assumptions are made on the remaining data. We study the fundamental task of list-decodable mean estimation in high dimensions. Our main result is a new algorithm for bounded covariance distributions \nwith optimal sample complexity and near-optimal error guarantee, running in {\\em nearly-PCA time}. Assuming the ground truth distribution on $\\mathbb{R}^d$ has identity-bounded covariance, our algorithm outputs $O(k)$ candidate means, one of which is within distance $O(\\sqrt{k\\log k})$ from the truth. \n  \n Our algorithm runs in time $\\widetilde{O}(ndk)$, where $n$ is the dataset size. This runtime nearly matches the cost of performing $k$-PCA on the data, a natural bottleneck of known algorithms for (very) special cases of our problem, such as clustering well-separated mixtures. Prior to our work, the fastest runtimes were $\\widetilde{O}(n^2 d k^2)$~\\cite{DiakonikolasKK20}, and $\\widetilde{O}(nd k^C)$ \\cite{CherapanamjeriMY20} for an unspecified constant $C \\geq 6$. Our approach builds on a novel soft downweighting method we term SIFT, arguably the simplest known polynomial-time mean estimator in the list-decodable setting. To develop our fast algorithms, we boost the computational cost of SIFT via a careful ``win-win-win'' analysis of an approximate Ky Fan matrix multiplicative weights procedure we develop, which may be of independent interest.", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "diakonikolas|listdecodable_mean_estimation_in_nearlypca_time", "pdf": "/pdf/365c02ba287ba774c11f024fec02579b89a71a03.pdf", "supplementary_material": "/attachment/8872593663e6e4f847173c364030d300f8c252d5.pdf", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "checklist": "", "thumbnail": "", "_bibtex": "@inproceedings{\ndiakonikolas2021listdecodable,\ntitle={List-Decodable Mean Estimation in Nearly-{PCA} Time},\nauthor={Ilias Diakonikolas and Daniel Kane and Daniel Kongsgaard and Jerry Li and Kevin Tian},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=qb0qTdxPWzY}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492760766, "odate": 1636492760766, "details": {"replyCount": 9}}, {"id": "ebIORrYImx", "original": "eWO05V8RPRC", "number": 7254, "cdate": 1621630090892, "ddate": null, "tcdate": 1621630090892, "tmdate": 1683307690844, "tddate": null, "forum": "ebIORrYImx", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": " Practical Near Neighbor Search via Group Testing", "authorids": ["~Joshua_Engels1", "~Benjamin_Coleman1", "~Anshumali_Shrivastava1"], "authors": ["Joshua Engels", "Benjamin Coleman", "Anshumali Shrivastava"], "keywords": ["group testing", "locality sensitive hashing", "near neighbor search", "index"], "TL;DR": "We combine group testing with locality sensitive hashing to develop a near neighbor search algorithm with 10x faster query time on high-dimensional datasets.", "abstract": "We present a new algorithm for the approximate near neighbor problem that combines classical ideas from group testing with locality-sensitive hashing (LSH). We reduce the near neighbor search problem to a group testing problem by designating neighbors as \"positives,\" non-neighbors as \"negatives,\" and approximate membership queries as group tests. We instantiate this framework using distance-sensitive Bloom Filters to Identify Near-Neighbor Groups (FLINNG). We prove that FLINNG has sub-linear query time and show that our algorithm comes with a variety of practical advantages. For example, FLINNG can be constructed in a single pass through the data, consists entirely of efficient integer operations, and does not require any distance computations. We conduct large-scale experiments on high-dimensional search tasks such as genome search, URL similarity search, and embedding search over the massive YFCC100M dataset. In our comparison with leading algorithms such as HNSW and FAISS, we find that FLINNG can provide up to a 10x query speedup with substantially smaller indexing time and memory.", "submission_history": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "engels|practical_near_neighbor_search_via_group_testing", "pdf": "/pdf/1f558c612d94e54cd226bca15b5dc2c3efc4aeda.pdf", "checklist": "", "supplementary_material": "/attachment/6db845cea1628a793111615efa9e09253a7e82cc.pdf", "code": "https://github.com/JoshuaEng/FLINNG", "thumbnail": "", "_bibtex": "@inproceedings{\nengels2021,\ntitle={ Practical Near Neighbor Search via Group Testing},\nauthor={Joshua Engels and Benjamin Coleman and Anshumali Shrivastava},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=ebIORrYImx}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492730748, "odate": 1636492730748, "details": {"replyCount": 13}}, {"id": "ii5mGEbRo93", "original": "LtNHE4mNlyo", "number": 7237, "cdate": 1621630089871, "ddate": null, "tcdate": 1621630089871, "tmdate": 1683307690634, "tddate": null, "forum": "ii5mGEbRo93", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Logarithmic Regret in Feature-based Dynamic Pricing", "authorids": ["~Jianyu_Xu1", "~Yu-Xiang_Wang1"], "authors": ["Jianyu Xu", "Yu-Xiang Wang"], "keywords": ["dynamic pricing", "online learning", "adversarial features", "optimal regret", "affine invariant", "distribution-free."], "TL;DR": "We present algorithms that guarantees logarithmic (minimax) regrets in both stochastic and adversarial feature-based dynamic pricing problems with market noises.", "abstract": "Feature-based dynamic pricing is an increasingly popular model of setting prices for highly differentiated products with applications in digital marketing, online sales, real estate and so on. The problem was formally studied as an online learning problem [Javanmard & Nazerzadeh, 2019] where a seller needs to propose prices on the fly for a sequence of $T$ products based on their features $x$ while having a small regret relative to the best ---\"omniscient\"--- pricing strategy she could have come up with in hindsight. We revisit this problem and provide two algorithms (EMLP and ONSP) for stochastic and adversarial feature settings, respectively, and prove the optimal $O(d\\log{T})$ regret bounds for both. In comparison, the best existing results are $O\\left(\\min\\left\\{\\frac{1}{\\lambda_{\\min}^2}\\log{T}, \\sqrt{T}\\right\\}\\right)$ and $O(T^{2/3})$ respectively, with $\\lambda_{\\min}$ being the smallest eigenvalue of $\\mathbb{E}[xx^T]$ that could be arbitrarily close to $0$.  We also prove an $\\Omega(\\sqrt{T})$ information-theoretic lower bound for a slightly more general setting, which demonstrates that \"knowing-the-demand-curve\" leads to an exponential improvement in feature-based dynamic pricing. ", "submission_history": "", "submission_history_-_venue_and_year": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "xu|logarithmic_regret_in_featurebased_dynamic_pricing", "pdf": "/pdf/5403f409bffd0281596b9b2ab39ad43883a57bf9.pdf", "supplementary_material": "/attachment/1c3b12d82c258a28456f36283d0c43161dda4d6d.pdf", "submission_history_-_improvements_made": "", "checklist": "", "code": "https://github.com/Xu-JY/log-regret-in-feature-based-dynamic-pricing", "thumbnail": "", "_bibtex": "@inproceedings{\nxu2021logarithmic,\ntitle={Logarithmic Regret in Feature-based Dynamic Pricing},\nauthor={Jianyu Xu and Yu-Xiang Wang},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=ii5mGEbRo93}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492772718, "odate": 1636492772718, "details": {"replyCount": 14}}, {"id": "JpDlWGTBHB", "original": "gMUWIjs2gZh", "number": 7195, "cdate": 1621630087366, "ddate": null, "tcdate": 1621630087366, "tmdate": 1697937466887, "tddate": null, "forum": "JpDlWGTBHB", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Probabilistic Attention for Interactive Segmentation", "authorids": ["~Prasad_Gabbur1", "~Manjot_Bilkhu1", "~Javier_Movellan1"], "authors": ["Prasad Gabbur", "Manjot Bilkhu", "Javier Movellan"], "keywords": ["Attention", "Transformers", "Probabilistic model", "Gaussian mixture model", "Interactive segmentation", "Semantic segmentation"], "TL;DR": "A new perspective of attention as a probabilistic generative model with applications to interactive image segmentation.", "abstract": "We provide a probabilistic interpretation of attention and show that the standard dot-product attention in transformers is a special case of Maximum A Posteriori (MAP) inference. The proposed approach suggests the use of Expectation Maximization algorithms for on-line adaptation of key and value model parameters. This approach is  useful for cases in which external agents, e.g., annotators, provide inference-time information about the correct values of some tokens, e.g., the semantic category of some pixels,  and we need for this new information to propagate to other tokens in a principled manner. We illustrate the approach on an interactive semantic segmentation task in which annotators and models collaborate online to improve annotation efficiency. Using standard benchmarks, we observe that key adaptation boosts model performance ($\\sim10\\%$ mIoU) in the low feedback regime and value propagation improves model responsiveness in the high feedback regime. A PyTorch layer implementation of our probabilistic attention model is available here: https://github.com/apple/ml-probabilistic-attention.", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "gabbur|probabilistic_attention_for_interactive_segmentation", "pdf": "/pdf/7684cecc5cb449e0bd5f7e0210025c53196a04e4.pdf", "supplementary_material": "/attachment/426075b082ae0e88a9159fa6b384e0367c0ef118.pdf", "checklist": "", "code": "https://github.com/apple/ml-probabilistic-attention", "thumbnail": "", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2106.15338/code)", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\ngabbur2021probabilistic,\ntitle={Probabilistic Attention for Interactive Segmentation},\nauthor={Prasad Gabbur and Manjot Bilkhu and Javier Movellan},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=JpDlWGTBHB}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492711810, "odate": 1636492711810, "details": {"replyCount": 11}}, {"id": "GEm4o9A6Jfb", "original": "CHeB-91PueB", "number": 7185, "cdate": 1621630086773, "ddate": null, "tcdate": 1621630086773, "tmdate": 1683307689698, "tddate": null, "forum": "GEm4o9A6Jfb", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "PLUR: A Unifying, Graph-Based View of Program Learning, Understanding, and Repair", "authorids": ["~Zimin_Chen1", "~Vincent_Josua_Hellendoorn1", "~Pascal_Lamblin1", "~Petros_Maniatis1", "~Pierre-Antoine_Manzagol1", "~Daniel_Tarlow1", "~Subhodeep_Moitra2"], "authors": ["Zimin Chen", "Vincent Josua Hellendoorn", "Pascal Lamblin", "Petros Maniatis", "Pierre-Antoine Manzagol", "Daniel Tarlow", "Subhodeep Moitra"], "keywords": ["learning for code", "program understanding", "program repair", "relation-aware transformers", "graph-based deep learning"], "TL;DR": "A single graph-based architecture can be applied to 16 seemingly different ML4Code tasks and achieves great results.", "abstract": "Machine learning for understanding and editing source code has recently attracted significant interest, with many developments in new models, new code representations, and new tasks.\nThis proliferation can appear disparate and disconnected, making each approach seemingly unique and incompatible, thus obscuring the core machine learning challenges and contributions.\nIn this work, we demonstrate that the landscape can be significantly simplified by taking a general approach of mapping a graph to a sequence of tokens and pointers.\nOur main result is to show that 16 recently published tasks of different shapes can be cast in this form, based on which a single model architecture achieves near or above state-of-the-art results on nearly all tasks, outperforming custom models like code2seq and alternative generic models like Transformers.\nThis unification further enables multi-task learning and a series of cross-cutting experiments about the importance of different modeling choices for code understanding and repair tasks.\nThe full framework, called PLUR, is easily extensible to more tasks, and will be open-sourced (https://github.com/google-research/plur).", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "chen|plur_a_unifying_graphbased_view_of_program_learning_understanding_and_repair", "pdf": "/pdf/8392b4c1dd1fe416bf6a9bd63a3a85070226d1e4.pdf", "checklist": "", "supplementary_material": "/attachment/f9071df2899ec7b0c65eca6e56bb2a408d6b5bd0.pdf", "thumbnail": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nchen2021plur,\ntitle={{PLUR}: A Unifying, Graph-Based View of Program Learning, Understanding, and Repair},\nauthor={Zimin Chen and Vincent Josua Hellendoorn and Pascal Lamblin and Petros Maniatis and Pierre-Antoine Manzagol and Daniel Tarlow and Subhodeep Moitra},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=GEm4o9A6Jfb}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492707888, "odate": 1636492707888, "details": {"replyCount": 13}}, {"id": "W9oywyjO8VN", "original": "Hk74IMGfiKR", "number": 7172, "cdate": 1621630086010, "ddate": null, "tcdate": 1621630086010, "tmdate": 1683307689244, "tddate": null, "forum": "W9oywyjO8VN", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Tractable Regularization of Probabilistic Circuits", "authorids": ["~Anji_Liu1", "~Guy_Van_den_Broeck1"], "authors": ["Anji Liu", "Guy Van den Broeck"], "keywords": ["Probabilistic Circuits", "Tractable Probabilistic Models", "Parameter Regularization", "Overfitting"], "TL;DR": "We proposed tractable regularization techniques for Probabilistic Circuits.", "abstract": "Probabilistic Circuits (PCs) are a promising avenue for probabilistic modeling. They combine advantages of probabilistic graphical models (PGMs) with those of neural networks (NNs). Crucially, however, they are tractable probabilistic models, supporting efficient and exact computation of many probabilistic inference queries, such as marginals and MAP. Further, since PCs are structured computation graphs, they can take advantage of deep-learning-style parameter updates, which greatly improves their scalability. However, this innovation also makes PCs prone to overfitting, which has been observed in many standard benchmarks. Despite the existence of abundant regularization techniques for both PGMs and NNs, they are not effective enough when applied to PCs. Instead, we re-think regularization for PCs and propose two intuitive techniques, data softening and entropy regularization, that both take advantage of PCs' tractability and still have an efficient implementation as a computation graph. Specifically, data softening provides a principled way to add uncertainty in datasets in closed form, which implicitly regularizes PC parameters. To learn parameters from a softened dataset, PCs only need linear time by virtue of their tractability. In entropy regularization, the exact entropy of the distribution encoded by a PC can be regularized directly, which is again infeasible for most other density estimation models. We show that both methods consistently improve the generalization performance of a wide variety of PCs. Moreover, when paired with a simple PC structure, we achieved state-of-the-art results on 10 out of 20 standard discrete density estimation benchmarks. Open-source code and experiments are available at https://github.com/UCLA-StarAI/Tractable-PC-Regularization.", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "liu|tractable_regularization_of_probabilistic_circuits", "pdf": "/pdf/18f46c6ed2de20663a028655c60b11f3f24fbd1a.pdf", "checklist": "", "supplementary_material": "/attachment/b0baa4e3096b240d0e19ea0cf978aeef67602185.pdf", "code": "https://github.com/UCLA-StarAI/Tractable-PC-Regularization", "thumbnail": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nliu2021tractable,\ntitle={Tractable Regularization of Probabilistic Circuits},\nauthor={Anji Liu and Guy Van den Broeck},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=W9oywyjO8VN}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492746093, "odate": 1636492746093, "details": {"replyCount": 9}}, {"id": "LAwuz_L9U9j", "original": "1zJb0qFVnDF", "number": 7148, "cdate": 1621630084654, "ddate": null, "tcdate": 1621630084654, "tmdate": 1683307688143, "tddate": null, "forum": "LAwuz_L9U9j", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Representation Learning for Event-based Visuomotor Policies", "authorids": ["~Sai_Vemprala1", "~Sami_Mian1", "~Ashish_Kapoor1"], "authors": ["Sai Vemprala", "Sami Mian", "Ashish Kapoor"], "keywords": ["Event cameras", "Representation Learning", "Reinforcement Learning", "Variational Autoencoder"], "TL;DR": "We present methods for representation learning and reinforcement learning directly from asynchronous event camera, and demonstrate advantages over frame-based techniques using an obstacle avoidance task.", "abstract": "Event-based cameras are dynamic vision sensors that provide asynchronous measurements of changes in per-pixel brightness at a microsecond level. This makes them significantly faster than conventional frame-based cameras, and an appealing choice for high-speed robot navigation. While an interesting sensor modality, this asynchronously streamed event data poses a challenge for machine learning based computer vision techniques that are more suited for synchronous, frame-based data. In this paper, we present an event variational autoencoder through which compact representations can be learnt directly from asynchronous spatiotemporal event data. Furthermore, we show that such pretrained representations can be used for event-based reinforcement learning instead of end-to-end reward driven perception. We validate this framework of learning event-based visuomotor policies by applying it to an obstacle avoidance scenario in simulation. Compared to techniques that treat event data as images, we show that representations learnt from event streams result in faster policy training, adapt to different control capacities, and demonstrate a higher degree of robustness to environmental changes and sensor noise.", "submission_history": "", "submission_history_-_venue_and_year": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "vemprala|representation_learning_for_eventbased_visuomotor_policies", "pdf": "/pdf/49f03cfae6ff9f28a4ce52943065bacee160dd7d.pdf", "submission_history_-_improvements_made": "", "checklist": "", "supplementary_material": "/attachment/c2f261eb8811f7d8e4c5db8e7cc5128c211dd6c6.pdf", "code": "https://github.com/microsoft/event-vae-rl", "thumbnail": "", "_bibtex": "@inproceedings{\nvemprala2021representation,\ntitle={Representation Learning for Event-based Visuomotor Policies},\nauthor={Sai Vemprala and Sami Mian and Ashish Kapoor},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=LAwuz_L9U9j}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492748870, "odate": 1636492748870, "details": {"replyCount": 11}}, {"id": "hJOLFJIJ_zy", "original": "8EReZ5YrKmb", "number": 7142, "cdate": 1621630084363, "ddate": null, "tcdate": 1621630084363, "tmdate": 1683307687928, "tddate": null, "forum": "hJOLFJIJ_zy", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Dense Keypoints via Multiview Supervision", "authorids": ["~Zhixuan_Yu1", "~Haozheng_Yu1", "~Long_Sha2", "sujoy.ganguly@unity3d.com", "~Hyun_Soo_Park1"], "authors": ["Zhixuan Yu", "Haozheng Yu", "Long Sha", "Sujoy Ganguly", "Hyun Soo Park"], "keywords": ["Dense keypoint estimation", "Multiview supervision", "Dense epipolar geometry", "Semi-supervised learning"], "abstract": "This paper presents a new end-to-end semi-supervised framework to learn a dense keypoint detector using unlabeled multiview images. A key challenge lies in \ufb01nding the exact correspondences between the dense keypoints in multiple views since the inverse of the keypoint mapping can be neither analytically derived nor differentiated. This limits applying existing multiview supervision approaches used to learn sparse keypoints that rely on the exact correspondences. To address this challenge, we derive a new probabilistic epipolar constraint that encodes the two desired properties. (1) Soft correspondence: we de\ufb01ne a matchability, which measures a likelihood of a point matching to the other image\u2019s corresponding point, thus relaxing the requirement of the exact correspondences. (2) Geometric consistency: every point in the continuous correspondence \ufb01elds must satisfy the multiview consistency collectively. We formulate a probabilistic epipolar constraint using a weighted average of epipolar errors through the matchability thereby generalizing the point-to-point geometric error to the \ufb01eld-to-\ufb01eld geometric error. This generalization facilitates learning a geometrically coherent dense keypoint detection model by utilizing a large number of unlabeled multiview images. Additionally, to prevent degenerative cases, we employ a distillation-based regularization by using a pretrained model. Finally, we design a new neural network architecture, made of twin networks, that effectively minimizes the probabilistic epipolar errors of all possible correspondences between two view images by building af\ufb01nity matrices. Our method shows superior performance compared to existing methods, including non-differentiable bootstrapping in terms of keypoint accuracy, multiview consistency, and 3D reconstruction accuracy.", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "yu|dense_keypoints_via_multiview_supervision", "pdf": "/pdf/00df35ead9bf77b6cb47b90e6fcfffa4482693cb.pdf", "checklist": "", "supplementary_material": "/attachment/1ac8a53f298d3f90216768f02ed796a3ceb986f3.pdf", "thumbnail": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nyu2021dense,\ntitle={Dense Keypoints via Multiview Supervision},\nauthor={Zhixuan Yu and Haozheng Yu and Long Sha and Sujoy Ganguly and Hyun Soo Park},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=hJOLFJIJ_zy}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492720823, "odate": 1636492720823, "details": {"replyCount": 24}}, {"id": "oErdeq9ajjX", "original": "JdHcx-LB1e", "number": 7067, "cdate": 1621630080348, "ddate": null, "tcdate": 1621630080348, "tmdate": 1697937473563, "tddate": null, "forum": "oErdeq9ajjX", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Learning Generalized Gumbel-max Causal Mechanisms", "authorids": ["~Guy_Lorberbom1", "~Daniel_D._Johnson1", "~Chris_J._Maddison1", "~Daniel_Tarlow1", "~Tamir_Hazan1"], "authors": ["Guy Lorberbom", "Daniel D. Johnson", "Chris J. Maddison", "Daniel Tarlow", "Tamir Hazan"], "keywords": ["Gumbel max", "reparameterization trick", "structural causal model"], "TL;DR": "Learn a causal mechanism that minimizes a quantitative criteria (such as variance) when used in a counterfactual context.", "abstract": "To perform counterfactual reasoning in Structural Causal Models (SCMs), one needs to know the causal mechanisms, which provide factorizations of conditional distributions into noise sources and deterministic functions mapping realizations of noise to samples. Unfortunately, the causal mechanism is not uniquely identified by data that can be gathered by observing and interacting with the world, so there remains the question of how to choose causal mechanisms. In recent work, Oberst & Sontag (2019) propose Gumbel-max SCMs, which use Gumbel-max reparameterizations as the causal mechanism due to an appealing  counterfactual stability property. However, the justification requires appealing to intuition. In this work, we instead argue for choosing a causal mechanism that is best under a quantitative criteria such as minimizing variance when estimating counterfactual treatment effects. We propose a parameterized family of causal mechanisms that generalize Gumbel-max. We show that they can be trained to minimize counterfactual effect variance and other losses on a distribution of queries of interest, yielding lower variance estimates of counterfactual treatment effect than fixed alternatives, also generalizing to queries not seen at training time.", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "lorberbom|learning_generalized_gumbelmax_causal_mechanisms", "pdf": "/pdf/ab8f78632111077a50132193913c15a64e4b00e8.pdf", "supplementary_material": "/attachment/0dfe920228dd5cbdedbb46b85dc68d9954d287fb.pdf", "checklist": "", "code": "https://github.com/google-research/google-research/tree/master/gumbel_max_causal_gadgets", "thumbnail": "", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2111.06888/code)", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nlorberbom2021learning,\ntitle={Learning Generalized Gumbel-max Causal Mechanisms},\nauthor={Guy Lorberbom and Daniel D. Johnson and Chris J. Maddison and Daniel Tarlow and Tamir Hazan},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=oErdeq9ajjX}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492719440, "odate": 1636492719390, "details": {"replyCount": 7}}, {"id": "YFysbLCFdIe", "original": "VhAaHZbOQde", "number": 7021, "cdate": 1621630077639, "ddate": null, "tcdate": 1621630077639, "tmdate": 1697937475639, "tddate": null, "forum": "YFysbLCFdIe", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Neural Human Performer: Learning Generalizable Radiance Fields for Human Performance Rendering", "authorids": ["~YoungJoong_Kwon1", "~Dahun_Kim1", "~Duygu_Ceylan1", "~Henry_Fuchs1"], "authors": ["YoungJoong Kwon", "Dahun Kim", "Duygu Ceylan", "Henry Fuchs"], "keywords": ["Novel view synthesis", "Neural radiance fields", "Human performance capture", "Generalizable Neural radiance fields"], "abstract": "In this paper, we aim at synthesizing a free-viewpoint video of an arbitrary human performance using sparse multi-view cameras. Recently, several works have addressed this problem by learning person-specific neural radiance fields (NeRF) to capture the appearance of a particular human. In parallel, some work proposed to use pixel-aligned features to generalize radiance fields to arbitrary new scenes and objects. Adopting such generalization approaches to humans, however, is highly challenging due to the heavy occlusions and dynamic articulations of body parts. To tackle this, we propose Neural Human Performer, a novel approach that learns generalizable neural radiance fields based on a parametric human body model for robust performance capture. Specifically, we first introduce a temporal transformer that aggregates tracked visual features based on the skeletal body motion over time. Moreover, a multi-view transformer is proposed to perform cross-attention between the temporally-fused features and the pixel-aligned features at each time step to integrate observations on the fly from multiple views. Experiments on the ZJU-MoCap and AIST datasets show that our method significantly outperforms recent generalizable NeRF methods on unseen identities and poses.", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "kwon|neural_human_performer_learning_generalizable_radiance_fields_for_human_performance_rendering", "pdf": "/pdf/d64d45c80d395213a756be07e4bb15893f371d48.pdf", "checklist": "", "supplementary_material": "/attachment/330b186b44ea4424a65e64c3d922cd975ffe2522.pdf", "thumbnail": "", "TL;DR": "Generalizable NeRF methods for synthesizing a free-viewpoint video of an arbitrary human performance using sparse multi-view cameras", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2109.07448/code)", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nkwon2021neural,\ntitle={Neural Human Performer: Learning Generalizable Radiance Fields for Human Performance Rendering},\nauthor={YoungJoong Kwon and Dahun Kim and Duygu Ceylan and Henry Fuchs},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=YFysbLCFdIe}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492708808, "odate": 1636492708808, "details": {"replyCount": 9}}, {"id": "wHkKTW2wrmm", "original": "k1mYK_ot8xK", "number": 6988, "cdate": 1621630075681, "ddate": null, "tcdate": 1621630075681, "tmdate": 1697937477581, "tddate": null, "forum": "wHkKTW2wrmm", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Neural Additive Models: Interpretable Machine Learning with Neural Nets", "authorids": ["~Rishabh_Agarwal2", "~Levi_Melnick1", "~Nicholas_Frosst1", "~Xuezhou_Zhang2", "~Ben_Lengerich1", "~Rich_Caruana1", "~Geoffrey_Hinton1"], "authors": ["Rishabh Agarwal", "Levi Melnick", "Nicholas Frosst", "Xuezhou Zhang", "Ben Lengerich", "Rich Caruana", "Geoffrey Hinton"], "keywords": ["Additive Models", "Interpretability", "Multitask learning", "Explainable AI"], "abstract": "Deep neural networks (DNNs) are powerful black-box predictors that have achieved impressive performance on a wide variety of tasks. However, their accuracy comes at the cost of intelligibility: it is usually unclear how they make their decisions. This hinders their applicability to high stakes decision-making domains such as healthcare. We propose Neural Additive Models (NAMs) which combine some of the expressivity of DNNs with the inherent intelligibility of generalized additive models. NAMs learn a linear combination of neural networks that each attend to a single input feature. These networks are trained jointly and can learn arbitrarily complex relationships between their input feature and the output. Our experiments on regression and classification datasets show that NAMs are more accurate than widely used intelligible models such as logistic regression and shallow decision trees. They perform similarly to existing state-of-the-art generalized additive models in accuracy, but are more flexible because they are based on neural nets instead of boosted trees. To demonstrate this, we show how NAMs can be used for multitask learning on synthetic data and on the COMPAS recidivism data due to their composability, and demonstrate that the differentiability of NAMs allows them to train more complex interpretable models for COVID-19. ", "submission_history": "", "submission_history_-_venue_and_year": "", "checklist": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "agarwal|neural_additive_models_interpretable_machine_learning_with_neural_nets", "pdf": "/pdf/a7c0719bc57273993d24ab46199bac6d1a76c02f.pdf", "submission_history_-_improvements_made": "", "supplementary_material": "/attachment/816d3747fd16271de795f5af03d98341c4f47733.pdf", "TL;DR": "We propose Neural Additive Models that combine some of the expressivity of DNNs with the inherent intelligibility of generalized additive models. ", "code": "https://neural-additive-models.github.io/", "thumbnail": "", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 3 code implementations](https://www.catalyzex.com/paper/arxiv:2004.13912/code)", "_bibtex": "@inproceedings{\nagarwal2021neural,\ntitle={Neural Additive Models: Interpretable Machine Learning with Neural Nets},\nauthor={Rishabh Agarwal and Levi Melnick and Nicholas Frosst and Xuezhou Zhang and Ben Lengerich and Rich Caruana and Geoffrey Hinton},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=wHkKTW2wrmm}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492775999, "odate": 1636492775999, "details": {"replyCount": 9}}, {"id": "b8Kl8mcK6tb", "original": "-mWyiU0q-jM", "number": 6963, "cdate": 1621630074147, "ddate": null, "tcdate": 1621630074147, "tmdate": 1683307682421, "tddate": null, "forum": "b8Kl8mcK6tb", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Bellman Eluder Dimension: New Rich Classes of RL Problems, and Sample-Efficient Algorithms", "authorids": ["~Chi_Jin1", "~Qinghua_Liu1", "~Sobhan_Miryoosefi1"], "authors": ["Chi Jin", "Qinghua Liu", "Sobhan Miryoosefi"], "keywords": ["reinforcement learning theory", "function approximation", "Bellman Eluder dimension"], "abstract": "Finding the minimal structural assumptions that empower sample-efficient learning is one of the most important research directions in Reinforcement Learning (RL). This paper advances our understanding of this fundamental question by introducing a new complexity measure\u2014Bellman Eluder (BE) dimension. We show that the family of RL problems of low BE dimension is remarkably rich, which subsumes a vast majority of existing tractable RL problems including but not limited to tabular MDPs, linear MDPs, reactive POMDPs, low Bellman rank problems as well as low Eluder dimension problems. This paper further designs a new optimization-based algorithm\u2014 GOLF, and reanalyzes a hypothesis elimination-based algorithm\u2014OLIVE (proposed in Jiang et al. (2017)). We prove that both algorithms learn the near-optimal policies of low BE dimension problems in a number of samples that is polynomial in all relevant parameters, but independent of the size of state-action space. Our regret and sample complexity results match or improve the best existing results for several well-known subclasses of low BE dimension problems.", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "jin|bellman_eluder_dimension_new_rich_classes_of_rl_problems_and_sampleefficient_algorithms", "pdf": "/pdf/045f766ae9494ffbeb54a5e3e16166a0cc0a6abd.pdf", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "checklist": "", "supplementary_material": "/attachment/a803e8e8800f3d4f4ab7bb8013774fdab8d276f9.pdf", "thumbnail": "", "_bibtex": "@inproceedings{\njin2021bellman,\ntitle={Bellman Eluder Dimension: New Rich Classes of {RL} Problems, and Sample-Efficient Algorithms},\nauthor={Chi Jin and Qinghua Liu and Sobhan Miryoosefi},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=b8Kl8mcK6tb}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492758743, "odate": 1636492758743, "details": {"replyCount": 11}}, {"id": "85BzB3WP-qj", "original": "rwwkL3hJlhp", "number": 6941, "cdate": 1621630072791, "ddate": null, "tcdate": 1621630072791, "tmdate": 1683307681593, "tddate": null, "forum": "85BzB3WP-qj", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Across-animal odor decoding by probabilistic manifold alignment", "authorids": ["~Pedro_Herrero-Vidal1", "~Dmitry_Rinberg1", "~Cristina_Savin1"], "authors": ["Pedro Herrero-Vidal", "Dmitry Rinberg", "Cristina Savin"], "keywords": ["neuroscience", "probabilistic models", "latent dynamical systems", "decoding", "neural alignment", "across-animal neural analysis"], "abstract": "Identifying the common structure of neural dynamics across subjects is key for extracting unifying principles of brain computation and for many brain machine interface applications. Here, we propose a novel probabilistic approach for aligning stimulus-evoked responses from multiple animals in a common low dimensional manifold and use hierarchical inference to identify which stimulus drives neural activity in any given trial. Our probabilistic decoder is robust to a range of features of the neural responses and significantly outperforms existing neural alignment procedures. When applied to recordings from the mouse olfactory bulb, our approach reveals low-dimensional population dynamics that are odor specific and have consistent structure across animals. Thus, our decoder can be used for increasing the robustness and scalability of neural-based chemical detection.", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "herrerovidal|acrossanimal_odor_decoding_by_probabilistic_manifold_alignment", "TL;DR": "A novel probabilistic model can align neural responses and efficiently decode odors across animals.", "pdf": "/pdf/b94a04a54ee9131793eb695b13f7de9b80af0645.pdf", "checklist": "", "supplementary_material": "/attachment/f8bd467468471a56f7ffaf221f19493e9047c011.zip", "code": "https://github.com/pedroherrerovidal/amLDS", "thumbnail": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nherrero-vidal2021acrossanimal,\ntitle={Across-animal odor decoding by probabilistic manifold alignment},\nauthor={Pedro Herrero-Vidal and Dmitry Rinberg and Cristina Savin},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=85BzB3WP-qj}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492765292, "odate": 1636492765292, "details": {"replyCount": 13}}, {"id": "hg0s8od-jd", "original": "bQZzxfdPIAs", "number": 6887, "cdate": 1621630069436, "ddate": null, "tcdate": 1621630069436, "tmdate": 1683307679966, "tddate": null, "forum": "hg0s8od-jd", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Correlated Stochastic Block Models: Exact Graph Matching with Applications to Recovering Communities", "authorids": ["~Miklos_Z._Racz1", "~Anirudh_Sridhar1"], "authors": ["Miklos Z. Racz", "Anirudh Sridhar"], "keywords": ["Stochastic block model", "community recovery", "graph matching", "correlated random graphs", "information-theoretic limits"], "abstract": "We consider the task of learning latent community structure from multiple correlated networks. First, we study the problem of learning the latent vertex correspondence between two edge-correlated stochastic block models, focusing on the regime where the average degree is logarithmic in the number of vertices. We derive the precise information-theoretic threshold for exact recovery: above the threshold there exists an estimator that outputs the true correspondence with probability close to 1, while below it no estimator can recover the true correspondence with probability bounded away from 0. As an application of our results, we show how one can exactly recover the latent communities using \\emph{multiple} correlated graphs in parameter regimes where it is information-theoretically impossible to do so using just a single graph.", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "racz|correlated_stochastic_block_models_exact_graph_matching_with_applications_to_recovering_communities", "TL;DR": "By determining the information-theoretic limits for exact graph matching in edge-correlated stochastic block models, we show how to combine information from multiple networks to improve community recovery algorithms.", "pdf": "/pdf/2abc38bb744b3f04de7bad5370229d119dfae648.pdf", "checklist": "", "supplementary_material": "/attachment/ce72f4d8a4e79101e06723ca8d20dde4c9eea386.pdf", "thumbnail": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nracz2021correlated,\ntitle={Correlated Stochastic Block Models: Exact Graph Matching with Applications to Recovering Communities},\nauthor={Miklos Z. Racz and Anirudh Sridhar},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=hg0s8od-jd}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492776944, "odate": 1636492776944, "details": {"replyCount": 9}}, {"id": "_1HETTYd7Wr", "original": "ejTgbD0TPmu", "number": 6859, "cdate": 1621630067688, "ddate": null, "tcdate": 1621630067688, "tmdate": 1683307679665, "tddate": null, "forum": "_1HETTYd7Wr", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Constrained Robust Submodular Partitioning", "authorids": ["~Shengjie_Wang1", "~Tianyi_Zhou1", "~Chandrashekhar_Lavania2", "~Jeff_Bilmes1"], "authors": ["Shengjie Wang", "Tianyi Zhou", "Chandrashekhar Lavania", "Jeff Bilmes"], "keywords": ["Submodular Optimization"], "TL;DR": "We propose algorithms for the  constrained robust submodular partitioning problem with theoretical guarantees.", "abstract": "In the robust submodular partitioning problem, we aim to allocate a set of items into $m$ blocks, so that the evaluation of the minimum block according to a submodular function is maximized. Robust submodular partitioning promotes the diversity of every block in the partition. It has many applications in machine learning, e.g., partitioning data for distributed training so that the gradients computed on every block are consistent. We study an extension of the robust submodular partition problem with additional constraints (e.g., cardinality, multiple matroids, and/or knapsack) on every block. For example, when partitioning data for distributed training, we can add a constraint that the number of samples of each class is the same in each partition block, ensuring data balance. We present two classes of algorithms, i.e., Min-Block Greedy based algorithms (with an $\\Omega(1/m)$ bound), and Round-Robin Greedy based algorithms (with a constant bound) and show that under various constraints, they still have good approximation guarantees. Interestingly, while normally the latter runs in only weakly polynomial time, we show that using the two together yields strongly polynomial running time while preserving the approximation guarantee. Lastly, we apply the algorithms on a real-world machine learning data partitioning problem showing good results.", "submission_history": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "wang|constrained_robust_submodular_partitioning", "pdf": "/pdf/a9c5f2763663acf283d5a9c5ee49881adf245720.pdf", "supplementary_material": "/attachment/2055f25bcf6ac1118a8d71f19ecb21d61bc772e5.pdf", "checklist": "", "thumbnail": "", "code": "/attachment/f5aaca9de557339ec400ed0ade62eb153c10f9f1.zip", "_bibtex": "@inproceedings{\nwang2021constrained,\ntitle={Constrained Robust Submodular Partitioning},\nauthor={Shengjie Wang and Tianyi Zhou and Chandrashekhar Lavania and Jeff Bilmes},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=_1HETTYd7Wr}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492704838, "odate": 1636492704838, "details": {"replyCount": 10}}, {"id": "GSXEx6iYd0", "original": "9SzVif2MILJ", "number": 6790, "cdate": 1621630063410, "ddate": null, "tcdate": 1621630063410, "tmdate": 1697937486862, "tddate": null, "forum": "GSXEx6iYd0", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Numerical Composition of Differential Privacy", "authorids": ["~Sivakanth_Gopi1", "~Yin_Tat_Lee1", "~Lukas_Wutschitz1"], "authors": ["Sivakanth Gopi", "Yin Tat Lee", "Lukas Wutschitz"], "keywords": ["Differential Privacy", "Composition"], "TL;DR": "A fast and accurate algorithm to compose privacy guarantees of differentially private algorithms.", "abstract": "We give a fast algorithm to compose privacy guarantees of differentially private (DP) algorithms to arbitrary accuracy. Our method is based on the notion of privacy loss random variables to quantify the privacy loss of DP algorithms. The running time and memory needed for our algorithm to approximate the privacy curve of a DP algorithm composed with itself $k$ times is $\\tilde{O}(\\sqrt{k})$. This improves over the best prior method by Koskela et al. (2020) which requires $\\tilde{\\Omega}(k^{1.5})$ running time. We demonstrate the utility of our algorithm by accurately computing the privacy loss of DP-SGD algorithm of Abadi et al. (2016) and showing that our algorithm speeds up the privacy computations by a few orders of magnitude compared to prior work, while maintaining similar accuracy.\n", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "gopi|numerical_composition_of_differential_privacy", "pdf": "/pdf/8766854de54df2e08797499be336e5370a9273cc.pdf", "checklist": "", "supplementary_material": "/attachment/a6be91340e06c5c43f81ba21dccbdebf63515c6f.pdf", "code": "https://github.com/microsoft/prv_accountant", "thumbnail": "", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2106.02848/code)", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\ngopi2021numerical,\ntitle={Numerical Composition of Differential Privacy},\nauthor={Sivakanth Gopi and Yin Tat Lee and Lukas Wutschitz},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=GSXEx6iYd0}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492758108, "odate": 1636492758108, "details": {"replyCount": 14}}, {"id": "wdIDt--oLmV", "original": "2_HdM268QXe", "number": 6769, "cdate": 1621630062089, "ddate": null, "tcdate": 1621630062089, "tmdate": 1683307677005, "tddate": null, "forum": "wdIDt--oLmV", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Amortized Synthesis of Constrained Configurations Using a Differentiable Surrogate", "authorids": ["~Xingyuan_Sun1", "~Tianju_Xue1", "~Szymon_Rusinkiewicz2", "~Ryan_P_Adams1"], "authors": ["Xingyuan Sun", "Tianju Xue", "Szymon Rusinkiewicz", "Ryan P Adams"], "keywords": ["Amortization", "Inverse design", "Differentiable surrogate", "3D printing", "Soft robot"], "abstract": "In design, fabrication, and control problems, we are often faced with the task of synthesis, in which we must generate an object or configuration that satisfies a set of constraints while maximizing one or more objective functions. The synthesis problem is typically characterized by a physical process in which many different realizations may achieve the goal. This many-to-one map presents challenges to the supervised learning of feed-forward synthesis, as the set of viable designs may have a complex structure. In addition, the non-differentiable nature of many physical simulations prevents efficient direct optimization. We address both of these problems with a two-stage neural network architecture that we may consider to be an autoencoder. We first learn the decoder: a differentiable surrogate that approximates the many-to-one physical realization process. We then learn the encoder, which maps from goal to design, while using the fixed decoder to evaluate the quality of the realization. We evaluate the approach on two case studies: extruder path planning in additive manufacturing and constrained soft robot inverse kinematics. We compare our approach to direct optimization of the design using the learned surrogate, and to supervised learning of the synthesis problem. We find that our approach produces higher quality solutions than supervised learning, while being competitive in quality with direct optimization, at a greatly reduced computational cost.", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "sun|amortized_synthesis_of_constrained_configurations_using_a_differentiable_surrogate", "pdf": "/pdf/bcad770e503173397c22c35303d5645bc4282a9f.pdf", "checklist": "", "supplementary_material": "/attachment/9d08485ee3512109cdd06f01b922f45a93906bd6.pdf", "code": "https://github.com/xingyuansun/amorsyn", "thumbnail": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nsun2021amortized,\ntitle={Amortized Synthesis of Constrained Configurations Using a Differentiable Surrogate},\nauthor={Xingyuan Sun and Tianju Xue and Szymon Rusinkiewicz and Ryan P Adams},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=wdIDt--oLmV}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492710331, "odate": 1636492710331, "details": {"replyCount": 13}}, {"id": "rxud5HYKX55", "original": "z6OjKOEgZdM", "number": 6760, "cdate": 1621630061540, "ddate": null, "tcdate": 1621630061540, "tmdate": 1683307676578, "tddate": null, "forum": "rxud5HYKX55", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Optimal Sketching for Trace Estimation", "authorids": ["~Shuli_Jiang1", "~Hai_Pham2", "~David_Woodruff1", "~Qiuyi_Zhang1"], "authors": ["Shuli Jiang", "Hai Pham", "David Woodruff", "Qiuyi Zhang"], "keywords": ["Trace estimation", "Query complexity", "Sketching algorithms"], "abstract": "Matrix trace estimation is ubiquitous in machine learning applications and has traditionally relied on Hutchinson's method, which requires $O(\\log(1/\\delta)/\\epsilon^2)$ matrix-vector product queries to achieve a $(1 \\pm \\epsilon)$-multiplicative approximation to $\\text{trace}(A)$ with failure probability $\\delta$ on positive-semidefinite input matrices $A$. Recently, the Hutch++ algorithm was proposed, which reduces the number of matrix-vector queries from $O(1/\\epsilon^2)$ to the optimal $O(1/\\epsilon)$, and the algorithm succeeds with constant probability. However, in the high probability setting, the non-adaptive Hutch++ algorithm suffers an extra $O(\\sqrt{\\log(1/\\delta)})$ multiplicative factor in its query complexity. Non-adaptive methods are important, as they correspond to sketching algorithms, which are mergeable, highly parallelizable, and provide low-memory streaming algorithms as well as low-communication distributed protocols. In this work, we close the gap between non-adaptive and adaptive algorithms, showing that even non-adaptive algorithms can achieve $O(\\sqrt{\\log(1/\\delta)}/\\epsilon + \\log(1/\\delta))$ matrix-vector products. In addition, we prove matching lower bounds demonstrating that, up to a $\\log \\log(1/\\delta)$ factor, no further improvement in the dependence on $\\delta$ or $\\epsilon$ is possible by any non-adaptive algorithm. Finally, our experiments demonstrate the superior performance of our sketch over the adaptive Hutch++ algorithm, which is less parallelizable, as well as over the non-adaptive Hutchinson's method.", "submission_history": "", "checklist": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "jiang|optimal_sketching_for_trace_estimation", "pdf": "/pdf/4c6599a9ebf408953946ff55db6fb7606f2dd2a5.pdf", "supplementary_material": "/attachment/20e64ad3f7a31f4744477ac5a97d3e4c16248b0f.pdf", "code": "https://github.com/11hifish/OptSketchTraceEst", "thumbnail": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\njiang2021optimal,\ntitle={Optimal Sketching for Trace Estimation},\nauthor={Shuli Jiang and Hai Pham and David Woodruff and Qiuyi Zhang},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=rxud5HYKX55}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492685353, "odate": 1636492685353, "details": {"replyCount": 9}}, {"id": "AvVDR8R-kQX", "original": "HoeXDjIpL8t", "number": 6740, "cdate": 1621630060270, "ddate": null, "tcdate": 1621630060270, "tmdate": 1683307675927, "tddate": null, "forum": "AvVDR8R-kQX", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "A Provably Efficient Sample Collection Strategy for Reinforcement Learning", "authorids": ["~Jean_Tarbouriech1", "~Matteo_Pirotta1", "~Michal_Valko1", "~Alessandro_Lazaric2"], "authors": ["Jean Tarbouriech", "Matteo Pirotta", "Michal Valko", "Alessandro Lazaric"], "keywords": ["exploration", "sample complexity", "Markov decision process", "reinforcement learning"], "abstract": "One of the challenges in online reinforcement learning (RL) is that the agent needs to trade off the exploration of the environment and the exploitation of the samples to optimize its behavior. Whether we optimize for regret, sample complexity, state-space coverage or model estimation, we need to strike a different exploration-exploitation trade-off. In this paper, we propose to tackle the exploration-exploitation problem following a decoupled approach composed of: 1) An \"objective-specific\" algorithm that (adaptively) prescribes how many samples to collect at which states, as if it has access to a generative model (i.e., a simulator of the environment); 2) An \"objective-agnostic\" sample collection exploration strategy responsible for generating the prescribed samples as fast as possible. Building on recent methods for exploration in the stochastic shortest path problem, we first provide an algorithm that, given as input the number of samples $b(s,a)$ needed in each state-action pair, requires $\\widetilde{O}(B D + D^{3/2} S^2 A)$ time steps to collect the $B=\\sum_{s,a} b(s,a)$ desired samples, in any unknown communicating MDP with $S$ states, $A$ actions and diameter $D$. Then we show how this general-purpose exploration algorithm can be paired with \"objective-specific\" strategies that prescribe the sample requirements to tackle a variety of settings \u2014 e.g., model estimation, sparse reward discovery, goal-free cost-free exploration in communicating MDPs \u2014 for which we obtain improved or novel sample complexity guarantees.", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "tarbouriech|a_provably_efficient_sample_collection_strategy_for_reinforcement_learning", "TL;DR": "We tackle various exploration problems (for which we get improved/novel guarantees) by introducing a decoupled approach: 1) prescribe (akin to a generative model) the samples and 2) provably collect them via a goal-conditioned exploration strategy.", "pdf": "/pdf/3e27c044e078e885484cb005da6af8409021ff24.pdf", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "checklist": "", "supplementary_material": "/attachment/08b6d5cc2170ec21ad28c7584ba42724a40ec1c6.pdf", "thumbnail": "", "_bibtex": "@inproceedings{\ntarbouriech2021a,\ntitle={A Provably Efficient Sample Collection Strategy for Reinforcement Learning},\nauthor={Jean Tarbouriech and Matteo Pirotta and Michal Valko and Alessandro Lazaric},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=AvVDR8R-kQX}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492724967, "odate": 1636492724967, "details": {"replyCount": 11}}, {"id": "cx2q4cOBnne", "original": "BHGC2uvMYrW", "number": 6737, "cdate": 1621630060081, "ddate": null, "tcdate": 1621630060081, "tmdate": 1683307675804, "tddate": null, "forum": "cx2q4cOBnne", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Reinforcement Learning in Newcomblike Environments", "authorids": ["~James_Henry_Bell1", "~Linda_Linsefors1", "~Caspar_Oesterheld1", "~Joar_Max_Viktor_Skalse1"], "authors": ["James Henry Bell", "Linda Linsefors", "Caspar Oesterheld", "Joar Max Viktor Skalse"], "keywords": ["reinforcement learning", "learning in games", "decision theory"], "TL;DR": "How do value-based reinforcement learning algorithms behave when the environment can predict the agent's policy?", "abstract": "Newcomblike decision problems have been studied extensively in the decision theory literature, but they have so far been largely absent in the reinforcement learning literature. In this paper we study value-based reinforcement learning algorithms in the Newcomblike setting, and answer some of the fundamental theoretical questions about the behaviour of such algorithms in these environments. We show that a value-based reinforcement learning agent cannot converge to a policy that is not \\emph{ratifiable}, i.e., does not only choose actions that are optimal given that policy. This gives us a powerful tool for reasoning about the limit behaviour of agents -- for example, it lets us show that there are Newcomblike environments in which a reinforcement learning agent cannot converge to any optimal policy. We show that a ratifiable policy always exists in our setting, but that there are cases in which a reinforcement learning agent normally cannot converge to it (and hence cannot converge at all). We also prove several results about the possible limit behaviours of agents in cases where they do not converge to any policy.", "submission_history": "", "submission_history_-_venue_and_year": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "bell|reinforcement_learning_in_newcomblike_environments", "pdf": "/pdf/0c82c8efc0ce2dcbb699864a81ca2ae761b368dd.pdf", "submission_history_-_improvements_made": "", "checklist": "", "supplementary_material": "/attachment/31474ea25a9467e64963d54a5755f006fd2d2077.pdf", "code": "https://github.com/mathsjames/Safe-AF", "thumbnail": "", "_bibtex": "@inproceedings{\nbell2021reinforcement,\ntitle={Reinforcement Learning in Newcomblike Environments},\nauthor={James Henry Bell and Linda Linsefors and Caspar Oesterheld and Joar Max Viktor Skalse},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=cx2q4cOBnne}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492715061, "odate": 1636492715061, "details": {"replyCount": 18}}, {"id": "c34cJa9uZn", "original": "6Qc9wLICmVw", "number": 6719, "cdate": 1621630058946, "ddate": null, "tcdate": 1621630058946, "tmdate": 1683307674967, "tddate": null, "forum": "c34cJa9uZn", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Shaping embodied agent behavior with activity-context priors from egocentric video", "authorids": ["~Tushar_Nagarajan1", "~Kristen_Grauman1"], "authors": ["Tushar Nagarajan", "Kristen Grauman"], "keywords": ["embodied AI", "learning from passive videos", "visual semantic planning", "interaction exploration", "object interaction", "egocentric video", "human activity understanding", "computer vision"], "TL;DR": "We learn from real-world egocentric video what objects together enable activities (e.g., a knife and cutting board brought together with a tomato are conducive to cutting), and use this to improve training virtual household embodied AI agents.", "abstract": "Complex physical tasks entail a sequence of object interactions, each with its own preconditions -- which can be difficult for robotic agents to learn efficiently solely through their own experience. We introduce an approach to discover activity-context priors from in-the-wild egocentric video captured with human worn cameras. For a given object, an activity-context prior represents the set of other compatible objects that are required for activities to succeed (e.g., a knife and cutting board brought together with a tomato are conducive to cutting). We encode our video-based prior as an auxiliary reward function that encourages an agent to bring compatible objects together before attempting an interaction. In this way, our model translates everyday human experience into embodied agent skills. We demonstrate our idea using egocentric EPIC-Kitchens video of people performing unscripted kitchen activities to benefit virtual household robotic agents performing various complex tasks in AI2-iTHOR, significantly accelerating agent learning. ", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "nagarajan|shaping_embodied_agent_behavior_with_activitycontext_priors_from_egocentric_video", "pdf": "/pdf/ba11f672f19300d6e8d54fa2655d84185c4405c9.pdf", "checklist": "", "supplementary_material": "/attachment/b9b8c45276673361e0f1ef7b5966da0a992cc0ff.pdf", "thumbnail": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nnagarajan2021shaping,\ntitle={Shaping embodied agent behavior with activity-context priors from egocentric video},\nauthor={Tushar Nagarajan and Kristen Grauman},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=c34cJa9uZn}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492752491, "odate": 1636492752491, "details": {"replyCount": 16}}, {"id": "X4_aAfxsOoE", "original": "uyOwIuwBc8", "number": 6680, "cdate": 1621630056530, "ddate": null, "tcdate": 1621630056530, "tmdate": 1683307673968, "tddate": null, "forum": "X4_aAfxsOoE", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Slice Sampling Reparameterization Gradients", "authorids": ["~David_M._Zoltowski1", "~Diana_Cai1", "~Ryan_P_Adams1"], "authors": ["David M. Zoltowski", "Diana Cai", "Ryan P Adams"], "keywords": ["Monte Carlo gradient estimation", "slice sampling", "energy-based models", "variational inference"], "abstract": "Many probabilistic modeling problems in machine learning use gradient-based optimization in which the objective takes the form of an expectation. These problems can be challenging when the parameters to be optimized determine the probability distribution under which the expectation is being taken, as the na\\\"ive Monte Carlo procedure is not differentiable. Reparameterization gradients make it possible to efficiently perform optimization of these Monte Carlo objectives by transforming the expectation to be differentiable, but the approach is typically limited to distributions with simple forms and tractable normalization constants. Here we describe how to differentiate samples from slice sampling to compute \\textit{slice sampling reparameterization gradients}, enabling a richer class of Monte Carlo objective functions to be optimized. Slice sampling is a Markov chain Monte Carlo algorithm for simulating samples from probability distributions; it only requires a density function that can be evaluated point-wise up to a normalization constant, making it applicable to a variety of inference problems and unnormalized models. Our approach is based on the observation that when the slice endpoints are known, the sampling path is a deterministic and differentiable function of the pseudo-random variables, since the algorithm is rejection-free. We evaluate the method on synthetic examples and apply it to a variety of applications with reparameterization of unnormalized probability distributions. ", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "zoltowski|slice_sampling_reparameterization_gradients", "TL;DR": "We present slice sampling reparameterization gradients for optimizing probabilistic objectives with respect to parameterized unnormalized distributions.", "pdf": "/pdf/1fd7f3cf3a56ee691b7db0dfaf8794c211954ef4.pdf", "checklist": "", "supplementary_material": "/attachment/7ce237727c659b2f4cc59a216cf733da681bc7a4.pdf", "code": "https://github.com/PrincetonLIPS/slicereparam", "thumbnail": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nzoltowski2021slice,\ntitle={Slice Sampling Reparameterization Gradients},\nauthor={David M. Zoltowski and Diana Cai and Ryan P Adams},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=X4_aAfxsOoE}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492708541, "odate": 1636492708541, "details": {"replyCount": 11}}, {"id": "aUuTEEcyY_", "original": "FGHFyQxOlBQ", "number": 6670, "cdate": 1621630055898, "ddate": null, "tcdate": 1621630055898, "tmdate": 1697937492788, "tddate": null, "forum": "aUuTEEcyY_", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Instance-Conditioned GAN", "authorids": ["~Arantxa_Casanova1", "~Marlene_Careil1", "~Jakob_Verbeek1", "~Michal_Drozdzal1", "~Adriana_Romero1"], "authors": ["Arantxa Casanova", "Marlene Careil", "Jakob Verbeek", "Michal Drozdzal", "Adriana Romero"], "keywords": ["generative adversarial networks", "GAN", "conditional GAN", "image generation", "scene generation", "kernel density estimation", "class conditional GAN", "unbalanced classes", "long-tail distribution"], "TL;DR": "We partition the data manifold into a mixture of overlapping neighborhoods described by a datapoint and its nearest neighbors, and introduce a model, called instance-conditioned GAN (IC-GAN), which learns the distribution around each datapoint.", "abstract": "Generative Adversarial Networks (GANs) can generate near photo realistic images in narrow domains such as human faces. Yet, modeling complex distributions of datasets such as ImageNet and COCO-Stuff remains challenging in unconditional settings. In this paper, we take inspiration from kernel density estimation techniques and introduce a non-parametric approach to modeling distributions of complex datasets. We partition the data manifold into a mixture of overlapping neighborhoods described by a datapoint and its nearest neighbors, and introduce a model, called instance-conditioned GAN (IC-GAN), which learns the distribution around each datapoint. Experimental results on ImageNet and COCO-Stuff show that IC-GAN significantly improves over unconditional models and unsupervised data partitioning baselines. Moreover, we show that IC-GAN can effortlessly transfer to datasets not seen during training by simply changing the conditioning instances, and still generate realistic images. Finally, we extend IC-GAN to the class-conditional case and show semantically controllable generation and competitive quantitative results on ImageNet; while improving over BigGAN on ImageNet-LT. Code and trained models to reproduce the reported results are available at https://github.com/facebookresearch/ic_gan.\n", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "casanova|instanceconditioned_gan", "pdf": "/pdf/7ca4855438c419e99bd8ee2c2868b337a2bd591d.pdf", "checklist": "", "supplementary_material": "/attachment/5730551340c48952bd19d027d1ced7adf2cf6625.pdf", "code": "https://github.com/facebookresearch/ic_gan", "thumbnail": "", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 11 code implementations](https://www.catalyzex.com/paper/arxiv:2109.05070/code)", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\ncasanova2021instanceconditioned,\ntitle={Instance-Conditioned {GAN}},\nauthor={Arantxa Casanova and Marlene Careil and Jakob Verbeek and Michal Drozdzal and Adriana Romero},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=aUuTEEcyY_}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492782121, "odate": 1636492782121, "details": {"replyCount": 9}}, {"id": "-S1V_oEOE52", "original": "OWdSbD7pR6E", "number": 6644, "cdate": 1621630054309, "ddate": null, "tcdate": 1621630054309, "tmdate": 1683307673188, "tddate": null, "forum": "-S1V_oEOE52", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Iteratively Reweighted Least Squares for Basis Pursuit with Global Linear Convergence Rate", "authorids": ["~Christian_K\u00fcmmerle1", "~Claudio_Mayrink_Verdun1", "~Dominik_St\u00f6ger1"], "authors": ["Christian K\u00fcmmerle", "Claudio Mayrink Verdun", "Dominik St\u00f6ger"], "keywords": ["compressed sensing", "sparse models", "signal processing", "iteratively reweighted least squares", "convex optimization", "linear convergence"], "TL;DR": "We show that IRLS for basis pursuit achieves linear convergence starting from any initialization, whereas previous results only provided a local linear convergence rate.", "abstract": "The recovery of sparse data is at the core of many applications in machine learning and signal processing. While such problems can be tackled using $\\ell_1$-regularization as in the LASSO estimator and in the Basis Pursuit approach, specialized algorithms are typically required to solve the corresponding high-dimensional non-smooth optimization for large instances.\nIteratively Reweighted Least Squares (IRLS) is a widely used algorithm for this purpose due to its excellent numerical performance. However, while existing theory is able to guarantee convergence of this algorithm to the minimizer, it does not provide a global convergence rate. In this paper, we prove that a variant of IRLS converges \\emph{with a global linear rate} to a sparse solution, i.e., with a linear error decrease occurring immediately from any initialization if the measurements fulfill the usual null space property assumption. We support our theory by numerical experiments showing that our linear rate captures the correct dimension dependence. We anticipate that our theoretical findings will lead to new insights for many other use cases of the IRLS algorithm, such as in low-rank matrix recovery.", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "k\u00fcmmerle|iteratively_reweighted_least_squares_for_basis_pursuit_with_global_linear_convergence_rate", "pdf": "/pdf/b1f7e4c2df5a185480fb750d05696d3c889265c6.pdf", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "checklist": "", "supplementary_material": "/attachment/11e05a2c2a311cb0217d483fc2ae9dedd31c8f0d.pdf", "thumbnail": "", "code": "https://github.com/ckuemmerle/IRLSGlobalLinConv", "_bibtex": "@inproceedings{\nk{\\\"u}mmerle2021iteratively,\ntitle={Iteratively Reweighted Least Squares for Basis Pursuit with Global Linear Convergence Rate},\nauthor={Christian K{\\\"u}mmerle and Claudio Mayrink Verdun and Dominik St{\\\"o}ger},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=-S1V_oEOE52}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492703584, "odate": 1636492703584, "details": {"replyCount": 12}}, {"id": "9J2wV5E1Aq_", "original": "uEZcKtdJnRv", "number": 6639, "cdate": 1621630054013, "ddate": null, "tcdate": 1621630054013, "tmdate": 1683307672951, "tddate": null, "forum": "9J2wV5E1Aq_", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Generalization Bounds For Meta-Learning: An Information-Theoretic Analysis", "authorids": ["~Qi_CHEN6", "~Changjian_Shui2", "~Mario_Marchand1"], "authors": ["Qi CHEN", "Changjian Shui", "Mario Marchand"], "keywords": ["meta-learning", "few-shot learning", "deep learning"], "abstract": "We derive a novel information-theoretic analysis of the generalization property of meta-learning algorithms. Concretely, our analysis proposes a generic understanding in both the conventional learning-to-learn framework \\citep{amit2018meta} and the modern model-agnostic meta-learning (MAML) algorithms \\citep{finn2017model}.\nMoreover, we provide a data-dependent generalization bound for the stochastic variant of MAML, which is \\emph{non-vacuous} for deep few-shot learning. As compared to previous bounds that depend on the square norms of gradients, empirical validations on both simulated data and a well-known few-shot benchmark show that our bound is orders of magnitude tighter in most conditions.", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "chen|generalization_bounds_for_metalearning_an_informationtheoretic_analysis", "pdf": "/pdf/17750e292c0bc449b8da69edb384d474e4e904af.pdf", "checklist": "", "supplementary_material": "/attachment/4db2a06078fe09849babfff995e67fb43e098cfb.pdf", "code": "https://github.com/livreQ/meta-sgld", "thumbnail": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nchen2021generalization,\ntitle={Generalization Bounds For Meta-Learning: An Information-Theoretic Analysis},\nauthor={Qi CHEN and Changjian Shui and Mario Marchand},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=9J2wV5E1Aq_}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492692459, "odate": 1636492692459, "details": {"replyCount": 17}}, {"id": "MDMV2SxCboX", "original": "BFbgPnnCRDQ", "number": 6636, "cdate": 1621630053881, "ddate": null, "tcdate": 1621630053881, "tmdate": 1683307672845, "tddate": null, "forum": "MDMV2SxCboX", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Why Do Pretrained Language Models Help in Downstream Tasks? An Analysis of Head and Prompt Tuning", "authorids": ["~Colin_Wei1", "~Sang_Michael_Xie1", "~Tengyu_Ma1"], "authors": ["Colin Wei", "Sang Michael Xie", "Tengyu Ma"], "keywords": ["theory", "representation learning theory", "self-supervised learning theory", "pretrained language models", "natural language processing"], "TL;DR": "We analyze settings where performing classification head or prompt tuning on a pretrained language model can provably help downstream task performance.", "abstract": "Pretrained language models have achieved state-of-the-art performance when adapted to a downstream NLP task. However, theoretical analysis of these models is scarce and challenging since the pretraining and downstream tasks can be very different. We propose an analysis framework that links the pretraining and downstream tasks with an underlying latent variable generative model of text -- the downstream classifier must recover a function of the posterior distribution over the latent variables. We analyze head tuning (learning a classifier on top of the frozen pretrained model) and prompt tuning in this setting. The generative model in our analysis is either a Hidden Markov Model (HMM) or an HMM augmented with a latent memory component, motivated by long-term dependencies in natural language. We show that 1) under certain non-degeneracy conditions on the HMM, simple classification heads can solve the downstream task, 2) prompt tuning obtains downstream guarantees with weaker non-degeneracy conditions, and 3) our recovery guarantees for the memory-augmented HMM are stronger than for the vanilla HMM because task-relevant information is easier to recover from the long-term memory. Experiments on synthetically generated data from HMMs back our theoretical findings.\n", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "wei|why_do_pretrained_language_models_help_in_downstream_tasks_an_analysis_of_head_and_prompt_tuning", "pdf": "/pdf/6360b8480b6e711cab6fa4f501d5ce55d1c771e8.pdf", "supplementary_material": "/attachment/62afdb7d7828bcf4d921a21f743b07dc1b3d33ce.pdf", "checklist": "", "code": "/attachment/9fc1b3723c5e86b502d9e6ad80e127e7281b79b1.zip", "thumbnail": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nwei2021why,\ntitle={Why Do Pretrained Language Models Help in Downstream Tasks? An Analysis of Head and Prompt Tuning},\nauthor={Colin Wei and Sang Michael Xie and Tengyu Ma},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=MDMV2SxCboX}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492690321, "odate": 1636492690321, "details": {"replyCount": 10}}, {"id": "jlchsFOLfeF", "original": "mComh29ZKId", "number": 6628, "cdate": 1621630053576, "ddate": null, "tcdate": 1621630053576, "tmdate": 1683307672380, "tddate": null, "forum": "jlchsFOLfeF", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Invariance Principle Meets Information Bottleneck for Out-of-Distribution Generalization", "authorids": ["~Kartik_Ahuja1", "~Ethan_Caballero1", "~Dinghuai_Zhang1", "~Jean-Christophe_Gagnon-Audet1", "~Yoshua_Bengio1", "~Ioannis_Mitliagkas1", "~Irina_Rish1"], "authors": ["Kartik Ahuja", "Ethan Caballero", "Dinghuai Zhang", "Jean-Christophe Gagnon-Audet", "Yoshua Bengio", "Ioannis Mitliagkas", "Irina Rish"], "keywords": ["out-of-distribution generalization", "invariance principle", "information bottleneck"], "TL;DR": "We prove information bottleneck along with invariance helps address key OOD generalization failures when invariant features capture all info about label. We propose an approach that incorporates both and demonstrate its OOD generalization capability.", "abstract": "The invariance principle from causality is at the heart of notable approaches such as invariant risk minimization (IRM) that seek to address out-of-distribution (OOD) generalization failures. Despite the promising theory, invariance principle-based approaches fail in common classification tasks, where invariant (causal) features capture all the information about the label.  Are these failures due to the methods failing to capture the invariance? Or is the invariance principle itself insufficient? To answer these questions, we revisit the fundamental assumptions in linear regression tasks, where invariance-based approaches were shown to provably generalize OOD. In contrast to the linear regression tasks, we show that for linear classification tasks we need much stronger restrictions on the distribution shifts, or otherwise OOD generalization is impossible.  Furthermore, even with appropriate restrictions on distribution shifts in place, we show that the invariance principle alone is insufficient. We prove that a form of the information bottleneck constraint along with invariance helps address the key failures when invariant features capture all the information about the label and also retains the existing success when they do not. We propose an approach that incorporates both of these principles and demonstrate its effectiveness in several experiments.", "pdf": "/pdf/10219b22ae8d6937af0d4500bcfeeb59a9f0cc91.pdf", "supplementary_material": "/attachment/d86525fde368087e7f003c34ecdff4912e4c4ea3.pdf", "submission_history": "", "checklist": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "ahuja|invariance_principle_meets_information_bottleneck_for_outofdistribution_generalization", "thumbnail": "", "code": "https://github.com/ahujak/IB-IRM; https://github.com/facebookresearch/DomainBed", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nahuja2021invariance,\ntitle={Invariance Principle Meets Information Bottleneck for Out-of-Distribution Generalization},\nauthor={Kartik Ahuja and Ethan Caballero and Dinghuai Zhang and Jean-Christophe Gagnon-Audet and Yoshua Bengio and Ioannis Mitliagkas and Irina Rish},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=jlchsFOLfeF}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492672981, "odate": 1636492672981, "details": {"replyCount": 21}}, {"id": "YA0wIYi-yM3", "original": "RwrK0MHvPB8", "number": 6610, "cdate": 1621630052593, "ddate": null, "tcdate": 1621630052593, "tmdate": 1683307671914, "tddate": null, "forum": "YA0wIYi-yM3", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Breaking the Sample Complexity Barrier to Regret-Optimal Model-Free Reinforcement Learning", "authorids": ["~Gen_Li2", "~Laixi_Shi1", "~Yuxin_Chen5", "~Yuantao_Gu1", "~Yuejie_Chi1"], "authors": ["Gen Li", "Laixi Shi", "Yuxin Chen", "Yuantao Gu", "Yuejie Chi"], "keywords": ["reinforcement learning", "memory efficiency", "model-free RL", "episodic MDPs", "variance reduction", "exploration"], "abstract": "Achieving sample efficiency in online episodic reinforcement learning (RL) requires optimally balancing  exploration and exploitation. When it comes to a finite-horizon episodic Markov decision process with $S$ states, $A$ actions and horizon length $H$, substantial progress has been achieved towards characterizing the minimax-optimal regret, which scales on the order of $\\sqrt{H^2SAT}$ (modulo log factors) with $T$ the total number of samples. While several competing solution paradigms have been proposed to minimize regret, they are either memory-inefficient, or fall short of optimality unless the sample size exceeds an enormous threshold (e.g., $S^6A^4 \\,\\mathrm{poly}(H)$ for existing model-free methods).\n\nTo overcome such a large sample size barrier to efficient RL, we design a novel model-free algorithm, with space complexity $O(SAH)$, that achieves near-optimal regret as soon as the sample size exceeds the order of $SA\\,\\mathrm{poly}(H)$. In terms of this sample size requirement (also referred to the initial burn-in cost), our method improves --- by at least a factor of $S^5A^3$ --- upon any prior memory-efficient algorithm that is asymptotically regret-optimal. Leveraging the recently introduced variance reduction strategy (also called {\\em reference-advantage decomposition}), the proposed algorithm employs an {\\em early-settled}  reference update rule, with the aid of two Q-learning sequences with upper and lower confidence bounds. The design principle of our early-settled variance reduction method might be of independent interest to other RL settings that involve intricate exploration-exploitation trade-offs.", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "li|breaking_the_sample_complexity_barrier_to_regretoptimal_modelfree_reinforcement_learning", "TL;DR": "This paper develops a model-free algorithm that is simultaneously regret-optimal and memory-efficient for a broad range of sample sizes. ", "pdf": "/pdf/436a95d96ddca8d0299e1d4ba80ea24c1e31f04c.pdf", "supplementary_material": "/attachment/fe370c86ffb31df41a4169abfb36012b230e9009.pdf", "checklist": "", "thumbnail": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nli2021breaking,\ntitle={Breaking the Sample Complexity Barrier to Regret-Optimal Model-Free Reinforcement Learning},\nauthor={Gen Li and Laixi Shi and Yuxin Chen and Yuantao Gu and Yuejie Chi},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=YA0wIYi-yM3}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492785000, "odate": 1636492785000, "details": {"replyCount": 10}}, {"id": "aXbuWbta0V8", "original": "FSq5MX4gYlm", "number": 6575, "cdate": 1621630050450, "ddate": null, "tcdate": 1621630050450, "tmdate": 1697937497260, "tddate": null, "forum": "aXbuWbta0V8", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Proper Value Equivalence", "authorids": ["~Christopher_Grimm1", "~Andre_Barreto1", "~Gregory_Farquhar1", "~David_Silver1", "~Satinder_Singh2"], "authors": ["Christopher Grimm", "Andre Barreto", "Gregory Farquhar", "David Silver", "Satinder Singh"], "keywords": ["model-based reinforcement learning", "reinforcement learning", "value function", "muzero", "value equivalence", "planning"], "TL;DR": "We study model classes that have the same k-step Bellman updates as the environment, focus on a special case as k --> infty which we can closely connect with MuZero and use insights from for practical benefit.", "abstract": "One of the main challenges in model-based reinforcement learning (RL) is to decide which aspects of the environment should be modeled. The value-equivalence (VE) principle proposes a simple answer to this question: a model should capture the aspects of the environment that are relevant for value-based planning. Technically, VE distinguishes models based on a set of policies and a set of functions: a model is said to be VE to the environment if the Bellman operators it induces for the policies yield the correct result when applied to the functions. As the number of policies and functions increase, the set of VE models shrinks, eventually collapsing to a single point corresponding to a perfect model. A fundamental question underlying the VE principle is thus how to select the smallest sets of policies and functions that are sufficient for planning. In this paper we take an important step towards answering this question. We start by generalizing the concept of VE to order-$k$ counterparts defined with respect to $k$ applications of the Bellman operator. This leads to a family of VE classes that increase in size as $k \\rightarrow \\infty$. In the limit, all functions become value functions, and we have a special instantiation of VE which we call proper VE or simply PVE. Unlike VE, the PVE class may contain multiple models even in the limit when all value functions are used. Crucially, all these models are sufficient for planning, meaning that they will yield an optimal policy despite the fact that they may ignore many aspects of the environment. We construct a loss function for learning PVE models and argue that popular algorithms such as MuZero can be understood as minimizing an upper bound for this loss. We leverage this connection to propose a modification to MuZero and show that it can lead to improved performance in practice.", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "grimm|proper_value_equivalence", "pdf": "/pdf/7b54d3fc970be587e3af3272bca51cb326303cd4.pdf", "supplementary_material": "/attachment/1fbe902480c8787d85a00d9f49f9d35ab0d402e7.pdf", "checklist": "", "code": "https://github.com/chrisgrimm/proper_value_equivalence", "thumbnail": "", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2106.10316/code)", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\ngrimm2021proper,\ntitle={Proper Value Equivalence},\nauthor={Christopher Grimm and Andre Barreto and Gregory Farquhar and David Silver and Satinder Singh},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=aXbuWbta0V8}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492716846, "odate": 1636492716846, "details": {"replyCount": 11}}, {"id": "TgDTMyA9Nk", "original": "f_dC5YsFdiG", "number": 6568, "cdate": 1621630050010, "ddate": null, "tcdate": 1621630050010, "tmdate": 1683307670540, "tddate": null, "forum": "TgDTMyA9Nk", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Learning Equilibria in Matching Markets from Bandit Feedback", "authorids": ["~Meena_Jagadeesan1", "~Alexander_Wei2", "~Yixin_Wang1", "~Michael_Jordan1", "~Jacob_Steinhardt1"], "authors": ["Meena Jagadeesan", "Alexander Wei", "Yixin Wang", "Michael Jordan", "Jacob Steinhardt"], "keywords": ["matching markets", "learning equilibria", "multi-armed bandits"], "abstract": "Large-scale, two-sided matching platforms must find market outcomes that align with user preferences while simultaneously learning these preferences from data. But since preferences are inherently uncertain during learning, the classical notion of stability (Gale and Shapley, 1962; Shapley and Shubik, 1971) is unattainable in these settings. To bridge this gap, we develop a framework and algorithms for learning stable market outcomes under uncertainty. Our primary setting is matching with transferable utilities, where the platform both matches agents and sets monetary transfers between them. We design an incentive-aware learning objective that captures the distance of a market outcome from equilibrium. Using this objective, we analyze the complexity of learning as a function of preference structure, casting learning as a stochastic multi-armed bandit problem. Algorithmically, we show that \"optimism in the face of uncertainty,\" the principle underlying many bandit algorithms, applies to a primal-dual formulation of matching with transfers and leads to near-optimal regret bounds. Our work takes a first step toward elucidating when and how stable matchings arise in large, data-driven marketplaces.", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "jagadeesan|learning_equilibria_in_matching_markets_from_bandit_feedback", "TL;DR": "We develop a framework and algorithms for learning efficient market outcomes when preferences are uncertain.", "pdf": "/pdf/903eac308d4151406e852db95c7d10ff5631c107.pdf", "checklist": "", "supplementary_material": "/attachment/19e8b3650a76e9da5c11932a390631a0aaf9551e.pdf", "thumbnail": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\njagadeesan2021learning,\ntitle={Learning Equilibria in Matching Markets from Bandit Feedback},\nauthor={Meena Jagadeesan and Alexander Wei and Yixin Wang and Michael Jordan and Jacob Steinhardt},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=TgDTMyA9Nk}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492711984, "odate": 1636492711984, "details": {"replyCount": 12}}, {"id": "rxAS126OC-A", "original": "b0jO87YBWC2", "number": 6545, "cdate": 1621630048607, "ddate": null, "tcdate": 1621630048607, "tmdate": 1683307670285, "tddate": null, "forum": "rxAS126OC-A", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "PLUGIn: A simple algorithm for inverting generative models with recovery guarantees", "authorids": ["~Babhru_Joshi1", "~Xiaowei_Li3", "~Yaniv_Plan1", "~Ozgur_Yilmaz1"], "authors": ["Babhru Joshi", "Xiaowei Li", "Yaniv Plan", "Ozgur Yilmaz"], "keywords": ["generative neural network", "inverse problem", "denoise", "gradient type method", "non-convex optimization"], "abstract": "We consider the problem of recovering an unknown latent code vector under a known generative model. For a $d$-layer deep generative network $\\mathcal{G}:\\mathbb{R}^{n_0}\\rightarrow \\mathbb{R}^{n_d}$ with ReLU activation functions, let the observation be $\\mathcal{G}(x)+\\epsilon$ where $\\epsilon$ is noise. We introduce a simple novel algorithm, Partially Linearized Update for Generative Inversion (PLUGIn), to estimate $x$ (and thus $\\mathcal{G}(x)$). We prove that, when weights are Gaussian and layer widths $n_i \\gtrsim 5^i n_0$ (up to log factors), the algorithm converges geometrically to a neighbourhood of $x$ with high probability. Note the inequality on layer widths allows $n_i>n_{i+1}$ when $i\\geq 1$. To our knowledge, this is the first such result for networks with some contractive layers. After a sufficient number of iterations, the estimation errors for both $x$ and $\\mathcal{G}(x)$ are at most in the order of $\\sqrt{4^dn_0/n_d} \\|\\epsilon\\|$. Thus, the algorithm can denoise when the expansion ratio $n_d/n_0$ is large. Numerical experiments on synthetic data and real data are provided to validate our theoretical results and to illustrate that the algorithm can effectively remove artifacts in an image.", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "joshi|plugin_a_simple_algorithm_for_inverting_generative_models_with_recovery_guarantees", "pdf": "/pdf/0b646549e14e30628ab2c07d5f115c4fb016b545.pdf", "checklist": "", "supplementary_material": "/attachment/ad774369fd06df677b2be8fd13abdb1d3b80a62a.pdf", "code": "https://github.com/babhrujoshi/PLUGIn", "thumbnail": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\njoshi2021plugin,\ntitle={{PLUGI}n: A simple algorithm for inverting generative models with recovery guarantees},\nauthor={Babhru Joshi and Xiaowei Li and Yaniv Plan and Ozgur Yilmaz},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=rxAS126OC-A}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492725155, "odate": 1636492725155, "details": {"replyCount": 8}}, {"id": "rC3zu-OqnII", "original": "W1ApFpo5odT", "number": 6495, "cdate": 1621630045573, "ddate": null, "tcdate": 1621630045573, "tmdate": 1683307669245, "tddate": null, "forum": "rC3zu-OqnII", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "A Closer Look at the Worst-case Behavior of Multi-armed Bandit Algorithms", "authorids": ["~Anand_Kalvit1", "~assaf_zeevi2"], "authors": ["Anand Kalvit", "assaf zeevi"], "keywords": ["multi-armed bandits", "learning algorithms", "UCB", "Thompson Sampling", "minimax regret", "diffusion approximation", "distribution of arm-pulls"], "TL;DR": "This paper provides the first complete characterization of the arm-sampling distributions under UCB as a function of the problem hardness.", "abstract": "One of the key drivers of complexity in the classical (stochastic) multi-armed bandit (MAB) problem is the difference between mean rewards in the top two arms, also known as the instance gap. The celebrated Upper Confidence Bound (UCB) policy is among the simplest optimism-based MAB algorithms that naturally adapts to this gap: for a horizon of play n, it achieves optimal O(log n) regret in instances with \"large\" gaps, and a near-optimal O(\\sqrt{n log n}) minimax regret when the gap can be arbitrarily \"small.\" This paper provides new results on the arm-sampling behavior of UCB, leading to several important insights. Among these, it is shown that arm-sampling rates under UCB are asymptotically deterministic, regardless of the problem complexity. This discovery facilitates new sharp asymptotics and a novel alternative proof for the O(\\sqrt{n log n}) minimax regret of UCB. Furthermore, the paper also provides the first complete process-level characterization of the MAB problem in the conventional diffusion scaling. Among other things, the \"small\" gap worst-case lens adopted in this paper also reveals profound distinctions between the behavior of UCB and Thompson Sampling, such as an \"incomplete learning\" phenomenon characteristic of the latter.", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "kalvit|a_closer_look_at_the_worstcase_behavior_of_multiarmed_bandit_algorithms", "pdf": "/pdf/d8264eb14a1ae548eb307db35fa6ef84a283f5ec.pdf", "checklist": "", "supplementary_material": "/attachment/cdac3358b242b4bba6f1ff9c29cb5c518640319d.pdf", "thumbnail": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nkalvit2021a,\ntitle={A Closer Look at the Worst-case Behavior of Multi-armed Bandit Algorithms},\nauthor={Anand Kalvit and assaf zeevi},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=rC3zu-OqnII}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492750773, "odate": 1636492750773, "details": {"replyCount": 9}}, {"id": "lZJHxMxUhV_", "original": "ICnSxbZY-oK", "number": 6387, "cdate": 1621630039026, "ddate": null, "tcdate": 1621630039026, "tmdate": 1697937504915, "tddate": null, "forum": "lZJHxMxUhV_", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Techniques for Symbol Grounding with SATNet", "authorids": ["~Sever_Topan1", "~David_Rolnick1", "~Xujie_Si1"], "authors": ["Sever Topan", "David Rolnick", "Xujie Si"], "keywords": ["Symbol Grounding", "MAXSAT", "Neurosymbolic Reasoning", "Self-Supervision", "Visual Reasoning", "SATNet"], "TL;DR": "We describe a methodology that enables SATNet architectures to solve the Symbol Grounding Problem for visual reasoning tasks.", "abstract": "Many experts argue that the future of artificial intelligence is limited by the field\u2019s ability to integrate symbolic logical reasoning into deep learning architectures. The recently proposed differentiable MAXSAT solver, SATNet, was a breakthrough in its capacity to integrate with a traditional neural network and solve visual reasoning problems. For instance, it can learn the rules of Sudoku purely from image examples. Despite its success, SATNet was shown to succumb to a key challenge in neurosymbolic systems known as the Symbol Grounding Problem: the inability to map visual inputs to symbolic variables without explicit supervision (\"label leakage\"). In this work, we present a self-supervised pre-training pipeline that enables SATNet to overcome this limitation, thus broadening the class of problems that SATNet architectures can solve to include datasets where no intermediary labels are available at all. We demonstrate that our method allows SATNet to attain full accuracy even with a harder problem setup that prevents any label leakage. We additionally introduce a proofreading method that further improves the performance of SATNet architectures, beating the state-of-the-art on Visual Sudoku. ", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "topan|techniques_for_symbol_grounding_with_satnet", "pdf": "/pdf/784a125496d51f396e7911f830a52b9206830469.pdf", "supplementary_material": "/attachment/a376733cee68e1fd6e857e5309f167efe1402184.pdf", "checklist": "", "code": "https://github.com/SeverTopan/SATNet", "thumbnail": "", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 3 code implementations](https://www.catalyzex.com/paper/arxiv:2106.11072/code)", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\ntopan2021techniques,\ntitle={Techniques for Symbol Grounding with {SATN}et},\nauthor={Sever Topan and David Rolnick and Xujie Si},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=lZJHxMxUhV_}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492721357, "odate": 1636492721357, "details": {"replyCount": 17}}, {"id": "fOaks7LY5R", "original": "bTfVN5cYno2", "number": 6366, "cdate": 1621630037824, "ddate": null, "tcdate": 1621630037824, "tmdate": 1683307666074, "tddate": null, "forum": "fOaks7LY5R", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Differentially Private Model Personalization", "authorids": ["~Prateek_Jain1", "~J_Keith_Rush1", "~Adam_Smith1", "~Shuang_Song3", "~Abhradeep_Guha_Thakurta1"], "authors": ["Prateek Jain", "J Keith Rush", "Adam Smith", "Shuang Song", "Abhradeep Guha Thakurta"], "keywords": ["Differential Privacy", "Model Personalization", "Alternating Minimization", "Learning Theory"], "abstract": "We study personalization of supervised learning with user-level differential privacy. Consider a setting with many users, each of whom has a training data set drawn from their own distribution $P_i$. Assuming some shared structure among the problems $P_i$, can users collectively learn the shared structure---and solve their tasks better than they could individually---while preserving the privacy of their data? We formulate this question using joint, user-level differential privacy---that is, we control what is leaked about each user's entire data set. \nWe provide algorithms that exploit popular non-private approaches in this domain like the Almost-No-Inner-Loop (ANIL) method, and give strong user-level privacy guarantees for our general approach. When the problems $P_i$ are linear regression problems with each user's regression vector lying in a common, unknown low-dimensional subspace, we show that our efficient algorithms satisfy nearly optimal estimation error guarantees. We also establish a general, information-theoretic upper bound via an exponential mechanism-based algorithm.", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "jain|differentially_private_model_personalization", "pdf": "/pdf/646e544be3251b74e1f838481408c1f0e736a3ae.pdf", "checklist": "", "supplementary_material": "/attachment/7c31be3815b23824d556c1fbe32d7988d7c29251.pdf", "TL;DR": "In this paper, we formulate a model for reasoning rigorously about the loss to privacy incurred by sharing information for model personalization.", "thumbnail": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\njain2021differentially,\ntitle={Differentially Private Model Personalization},\nauthor={Prateek Jain and J Keith Rush and Adam Smith and Shuang Song and Abhradeep Guha Thakurta},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=fOaks7LY5R}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492719737, "odate": 1636492719737, "details": {"replyCount": 12}}, {"id": "B9yXBaZDUxp", "original": "kGbMX8DRt4w", "number": 6324, "cdate": 1621630035178, "ddate": null, "tcdate": 1621630035178, "tmdate": 1697937507307, "tddate": null, "forum": "B9yXBaZDUxp", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Bootstrap Your Object Detector via Mixed Training", "authorids": ["~Mengde_Xu1", "~Zheng_Zhang4", "~Fangyun_Wei1", "~Yutong_Lin1", "~Yue_Cao2", "~Stephen_Lin1", "~Han_Hu1", "~Xiang_Bai1"], "authors": ["Mengde Xu", "Zheng Zhang", "Fangyun Wei", "Yutong Lin", "Yue Cao", "Stephen Lin", "Han Hu", "Xiang Bai"], "keywords": ["object detection"], "abstract": "We introduce MixTraining, a new training paradigm for object detection that can improve the performance of existing detectors for free. MixTraining enhances data augmentation by utilizing augmentations of different strengths while excluding the strong augmentations of certain training samples that may be detrimental to training. In addition, it addresses localization noise and missing labels in human annotations by incorporating pseudo boxes that can compensate for these errors. Both of these MixTraining capabilities are made possible through bootstrapping on the detector, which can be used to predict the difficulty of training on a strong augmentation, as well as to generate reliable pseudo boxes thanks to the robustness of neural networks to labeling error. MixTraining is found to bring consistent improvements across various detectors on the COCO dataset. In particular, the performance of Faster R-CNN~\\cite{ren2015faster} with a ResNet-50~\\cite{he2016deep} backbone is improved from 41.7 mAP to 44.0 mAP, and the accuracy of Cascade-RCNN~\\cite{cai2018cascade} with a Swin-Small~\\cite{liu2021swin} backbone is raised from 50.9 mAP to 52.8 mAP.\n", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "xu|bootstrap_your_object_detector_via_mixed_training", "TL;DR": "We introduce a new training paradigm for object detection named MixTraining for improving the detection performance for free.", "pdf": "/pdf/d403c9b1e53be9c3acc7e5640c5f15d24c4f912a.pdf", "checklist": "", "thumbnail": "", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2111.03056/code)", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nxu2021bootstrap,\ntitle={Bootstrap Your Object Detector via Mixed Training},\nauthor={Mengde Xu and Zheng Zhang and Fangyun Wei and Yutong Lin and Yue Cao and Stephen Lin and Han Hu and Xiang Bai},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=B9yXBaZDUxp}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492730336, "odate": 1636492730336, "details": {"replyCount": 12}}, {"id": "Bl0GlLmNGLV", "original": "4K8VOFAzZx2", "number": 6190, "cdate": 1621630027026, "ddate": null, "tcdate": 1621630027026, "tmdate": 1683307662023, "tddate": null, "forum": "Bl0GlLmNGLV", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Newton-LESS: Sparsification without Trade-offs for the Sketched Newton Update", "authorids": ["~Michal_Derezinski1", "~Jonathan_Lacotte1", "~Mert_Pilanci3", "~Michael_W._Mahoney1"], "authors": ["Michal Derezinski", "Jonathan Lacotte", "Mert Pilanci", "Michael W. Mahoney"], "keywords": ["Second-order methods", "Newton Sketch", "Optimization", "Random Matrix Theory", "Least Squares"], "TL;DR": "The Gaussian sketch can be drastically sparsified without affecting the convergence of Newton Sketch.", "abstract": "In second-order optimization, a potential bottleneck can be computing the Hessian matrix of the optimized function at every iteration. Randomized sketching has emerged as a powerful technique for constructing estimates of the Hessian which can be used to perform approximate Newton steps. This involves multiplication by a random sketching matrix, which introduces a trade-off between the computational cost of sketching and the convergence rate of the optimization. A theoretically desirable but practically much too expensive choice is to use a dense Gaussian sketching matrix, which produces unbiased estimates of the exact Newton step and offers strong problem-independent convergence guarantees. We show that the Gaussian matrix can be drastically sparsified, substantially reducing the computational cost, without affecting its convergence properties in any way. This approach, called Newton-LESS, is based on a recently introduced sketching technique: LEverage Score Sparsified (LESS) embeddings. We prove that Newton-LESS enjoys nearly the same problem-independent local convergence rate as Gaussian embeddings for a large class of functions. In particular, this leads to a new state-of-the-art convergence result for an iterative least squares solver. Finally, we substantially extend LESS embeddings to include uniformly sparsified random sign matrices which can be implemented efficiently and perform well in numerical experiments. ", "submission_history": "", "checklist": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "derezinski|newtonless_sparsification_without_tradeoffs_for_the_sketched_newton_update", "pdf": "/pdf/1ab5e137cd328b67fe52e5e1afa6f40fc3a8bd3d.pdf", "supplementary_material": "/attachment/abd94632a3c6e8be62611796634bcdb4348ded11.pdf", "thumbnail": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nderezinski2021newtonless,\ntitle={Newton-{LESS}: Sparsification without Trade-offs for the Sketched Newton Update},\nauthor={Michal Derezinski and Jonathan Lacotte and Mert Pilanci and Michael W. Mahoney},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=Bl0GlLmNGLV}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492735513, "odate": 1636492735513, "details": {"replyCount": 12}}, {"id": "68B1ezcffDc", "original": "31pTvnZhI-", "number": 6184, "cdate": 1621630026673, "ddate": null, "tcdate": 1621630026673, "tmdate": 1697937513224, "tddate": null, "forum": "68B1ezcffDc", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Subgroup Generalization and Fairness of Graph Neural Networks", "authorids": ["~Jiaqi_Ma1", "~Junwei_Deng1", "~Qiaozhu_Mei1"], "authors": ["Jiaqi Ma", "Junwei Deng", "Qiaozhu Mei"], "keywords": ["Graph Neural Networks", "Generalization", "Fairness", "PAC-Bayesian Analysis"], "abstract": "Despite enormous successful applications of graph neural networks (GNNs), theoretical understanding of their generalization ability, especially for node-level tasks where data are not independent and identically-distributed (IID), has been sparse. The theoretical investigation of the generalization performance is beneficial for understanding fundamental issues (such as fairness) of GNN models and designing better learning methods. In this paper, we present a novel PAC-Bayesian analysis for GNNs under a non-IID semi-supervised learning setup. Moreover, we analyze the generalization performances on different subgroups of unlabeled nodes, which allows us to further study an accuracy-(dis)parity-style (un)fairness of GNNs from a theoretical perspective. Under reasonable assumptions, we demonstrate that the distance between a test subgroup and the training set can be a key factor affecting the GNN performance on that subgroup, which calls special attention to the training node selection for fair learning. Experiments across multiple GNN models and datasets support our theoretical results.", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "ma|subgroup_generalization_and_fairness_of_graph_neural_networks", "TL;DR": "We present a novel PAC-Bayesian analysis for the generalization ability of graph neural networks on non-IID node-level tasks, which has implications on the fairness of graph neural networks.", "pdf": "/pdf/72d0a324285c66c804b572802303d08a6378174e.pdf", "checklist": "", "supplementary_material": "/attachment/208ffe60a617e034b4205050b96ed34e153e271c.pdf", "code": "https://github.com/TheaperDeng/GNN-Generalization-Fairness", "thumbnail": "", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2106.15535/code)", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nma2021subgroup,\ntitle={Subgroup Generalization and Fairness of Graph Neural Networks},\nauthor={Jiaqi Ma and Junwei Deng and Qiaozhu Mei},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=68B1ezcffDc}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492666950, "odate": 1636492666950, "details": {"replyCount": 13}}, {"id": "vLPqnPf9k0", "original": "cnFPN3ySxAE", "number": 6139, "cdate": 1621630024007, "ddate": null, "tcdate": 1621630024007, "tmdate": 1697937515094, "tddate": null, "forum": "vLPqnPf9k0", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "How Well do Feature Visualizations Support Causal Understanding of CNN Activations?", "authorids": ["~Roland_Simon_Zimmermann1", "~Judy_Borowski1", "~Robert_Geirhos1", "~Matthias_Bethge1", "~Thomas_S._A._Wallis1", "~Wieland_Brendel1"], "authors": ["Roland Simon Zimmermann", "Judy Borowski", "Robert Geirhos", "Matthias Bethge", "Thomas S. A. Wallis", "Wieland Brendel"], "keywords": ["evaluation of interpretability", "feature visualization", "activation maximization", "human psychophysics", "understanding CNNs", "explanation method", "counterfactual", "causal understanding"], "abstract": "A precise understanding of why units in an artificial network respond to certain stimuli would constitute a big step towards explainable artificial intelligence. One widely used approach towards this goal is to visualize unit responses via activation maximization. These feature visualizations are purported to provide humans with precise information about the image features that cause a unit to be activated - an advantage over other alternatives like strongly activating dataset samples. If humans indeed gain causal insight from visualizations, this should enable them to predict the effect of an intervention, such as how occluding a certain patch of the image (say, a dog's head) changes a unit's activation. Here, we test this hypothesis by asking humans to decide which of two square occlusions causes a larger change to a unit's activation.\nBoth a large-scale crowdsourced experiment and measurements with experts show that on average the extremely activating feature visualizations by Olah et al. (2017) indeed help humans on this task ($68 \\pm 4$% accuracy; baseline performance without any visualizations is $60 \\pm 3$%). However, they do not provide any substantial advantage over other visualizations (such as e.g. dataset samples), which yield similar performance ($66\\pm3$% to $67 \\pm3$% accuracy). \nTaken together, we propose an objective psychophysical task to quantify the benefit of unit-level interpretability methods for humans, and find no evidence that a widely-used feature visualization method provides humans with better \"causal understanding\" of unit activations than simple alternative visualizations.", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "zimmermann|how_well_do_feature_visualizations_support_causal_understanding_of_cnn_activations", "TL;DR": "Using psychophysical experiments, we show that state-of-the-art synthetic feature visualizations do not support causal understanding much better than no visualizations, and only similarly well as other visualizations like natural dataset samples.", "pdf": "/pdf/2fe99e622a45a2219709a5e30bef4bf08cc780d3.pdf", "checklist": "", "supplementary_material": "/attachment/b27ca814ec7661a70fb8276a45b173f311cc98ed.zip", "code": "https://github.com/brendel-group/causal-understanding-via-visualizations", "thumbnail": "", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 2 code implementations](https://www.catalyzex.com/paper/arxiv:2106.12447/code)", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nzimmermann2021how,\ntitle={How Well do Feature Visualizations Support Causal Understanding of {CNN} Activations?},\nauthor={Roland Simon Zimmermann and Judy Borowski and Robert Geirhos and Matthias Bethge and Thomas S. A. Wallis and Wieland Brendel},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=vLPqnPf9k0}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492763967, "odate": 1636492763967, "details": {"replyCount": 13}}, {"id": "CU8qQMhB3dh", "original": "s7gHmVNxgs-", "number": 6095, "cdate": 1621630021452, "ddate": null, "tcdate": 1621630021452, "tmdate": 1683307659843, "tddate": null, "forum": "CU8qQMhB3dh", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Beyond Value-Function Gaps: Improved Instance-Dependent Regret Bounds for Episodic Reinforcement Learning", "authorids": ["~Christoph_Dann1", "~Teodor_Vanislavov_Marinov1", "~Mehryar_Mohri2", "~Julian_Zimmert1"], "authors": ["Christoph Dann", "Teodor Vanislavov Marinov", "Mehryar Mohri", "Julian Zimmert"], "keywords": ["reinforcement learning", "MDP", "rl", "instance-dependent regret bounds", "theory", "regret", "gap-dependent"], "TL;DR": "We provide improved gap-dependent regret bounds for reinforcement learning in finite episodic Markov decision processes.", "abstract": "We provide improved gap-dependent regret bounds for reinforcement learning in finite episodic Markov decision processes. Compared to prior work, our bounds depend on alternative definitions of gaps. These definitions are based on the insight that, in order to achieve a favorable regret, an algorithm does not need to learn how to behave optimally in states that are not reached by an optimal policy. We prove tighter upper regret bounds for optimistic algorithms and accompany them with new information-theoretic lower bounds for a large class of MDPs. Our results show that optimistic algorithms can not achieve the information-theoretic lower bounds even in deterministic MDPs unless there is a unique optimal policy.\n", "submission_history": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "checklist": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "dann|beyond_valuefunction_gaps_improved_instancedependent_regret_bounds_for_episodic_reinforcement_learning", "pdf": "/pdf/577f9528854d8acf450ac1b3d8b357b7c96e0f2f.pdf", "supplementary_material": "/attachment/9222744719b817e61e438873c4d5c3fb05296aa0.pdf", "thumbnail": "", "_bibtex": "@inproceedings{\ndann2021beyond,\ntitle={Beyond Value-Function Gaps: Improved Instance-Dependent Regret Bounds for Episodic Reinforcement Learning},\nauthor={Christoph Dann and Teodor Vanislavov Marinov and Mehryar Mohri and Julian Zimmert},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=CU8qQMhB3dh}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492743198, "odate": 1636492743198, "details": {"replyCount": 10}}, {"id": "9BnCwiXB0ty", "original": "EylXU20P85S", "number": 6080, "cdate": 1621630020506, "ddate": null, "tcdate": 1621630020506, "tmdate": 1683307659698, "tddate": null, "forum": "9BnCwiXB0ty", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Diffusion Schr\u00f6dinger Bridge with Applications to Score-Based Generative Modeling", "authorids": ["~Valentin_De_Bortoli1", "~James_Thornton1", "~Jeremy_Heng1", "~Arnaud_Doucet2"], "authors": ["Valentin De Bortoli", "James Thornton", "Jeremy Heng", "Arnaud Doucet"], "keywords": ["Theory", "Optimal Transport", "Diffusion", "Schrodinger Bridge", "Score matching"], "TL;DR": "A novel method for the Schr\u00f6dinger Bridge problem with applications in score-based generative modeling.", "abstract": "Progressively applying Gaussian noise transforms complex data distributions to approximately Gaussian. Reversing this dynamic defines a generative model. When the forward noising process is given by a Stochastic Differential Equation (SDE), Song et al (2021) demonstrate how the time inhomogeneous drift of the associated reverse-time SDE may be estimated using score-matching. A limitation of this approach is that the forward-time SDE must be run for a sufficiently long time for the final distribution to be approximately Gaussian. In contrast, solving the Schr\u00f6dinger Bridge (SB) problem, i.e. an entropy-regularized optimal transport problem on path spaces, yields diffusions which generate samples from the data distribution in finite time. We present Diffusion SB (DSB), an original approximation of the Iterative Proportional Fitting (IPF) procedure to solve the SB problem, and provide theoretical analysis along with generative modeling experiments. The first DSB iteration recovers the methodology proposed by Song et al. (2021), with the flexibility of using shorter time intervals, as subsequent DSB iterations reduce the discrepancy between the final-time marginal of the forward (resp. backward) SDE with respect to the prior (resp. data) distribution. Beyond generative modeling, DSB offers a widely applicable computational optimal transport tool as the continuous state-space analogue of the popular Sinkhorn algorithm (Cuturi, 2013).", "submission_history": "", "checklist": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "bortoli|diffusion_schr\u00f6dinger_bridge_with_applications_to_scorebased_generative_modeling", "pdf": "/pdf/954e321b6ae719eacbc65b50bb09cd26f21cf92b.pdf", "supplementary_material": "/attachment/8d9c6f11fb7cf8826cb89ecdc10a64e8ade960e1.pdf", "code": "https://github.com/JTT94/diffusion_schrodinger_bridge", "thumbnail": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nbortoli2021diffusion,\ntitle={Diffusion Schr\\\"odinger Bridge with Applications to Score-Based Generative Modeling},\nauthor={Valentin De Bortoli and James Thornton and Jeremy Heng and Arnaud Doucet},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=9BnCwiXB0ty}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492669072, "odate": 1636492669072, "details": {"replyCount": 11}}, {"id": "ST1P270dwOE", "original": "7_rEQmvgcM7", "number": 5975, "cdate": 1621630014214, "ddate": null, "tcdate": 1621630014214, "tmdate": 1683307656781, "tddate": null, "forum": "ST1P270dwOE", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "On the Representation of Solutions to Elliptic PDEs in Barron Spaces", "authorids": ["~Ziang_Chen1", "~Jianfeng_Lu1", "~Yulong_Lu1"], "authors": ["Ziang Chen", "Jianfeng Lu", "Yulong Lu"], "keywords": ["partial differential equations", "neural networks", "Barron norms", "high dimension", "approximation"], "abstract": "Numerical solutions to high-dimensional partial differential equations (PDEs) based on neural networks have seen exciting developments. This paper derives complexity estimates of the solutions of $d$-dimensional second-order elliptic PDEs in the Barron space, that is a set of functions admitting the integral of certain parametric ridge function against a probability measure on the parameters. We prove under some appropriate assumptions that if the coefficients and the source term of the elliptic PDE lie in Barron spaces, then the solution of the PDE is $\\epsilon$-close with respect to the $H^1$ norm to a Barron function. Moreover, we prove dimension-explicit bounds for the Barron norm of this approximate solution, depending at most polynomially on the dimension $d$ of the PDE. As a direct consequence of the complexity estimates, the solution of the PDE can be approximated on any bounded domain by a two-layer neural network with respect to the $H^1$ norm with a dimension-explicit convergence rate.", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "chen|on_the_representation_of_solutions_to_elliptic_pdes_in_barron_spaces", "pdf": "/pdf/de33619d61a758155365c03f86e4badd436b9873.pdf", "checklist": "", "supplementary_material": "/attachment/6b144af88fbe40db49bba94a8e2f6cf8ac5f27ad.pdf", "thumbnail": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nchen2021on,\ntitle={On the Representation of Solutions to Elliptic {PDE}s in Barron Spaces},\nauthor={Ziang Chen and Jianfeng Lu and Yulong Lu},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=ST1P270dwOE}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492742017, "odate": 1636492742017, "details": {"replyCount": 12}}, {"id": "NtivXxYNhjc", "original": "V-76I47ee4", "number": 5963, "cdate": 1621630013490, "ddate": null, "tcdate": 1621630013490, "tmdate": 1697937521880, "tddate": null, "forum": "NtivXxYNhjc", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Variational Bayesian Optimistic Sampling", "authorids": ["~Brendan_O'Donoghue1", "~Tor_Lattimore1"], "authors": ["Brendan O'Donoghue", "Tor Lattimore"], "keywords": ["Bayes", "Variational inference", "Bandits", "Decision problems", "Online learning"], "TL;DR": "A variational Bayesian approach to online learning, with provable regret bounds", "abstract": "We consider online sequential decision problems where an agent must balance  exploration and exploitation. We derive a set of Bayesian `optimistic' policies  which, in the stochastic multi-armed bandit case, includes the Thompson sampling  policy. We provide a new analysis showing that any algorithm producing policies in the optimistic set enjoys $\\tilde O(\\sqrt{AT})$ Bayesian regret for a problem with $A$ actions after $T$ rounds. We extend the regret analysis for optimistic policies to bilinear saddle-point problems which include zero-sum matrix games and constrained bandits as special cases. In this case we show that Thompson sampling can produce policies outside of the optimistic set and suffer linear regret in some instances. Finding a policy inside the optimistic set amounts to solving a convex optimization problem and we call the resulting algorithm `variational Bayesian optimistic sampling' (VBOS). The procedure works for any posteriors, \\ie, it does not require the posterior to have any special properties, such as log-concavity, unimodality, or smoothness. The variational view of the problem has many useful properties, including the ability to tune the exploration-exploitation tradeoff, add regularization, incorporate constraints, and linearly parameterize the policy.", "pdf": "/pdf/01c97b8a67710e6157fac50027ff722a4d02c107.pdf", "supplementary_material": "/attachment/80c2a2e99995359236fc66b37791078263ac3ccf.pdf", "submission_history": "", "checklist": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "odonoghue|variational_bayesian_optimistic_sampling", "thumbnail": "", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2110.15688/code)", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\no'donoghue2021variational,\ntitle={Variational Bayesian Optimistic Sampling},\nauthor={Brendan O'Donoghue and Tor Lattimore},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=NtivXxYNhjc}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492674079, "odate": 1636492674079, "details": {"replyCount": 16}}, {"id": "CLCVcl1rSPP", "original": "J7movQnDKv3", "number": 5919, "cdate": 1621630010793, "ddate": null, "tcdate": 1621630010793, "tmdate": 1683307654999, "tddate": null, "forum": "CLCVcl1rSPP", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "RL for Latent MDPs: Regret Guarantees and a Lower Bound", "authorids": ["~Jeongyeol_Kwon1", "~Yonathan_Efroni2", "~Constantine_Caramanis1", "~Shie_Mannor2"], "authors": ["Jeongyeol Kwon", "Yonathan Efroni", "Constantine Caramanis", "Shie Mannor"], "keywords": ["Reinforcement Learning", "Partially Observable", "Latent Variable", "Lower Bound", "Upper Confidence Bound", "Expectation-Maximization", "Predictive State Representation"], "TL;DR": "Fundamental Limits and Algorithms for Episodic Reinforcement Learning in MDPs with a Latent Context", "abstract": "In this work, we consider the regret minimization problem for reinforcement learning in latent Markov Decision Processes (LMDP). In an LMDP, an MDP is randomly drawn from a set of $M$ possible MDPs at the beginning of the interaction, but the identity of the chosen MDP is not revealed to the agent. We first show that a general instance of LMDPs requires at least $\\Omega((SA)^M)$ episodes to even approximate the optimal policy. Then, we consider sufficient assumptions under which learning good policies requires polynomial number of episodes. We show that the key link is a notion of separation between the MDP system dynamics. With sufficient separation, we provide an efficient algorithm with local guarantee, {\\it i.e.,} providing a sublinear regret guarantee when we are given a good initialization. Finally, if we are given standard statistical sufficiency assumptions common in the Predictive State Representation (PSR) literature (e.g., \\cite{boots2011online}) and a reachability assumption, we show that the need for initialization can be removed. ", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "kwon|rl_for_latent_mdps_regret_guarantees_and_a_lower_bound", "pdf": "/pdf/d14d2141c62ea7e492cc728b218f3c884cf28c19.pdf", "supplementary_material": "/attachment/f8bd41c72447a618ccbdf8cdad2c2ba80cdcb4bc.pdf", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "checklist": "", "thumbnail": "", "_bibtex": "@inproceedings{\nkwon2021rl,\ntitle={{RL} for Latent {MDP}s: Regret Guarantees and a Lower Bound},\nauthor={Jeongyeol Kwon and Yonathan Efroni and Constantine Caramanis and Shie Mannor},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=CLCVcl1rSPP}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492697004, "odate": 1636492697004, "details": {"replyCount": 11}}, {"id": "cc_AXK6rWPJ", "original": "9hePQXkO8G", "number": 5903, "cdate": 1621630010010, "ddate": null, "tcdate": 1621630010010, "tmdate": 1683307654445, "tddate": null, "forum": "cc_AXK6rWPJ", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Stochastic Shortest Path: Minimax, Parameter-Free and Towards Horizon-Free Regret", "authorids": ["~Jean_Tarbouriech1", "~Runlong_Zhou1", "~Simon_Shaolei_Du1", "~Matteo_Pirotta1", "~Michal_Valko1", "~Alessandro_Lazaric2"], "authors": ["Jean Tarbouriech", "Runlong Zhou", "Simon Shaolei Du", "Matteo Pirotta", "Michal Valko", "Alessandro Lazaric"], "keywords": ["regret minimization", "stochastic shortest path", "reinforcement learning theory", "minimax optimal"], "abstract": "We study the problem of learning in the stochastic shortest path (SSP) setting, where an agent seeks to minimize the expected cost accumulated before reaching a goal state. We design a novel model-based algorithm EB-SSP that carefully skews the empirical transitions and perturbs the empirical costs with an exploration bonus to induce an optimistic SSP problem whose associated value iteration scheme is guaranteed to converge. We prove that EB-SSP achieves the minimax regret rate $\\widetilde{O}(B_{\\star} \\sqrt{S A K})$, where $K$ is the number of episodes, $S$ is the number of states, $A$ is the number of actions and $B_{\\star}$ bounds the expected cumulative cost of the optimal policy from any state, thus closing the gap with the lower bound. Interestingly, EB-SSP obtains this result while being parameter-free, i.e., it does not require any prior knowledge of $B_{\\star}$, nor of $T_{\\star}$, which bounds the expected time-to-goal of the optimal policy from any state. Furthermore, we illustrate various cases (e.g., positive costs, or general costs when an order-accurate estimate of $T_{\\star}$ is available) where the regret only contains a logarithmic dependence on $T_{\\star}$, thus yielding the first (nearly) horizon-free regret bound beyond the finite-horizon MDP setting.", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "tarbouriech|stochastic_shortest_path_minimax_parameterfree_and_towards_horizonfree_regret", "TL;DR": "We derive a new learning algorithm for stochastic shortest path, whose regret guarantee is 1) simultaneously (nearly) minimax and parameter-free, and 2) (nearly) horizon-free in various cases.", "pdf": "/pdf/31e4c9cf061a42c94a19bb90d9ac4cef9b92296f.pdf", "checklist": "", "supplementary_material": "/attachment/b1c2663d7509f52148a6a31db5b488cf36bfcf06.pdf", "thumbnail": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\ntarbouriech2021stochastic,\ntitle={Stochastic Shortest Path: Minimax, Parameter-Free and Towards Horizon-Free Regret},\nauthor={Jean Tarbouriech and Runlong Zhou and Simon Shaolei Du and Matteo Pirotta and Michal Valko and Alessandro Lazaric},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=cc_AXK6rWPJ}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492724778, "odate": 1636492724778, "details": {"replyCount": 9}}, {"id": "IaM7U4J-w3c", "original": "4XVmMMkq9DV", "number": 5867, "cdate": 1621630007826, "ddate": null, "tcdate": 1621630007826, "tmdate": 1697937528282, "tddate": null, "forum": "IaM7U4J-w3c", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Learning Large Neighborhood Search Policy for Integer Programming", "authorids": ["~Yaoxin_Wu2", "~Wen_Song1", "~Zhiguang_Cao1", "~Jie_Zhang9"], "authors": ["Yaoxin Wu", "Wen Song", "Zhiguang Cao", "Jie Zhang"], "keywords": ["Deep Reinforcement Learning", "Integer Programming", "Large Neighborhood Search"], "abstract": "We propose a deep reinforcement learning (RL) method to learn large neighborhood search (LNS) policy for integer programming (IP). The RL policy is trained as the destroy operator to select a subset of variables at each step, which is reoptimized by an IP solver as the repair operator. However, the combinatorial number of variable subsets prevents direct application of typical RL algorithms. To tackle this challenge, we represent all subsets by factorizing them into binary decisions on each variable. We then design a neural network to learn policies for each variable in parallel, trained by a customized actor-critic algorithm. We evaluate the proposed method on four representative IP problems. Results show that it can find better solutions than SCIP in much less time, and significantly outperform other LNS baselines with the same runtime. Moreover, these advantages notably persist when the policies generalize to larger problems. Further experiments with Gurobi also reveal that our method can outperform this state-of-the-art commercial solver within the same time limit.", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "wu|learning_large_neighborhood_search_policy_for_integer_programming", "TL;DR": "This paper manages to learn effective LNS policies for solving integer programs, by tackling the issue of large action space in DRL. ", "pdf": "/pdf/2482520bb13586ad0ef726588b194868b9fed2f7.pdf", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "checklist": "", "supplementary_material": "/attachment/b92034496b670935a7571d25e7360882d5521037.pdf", "thumbnail": "", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2111.03466/code)", "_bibtex": "@inproceedings{\nwu2021learning,\ntitle={Learning Large Neighborhood Search Policy for Integer Programming},\nauthor={Yaoxin Wu and Wen Song and Zhiguang Cao and Jie Zhang},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=IaM7U4J-w3c}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492684963, "odate": 1636492684963, "details": {"replyCount": 12}}, {"id": "iFadi3f5V5I", "original": "rCkNxqaSgsW", "number": 5819, "cdate": 1621630005000, "ddate": null, "tcdate": 1621630005000, "tmdate": 1683307651990, "tddate": null, "forum": "iFadi3f5V5I", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Statistical Regeneration Guarantees of the Wasserstein Autoencoder with Latent Space Consistency", "authorids": ["~Anish_Chakrabarty1", "~Swagatam_Das2"], "authors": ["Anish Chakrabarty", "Swagatam Das"], "keywords": ["Autoencoders", "Optimal Transport", "VC dimension", "Deep Generative Models"], "abstract": "The introduction of Variational Autoencoders (VAE) has been marked as a breakthrough in the history of representation learning models. Besides having several accolades of its own, VAE has successfully flagged off a series of inventions in the form of its immediate successors. Wasserstein Autoencoder (WAE), being an heir to that realm carries with it all of the goodness and heightened generative promises, matching even the generative adversarial networks (GANs). Needless to say, recent years have witnessed a remarkable resurgence in statistical analyses of the GANs. Similar examinations for Autoencoders however, despite their diverse applicability and notable empirical performance, remain largely absent. To close this gap, in this paper, we investigate the statistical properties of WAE. Firstly, we provide statistical guarantees that WAE achieves the target distribution in the latent space, utilizing the Vapnik\u2013Chervonenkis (VC) theory. The main result, consequently ensures the regeneration of the input distribution, harnessing the potential offered by Optimal Transport of measures under the Wasserstein metric. This study, in turn, hints at the class of distributions WAE can reconstruct after suffering a compression in the form of a latent law. ", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "chakrabarty|statistical_regeneration_guarantees_of_the_wasserstein_autoencoder_with_latent_space_consistency", "pdf": "/pdf/b65fdf1bb468c66d2d2fe05bfc89e9aa5dcbd561.pdf", "checklist": "", "supplementary_material": "/attachment/a668c4c24f8950f3961597eb622c8c25fa4b5d34.pdf", "thumbnail": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nchakrabarty2021statistical,\ntitle={Statistical Regeneration Guarantees of the Wasserstein Autoencoder with Latent Space Consistency},\nauthor={Anish Chakrabarty and Swagatam Das},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=iFadi3f5V5I}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492726620, "odate": 1636492726620, "details": {"replyCount": 11}}, {"id": "uSQQH7Fj5U", "original": "8vq3Yd1oMpC", "number": 5800, "cdate": 1621630003873, "ddate": null, "tcdate": 1621630003873, "tmdate": 1683307651479, "tddate": null, "forum": "uSQQH7Fj5U", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Deep learning is adaptive to intrinsic dimensionality of model smoothness in anisotropic Besov space", "authorids": ["~Taiji_Suzuki1", "~Atsushi_Nitanda1"], "authors": ["Taiji Suzuki", "Atsushi Nitanda"], "keywords": ["deep learning", "Besov space", "minimax optimality"], "abstract": "Deep learning has exhibited superior performance for various tasks, especially for high-dimensional datasets, such as images. \nTo understand this property, we investigate the approximation and estimation ability of deep learning on {\\it anisotropic Besov spaces}.\nThe anisotropic Besov space is characterized by direction-dependent smoothness and includes several function classes that have been investigated thus far.\nWe demonstrate that the approximation error and estimation error of deep learning only depend on the average value of the smoothness parameters in all directions. Consequently, the curse of dimensionality can be avoided if the smoothness of the target function is highly anisotropic.\nUnlike existing studies, our analysis does not require a low-dimensional structure of the input data.\nWe also investigate the minimax optimality of deep learning and compare its performance with that of the kernel method (more generally, linear estimators).\nThe results show that deep learning has better dependence on the input dimensionality if the target function possesses anisotropic smoothness, and it achieves an adaptive rate for functions with spatially inhomogeneous smoothness.\n", "submission_history": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "suzuki|deep_learning_is_adaptive_to_intrinsic_dimensionality_of_model_smoothness_in_anisotropic_besov_space", "pdf": "/pdf/92293075f71098b21186f478eaa404c549d885cb.pdf", "supplementary_material": "/attachment/4a62d9d993cf094a55b73605d43efe021e96a78e.pdf", "thumbnail": "", "checklist": "", "_bibtex": "@inproceedings{\nsuzuki2021deep,\ntitle={Deep learning is adaptive to intrinsic dimensionality of model smoothness in anisotropic Besov space},\nauthor={Taiji Suzuki and Atsushi Nitanda},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=uSQQH7Fj5U}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492766842, "odate": 1636492766842, "details": {"replyCount": 8}}, {"id": "t1czgrQOrwW", "original": "PYPQEfF-pBu", "number": 5762, "cdate": 1621630001510, "ddate": null, "tcdate": 1621630001510, "tmdate": 1683307651029, "tddate": null, "forum": "t1czgrQOrwW", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "The functional specialization of visual cortex emerges from training parallel pathways with self-supervised predictive learning", "authorids": ["~Shahab_Bakhtiari1", "~Patrick_J_Mineault1", "~Tim_Lillicrap1", "~Christopher_C_Pack1", "~Blake_Aaron_Richards1"], "authors": ["Shahab Bakhtiari", "Patrick J Mineault", "Tim Lillicrap", "Christopher C Pack", "Blake Aaron Richards"], "keywords": ["neuroscience", "visual system", "self-supervised learning", "visual cortex"], "abstract": "The visual system of mammals is comprised of parallel, hierarchical specialized pathways. Different pathways are specialized in so far as they use representations that are more suitable for supporting specific downstream behaviours. In particular, the clearest example is the specialization of the ventral (\"what\") and dorsal (\"where\") pathways of the visual cortex. These two pathways support behaviours related to visual recognition and movement, respectively. To-date, deep neural networks have mostly been used as models of the ventral, recognition pathway. However, it is unknown whether both pathways can be modelled with a single deep ANN. Here, we ask whether a single model with a single loss function can capture the properties of both the ventral and the dorsal pathways. We explore this question using data from mice, who like other mammals, have specialized pathways that appear to support recognition and movement behaviours. We show that when we train a deep neural network architecture with two parallel pathways using a self-supervised predictive loss function, we can outperform other models in fitting mouse visual cortex. Moreover, we can model both the dorsal and ventral pathways. These results demonstrate that a self-supervised predictive learning approach applied to parallel pathway architectures can account for some of the functional specialization seen in mammalian visual systems.", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "bakhtiari|the_functional_specialization_of_visual_cortex_emerges_from_training_parallel_pathways_with_selfsupervised_predictive_learning", "TL;DR": " Self-supervised predictive learning applied to a neural network with parallel pathways can account for some of the functional specialization of the visual systems.", "pdf": "/pdf/bdfc1d3036472e12f8fc812a2734ee066dc0eb4c.pdf", "checklist": "", "supplementary_material": "/attachment/b27907668552c705413d96e253632e6303c3ce78.pdf", "thumbnail": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nbakhtiari2021the,\ntitle={The functional specialization of visual cortex emerges from training parallel pathways with self-supervised predictive learning},\nauthor={Shahab Bakhtiari and Patrick J Mineault and Tim Lillicrap and Christopher C Pack and Blake Aaron Richards},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=t1czgrQOrwW}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492741489, "odate": 1636492741489, "details": {"replyCount": 19}}, {"id": "-t9LPHRYKmi", "original": "B7LveD0GwyM", "number": 5717, "cdate": 1621629998629, "ddate": null, "tcdate": 1621629998629, "tmdate": 1697937533220, "tddate": null, "forum": "-t9LPHRYKmi", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Tensor Normal Training for Deep Learning Models", "authorids": ["~Yi_Ren7", "~Donald_Goldfarb1"], "authors": ["Yi Ren", "Donald Goldfarb"], "keywords": ["Optimization for deep networks"], "abstract": "Despite the predominant use of first-order methods for training deep learning models, second-order methods, and in particular, natural gradient methods, remain of interest because of their potential for accelerating training through the use of curvature information. Several methods with non-diagonal preconditioning matrices, including KFAC, Shampoo, and K-BFGS, have been proposed and shown to be effective. Based on the so-called tensor normal (TN) distribution, we propose and analyze a brand new approximate natural gradient method, Tensor Normal Training (TNT), which like Shampoo, only requires knowledge of the shape of the training parameters. By approximating the probabilistically based Fisher matrix, as opposed to the empirical Fisher matrix, our method uses the block-wise covariance of the sampling based gradient as the pre-conditioning matrix. Moreover, the assumption that the sampling-based (tensor) gradient follows a TN distribution, ensures that its covariance has a Kronecker separable structure, which leads to a tractable approximation to the Fisher matrix. Consequently, TNT's memory requirements and per-iteration computational costs are only slightly higher than those for first-order methods. In our experiments, TNT exhibited superior optimization performance to state-of-the-art first-order methods, and comparable optimization performance to the state-of-the-art second-order methods KFAC and Shampoo. Moreover, TNT demonstrated its ability to generalize as well as first-order methods, while using fewer epochs.", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "ren|tensor_normal_training_for_deep_learning_models", "TL;DR": "We proposed a new second-order method (approximate natural gradient method) using tensor normal distribution for training deep learning models.", "pdf": "/pdf/e3ede48ac0c17c33db4db5726b0d1e65e666eb77.pdf", "checklist": "", "supplementary_material": "/attachment/9cd34b8718f1e3e0990fc293d18182f541bc9bc2.pdf", "code": "https://github.com/renyiryry/tnt_neurips_2021", "thumbnail": "", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 2 code implementations](https://www.catalyzex.com/paper/arxiv:2106.02925/code)", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nren2021tensor,\ntitle={Tensor Normal Training for Deep Learning Models},\nauthor={Yi Ren and Donald Goldfarb},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=-t9LPHRYKmi}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492722951, "odate": 1636492722951, "details": {"replyCount": 12}}, {"id": "syIj5ggwCYJ", "original": "_LZXk162jOE", "number": 5689, "cdate": 1621629994118, "ddate": null, "tcdate": 1621629994118, "tmdate": 1683307649439, "tddate": null, "forum": "syIj5ggwCYJ", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Information Directed Sampling for Sparse Linear Bandits", "authorids": ["~Botao_Hao1", "~Tor_Lattimore1", "~Wei_Deng1"], "authors": ["Botao Hao", "Tor Lattimore", "Wei Deng"], "keywords": ["Information-directed sampling", "sparse linear bandits", "Bayesian regret"], "TL;DR": "We investigate the theoretic and practical applicability of information-directed sampling for sparse linear bandits.", "abstract": "Stochastic sparse linear bandits offer a practical model for high-dimensional online decision-making problems and have a rich information-regret structure. In this work we explore the use of information-directed sampling (IDS), which naturally balances the information-regret trade-off. We develop a class of information-theoretic Bayesian regret bounds that nearly match existing lower bounds on a variety of problem instances, demonstrating the adaptivity of IDS. To efficiently implement sparse IDS, we propose an empirical Bayesian approach for sparse posterior sampling using a spike-and-slab Gaussian-Laplace prior.  Numerical results demonstrate significant regret reductions by sparse IDS relative to several baselines.\n", "pdf": "/pdf/5e1a67215084bf911ced2a7921c6fe1fce36d52c.pdf", "supplementary_material": "/attachment/5e3b2471e66538f85903961d2fb30ecd760daf9a.pdf", "submission_history": "", "checklist": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "hao|information_directed_sampling_for_sparse_linear_bandits", "thumbnail": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nhao2021information,\ntitle={Information Directed Sampling for Sparse Linear Bandits},\nauthor={Botao Hao and Tor Lattimore and Wei Deng},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=syIj5ggwCYJ}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492787519, "odate": 1636492787519, "details": {"replyCount": 11}}, {"id": "ELndVeVA-TR", "original": "Topi30uFc0K", "number": 5653, "cdate": 1621629991933, "ddate": null, "tcdate": 1621629991933, "tmdate": 1683307649105, "tddate": null, "forum": "ELndVeVA-TR", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Reward is enough for convex MDPs", "authorids": ["~Tom_Zahavy2", "~Brendan_O'Donoghue1", "~Guillaume_Desjardins1", "~Satinder_Singh2"], "authors": ["Tom Zahavy", "Brendan O'Donoghue", "Guillaume Desjardins", "Satinder Singh"], "keywords": ["reinforcement-learning", "convex optimisation"], "abstract": "Maximising a cumulative reward function that is Markov and stationary, i.e., defined over state-action pairs and independent of time, is sufficient to capture many kinds of goals in a Markov decision process (MDP). However, not all goals can be captured in this manner. In this paper we study convex MDPs in which goals are expressed as convex functions of the stationary distribution and show that they cannot be formulated using stationary reward functions. Convex MDPs generalize the standard reinforcement learning (RL) problem formulation to a larger framework that includes many supervised and unsupervised RL problems, such as apprenticeship learning, constrained MDPs, and so-called `pure exploration'. Our approach is to reformulate the convex MDP problem as a min-max game involving policy and cost (negative reward) `players', using Fenchel duality. We propose a meta-algorithm for solving this problem and show that it unifies many existing algorithms in the literature.", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "zahavy|reward_is_enough_for_convex_mdps", "TL;DR": "Convex MDPs, which include RL, apprenticeship learning, constrained MDPs, and pure exploration are shown to be solved by an RL algorithm that maximizes the gradient of the convex objective as a non-stationary reward", "pdf": "/pdf/c166b98807c737e7f17fe7d7da108d192c10f2b9.pdf", "supplementary_material": "/attachment/d4d22510a620b9f29be2d693233251eb74fb3d96.pdf", "checklist": "", "thumbnail": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nzahavy2021reward,\ntitle={Reward is enough for convex {MDP}s},\nauthor={Tom Zahavy and Brendan O'Donoghue and Guillaume Desjardins and Satinder Singh},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=ELndVeVA-TR}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492694800, "odate": 1636492694800, "details": {"replyCount": 14}}, {"id": "LAKplpLMbP8", "original": "-A0r0ThgEVb", "number": 5541, "cdate": 1621629985076, "ddate": null, "tcdate": 1621629985076, "tmdate": 1683307646433, "tddate": null, "forum": "LAKplpLMbP8", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Repulsive Deep Ensembles are Bayesian", "authorids": ["~Francesco_D'Angelo1", "~Vincent_Fortuin1"], "authors": ["Francesco D'Angelo", "Vincent Fortuin"], "keywords": ["Bayesian deep learning", "Deep ensembles", "Wasserstein gradient flow"], "TL;DR": "We show that adding a repulsive term to the gradient update of deep ensembles improves their uncertainty estimates and corresponds to a proper Bayesian approximation procedure.", "abstract": "Deep ensembles have recently gained popularity in the deep learning community for their conceptual simplicity and efficiency. However, maintaining functional diversity between ensemble members that are independently trained with gradient descent is challenging. This can lead to pathologies when adding more ensemble members, such as a saturation of the ensemble performance, which converges to the performance of a single model. Moreover, this does not only affect the quality of its predictions, but even more so the uncertainty estimates of the ensemble, and thus its performance on out-of-distribution data. We hypothesize that this limitation can be overcome by discouraging different ensemble members from collapsing to the same function. To this end, we introduce a kernelized repulsive term in the update rule of the deep ensembles. We show that this simple modification not only enforces and maintains diversity among the members but, even more importantly, transforms the maximum a posteriori inference into proper Bayesian inference. Namely, we show that the training dynamics of our proposed repulsive ensembles follow a Wasserstein gradient flow of the KL divergence with the true posterior. We study repulsive terms in weight and function space and empirically compare their performance to standard ensembles and Bayesian baselines on synthetic and real-world prediction tasks.", "submission_history": "", "checklist": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "dangelo|repulsive_deep_ensembles_are_bayesian", "pdf": "/pdf/c3cf44487146e788e049cc2004b7fd14f922f175.pdf", "supplementary_material": "/attachment/349fd78ad9d577f44053ade6912d569a84a7c521.pdf", "thumbnail": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nd'angelo2021repulsive,\ntitle={Repulsive Deep Ensembles are Bayesian},\nauthor={Francesco D'Angelo and Vincent Fortuin},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=LAKplpLMbP8}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492720013, "odate": 1636492720013, "details": {"replyCount": 12}}, {"id": "D7bPRxNt_AP", "original": "_41iBg_3uB5", "number": 5527, "cdate": 1621629984232, "ddate": null, "tcdate": 1621629984232, "tmdate": 1697937541320, "tddate": null, "forum": "D7bPRxNt_AP", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "NeuS: Learning Neural Implicit Surfaces by Volume Rendering for Multi-view Reconstruction", "authorids": ["~Peng_Wang17", "~Lingjie_Liu1", "~Yuan_Liu3", "~Christian_Theobalt2", "taku@cs.hku.hk", "~Wenping_Wang1"], "authors": ["Peng Wang", "Lingjie Liu", "Yuan Liu", "Christian Theobalt", "Taku Komura", "Wenping Wang"], "keywords": ["neural rendering", "3d reconstruction"], "TL;DR": "We propose a novel method for multi-view neural surface reconstruction.", "abstract": "We present a novel neural surface reconstruction method, called NeuS, for reconstructing objects and scenes with high fidelity from 2D image inputs. Existing neural surface reconstruction approaches, such as DVR [Niemeyer et al., 2020] and IDR [Yariv et al., 2020], require foreground mask as supervision, easily get trapped in local minima, and therefore struggle with the reconstruction of objects with severe self-occlusion or thin structures. Meanwhile, recent neural methods for novel view synthesis, such as NeRF [Mildenhall et al., 2020] and its variants, use volume rendering to produce a neural scene representation with robustness of optimization, even for highly complex objects. However, extracting high-quality surfaces from this learned implicit representation is difficult because there are not sufficient surface constraints in the representation. In NeuS, we propose to represent a surface as the zero-level set of a signed distance function (SDF) and develop a new volume rendering method to train a neural SDF representation. We observe that the conventional volume rendering method causes inherent geometric errors (i.e. bias) for surface reconstruction, and therefore propose a new formulation that is free of bias in the first order of approximation, thus leading to more accurate surface reconstruction even without the mask supervision. Experiments on the DTU dataset and the BlendedMVS dataset show that NeuS outperforms the state-of-the-arts in high-quality surface reconstruction, especially for objects and scenes with complex structures and self-occlusion. ", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "wang|neus_learning_neural_implicit_surfaces_by_volume_rendering_for_multiview_reconstruction", "pdf": "/pdf/877129cc2a2d734d8c2faa805195fcb987759314.pdf", "checklist": "", "supplementary_material": "/attachment/7226cf591a7fc641754cc5993d61118718a08a8c.pdf", "code": "https://github.com/Totoro97/NeuS", "thumbnail": "", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2106.10689/code)", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nwang2021neus,\ntitle={NeuS: Learning Neural Implicit Surfaces by Volume Rendering for Multi-view Reconstruction},\nauthor={Peng Wang and Lingjie Liu and Yuan Liu and Christian Theobalt and Taku Komura and Wenping Wang},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=D7bPRxNt_AP}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492728638, "odate": 1636492728638, "details": {"replyCount": 10}}, {"id": "QCPY2eMXYs", "original": "wZmMoPEfhxP", "number": 5507, "cdate": 1621629982986, "ddate": null, "tcdate": 1621629982986, "tmdate": 1697937541841, "tddate": null, "forum": "QCPY2eMXYs", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Pruning Randomly Initialized Neural Networks with Iterative Randomization", "authorids": ["~Daiki_Chijiwa1", "~Shin'ya_Yamaguchi1", "~Yasutoshi_Ida1", "~Kenji_Umakoshi1", "~Tomohiro_INOUE1"], "authors": ["Daiki Chijiwa", "Shin'ya Yamaguchi", "Yasutoshi Ida", "Kenji Umakoshi", "Tomohiro INOUE"], "keywords": ["lottery ticket hypothesis", "approximation theorem", "neural network pruning"], "abstract": "Pruning the weights of randomly initialized neural networks plays an important role in the context of lottery ticket hypothesis. Ramanujan et al. (2020) empirically showed that only pruning the weights can achieve remarkable performance instead of optimizing the weight values. However, to achieve the same level of performance as the weight optimization, the pruning approach requires more parameters in the networks before pruning and thus more memory space. To overcome this parameter inefficiency, we introduce a novel framework to prune randomly initialized neural networks with iteratively randomizing weight values (IteRand). Theoretically, we prove an approximation theorem in our framework, which indicates that the randomizing operations are provably effective to reduce the required number of the parameters. We also empirically demonstrate the parameter efficiency in multiple experiments on CIFAR-10 and ImageNet.", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "chijiwa|pruning_randomly_initialized_neural_networks_with_iterative_randomization", "TL;DR": "We propose a novel framework of iterative randomization (IteRand) for pruning randomly initialized neural networks, and demonstrate the parameter efficiency both theoretically and empirically.", "pdf": "/pdf/c440febf57cd3aaf653542e1427b9f6b7a0860ed.pdf", "checklist": "", "supplementary_material": "/attachment/fdf51d7781029d535179fb4cda026faef8fdb09b.pdf", "code": "https://github.com/dchiji-ntt/iterand", "thumbnail": "", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2106.09269/code)", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nchijiwa2021pruning,\ntitle={Pruning Randomly Initialized Neural Networks with Iterative Randomization},\nauthor={Daiki Chijiwa and Shin'ya Yamaguchi and Yasutoshi Ida and Kenji Umakoshi and Tomohiro INOUE},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=QCPY2eMXYs}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492758825, "odate": 1636492758825, "details": {"replyCount": 12}}, {"id": "UDe_F-4EeHd", "original": "_oWQMxFxHex", "number": 5428, "cdate": 1621629977603, "ddate": null, "tcdate": 1621629977603, "tmdate": 1683307642279, "tddate": null, "forum": "UDe_F-4EeHd", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Sequential Algorithms for Testing Closeness of Distributions", "authorids": ["~Aadil_Oufkir1", "~Omar_Fawzi1", "~Nicolas_Flammarion1", "~Aur\u00e9lien_Garivier1"], "authors": ["Aadil Oufkir", "Omar Fawzi", "Nicolas Flammarion", "Aur\u00e9lien Garivier"], "keywords": ["Distribution testing", "property testing", "sequential algorithms"], "abstract": "  What advantage do sequential procedures provide over batch algorithms for testing properties of unknown distributions? Focusing on the problem of testing whether two distributions $\\mathcal{D}_1$ and $\\mathcal{D}_2$ on $\\{1,\\dots, n\\}$ are equal or $\\epsilon$-far, we give several answers to this question. We show that for a small alphabet size $n$, there is a sequential algorithm that outperforms any batch algorithm by a factor of at least $4$ in terms sample complexity. For a general alphabet size $n$, we give a sequential algorithm that uses no more samples than its batch counterpart, and possibly fewer if the actual distance between $\\mathcal{D}_1$ and $\\mathcal{D}_2$ is larger than $\\epsilon$. As a corollary, letting $\\epsilon$ go to $0$, we obtain a sequential algorithm for testing closeness (with no a priori bound on the distance between $\\mathcal{D}_1$ and $\\mathcal{D}_2$) with a sample complexity $\\tilde{\\mathcal{O}}(\\frac{n^{2/3}}{TV(\\mathcal{D}_1, \\mathcal{D}_2)^{4/3}})$: this improves over the $\\tilde{\\mathcal{O}}(\\frac{n/\\log n}{TV(\\mathcal{D}_1, \\mathcal{D}_2)^{2} })$ tester of [Daskalakis and Kawase 2017]  and is optimal up to multiplicative constants. We also establish limitations of sequential algorithms for the problem of testing closeness: they can improve the worst case number of samples by at most a constant factor. ", "submission_history": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "oufkir|sequential_algorithms_for_testing_closeness_of_distributions", "pdf": "/pdf/dd52ac288a54cc1d406f41866a75fa47496cc205.pdf", "supplementary_material": "/attachment/060b293523bd9ec56a2046cded468ce687f8f69c.pdf", "thumbnail": "", "checklist": "", "_bibtex": "@inproceedings{\noufkir2021sequential,\ntitle={Sequential Algorithms for Testing Closeness of Distributions},\nauthor={Aadil Oufkir and Omar Fawzi and Nicolas Flammarion and Aur{\\'e}lien Garivier},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=UDe_F-4EeHd}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492713747, "odate": 1636492713747, "details": {"replyCount": 13}}, {"id": "YqYt54gU-XV", "original": "Z2moI-ZvCWK", "number": 5405, "cdate": 1621629976207, "ddate": null, "tcdate": 1621629976207, "tmdate": 1697937548197, "tddate": null, "forum": "YqYt54gU-XV", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "DiBS: Differentiable Bayesian Structure Learning", "authorids": ["~Lars_Lorch1", "~Jonas_Rothfuss1", "~Bernhard_Sch\u00f6lkopf1", "~Andreas_Krause1"], "authors": ["Lars Lorch", "Jonas Rothfuss", "Bernhard Sch\u00f6lkopf", "Andreas Krause"], "keywords": ["causality", "structure learning", "Bayesian networks", "Bayesian inference"], "TL;DR": "A fully differentiable method for joint Bayesian inference of graphs and parameters of general Bayesian networks ", "abstract": "Bayesian structure learning allows inferring Bayesian network structure from data while reasoning about the epistemic uncertainty---a key element towards enabling active causal discovery and designing interventions in real world systems. In this work, we propose a general, fully differentiable framework for Bayesian structure learning (DiBS) that operates in the continuous space of a latent probabilistic graph representation. Contrary to existing work, DiBS is agnostic to the form of the local conditional distributions and allows for joint posterior inference of both the graph structure and the conditional distribution parameters. This makes our formulation directly applicable to posterior inference of nonstandard Bayesian network models, e.g., with nonlinear dependencies encoded by neural networks. Using DiBS, we devise an efficient, general purpose variational inference method for approximating distributions over structural models. In evaluations on simulated and real-world data, our method significantly outperforms related approaches to joint posterior inference.\n\n", "pdf": "/pdf/2bec3af5778e413bc2584e4b3e72f04c6ee1c628.pdf", "submission_history": "", "checklist": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "lorch|dibs_differentiable_bayesian_structure_learning", "supplementary_material": "/attachment/0bfff5a20d26bb7e356f703704db8630dc0e4f49.pdf", "code": "https://github.com/larslorch/dibs", "thumbnail": "", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 3 code implementations](https://www.catalyzex.com/paper/arxiv:2105.11839/code)", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nlorch2021dibs,\ntitle={Di{BS}: Differentiable Bayesian Structure Learning},\nauthor={Lars Lorch and Jonas Rothfuss and Bernhard Sch{\\\"o}lkopf and Andreas Krause},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=YqYt54gU-XV}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492670644, "odate": 1636492670644, "details": {"replyCount": 14}}, {"id": "j3eGyNMPvh", "original": "jK9pmtS6ulb", "number": 5378, "cdate": 1621629974611, "ddate": null, "tcdate": 1621629974611, "tmdate": 1683307640733, "tddate": null, "forum": "j3eGyNMPvh", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Learning Gaussian Mixtures with Generalized Linear Models: Precise Asymptotics in High-dimensions", "authorids": ["~Bruno_Loureiro1", "~Gabriele_Sicuro1", "~Cedric_Gerbelot1", "~Alessandro_Pacco1", "~Florent_Krzakala1", "~Lenka_Zdeborova1"], "authors": ["Bruno Loureiro", "Gabriele Sicuro", "Cedric Gerbelot", "Alessandro Pacco", "Florent Krzakala", "Lenka Zdeborova"], "keywords": ["Statistical Physics", "Replica method", "High-dimensional statistics", "Approximate Message Passing", "Gaussian Mixture Models"], "TL;DR": "We give a rigorous formula for the error of generalised linear models fitting mixtures of Gaussian in high-dimensions.", "abstract": "Generalised linear models for multi-class classification problems are one of the fundamental building blocks of modern machine learning tasks. In this manuscript, we characterise the learning of a mixture of $K$ Gaussians with generic means and covariances via empirical risk minimisation (ERM) with any convex loss and regularisation. In particular, we prove exact asymptotics characterising the ERM estimator in high-dimensions, extending several previous results about Gaussian mixture classification in the literature. We exemplify our result in two tasks of interest in statistical learning: a) classification for a mixture with sparse means, where we study the efficiency of $\\ell_1$ penalty with respect to $\\ell_2$; b) max-margin multi-class classification, where we characterise the phase transition on the existence of the multi-class logistic maximum likelihood estimator for $K>2$. Finally, we discuss how our theory can be applied beyond the scope of synthetic data, showing that in different cases Gaussian mixtures capture closely the learning curve of classification tasks in real data sets.", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "loureiro|learning_gaussian_mixtures_with_generalized_linear_models_precise_asymptotics_in_highdimensions", "pdf": "/pdf/1e431d2c58179fbf48e57dad0945025d979b2080.pdf", "checklist": "", "supplementary_material": "/attachment/4f82f08dfd7098630e793c7594418c9e993aa82d.pdf", "code": "https://github.com/IdePHICS/GaussMixtureProject", "thumbnail": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nloureiro2021learning,\ntitle={Learning Gaussian Mixtures with Generalized Linear Models: Precise Asymptotics in High-dimensions},\nauthor={Bruno Loureiro and Gabriele Sicuro and Cedric Gerbelot and Alessandro Pacco and Florent Krzakala and Lenka Zdeborova},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=j3eGyNMPvh}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492752189, "odate": 1636492752189, "details": {"replyCount": 7}}, {"id": "WBVbl8POq8v", "original": "j5Q8TAA18Z6", "number": 5193, "cdate": 1621629963718, "ddate": null, "tcdate": 1621629963718, "tmdate": 1683307636673, "tddate": null, "forum": "WBVbl8POq8v", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Doubly Robust Thompson Sampling with Linear Payoffs", "authorids": ["~Wonyoung_Kim2", "~Gi-Soo_Kim1", "~Myunghee_Cho_Paik2"], "authors": ["Wonyoung Kim", "Gi-Soo Kim", "Myunghee Cho Paik"], "keywords": ["Linear contextual bandits", "Thompson Sampling", "Using contexts of all arms", "An improved regret bound"], "abstract": "A challenging aspect of the bandit problem is that a stochastic reward is observed only for the chosen arm and the rewards of other arms remain missing.    \nThe dependence of the arm choice on the past context and reward pairs compounds the complexity of regret analysis.\nWe propose a novel multi-armed contextual bandit algorithm called Doubly Robust Thompson Sampling (DRTS) employing the doubly-robust estimator used in missing data literature to Thompson Sampling with contexts (\\texttt{LinTS}).\nDifferent from previous works relying on missing data techniques (Dimakopoulou et al. [2019], Kim and Paik [2019]), the proposed algorithm is designed to allow a novel additive regret decomposition leading to an improved regret bound with the order of $\\tilde{O}(\\phi^{-2}\\sqrt{T})$, where $\\phi^2$ is the minimum eigenvalue of the covariance matrix of contexts.\nThis is the first regret bound of \\texttt{LinTS} using $\\phi^2$ without $d$,  where $d$ is the dimension of the context.\nApplying the relationship between $\\phi^2$ and $d$, the regret bound of the proposed algorithm is $\\tilde{O}(d\\sqrt{T})$ in many practical scenarios, improving the bound of \\texttt{LinTS} by a factor of $\\sqrt{d}$.\nA benefit of the proposed method is that it uses all the context data, chosen or not chosen, thus allowing to circumvent the technical definition of unsaturated arms used in theoretical analysis of \\texttt{LinTS}.\nEmpirical studies show the advantage of the proposed algorithm over \\texttt{LinTS}.", "submission_history": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "kim|doubly_robust_thompson_sampling_with_linear_payoffs", "pdf": "/pdf/39845e8d1a553eecd81f6dcf52b038fb1764e73c.pdf", "checklist": "", "supplementary_material": "/attachment/5035869f0854d34b6e52956d7fad8ca0caecb218.pdf", "TL;DR": "A novel Thompson Sampling algorithm which utilizes contexts of all arms with an improved regret bound.", "thumbnail": "", "code": "https://github.com/gisoo1989/DRTS", "_bibtex": "@inproceedings{\nkim2021doubly,\ntitle={Doubly Robust Thompson Sampling with Linear Payoffs},\nauthor={Wonyoung Kim and Gi-Soo Kim and Myunghee Cho Paik},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=WBVbl8POq8v}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492734518, "odate": 1636492734518, "details": {"replyCount": 17}}, {"id": "QpRufbD4xdn", "original": "hhgjvIoVWtt", "number": 5131, "cdate": 1621629960088, "ddate": null, "tcdate": 1621629960088, "tmdate": 1683307635550, "tddate": null, "forum": "QpRufbD4xdn", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Determinantal point processes based on orthogonal polynomials for sampling minibatches in SGD", "authorids": ["~R\u00e9mi_Bardenet1", "~Subhroshekhar_Ghosh1", "~Meixia_LIN1"], "authors": ["R\u00e9mi Bardenet", "Subhroshekhar Ghosh", "Meixia LIN"], "keywords": ["determinantal point processes", "variance reduction", "stochastic gradient descent", "orthogonal polynomials"], "TL;DR": "We contribute a DPP-based paradigm for sampling minibatches in SGD that is driven by orthogonal polynomials, and substantiate it with a theoretical investigation of why and how it can reduce the variance of the gradient estimator in SGD.", "abstract": "Stochastic gradient descent (SGD) is a cornerstone of machine learning. When the number $N$ of data items is large, SGD relies on constructing an unbiased estimator of the gradient of the empirical risk using a small subset of the original dataset, called a minibatch. Default minibatch construction involves uniformly sampling a subset of the desired size, but alternatives have been explored for variance reduction. In particular, experimental evidence suggests drawing minibatches from determinantal point processes (DPPs), tractable distributions over minibatches that favour diversity among selected items. However, like in recent work on DPPs for coresets, providing a systematic and principled understanding of how and why DPPs help has been difficult. In this work, we contribute an orthogonal polynomial-based determinantal point process paradigm for performing minibatch sampling in SGD. Our approach leverages the specific data distribution at hand, which endows it with greater sensitivity and power over existing data-agnostic methods. We substantiate our method via a detailed theoretical analysis of its convergence properties, interweaving between the discrete data set and the underlying continuous domain. In particular, we show how specific DPPs and a string of controlled approximations can lead to gradient estimators with a variance that decays faster with the batchsize than under uniform sampling. Coupled with existing finite-time guarantees for SGD on convex objectives, this entails that, for a large enough batchsize and a fixed budget of item-level gradients to evaluate, DPP minibatches lead to a smaller bound on the mean square approximation error than uniform minibatches. Moreover, our estimators are amenable to a recent algorithm that directly samples linear statistics of DPPs (i.e., the gradient estimator) without sampling the underlying DPP (i.e., the minibatch), thereby reducing computational overhead. We provide detailed synthetic as well as real data experiments to substantiate our theoretical claims.", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "bardenet|determinantal_point_processes_based_on_orthogonal_polynomials_for_sampling_minibatches_in_sgd", "pdf": "/pdf/76a9481c7e78719e98baff680fb72cd07586437e.pdf", "checklist": "", "supplementary_material": "/attachment/0754e34c6b2e9c34de914ffa44b8b425483dc986.pdf", "thumbnail": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nbardenet2021determinantal,\ntitle={Determinantal point processes based on orthogonal polynomials for sampling minibatches in {SGD}},\nauthor={R{\\'e}mi Bardenet and Subhroshekhar Ghosh and Meixia LIN},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=QpRufbD4xdn}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492761287, "odate": 1636492761287, "details": {"replyCount": 12}}, {"id": "vGjTOxss-Dl", "original": "2Y8LvrpXms_", "number": 5100, "cdate": 1621629958260, "ddate": null, "tcdate": 1621629958260, "tmdate": 1683307634758, "tddate": null, "forum": "vGjTOxss-Dl", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Property-Aware Relation Networks for Few-Shot Molecular Property Prediction", "authorids": ["~Yaqing_Wang2", "~ABULIKEMU_ABUDUWEILI1", "~quanming_yao1", "~Dejing_Dou3"], "authors": ["Yaqing Wang", "ABULIKEMU ABUDUWEILI", "quanming yao", "Dejing Dou"], "keywords": ["molecular property prediction", "few-shot learning", "meta-learning"], "TL;DR": "To handle few-shot molecular property prediction problem,  we propose Property-Aware Relation networks (PAR) which can obtain property-aware molecular embeddings and model molecular relation graph adaptively. ", "abstract": "Molecular property prediction plays a fundamental role in drug discovery to identify candidate molecules with target properties. However, molecular property prediction is essentially a few-shot problem, which makes it hard to use regular machine learning models. In this paper, we propose Property-Aware Relation networks (PAR) to handle this problem. In comparison to existing works, we leverage the fact that both relevant substructures and relationships among molecules change across different molecular properties. We first introduce a property-aware embedding function to transform the generic molecular embeddings to substructure-aware space relevant to the target property.  Further, we design an adaptive relation graph learning module to jointly estimate molecular relation graph and refine molecular embeddings w.r.t. the target property, such that the limited labels can be effectively propagated among similar molecules. We adopt a meta-learning strategy where the parameters are selectively updated within tasks in order to model generic and property-aware knowledge separately. Extensive experiments on benchmark molecular property prediction datasets show that PAR consistently outperforms existing methods and can obtain property-aware molecular embeddings and model molecular relation graph properly.  ", "pdf": "/pdf/d689c2b68555e981703886377e707bd5a18102b5.pdf", "supplementary_material": "/attachment/831f7ff5bc9095f06ff90144df6a0c0abf0bc8ac.pdf", "submission_history": "", "checklist": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "wang|propertyaware_relation_networks_for_fewshot_molecular_property_prediction", "code": "https://github.com/tata1661/PAR-NeurIPS21", "thumbnail": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nwang2021propertyaware,\ntitle={Property-Aware Relation Networks for Few-Shot Molecular Property Prediction},\nauthor={Yaqing Wang and ABULIKEMU ABUDUWEILI and quanming yao and Dejing Dou},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=vGjTOxss-Dl}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492678921, "odate": 1636492678921, "details": {"replyCount": 12}}, {"id": "1H6zA8wIhKk", "original": "vILNiBD_Ns", "number": 5096, "cdate": 1621629958005, "ddate": null, "tcdate": 1621629958005, "tmdate": 1683307634294, "tddate": null, "forum": "1H6zA8wIhKk", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Coresets for Clustering with Missing Values", "authorids": ["~Vladimir_Braverman1", "~Shaofeng_H.-C._Jiang1", "~Robert_Krauthgamer1", "~Xuan_Wu2"], "authors": ["Vladimir Braverman", "Shaofeng H.-C. Jiang", "Robert Krauthgamer", "Xuan Wu"], "keywords": ["coreset", "clustering", "k-means", "missing values"], "TL;DR": "We provide the first coreset and near-linear time PTAS for clustering with (multiple) missing values", "abstract": "We provide the first coreset for clustering points in $\\mathbb{R}^d$ that have multiple missing values (coordinates). Previous coreset constructions only allow one missing coordinate. The challenge in this setting is that objective functions, like \\kMeans, are evaluated only on the set of available (non-missing) coordinates, which varies across points. Recall that an $\\epsilon$-coreset of a large dataset is a small proxy, usually a reweighted subset of points, that $(1+\\epsilon)$-approximates the clustering objective for every possible center set.\n\nOur coresets for $k$-Means and $k$-Median clustering have size $(jk)^{O(\\min(j,k))} (\\epsilon^{-1} d \\log n)^2$, where $n$ is the number of data points, $d$ is the dimension and $j$ is the maximum number of missing coordinates for each data point. We further design an algorithm to construct these coresets in near-linear time, and consequently improve a recent quadratic-time PTAS for $k$-Means with missing values [Eiben et al., SODA 2021] to near-linear time.\n\nWe validate our coreset construction, which is based on importance sampling and is easy to implement, on various real data sets. Our coreset exhibits a flexible tradeoff between coreset size and accuracy, and generally outperforms the uniform-sampling baseline. Furthermore, it significantly speeds up a Lloyd's-style heuristic for $k$-Means with missing values.", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "braverman|coresets_for_clustering_with_missing_values", "pdf": "/pdf/db5e422d014c1b02d7dbdeffadc0662c9040bc3b.pdf", "checklist": "", "supplementary_material": "/attachment/ba49d8eb3ee0f1834dd11a7f4b84f062e4b842f3.pdf", "thumbnail": "", "code": "/attachment/c03b616b70fdda422b4826429bc9596beab67037.zip", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nbraverman2021coresets,\ntitle={Coresets for Clustering with Missing Values},\nauthor={Vladimir Braverman and Shaofeng H.-C. Jiang and Robert Krauthgamer and Xuan Wu},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=1H6zA8wIhKk}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492751550, "odate": 1636492751550, "details": {"replyCount": 11}}, {"id": "k-ghaB9VZBw", "original": "wM3eCwtNUTL", "number": 5077, "cdate": 1621629956846, "ddate": null, "tcdate": 1621629956846, "tmdate": 1683307634114, "tddate": null, "forum": "k-ghaB9VZBw", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Process for Adapting Language Models to Society (PALMS) with Values-Targeted Datasets", "authorids": ["~Irene_Solaiman1", "~Christy_Dennison1"], "authors": ["Irene Solaiman", "Christy Dennison"], "keywords": ["nlp", "bias", "bias mitigation", "fine-tuning", "language model behavior", "policy", "alignment"], "TL;DR": "Small, hand-curated fine-tuning datasets can significantly change language model behavior", "abstract": "Language models can generate harmful and biased outputs and exhibit undesirable behavior according to a given cultural context. We propose a Process for Adapting Language Models to Society (PALMS) with Values-Targeted Datasets, an iterative process to significantly change model behavior by crafting and fine-tuning on a dataset that reflects a predetermined set of target values. We evaluate our process using three metrics: quantitative metrics with human evaluations that score output adherence to a target value, toxicity scoring on outputs; and qualitative metrics analyzing the most common word associated with a given social category. Through each iteration, we add additional training dataset examples based on observed shortcomings from evaluations. PALMS performs significantly better on all metrics compared to baseline and control models for a broad range of GPT-3 language model sizes without compromising capability integrity. We find that the effectiveness of PALMS increases with model size. We show that significantly adjusting language model behavior is feasible with a small, hand-curated dataset.", "pdf": "/pdf/c04f3c223ff2c4548bd335e32d87bd07713e1fd5.pdf", "supplementary_material": "/attachment/cb4b0c92582dc412450afe07d00fb65bce819e1e.pdf", "submission_history": "", "checklist": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "solaiman|process_for_adapting_language_models_to_society_palms_with_valuestargeted_datasets", "thumbnail": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nsolaiman2021process,\ntitle={Process for Adapting Language Models to Society ({PALMS}) with Values-Targeted Datasets},\nauthor={Irene Solaiman and Christy Dennison},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=k-ghaB9VZBw}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492778326, "odate": 1636492778326, "details": {"replyCount": 17}}, {"id": "SEz-FQltAYN", "original": "2HZvGo2WFIF", "number": 5043, "cdate": 1621629954742, "ddate": null, "tcdate": 1621629954742, "tmdate": 1683307633703, "tddate": null, "forum": "SEz-FQltAYN", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Widening the Pipeline in Human-Guided Reinforcement Learning with Explanation and Context-Aware Data Augmentation", "authorids": ["~Lin_Guan1", "~Mudit_Verma2", "~Sihang_Guo1", "~Ruohan_Zhang1", "~Subbarao_Kambhampati1"], "authors": ["Lin Guan", "Mudit Verma", "Sihang Guo", "Ruohan Zhang", "Subbarao Kambhampati"], "keywords": ["human-in-the-loop reinforcement learning", "interactive reinforcement learning", "explanations", "saliency map", "visual explanations", "human-agent interaction", "multimodal human-agent interaction"], "abstract": "Human explanation (e.g., in terms of feature importance) has been recently used to extend the communication channel between human and agent in interactive machine learning. Under this setting, human trainers provide not only the ground truth but also some form of explanation. However, this kind of human guidance was only investigated in supervised learning tasks, and it remains unclear how to best incorporate this type of human knowledge into deep reinforcement learning. In this paper, we present the first study of using human visual explanations in human-in-the-loop reinforcement learning (HIRL). We focus on the task of learning from feedback, in which the human trainer not only gives binary evaluative \"good\" or \"bad\" feedback for queried state-action pairs, but also provides a visual explanation by annotating relevant features in images. We propose EXPAND (EXPlanation AugmeNted feeDback) to encourage the model to encode task-relevant features through a context-aware data augmentation that only perturbs irrelevant features in human salient information. We choose five tasks, namely Pixel-Taxi and four Atari games, to evaluate the performance and sample efficiency of this approach. We show that our method significantly outperforms methods leveraging human explanation that are adapted from supervised learning, and Human-in-the-loop RL baselines that only utilize evaluative feedback.", "submission_history": "", "checklist": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "guan|widening_the_pipeline_in_humanguided_reinforcement_learning_with_explanation_and_contextaware_data_augmentation", "TL;DR": "EXPAND is a Context-Aware Data Augmentation technique under the paradigm of HIRL, utilising novel integration of human explanatory feedback with human binary feedback, that has shown to improve on the environment sample & human feedback efficiency.", "pdf": "/pdf/3f6754c2e01c72dc30d6c1858ce5c13ee3ffb2ab.pdf", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "supplementary_material": "/attachment/0d0af964ac3fc4c094ec3bcb5c61e230aef10312.pdf", "thumbnail": "", "_bibtex": "@inproceedings{\nguan2021widening,\ntitle={Widening the Pipeline in Human-Guided Reinforcement Learning with Explanation and Context-Aware Data Augmentation},\nauthor={Lin Guan and Mudit Verma and Sihang Guo and Ruohan Zhang and Subbarao Kambhampati},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=SEz-FQltAYN}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492717657, "odate": 1636492717657, "details": {"replyCount": 9}}, {"id": "UoVpP8R2Vn", "original": "kVqNMjo146l", "number": 5023, "cdate": 1621629953644, "ddate": null, "tcdate": 1621629953644, "tmdate": 1697937560605, "tddate": null, "forum": "UoVpP8R2Vn", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "PARP: Prune, Adjust and Re-Prune for Self-Supervised Speech Recognition", "authorids": ["~Cheng-I_Lai1", "~Yang_Zhang3", "~Alexander_H._Liu1", "~Shiyu_Chang2", "~Yi-Lun_Liao1", "~Yung-Sung_Chuang1", "~Kaizhi_Qian1", "~Sameer_Khurana1", "~David_Daniel_Cox1", "~James_R._Glass1"], "authors": ["Cheng-I Lai", "Yang Zhang", "Alexander H. Liu", "Shiyu Chang", "Yi-Lun Liao", "Yung-Sung Chuang", "Kaizhi Qian", "Sameer Khurana", "David Daniel Cox", "James R. Glass"], "keywords": ["Speech Recognition", "Self-Supervised Learning", "Lottery Ticket Hypothesis", "Pruning"], "TL;DR": "A new pruning method for self-supervised speech recognition that achieves better performance than conventional pruning methods while using a fraction of the computational cost.", "abstract": "Self-supervised speech representation learning (speech SSL) has demonstrated the benefit of scale in learning rich representations for Automatic Speech Recognition (ASR) with limited paired data, such as wav2vec 2.0. We investigate the existence of sparse subnetworks in pre-trained speech SSL models that achieve even better low-resource ASR results. However, directly applying widely adopted pruning methods such as the Lottery Ticket Hypothesis (LTH) is suboptimal in the computational cost needed. Moreover, we show that the discovered subnetworks yield minimal performance gain compared to the original dense network.\nWe present Prune-Adjust-Re-Prune (PARP), which discovers and finetunes subnetworks for much better performance, while only requiring a single downstream ASR finetuning run. PARP is inspired by our surprising observation that subnetworks pruned for pre-training tasks need merely a slight adjustment to achieve a sizeable performance boost in downstream ASR tasks. Extensive experiments on low-resource ASR verify (1) sparse subnetworks exist in mono-lingual/multi-lingual pre-trained speech SSL, and (2) the computational advantage and performance gain of PARP over baseline pruning methods.\nIn particular, on the 10min Librispeech split without LM decoding, PARP discovers subnetworks from wav2vec 2.0 with an absolute 10.9%/12.6% WER decrease compared to the full model. We further demonstrate the effectiveness of PARP via: cross-lingual pruning without any phone recognition degradation, the discovery of a multi-lingual subnetwork for 10 spoken languages in 1 finetuning run, and its applicability to pre-trained BERT/XLNet for natural language tasks1.", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "lai|parp_prune_adjust_and_reprune_for_selfsupervised_speech_recognition", "pdf": "/pdf/9b0c9a372e97938a5e4648cdbf51404084dc617d.pdf", "checklist": "", "supplementary_material": "/attachment/2c7bf6a8277c913c33291371b00b344595ec591c.pdf", "code": "https://github.com/jefflai108/PARP-wav2vec-PyTorch", "thumbnail": "", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 2 code implementations](https://www.catalyzex.com/paper/arxiv:2106.05933/code)", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nlai2021parp,\ntitle={{PARP}: Prune, Adjust and Re-Prune for Self-Supervised Speech Recognition},\nauthor={Cheng-I Lai and Yang Zhang and Alexander H. Liu and Shiyu Chang and Yi-Lun Liao and Yung-Sung Chuang and Kaizhi Qian and Sameer Khurana and David Daniel Cox and James R. Glass},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=UoVpP8R2Vn}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492730161, "odate": 1636492730161, "details": {"replyCount": 14}}, {"id": "C0GmZH2RnVR", "original": "p_zulVJUBS", "number": 4975, "cdate": 1621629950791, "ddate": null, "tcdate": 1621629950791, "tmdate": 1697937563223, "tddate": null, "forum": "C0GmZH2RnVR", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Breaking the Dilemma of Medical Image-to-image Translation", "authorids": ["~Lingke_Kong1", "~Chenyu_Lian1", "~Detian_Huang1", "zhenjli1987@163.com", "~Yanle_Hu1", "~Qichao_Zhou1"], "authors": ["Lingke Kong", "Chenyu Lian", "Detian Huang", "ZhenJiang Li", "Yanle Hu", "Qichao Zhou"], "keywords": ["Image-to-image Translation"], "abstract": "Supervised Pix2Pix and unsupervised Cycle-consistency are two modes that dominate the field of medical image-to-image translation. However, neither modes are ideal. The Pix2Pix mode has excellent performance. But it requires paired and well pixel-wise aligned images, which may not always be achievable due to respiratory motion or anatomy change between times that paired images are acquired. The Cycle-consistency mode is less stringent with training data and works well on unpaired or misaligned images. But its performance may not be optimal. In order to break the dilemma of the existing modes, we propose a new unsupervised mode called RegGAN for medical image-to-image translation. It is based on the theory of \"loss-correction\". In RegGAN, the misaligned\u00a0target images are considered as noisy labels\u00a0and the generator is trained with an additional registration network to fit the misaligned noise distribution adaptively. The goal is to search for the common optimal solution to both image-to-image translation and registration tasks. We incorporated RegGAN into a few state-of-the-art image-to-image translation methods and demonstrated that RegGAN could be easily combined with these methods to improve their performances. Such as a simple CycleGAN in our mode surpasses latest NICEGAN even though using less network parameters. Based on our results, RegGAN outperformed both Pix2Pix on aligned data and Cycle-consistency on misaligned or unpaired data. RegGAN is insensitive to noises which makes it a better choice for a wide range of scenarios, especially for medical image-to-image translation tasks in which well pixel-wise aligned data are not available. Code and dataset are available at https://github.com/Kid-Liet/Reg-GAN.", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "kong|breaking_the_dilemma_of_medical_imagetoimage_translation", "pdf": "/pdf/635fd0e10fce7c374460fca897ce1fdf83793642.pdf", "checklist": "", "supplementary_material": "/attachment/ef927dedcbf8e69c484e8f27a54b95ee134f3db5.pdf", "thumbnail": "", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 5 code implementations](https://www.catalyzex.com/paper/arxiv:2110.06465/code)", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nkong2021breaking,\ntitle={Breaking the Dilemma of Medical Image-to-image Translation},\nauthor={Lingke Kong and Chenyu Lian and Detian Huang and ZhenJiang Li and Yanle Hu and Qichao Zhou},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=C0GmZH2RnVR}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492772990, "odate": 1636492772990, "details": {"replyCount": 13}}, {"id": "SJHRf5nW93", "original": "W1HTInXjdLt", "number": 4974, "cdate": 1621629950733, "ddate": null, "tcdate": 1621629950733, "tmdate": 1697937563205, "tddate": null, "forum": "SJHRf5nW93", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Subgraph Federated Learning with Missing Neighbor Generation", "authorids": ["~Ke_ZHANG7", "~Carl_Yang1", "~Xiaoxiao_Li1", "~Lichao_Sun1", "~Siu_Ming_Yiu1"], "authors": ["Ke ZHANG", "Carl Yang", "Xiaoxiao Li", "Lichao Sun", "Siu Ming Yiu"], "keywords": ["graph mining", "federated learning", "subgraph node classification", "neighbor prediction", "generative model"], "abstract": "Graphs have been widely used in data mining and machine learning due to their unique representation of real-world objects and their interactions. As graphs are getting bigger and bigger nowadays, it is common to see their subgraphs separately collected and stored in multiple local systems. Therefore, it is natural to consider the subgraph federated learning setting, where each local system holds a small subgraph that may be biased from the distribution of the whole graph. Hence, the subgraph federated learning aims to collaboratively train a powerful and generalizable graph mining model without directly sharing their graph data. In this work, towards the novel yet realistic setting of subgraph federated learning, we propose two major techniques: (1) FedSage, which trains a GraphSage model based on FedAvg to integrate node features, link structures, and task labels on multiple local subgraphs; (2) FedSage+, which trains a missing neighbor generator along FedSage to deal with missing links across local subgraphs. Empirical results on four real-world graph datasets with synthesized subgraph federated learning settings demonstrate the effectiveness and efficiency of our proposed techniques. At the same time, consistent theoretical implications are made towards their generalization ability on the global graphs.", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "zhang|subgraph_federated_learning_with_missing_neighbor_generation", "TL;DR": "We study a novel yet realistic setting of node classification in a distributed subgraph system, and propose novel federated learning frameworks to address the unique challenges in this setting.", "pdf": "/pdf/8c2df1b005df6e439a2287dbedf39bf677ef0f1a.pdf", "checklist": "", "supplementary_material": "/attachment/ae5cc5ab1159ace77ed267a6a79609bd32ed47b4.pdf", "code": "https://github.com/zkhku/fedsage", "thumbnail": "", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2106.13430/code)", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nzhang2021subgraph,\ntitle={Subgraph Federated Learning with Missing Neighbor Generation},\nauthor={Ke ZHANG and Carl Yang and Xiaoxiao Li and Lichao Sun and Siu Ming Yiu},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=SJHRf5nW93}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492675801, "odate": 1636492675801, "details": {"replyCount": 10}}, {"id": "LU687itn08w", "original": "MGwowvUg3SD", "number": 4837, "cdate": 1621629942646, "ddate": null, "tcdate": 1621629942646, "tmdate": 1697937566991, "tddate": null, "forum": "LU687itn08w", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Offline RL Without Off-Policy Evaluation", "authorids": ["~David_Brandfonbrener1", "~William_F_Whitney1", "~Rajesh_Ranganath2", "~Joan_Bruna1"], "authors": ["David Brandfonbrener", "William F Whitney", "Rajesh Ranganath", "Joan Bruna"], "keywords": ["Offline reinforcement learning", "reinforcement learning"], "abstract": "Most prior approaches to offline reinforcement learning (RL) have taken an iterative actor-critic approach involving off-policy evaluation. In this paper we show that simply doing one step of constrained/regularized policy improvement using an on-policy Q estimate of the behavior policy performs surprisingly well. This one-step algorithm beats the previously reported results of iterative algorithms on a large portion of the D4RL benchmark. The one-step baseline achieves this strong performance while being notably simpler and more robust to hyperparameters than previously proposed iterative algorithms. We argue that the relatively poor performance of iterative approaches is a result of the high variance inherent in doing off-policy evaluation and magnified by the repeated optimization of policies against those estimates. In addition, we hypothesize that the strong performance of the one-step algorithm is due to a combination of favorable structure in the environment and behavior policy.", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "brandfonbrener|offline_rl_without_offpolicy_evaluation", "pdf": "/pdf/7431019b4f1abb7b086fde48b4f19e12449f7739.pdf", "checklist": "", "supplementary_material": "/attachment/cd88de24d8371ce51a0e43af296c0c16e4f707a1.pdf", "TL;DR": "Performing one step of policy iteration provides a strong baseline for offline RL.", "code": "https://github.com/davidbrandfonbrener/onestep-rl", "thumbnail": "", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2106.08909/code)", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nbrandfonbrener2021offline,\ntitle={Offline {RL} Without Off-Policy Evaluation},\nauthor={David Brandfonbrener and William F Whitney and Rajesh Ranganath and Joan Bruna},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=LU687itn08w}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492763712, "odate": 1636492763671, "details": {"replyCount": 11}}, {"id": "aVKRtX-0rdW", "original": "8v7HP-Kl2v8", "number": 4822, "cdate": 1621629941715, "ddate": null, "tcdate": 1621629941715, "tmdate": 1683307628768, "tddate": null, "forum": "aVKRtX-0rdW", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Efficient Online Estimation of Causal Effects by Deciding What to Observe", "authorids": ["~Shantanu_Gupta2", "~Zachary_Chase_Lipton1", "~David_Childers1"], "authors": ["Shantanu Gupta", "Zachary Chase Lipton", "David Childers"], "keywords": ["online data collection", "causal inference", "online moment selection"], "abstract": "Researchers often face data fusion problems, where multiple data sources are available, each capturing a distinct subset of variables. While problem formulations typically take the data as given, in practice, data acquisition can be an ongoing process. In this paper, we introduce the problem of deciding, at each time, which data source to sample from. Our goal is to estimate a given functional of the parameters of a probabilistic model as efficiently as possible. We propose online moment selection (OMS), a framework in which structural assumptions are encoded as moment conditions. The optimal action at each step depends, in part, on the very moments that identify the functional of interest. Our algorithms balance exploration with choosing the best action as suggested by estimated moments. We propose two selection strategies: (1) explore-then-commit (ETC) and (2) explore-then-greedy (ETG), proving that both achieve zero asymptotic regret as assessed by MSE. We instantiate our setup for average treatment effect estimation, where structural assumptions are given by a causal graph and data sources include subsets of mediators, confounders, and instrumental variables.", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "gupta|efficient_online_estimation_of_causal_effects_by_deciding_what_to_observe", "pdf": "/pdf/b51e6c1c13f5b2f6691d6eba9b987cde5e2530f8.pdf", "checklist": "", "supplementary_material": "/attachment/ec385dbc6835ba5adf1853da84c3bfae64ad8471.pdf", "TL;DR": "Efficiently estimate a target parameter by sequentially querying data sources, each of which returns a specific subset of the variables.", "code": "https://github.com/acmi-lab/online-moment-selection", "thumbnail": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\ngupta2021efficient,\ntitle={Efficient Online Estimation of Causal Effects by Deciding What to Observe},\nauthor={Shantanu Gupta and Zachary Chase Lipton and David Childers},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=aVKRtX-0rdW}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492693358, "odate": 1636492693358, "details": {"replyCount": 13}}, {"id": "INBO6h9gtG", "original": "FIh4l4tYny9", "number": 4744, "cdate": 1621629937005, "ddate": null, "tcdate": 1621629937005, "tmdate": 1683307627674, "tddate": null, "forum": "INBO6h9gtG", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Covariance-Aware Private Mean Estimation Without Private Covariance Estimation", "authorids": ["~Gavin_R_Brown1", "~Marco_Gaboardi2", "~Adam_Smith1", "~Jonathan_Ullman1", "~Lydia_Zakynthinou1"], "authors": ["Gavin R Brown", "Marco Gaboardi", "Adam Smith", "Jonathan Ullman", "Lydia Zakynthinou"], "keywords": ["Differential Privacy", "Mean Estimation", "Gaussian Estimation", "Tukey Depth", "Statistical Learning Theory"], "TL;DR": "We design differentially private mean estimators for $d$-dimensional (sub)Gaussian distributions with unknown covariance which have nearly optimal sample complexity guarantees.", "abstract": "We present two sample-efficient differentially private mean estimators for $d$-dimensional (sub)Gaussian distributions with unknown covariance. Informally, given $n \\gtrsim d/\\alpha^2$ samples from such a distribution with mean $\\mu$ and covariance $\\Sigma$, our estimators output $\\tilde\\mu$ such that $\\| \\tilde\\mu - \\mu \\|_{\\Sigma} \\leq \\alpha$, where $\\| \\cdot \\|_{\\Sigma}$ is the \\emph{Mahalanobis distance}. All previous estimators with the same guarantee either require strong a priori bounds on the covariance matrix or require $\\Omega(d^{3/2})$ samples.  \n   \nEach of our estimators is based on a simple, general approach to designing differentially private mechanisms, but with novel technical steps to make the estimator private and sample-efficient. Our first estimator samples a point with approximately maximum Tukey depth using the exponential mechanism, but restricted to the set of points of large Tukey depth. Proving that this mechanism is private requires a novel analysis. Our second estimator perturbs the empirical mean of the data set with noise calibrated to the empirical covariance. Only the mean is released, however; the covariance is only used internally. Its sample complexity guarantees hold more generally for subgaussian distributions, albeit with a slightly worse dependence on the privacy parameter. For both estimators, careful preprocessing of the data is required to satisfy differential privacy.", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "brown|covarianceaware_private_mean_estimation_without_private_covariance_estimation", "pdf": "/pdf/0ad9726d42d0e6b5369b7fa7d40aaf7cd0d52012.pdf", "checklist": "", "supplementary_material": "/attachment/7f4825a461211184b4eefefc0098d93894bf8f67.pdf", "thumbnail": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nbrown2021covarianceaware,\ntitle={Covariance-Aware Private Mean Estimation Without Private Covariance Estimation},\nauthor={Gavin R Brown and Marco Gaboardi and Adam Smith and Jonathan Ullman and Lydia Zakynthinou},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=INBO6h9gtG}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492741531, "odate": 1636492741531, "details": {"replyCount": 6}}, {"id": "RX6PrcpXP-", "original": "mWqA_Y43PaO", "number": 4720, "cdate": 1621629935477, "ddate": null, "tcdate": 1621629935477, "tmdate": 1697937571732, "tddate": null, "forum": "RX6PrcpXP-", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Learning with Holographic Reduced Representations", "authorids": ["~Ashwinkumar_Ganesan1", "~Hang_Gao3", "~Sunil_Gandhi1", "~Edward_Raff1", "~Tim_Oates2", "~James_Holt1", "mrmclea@lps.umd.edu"], "authors": ["Ashwinkumar Ganesan", "Hang Gao", "Sunil Gandhi", "Edward Raff", "Tim Oates", "James Holt", "Mark McLean"], "keywords": ["Holographic Reduced Representations", "binding", "neuro-symbolic"], "TL;DR": "An approach to do symbolic AI using vectors from the 90s has been long neglected by ML ressearches, but some careful updates make it applicable to modern use.", "abstract": "Holographic Reduced Representations (HRR) are a method for performing symbolic AI on top of real-valued vectors by associating each vector with an abstract concept, and providing mathematical operations to manipulate vectors as if they were classic symbolic objects. This method has seen little use outside of older symbolic AI work and cognitive science. Our goal is to revisit this approach to understand if it is viable for enabling a hybrid neural-symbolic  approach to learning as a differential component of a deep learning architecture. HRRs today are not effective in a differential solution due to numerical instability, a problem we solve by introducing a projection step that forces the vectors to exist in a well behaved point in space. In doing so we improve the concept retrieval efficacy of HRRs by over $100\\times$. Using multi-label classification we demonstrate how to leverage the symbolic HRR properties to develop a output layer and loss function that is able to learn effectively, and allows us to investigate some of the pros and cons of an HRR neuro-symbolic learning approach. ", "submission_history": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "ganesan|learning_with_holographic_reduced_representations", "pdf": "/pdf/0ce1c221b0cf3953a1e3f354bd01944ac9441cb6.pdf", "supplementary_material": "/attachment/d23cc8c27770dab0d8936b58fcce0d4200a51f2b.pdf", "checklist": "", "code": "https://github.com/NeuromorphicComputationResearchProgram/Learning-with-Holographic-Reduced-Representations", "thumbnail": "", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2109.02157/code)", "_bibtex": "@inproceedings{\nganesan2021learning,\ntitle={Learning with Holographic Reduced Representations},\nauthor={Ashwinkumar Ganesan and Hang Gao and Sunil Gandhi and Edward Raff and Tim Oates and James Holt and Mark McLean},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=RX6PrcpXP-}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492719573, "odate": 1636492719530, "details": {"replyCount": 18}}, {"id": "kpTMw7ZMJB", "original": "tZFE1v33_Qm", "number": 4653, "cdate": 1621629931357, "ddate": null, "tcdate": 1621629931357, "tmdate": 1683307624635, "tddate": null, "forum": "kpTMw7ZMJB", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Supercharging Imbalanced Data Learning With Energy-based Contrastive Representation Transfer", "authorids": ["~Junya_Chen1", "~Zidi_Xiu1", "~Benjamin_Goldstein1", "~Ricardo_Henao1", "~Lawrence_Carin2", "~Chenyang_Tao1"], "authors": ["Junya Chen", "Zidi Xiu", "Benjamin Goldstein", "Ricardo Henao", "Lawrence Carin", "Chenyang Tao"], "keywords": ["imbalanced data learning", "causal representation learning", "rare-event modeling", "contrastive learning"], "abstract": "Dealing with severe class imbalance poses a major challenge for many real-world applications, especially when the accurate classification and generalization of minority classes are of primary interest.\nIn computer vision and NLP, learning from datasets with long-tail behavior is a recurring theme, especially for naturally occurring labels. Existing solutions mostly appeal to sampling or weighting adjustments to alleviate the extreme imbalance, or impose inductive bias to prioritize generalizable associations. Here we take a novel perspective to promote sample efficiency and model generalization based on the invariance principles of causality. Our contribution posits a meta-distributional scenario, where the causal generating mechanism for label-conditional features is invariant across different labels. Such causal assumption enables efficient knowledge transfer from the dominant classes to their under-represented counterparts, even if their feature distributions show apparent disparities. This allows us to leverage a causal data augmentation procedure to enlarge the representation of minority classes. Our development is orthogonal to the existing imbalanced data learning techniques thus can be seamlessly integrated. The proposed approach is validated on an extensive set of synthetic and real-world tasks against state-of-the-art solutions. ", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "chen|supercharging_imbalanced_data_learning_with_energybased_contrastive_representation_transfer", "TL;DR": "We present a new imbalanced data learning model using energy-based contrastive learning for causal representations. ", "pdf": "/pdf/c98834e332787ce17cb50b0538c8132c78f9b62b.pdf", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "checklist": "", "supplementary_material": "/attachment/bf356e8d9168bf48e964aaf266d71421084d0f4f.pdf", "code": "https://github.com/ZidiXiu/ECRT", "thumbnail": "", "_bibtex": "@inproceedings{\nchen2021supercharging,\ntitle={Supercharging Imbalanced Data Learning With Energy-based Contrastive Representation Transfer},\nauthor={Junya Chen and Zidi Xiu and Benjamin Goldstein and Ricardo Henao and Lawrence Carin and Chenyang Tao},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=kpTMw7ZMJB}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492755635, "odate": 1636492755635, "details": {"replyCount": 17}}, {"id": "RQUl8gZnN7O", "original": "KJ-hComFfO", "number": 4611, "cdate": 1621629928838, "ddate": null, "tcdate": 1621629928838, "tmdate": 1697937577387, "tddate": null, "forum": "RQUl8gZnN7O", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Learning to See by Looking at Noise", "authorids": ["~Manel_Baradad1", "~Jonas_Wulff1", "~Tongzhou_Wang1", "~Phillip_Isola1", "~Antonio_Torralba1"], "authors": ["Manel Baradad", "Jonas Wulff", "Tongzhou Wang", "Phillip Isola", "Antonio Torralba"], "keywords": ["unsupervised representation learning", "image generation", "contrastive training", "learning from noise"], "TL;DR": "We study unsupervised representation learning by training with generative image models that do not use real data.", "abstract": "Current vision systems are trained on huge datasets, and these datasets come with costs: curation is expensive, they inherit human biases, and there are concerns over privacy and usage rights. To counter these costs, interest has surged in learning from cheaper data sources, such as unlabeled images. In this paper we go a step further and ask if we can do away with real image datasets entirely, instead learning from procedural noise processes. \nWe investigate a suite of image generation models that produce images from simple random processes. These are then used as training data for a visual representation learner with a contrastive loss. In particular, we study statistical image models, randomly initialized deep generative models, and procedural graphics models.\nOur findings show that it is important for the noise to capture certain structural properties of real data but that good performance can be achieved even with processes that are far from realistic. We also find that diversity is a key property to learn good representations.", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "baradad|learning_to_see_by_looking_at_noise", "pdf": "/pdf/9ac7ee58b994560b74690951bc86a41e2181b5a6.pdf", "checklist": "", "supplementary_material": "/attachment/25515a00acd6455cd9a31f5c7a3787e61c5a6046.pdf", "code": "https://github.com/mbaradad/learning_with_noise", "thumbnail": "", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2106.05963/code)", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nbaradad2021learning,\ntitle={Learning to See by Looking at Noise},\nauthor={Manel Baradad and Jonas Wulff and Tongzhou Wang and Phillip Isola and Antonio Torralba},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=RQUl8gZnN7O}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492701913, "odate": 1636492701913, "details": {"replyCount": 16}}, {"id": "8kk8a_zvWua", "original": "ONUq0xrgR4j", "number": 4597, "cdate": 1621629928006, "ddate": null, "tcdate": 1621629928006, "tmdate": 1697937578828, "tddate": null, "forum": "8kk8a_zvWua", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Excess Capacity and Backdoor Poisoning", "authorids": ["~Naren_Sarayu_Manoj1", "~Avrim_Blum1"], "authors": ["Naren Sarayu Manoj", "Avrim Blum"], "keywords": ["algorithms", "theory", "security", "robustness", "adversarial learning", "adversarial examples"], "TL;DR": "We explore statistical and computational properties of backdoor data poisoning attacks.", "abstract": "A backdoor data poisoning attack is an adversarial attack wherein the attacker injects several watermarked, mislabeled training examples into a training set. The watermark does not impact the test-time performance of the model on typical data; however, the model reliably errs on watermarked examples.\n\nTo gain a better foundational understanding of backdoor data poisoning attacks, we present a formal theoretical framework within which one can discuss backdoor data poisoning attacks for classification problems. We then use this to analyze important statistical and computational issues surrounding these attacks.\n\nOn the statistical front, we identify a parameter we call the memorization capacity that captures the intrinsic vulnerability of a learning problem to a backdoor attack. This allows us to argue about the robustness of several natural learning problems to backdoor attacks. Our results favoring the attacker involve presenting explicit constructions of backdoor attacks, and our robustness results show that some natural problem settings cannot yield successful backdoor attacks.\n\nFrom a computational standpoint, we show that under certain assumptions, adversarial training can detect the presence of backdoors in a training set. We then show that under similar assumptions, two closely related problems we call backdoor filtering and robust generalization are nearly equivalent. This implies that it is both asymptotically necessary and sufficient to design algorithms that can identify watermarked examples in the training set in order to obtain a learning algorithm that both generalizes well to unseen data and is robust to backdoors.", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "manoj|excess_capacity_and_backdoor_poisoning", "pdf": "/pdf/01785325d1939c82e5d2da2815ef7acdb9644d34.pdf", "supplementary_material": "/attachment/4cd0f0b2a5c9f52b274695afc63341c31871306e.pdf", "checklist": "", "code": "https://github.com/narenmanoj/mnist-adv-training", "thumbnail": "", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 4 code implementations](https://www.catalyzex.com/paper/arxiv:2109.00685/code)", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nmanoj2021excess,\ntitle={Excess Capacity and Backdoor Poisoning},\nauthor={Naren Sarayu Manoj and Avrim Blum},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=8kk8a_zvWua}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492756782, "odate": 1636492756782, "details": {"replyCount": 11}}, {"id": "fNKwtwJHjx", "original": "Ga7DBX6SaS", "number": 4484, "cdate": 1621629921114, "ddate": null, "tcdate": 1621629921114, "tmdate": 1683307619975, "tddate": null, "forum": "fNKwtwJHjx", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Random Shuffling Beats SGD Only After Many Epochs on Ill-Conditioned Problems", "authorids": ["~Itay_Safran1", "~Ohad_Shamir1"], "authors": ["Itay Safran", "Ohad Shamir"], "keywords": ["Convex Optimization", "Stochastic Gradient Descent", "Without-Replacement SGD"], "TL;DR": "Tight lower and upper bounds for without-replacement SGD with respect to the condition number.", "abstract": "Recently, there has been much interest in studying the convergence rates of without-replacement SGD, and proving that it is faster than with-replacement SGD in the worst case. However, known lower bounds ignore the problem's geometry, including its condition number, whereas the upper bounds explicitly depend on it. Perhaps surprisingly, we prove that when the condition number is taken into account, without-replacement SGD \\emph{does not} significantly improve on with-replacement SGD in terms of worst-case bounds, unless the number of epochs (passes over the data) is larger than the condition number. Since many problems in machine learning and other areas are both ill-conditioned and involve large datasets, this indicates that without-replacement does not necessarily improve over with-replacement sampling for realistic iteration budgets. We show this by providing new lower and upper bounds which are tight (up to log factors), for quadratic problems with commuting quadratic terms, precisely quantifying the dependence on the problem parameters.", "submission_history": "", "checklist": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "safran|random_shuffling_beats_sgd_only_after_many_epochs_on_illconditioned_problems", "pdf": "/pdf/6914f6249d0ddd23bb7cb399e47e20b6b554433d.pdf", "supplementary_material": "/attachment/7dcbb45a1211758cfd2c79d70d36b7da4ab9170a.pdf", "thumbnail": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nsafran2021random,\ntitle={Random Shuffling Beats {SGD} Only After Many Epochs on Ill-Conditioned Problems},\nauthor={Itay Safran and Ohad Shamir},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=fNKwtwJHjx}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492740870, "odate": 1636492740870, "details": {"replyCount": 16}}, {"id": "Yt89iqqswiM", "original": "wBelRARbV8", "number": 4483, "cdate": 1621629921052, "ddate": null, "tcdate": 1621629921052, "tmdate": 1697937584529, "tddate": null, "forum": "Yt89iqqswiM", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Measuring Generalization with Optimal Transport", "authorids": ["~Ching-Yao_Chuang1", "~Youssef_Mroueh1", "~Kristjan_Greenewald1", "~Antonio_Torralba1", "~Stefanie_Jegelka3"], "authors": ["Ching-Yao Chuang", "Youssef Mroueh", "Kristjan Greenewald", "Antonio Torralba", "Stefanie Jegelka"], "keywords": ["generalization", "optimal transport", "representation"], "TL;DR": "We propose a generalization measure based on optimal transport.", "abstract": "Understanding the generalization of deep neural networks is one of the most important tasks in deep learning. Although much progress has been made, theoretical error bounds still often behave disparately from empirical observations. In this work, we develop margin-based generalization bounds, where the margins are normalized with optimal transport costs between independent random subsets sampled from the training distribution. In particular, the optimal transport cost can be interpreted as a generalization of variance which captures the structural properties of the learned feature space. Our bounds robustly predict the generalization error, given training data and network parameters, on large scale datasets. Theoretically, we demonstrate that the concentration and separation of features play crucial roles in generalization, supporting empirical results in the literature.", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "chuang|measuring_generalization_with_optimal_transport", "pdf": "/pdf/0b59260839c9078b87ccb9cc10d52d06b39eb553.pdf", "supplementary_material": "/attachment/44128345700b4835cd47ac1d5c4e104a814e4ad1.pdf", "checklist": "", "code": "https://github.com/chingyaoc/kV-Margin", "thumbnail": "", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 3 code implementations](https://www.catalyzex.com/paper/arxiv:2106.03314/code)", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nchuang2021measuring,\ntitle={Measuring Generalization with Optimal Transport},\nauthor={Ching-Yao Chuang and Youssef Mroueh and Kristjan Greenewald and Antonio Torralba and Stefanie Jegelka},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=Yt89iqqswiM}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492719696, "odate": 1636492719696, "details": {"replyCount": 13}}, {"id": "fpvUKdqcPV", "original": "cqGC04g6qOZ", "number": 4400, "cdate": 1621629916121, "ddate": null, "tcdate": 1621629916121, "tmdate": 1683307617147, "tddate": null, "forum": "fpvUKdqcPV", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "A Normative and Biologically Plausible Algorithm for Independent Component Analysis", "authorids": ["~Yanis_Bahroun1", "~Dmitri_Chklovskii1", "~Anirvan_M._Sengupta2"], "authors": ["Yanis Bahroun", "Dmitri Chklovskii", "Anirvan M. Sengupta"], "keywords": ["Blind source separation", "independent component analysis", "neural network", "local learning rules", "biologically plausible", "Hebbian learning"], "TL;DR": "A normative approach to independent component analysis leads to the derivation of a biologically plausible neural network with local learning rules. ", "abstract": "The brain effortlessly solves blind source separation (BSS) problems, but the algorithm it uses remains elusive. In signal processing, linear BSS problems are often solved by Independent Component Analysis (ICA). To serve as a model of a biological circuit, the ICA neural network (NN) must satisfy at least the following requirements: 1. The algorithm must operate in the online setting where data samples are streamed one at a time, and the NN computes the sources on the fly without storing any significant fraction of the data in memory. 2. The synaptic weight update is local, i.e., it depends only on the biophysical variables present in the vicinity of a synapse. Here, we propose a novel objective function for ICA from which we derive a biologically plausible NN, including both the neural architecture and the synaptic learning rules. Interestingly, our algorithm relies on modulating synaptic plasticity by the total activity of the output neurons. In the brain, this could be accomplished by neuromodulators, extracellular calcium, local field potential, or nitric oxide. ", "submission_history": "", "checklist": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "bahroun|a_normative_and_biologically_plausible_algorithm_for_independent_component_analysis", "pdf": "/pdf/28df2354231b10a5f8528f43042180ed97b52ad1.pdf", "supplementary_material": "/attachment/1450c37c0c3b8f6890bca714f20ed3e1845b3a63.pdf", "code": "/attachment/abec0282769d96e236596cbc9bf2f562f141bcd4.zip", "thumbnail": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nbahroun2021a,\ntitle={A Normative and Biologically Plausible Algorithm for Independent Component Analysis},\nauthor={Yanis Bahroun and Dmitri Chklovskii and Anirvan M. Sengupta},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=fpvUKdqcPV}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492712301, "odate": 1636492712301, "details": {"replyCount": 23}}, {"id": "BdKxQp0iBi8", "original": "HKcg5JPVmpF", "number": 4355, "cdate": 1621629913432, "ddate": null, "tcdate": 1621629913432, "tmdate": 1683307616575, "tddate": null, "forum": "BdKxQp0iBi8", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Counterfactual Invariance to Spurious Correlations in Text Classification", "authorids": ["~Victor_Veitch1", "~Alexander_D'Amour1", "~Steve_Yadlowsky1", "~Jacob_Eisenstein1"], "authors": ["Victor Veitch", "Alexander D'Amour", "Steve Yadlowsky", "Jacob Eisenstein"], "keywords": ["causality", "spurious correlation", "natural language", "stress test", "domain generalization"], "TL;DR": "Causally formalize \"irrelevant changes to input data shouldn't change predictions\", then derive ways of achieving this and show connections to domain generalization", "abstract": "Informally, a 'spurious correlation' is the dependence of a model on some aspect of the input data that an analyst thinks shouldn't matter. In machine learning, these have a know-it-when-you-see-it character; e.g., changing the gender of a sentence's subject changes a sentiment predictor's output. To check for spurious correlations, we can 'stress test' models by perturbing irrelevant parts of input data and seeing if model predictions change. In this paper, we study stress testing using the tools of causal inference. We introduce counterfactual invariance as a formalization of the requirement that changing irrelevant parts of the input shouldn't change model predictions. We connect counterfactual invariance to out-of-domain model performance, and provide practical schemes for learning (approximately) counterfactual invariant predictors (without access to counterfactual examples). It turns out that both the means and implications of counterfactual invariance depend fundamentally on the true underlying causal structure of the data---in particular, whether the label causes the features or the features cause the label. Distinct causal structures require distinct regularization schemes to induce counterfactual invariance. Similarly, counterfactual invariance implies different domain shift guarantees depending on the underlying causal structure. This theory is supported by empirical results on text classification.", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "veitch|counterfactual_invariance_to_spurious_correlations_in_text_classification", "pdf": "/pdf/a175004dfe933f15ec188126d6483b1a3eb0f3b6.pdf", "supplementary_material": "/attachment/f0acca56dd0df5bd82c0e0e4b52cda73421ada76.pdf", "checklist": "", "thumbnail": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nveitch2021counterfactual,\ntitle={Counterfactual Invariance to Spurious Correlations in Text Classification},\nauthor={Victor Veitch and Alexander D'Amour and Steve Yadlowsky and Jacob Eisenstein},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=BdKxQp0iBi8}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492681004, "odate": 1636492681004, "details": {"replyCount": 13}}, {"id": "6p-zJaheTW", "original": "r0luTCwMkPl", "number": 4335, "cdate": 1621629912121, "ddate": null, "tcdate": 1621629912121, "tmdate": 1683307615742, "tddate": null, "forum": "6p-zJaheTW", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Your head is there to move you around: Goal-driven models of the primate dorsal pathway", "authorids": ["~Patrick_J_Mineault1", "~Shahab_Bakhtiari1", "~Blake_Aaron_Richards1", "~Christopher_C_Pack1"], "authors": ["Patrick J Mineault", "Shahab Bakhtiari", "Blake Aaron Richards", "Christopher C Pack"], "keywords": ["sensory neuroscience", "systems identification", "goal-driven models", "vision neuroscience", "motion processing"], "TL;DR": "3D CNNs on trained on self-motion sequences recapitulate the dorsal visual stream", "abstract": "Neurons in the dorsal visual pathway of the mammalian brain are selective for motion stimuli, with the complexity of stimulus representations increasing along the hierarchy. This progression is similar to that of the ventral visual pathway, which is well characterized by artificial neural networks (ANNs) optimized for object recognition. In contrast, there are no image-computable models of the dorsal stream with comparable explanatory power. We hypothesized that the properties of dorsal stream neurons could be explained by a simple learning objective: the need for an organism to orient itself during self-motion. To test this hypothesis, we trained a 3D ResNet to predict an agent's self-motion parameters from visual stimuli in a simulated environment. We found that the responses in this network accounted well for the selectivity of neurons in a large database of single-neuron recordings from the dorsal visual stream of non-human primates. In contrast, ANNs trained on an action recognition dataset through supervised or self-supervised learning  could not explain responses in the dorsal stream, despite also being trained on naturalistic videos with moving objects. These results demonstrate that an ecologically relevant cost function can account for dorsal stream properties in the primate brain.", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "mineault|your_head_is_there_to_move_you_around_goaldriven_models_of_the_primate_dorsal_pathway", "pdf": "/pdf/7221ecd5ee05c87f7b840ebc3801e70042bb7cae.pdf", "checklist": "", "supplementary_material": "/attachment/04cf107d205898f7c3d99894070586dc9254cc80.pdf", "code": "https://github.com/patrickmineault/your-head-is-there-to-move-you-around", "thumbnail": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nmineault2021your,\ntitle={Your head is there to move you around: Goal-driven models of the primate dorsal pathway},\nauthor={Patrick J Mineault and Shahab Bakhtiari and Blake Aaron Richards and Christopher C Pack},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=6p-zJaheTW}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492758420, "odate": 1636492758420, "details": {"replyCount": 11}}, {"id": "HWshP75OfKR", "original": "z_E1qY2ZeBp", "number": 4315, "cdate": 1621629910884, "ddate": null, "tcdate": 1621629910884, "tmdate": 1697937594019, "tddate": null, "forum": "HWshP75OfKR", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "On Inductive Biases for Heterogeneous Treatment Effect Estimation", "authorids": ["~Alicia_Curth1", "~Mihaela_van_der_Schaar2"], "authors": ["Alicia Curth", "Mihaela van der Schaar"], "keywords": ["heterogeneous treatment effects", "potential outcomes", "causal inference", "counterfactual estimation"], "TL;DR": "We investigate and compare approaches to exploit the structural similarities of potential outcomes for improved heterogeneous treatment effect estimation.", "abstract": "We investigate how to exploit structural similarities of an individual's potential outcomes (POs) under different treatments to obtain better estimates of conditional average treatment effects in finite samples. Especially when it is unknown whether a treatment has an effect at all, it is natural to hypothesize that the POs are similar -- yet, some existing strategies for treatment effect estimation employ regularization schemes that implicitly encourage heterogeneity even when it does not exist and fail to fully make use of shared structure. In this paper, we investigate and compare three end-to-end learning strategies to overcome this problem -- based on regularization, reparametrization and a flexible multi-task architecture -- each encoding inductive bias favoring shared behavior across POs. To build understanding of their relative strengths, we implement all strategies using neural networks and conduct a wide range of semi-synthetic experiments. We observe that all three approaches can lead to substantial improvements upon numerous baselines and gain insight into performance differences across various experimental settings. ", "submission_history": "", "checklist": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "curth|on_inductive_biases_for_heterogeneous_treatment_effect_estimation", "pdf": "/pdf/a0276e5b90ff5f5c9a3ff5f119653a53d0acfb63.pdf", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "supplementary_material": "/attachment/a78f0d2499b7910f8cc176a67e9ab89a2d8e41e2.pdf", "code": "https://github.com/AliciaCurth/CATENets", "thumbnail": "", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 2 code implementations](https://www.catalyzex.com/paper/arxiv:2106.03765/code)", "_bibtex": "@inproceedings{\ncurth2021on,\ntitle={On Inductive Biases for Heterogeneous Treatment Effect Estimation},\nauthor={Alicia Curth and Mihaela van der Schaar},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=HWshP75OfKR}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492762673, "odate": 1636492762673, "details": {"replyCount": 13}}, {"id": "StbpmmlJbH", "original": "WbO0xuaeAsU", "number": 4310, "cdate": 1621629910622, "ddate": null, "tcdate": 1621629910622, "tmdate": 1683307615110, "tddate": null, "forum": "StbpmmlJbH", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Subgame solving without common knowledge", "authorids": ["~Brian_Hu_Zhang1", "~Tuomas_Sandholm1"], "authors": ["Brian Hu Zhang", "Tuomas Sandholm"], "keywords": ["Subgame solving", "imperfect information", "common knowledge"], "abstract": "In imperfect-information games, subgame solving is significantly more challenging than in perfect-information games, but in the last few years, such techniques have been developed. They were the key ingredient to the milestone of superhuman play in no-limit Texas hold'em poker. Current subgame-solving techniques analyze the entire common-knowledge closure of the player's current information set, that is, the smallest set of nodes within which it is common knowledge that the current node lies. While this is acceptable in games like poker where the common-knowledge closure is relatively small, many practical games have more complex information structure, which renders the common-knowledge closure impractically large to enumerate or even reasonably approximate. We introduce an approach that overcomes this obstacle, by instead working with only low-order knowledge. Our approach allows an agent, upon arriving at an infoset, to basically prune any node that is no longer reachable, thereby massively reducing the game tree size relative to the common-knowledge subgame. We prove that, as is, our approach can increase exploitability compared to the blueprint strategy. However, we develop three avenues by which safety can be guaranteed. First, safety is guaranteed if the results of subgame solves are incorporated back into the blueprint. Second, we provide a method where safety is achieved by limiting the infosets at which subgame solving is performed. Third, we prove that our approach, when applied at every infoset reached during play, achieves a weaker notion of equilibrium, which we coin affine equilibrium, and which may be of independent interest. We show that affine equilibria cannot be exploited by any Nash strategy of the opponent, so an opponent who wishes to exploit must open herself to counter-exploitation. Even without the safety-guaranteeing additions, experiments on medium-sized games show that our approach always reduced exploitability in practical games even when applied at every infoset, and a depth-limited version of it led to---to our knowledge---the first strong AI for the challenge problem dark chess.", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "zhang|subgame_solving_without_common_knowledge", "pdf": "/pdf/0b804501ab227e21bdc97230037ef55cda47acaa.pdf", "checklist": "", "supplementary_material": "/attachment/7d93ea79bfe7312c1590b7cb7635684978f1611a.pdf", "thumbnail": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nzhang2021subgame,\ntitle={Subgame solving without common knowledge},\nauthor={Brian Hu Zhang and Tuomas Sandholm},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=StbpmmlJbH}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492739475, "odate": 1636492739475, "details": {"replyCount": 10}}, {"id": "wvylaMP20_b", "original": "xP4xryEMiWk", "number": 4306, "cdate": 1621629910385, "ddate": null, "tcdate": 1621629910385, "tmdate": 1683307614833, "tddate": null, "forum": "wvylaMP20_b", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Improved Coresets and Sublinear Algorithms for Power Means in Euclidean Spaces", "authorids": ["~Vincent_Cohen-Addad1", "~David_Saulpic1", "~Chris_Schwiegelshohn1"], "authors": ["Vincent Cohen-Addad", "David Saulpic", "Chris Schwiegelshohn"], "keywords": ["Clustering", "sublinear algorithms", "coresets", "sampling"], "TL;DR": "We give an improved algorithms for finding centers with respect to arbitrary powers of Euclidean distances in a big data setting.", "abstract": "In this paper, we consider the problem of finding high dimensional power means: given a set $A$ of $n$ points in $\\R^d$, find the point $m$ that minimizes the sum of Euclidean distance, raised to the power $z$, over all input points. Special cases of problem include the well-known Fermat-Weber problem -- or geometric median problem -- where $z = 1$, the mean or centroid where $z=2$, and the Minimum Enclosing Ball problem, where $z = \\infty$.\n\nWe consider these problem in the big data regime.\nHere, we are interested in sampling as few points as possible such that we can accurately estimate $m$.\nMore specifically, we consider sublinear algorithms as well as coresets for these problems.\nSublinear algorithms have a random query access to the $A$ and the goal is to minimize the number of queries.\nHere, we show that $\\tilde{O}(\\varepsilon^{-z-3})$ samples are sufficient to achieve a $(1+\\varepsilon)$ approximation, generalizing the results from Cohen, Lee, Miller, Pachocki, and Sidford [STOC '16] and Inaba, Katoh, and Imai [SoCG '94] to arbitrary $z$. Moreover, we show that this bound is nearly optimal, as any algorithm requires at least $\\Omega(\\varepsilon^{-z+1})$ queries to achieve said approximation.\n\nThe second contribution are coresets for these problems, where we aim to find find a small, weighted subset of the points which approximate cost of every candidate point $c\\in \\mathbb{R}^d$ up to a $(1\\pm\\varepsilon)$ factor. Here, we show that $\\tilde{O}(\\varepsilon^{-2})$ points are sufficient, improving on the $\\tilde{O}(d\\varepsilon^{-2})$ bound by Feldman and Langberg [STOC '11] and the $\\tilde{O}(\\varepsilon^{-4})$ bound by Braverman, Jiang, Krauthgamer, and Wu [SODA 21].", "submission_history": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "cohenaddad|improved_coresets_and_sublinear_algorithms_for_power_means_in_euclidean_spaces", "pdf": "/pdf/3b805f91810592761d0e5bbc4268c4b9b4aabdf2.pdf", "supplementary_material": "/attachment/540e5a03062580ad4f638049af3ec9b20e09764e.pdf", "checklist": "", "code": "https://github.com/DaSau/power-mean", "thumbnail": "", "_bibtex": "@inproceedings{\ncohen-addad2021improved,\ntitle={Improved Coresets and Sublinear Algorithms for Power Means in Euclidean Spaces},\nauthor={Vincent Cohen-Addad and David Saulpic and Chris Schwiegelshohn},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=wvylaMP20_b}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492705154, "odate": 1636492705154, "details": {"replyCount": 19}}, {"id": "s-NI4H4e3Rf", "original": "f-eSCXyg8oQ", "number": 4293, "cdate": 1621629909694, "ddate": null, "tcdate": 1621629909694, "tmdate": 1683307614663, "tddate": null, "forum": "s-NI4H4e3Rf", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "H-NeRF: Neural Radiance Fields for Rendering and Temporal Reconstruction of Humans in Motion", "authorids": ["~Hongyi_Xu1", "~Thiemo_Alldieck1", "~Cristian_Sminchisescu1"], "authors": ["Hongyi Xu", "Thiemo Alldieck", "Cristian Sminchisescu"], "keywords": ["Neural Radiance Field", "SDF", "Human Reconstruction", "Dynamics"], "TL;DR": "We present neural radiance fields for rendering and temporal (4D) reconstruction of humans in motion (H-NeRF), as captured by a sparse set of cameras or even from a monocular video. ", "abstract": "We present neural radiance fields for rendering and temporal (4D) reconstruction of humans in motion (H-NeRF), as captured by a sparse set of cameras or even from a monocular video. Our approach combines ideas from neural scene representation, novel-view synthesis, and implicit statistical geometric human representations, coupled using novel loss functions. Instead of learning a radiance field with a uniform occupancy prior, we constrain it by a structured implicit human body model, represented using signed distance functions. This allows us to robustly fuse information from sparse views and generalize well beyond the poses or views observed in training. Moreover, we apply geometric constraints to co-learn the structure of the observed subject -- including both body and clothing -- and to regularize the radiance field to geometrically plausible solutions. Extensive experiments on multiple datasets demonstrate the robustness and the accuracy of our approach, its generalization capabilities significantly outside a small training set of poses and views, and statistical extrapolation beyond the observed shape.", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "xu|hnerf_neural_radiance_fields_for_rendering_and_temporal_reconstruction_of_humans_in_motion", "pdf": "/pdf/1f92f7cb3eb30050eaddd6098b33664099963868.pdf", "checklist": "", "supplementary_material": "/attachment/cb0a826a6de0f78a1e35330c2efda48380b93cfc.zip", "thumbnail": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nxu2021hnerf,\ntitle={H-Ne{RF}: Neural Radiance Fields for Rendering and Temporal Reconstruction of Humans in Motion},\nauthor={Hongyi Xu and Thiemo Alldieck and Cristian Sminchisescu},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=s-NI4H4e3Rf}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492681243, "odate": 1636492681243, "details": {"replyCount": 14}}, {"id": "yAvCV6NwWQ", "original": "aXJR39HjkJJ", "number": 4249, "cdate": 1621629906968, "ddate": null, "tcdate": 1621629906968, "tmdate": 1683307613757, "tddate": null, "forum": "yAvCV6NwWQ", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "On Linear Stability of SGD and Input-Smoothness of Neural Networks", "authorids": ["~Chao_Ma8", "~Lexing_Ying1"], "authors": ["Chao Ma", "Lexing Ying"], "keywords": ["Stochastic Gradient Descent", "Implicit regularization", "Linear stability", "Sobolev Seminorm"], "TL;DR": "On Linear Stability of SGD and Input-Smoothness of Neural Networks", "abstract": "The multiplicative structure of parameters and input data in the first layer of neural networks is explored to build connection between the landscape of the loss function with respect to parameters and the landscape of the model function with respect to input data. By this connection, it is shown that flat minima regularize the gradient of the model function, which explains the good generalization performance of flat minima. Then, we go beyond the flatness and consider high-order moments of the gradient noise, and show that Stochastic Gradient Dascent (SGD) tends to impose constraints on these moments by a linear stability analysis of SGD around global minima. Together with the multiplicative structure, we identify the Sobolev regularization effect of SGD, i.e. SGD regularizes the Sobolev seminorms of the model function with respect to the input data. Finally, bounds for generalization error and adversarial robustness are provided for solutions found by SGD under assumptions of the data distribution. ", "pdf": "/pdf/66031c43bc29441b675dcca1d7d745bb5828875e.pdf", "supplementary_material": "/attachment/1102d8bab5d80d1559f1468d06cb34a5f8573f33.pdf", "submission_history": "", "checklist": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "ma|on_linear_stability_of_sgd_and_inputsmoothness_of_neural_networks", "code": "https://github.com/ChaoMa93/Sobolev-Reg-of-SGD", "thumbnail": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nma2021on,\ntitle={On Linear Stability of {SGD} and Input-Smoothness of Neural Networks},\nauthor={Chao Ma and Lexing Ying},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=yAvCV6NwWQ}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492766495, "odate": 1636492766495, "details": {"replyCount": 10}}, {"id": "8V2hZW0d2aS", "original": "s2X5ft6DElD", "number": 4173, "cdate": 1621629902143, "ddate": null, "tcdate": 1621629902143, "tmdate": 1683307611712, "tddate": null, "forum": "8V2hZW0d2aS", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Speedy Performance Estimation for Neural Architecture Search", "authorids": ["~Binxin_Ru1", "~Clare_Lyle1", "~Lisa_Schut2", "~Miroslav_Fil1", "~Mark_van_der_Wilk1", "~Yarin_Gal1"], "authors": ["Binxin Ru", "Clare Lyle", "Lisa Schut", "Miroslav Fil", "Mark van der Wilk", "Yarin Gal"], "keywords": ["neural architecture search", "generalisation", "performance estimation"], "TL;DR": "A simple, cheap, model-free yet reliable performance estimator for ranking architectures", "abstract": "Reliable yet efficient evaluation of generalisation performance of a proposed architecture is crucial to the success of neural architecture search (NAS). Traditional approaches face a variety of limitations: training each architecture to completion is prohibitively expensive, early stopped validation accuracy may correlate poorly with fully trained performance, and model-based estimators require large training sets. We instead propose to estimate the final test performance based on a simple measure of training speed. Our estimator is theoretically motivated by the connection between generalisation and training speed, and is also inspired by the reformulation of a PAC-Bayes bound under the Bayesian setting. Our model-free estimator is simple, efficient, and cheap to implement, and does not require hyperparameter-tuning or surrogate training before deployment. We demonstrate on various NAS search spaces that our estimator consistently outperforms other alternatives in achieving better correlation with the true test performance rankings. We further show that our estimator can be easily incorporated into both query-based and one-shot NAS methods to improve the speed or quality of the search.", "submission_history": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "checklist": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "ru|speedy_performance_estimation_for_neural_architecture_search", "pdf": "/pdf/f0475bf9445e161b5a40a29df2d21275f3c85b96.pdf", "supplementary_material": "/attachment/005c59662817e3358638cfae5cad84997cef62e2.pdf", "code": "https://github.com/rubinxin/TSE", "thumbnail": "", "_bibtex": "@inproceedings{\nru2021speedy,\ntitle={Speedy Performance Estimation for Neural Architecture Search},\nauthor={Binxin Ru and Clare Lyle and Lisa Schut and Miroslav Fil and Mark van der Wilk and Yarin Gal},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=8V2hZW0d2aS}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492705332, "odate": 1636492705332, "details": {"replyCount": 15}}, {"id": "X0ein5pH4YJ", "original": "hpvAmSAuvq", "number": 4159, "cdate": 1621629901246, "ddate": null, "tcdate": 1621629901246, "tmdate": 1697937600742, "tddate": null, "forum": "X0ein5pH4YJ", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "ASSANet: An Anisotropic Separable Set Abstraction for Efficient Point Cloud Representation Learning", "authorids": ["~Guocheng_Qian1", "~Hasan_Abed_Al_Kader_Hammoud1", "~Guohao_Li1", "~Ali_Thabet1", "~Bernard_Ghanem1"], "authors": ["Guocheng Qian", "Hasan Abed Al Kader Hammoud", "Guohao Li", "Ali Thabet", "Bernard Ghanem"], "keywords": ["point cloud", "3D", "neural network", "efficiency"], "TL;DR": "We introduce a novel Anisotropic Separable Set Abstraction module and present ASSANet, a faster and more accurate variant of PointNet++.   ", "abstract": "Access to 3D point cloud representations has been widely facilitated by LiDAR sensors embedded in various mobile devices. This has led to an emerging need for fast and accurate point cloud processing techniques. In this paper, we revisit and dive deeper into PointNet++, one of the most influential yet under-explored networks, and develop faster and more accurate variants of the model. We first present a novel Separable Set Abstraction (SA) module that disentangles the vanilla SA module used in PointNet++ into two separate learning stages: (1) learning channel correlation and (2) learning spatial correlation. The Separable SA module is significantly faster than the vanilla version, yet it achieves comparable performance.  We then introduce a new Anisotropic Reduction function into our Separable SA module and propose an Anisotropic Separable SA (ASSA) module that substantially increases the network's accuracy. We later replace the vanilla SA modules in PointNet++ with the proposed ASSA modules, and denote the modified network as ASSANet. Extensive experiments on point cloud classification, semantic segmentation, and part segmentation show that ASSANet outperforms PointNet++ and other methods, achieving much higher accuracy and faster speeds. In particular, ASSANet outperforms PointNet++ by $7.4$ mIoU on S3DIS Area 5, while maintaining $1.6 \\times $ faster inference speed on a single NVIDIA 2080Ti GPU. Our scaled ASSANet variant achieves $66.8$ mIoU and outperforms KPConv, while being more than $54 \\times$ faster.", "pdf": "/pdf/464072f9c212f13a50e7771e9320bb500d73db56.pdf", "supplementary_material": "/attachment/aa720ce5bce78fd8a320ebc322ca251062e799cb.pdf", "submission_history": "", "checklist": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "qian|assanet_an_anisotropic_separable_set_abstraction_for_efficient_point_cloud_representation_learning", "code": "https://github.com/guochengqian/ASSANet", "thumbnail": "", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2110.10538/code)", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nqian2021assanet,\ntitle={{ASSAN}et: An Anisotropic Separable Set Abstraction for Efficient Point Cloud Representation Learning},\nauthor={Guocheng Qian and Hasan Abed Al Kader Hammoud and Guohao Li and Ali Thabet and Bernard Ghanem},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=X0ein5pH4YJ}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492774150, "odate": 1636492774150, "details": {"replyCount": 13}}, {"id": "ake1XpIrDKN", "original": "BF8Hh_EKfa6", "number": 3997, "cdate": 1621629891677, "ddate": null, "tcdate": 1621629891677, "tmdate": 1683307606521, "tddate": null, "forum": "ake1XpIrDKN", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Variational Inference for Continuous-Time Switching Dynamical Systems", "authorids": ["~Lukas_K\u00f6hs1", "~Bastian_Alt1", "~Heinz_Koeppl1"], "authors": ["Lukas K\u00f6hs", "Bastian Alt", "Heinz Koeppl"], "keywords": ["variational inference", "hybrid processes", "stochastic processes", "continuous time", "stochastic differential equations", "Markov jump processes"], "abstract": "Switching dynamical systems provide a powerful, interpretable modeling framework for inference in time-series data in, e.g., the natural sciences or engineering applications. Since many areas, such as biology or discrete-event systems, are naturally described in continuous time, we present a model based on a Markov jump process modulating a subordinated diffusion process. We provide the exact evolution equations for the prior and posterior marginal densities, the direct solutions of which are however computationally intractable. Therefore, we develop a new continuous-time variational inference algorithm, combining a Gaussian process approximation on the diffusion level with posterior inference for Markov jump processes. By minimizing the path-wise Kullback-Leibler divergence we obtain (i) Bayesian latent state estimates for arbitrary points on the real axis and (ii) point estimates of unknown system parameters, utilizing variational expectation maximization. We extensively evaluate our algorithm under the model assumption and for real-world examples.", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "k\u00f6hs|variational_inference_for_continuoustime_switching_dynamical_systems", "pdf": "/pdf/c4224d7d543d85e63ba4228630d6d46a4fa350ec.pdf", "checklist": "", "supplementary_material": "/attachment/fb07ea37b64a4715ddd667fb5f178bcebd8293bc.pdf", "thumbnail": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nk{\\\"o}hs2021variational,\ntitle={Variational Inference for Continuous-Time Switching Dynamical Systems},\nauthor={Lukas K{\\\"o}hs and Bastian Alt and Heinz Koeppl},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=ake1XpIrDKN}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492769974, "odate": 1636492769931, "details": {"replyCount": 12}}, {"id": "8PA2nX9v_r2", "original": "Zo5F08zaXr7", "number": 3958, "cdate": 1621629889390, "ddate": null, "tcdate": 1621629889390, "tmdate": 1697937611446, "tddate": null, "forum": "8PA2nX9v_r2", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Aligning Pretraining for Detection via Object-Level Contrastive Learning", "authorids": ["~Fangyun_Wei1", "~Yue_Gao6", "~Zhirong_Wu1", "~Han_Hu1", "~Stephen_Lin1"], "authors": ["Fangyun Wei", "Yue Gao", "Zhirong Wu", "Han Hu", "Stephen Lin"], "keywords": ["self-supervsied learning", "object detection", "pretraining"], "abstract": "Image-level contrastive representation learning has proven to be highly effective as a generic model for transfer learning.  Such generality for transfer learning, however, sacrifices specificity if we are interested in a certain downstream task. We argue that this could be sub-optimal and thus advocate a design principle which encourages alignment between the self-supervised pretext task and the downstream task. In this paper, we follow this principle with a pretraining method specifically designed for the task of object detection. We attain alignment in the following three aspects: 1) object-level representations are introduced via selective search bounding boxes as object proposals; 2) the pretraining network architecture incorporates the same dedicated modules used in the detection pipeline (e.g. FPN); 3) the pretraining is equipped with object detection properties such as object-level translation invariance and scale invariance. Our method, called Selective Object COntrastive learning (SoCo), achieves state-of-the-art results for transfer performance on COCO detection using a Mask R-CNN framework. Code is available at https://github.com/hologerry/SoCo.", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "wei|aligning_pretraining_for_detection_via_objectlevel_contrastive_learning", "TL;DR": "We introduce a self-supervised pretraining framework for object detection.", "pdf": "/pdf/b9bfcb33590098920a44c3eb29c32a80149cef0c.pdf", "checklist": "", "supplementary_material": "/attachment/d7060f246a5f4bdcc2e2ab4a7d590722c8dfa4c3.pdf", "code": "https://github.com/hologerry/SoCo", "thumbnail": "", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2106.02637/code)", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nwei2021aligning,\ntitle={Aligning Pretraining for Detection via Object-Level Contrastive Learning},\nauthor={Fangyun Wei and Yue Gao and Zhirong Wu and Han Hu and Stephen Lin},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=8PA2nX9v_r2}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492778453, "odate": 1636492778453, "details": {"replyCount": 12}}, {"id": "Xhj3PdCf4q9", "original": "pKHjch3rN4P", "number": 3942, "cdate": 1621629888393, "ddate": null, "tcdate": 1621629888393, "tmdate": 1683307604855, "tddate": null, "forum": "Xhj3PdCf4q9", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Clustering Effect of Adversarial Robust Models", "authorids": ["~Yang_Bai1", "~Xin_Yan2", "~Yong_Jiang3", "~Shu-Tao_Xia1", "~Yisen_Wang1"], "authors": ["Yang Bai", "Xin Yan", "Yong Jiang", "Shu-Tao Xia", "Yisen Wang"], "keywords": ["Adversarial robust models", "hierarchical clustering effect", "domain adaption tasks"], "abstract": "Adversarial robustness has received increasing attention along with the study of adversarial examples. So far, existing works show that robust models not only obtain robustness against various adversarial attacks but also boost the performance in some downstream tasks. However, the underlying mechanism of adversarial robustness is still not clear. In this paper, we interpret adversarial robustness from the perspective of linear components, and find that there exist some statistical properties for comprehensively robust models. Specifically, robust models show obvious hierarchical clustering effect on their linearized sub-networks, when removing or replacing all non-linear components (e.g., batch normalization, maximum pooling, or activation layers). Based on these observations, we propose a novel understanding of adversarial robustness and apply it on more tasks including domain adaption and robustness boosting. Experimental evaluations demonstrate the rationality and superiority of our proposed clustering strategy. Our code is available at https://github.com/bymavis/Adv_Weight_NeurIPS2021.", "submission_history": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "checklist": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "bai|clustering_effect_of_adversarial_robust_models", "pdf": "/pdf/a2ca93698d4980274afcb77eb99177cd419d965a.pdf", "supplementary_material": "/attachment/5c5aef608050666af9fd339b58cf99054e38b71a.pdf", "TL;DR": "Clustering Effect of (Linearized) Adversarial Robust Models", "code": "https://github.com/bymavis/Adv_Weight_NeurIPS2021", "thumbnail": "", "_bibtex": "@inproceedings{\nbai2021clustering,\ntitle={Clustering Effect of Adversarial Robust Models},\nauthor={Yang Bai and Xin Yan and Yong Jiang and Shu-Tao Xia and Yisen Wang},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=Xhj3PdCf4q9}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492736355, "odate": 1636492736312, "details": {"replyCount": 7}}, {"id": "xwGeq7I4Opv", "original": "qscnzMefW4x", "number": 3933, "cdate": 1621629887905, "ddate": null, "tcdate": 1621629887905, "tmdate": 1683307604415, "tddate": null, "forum": "xwGeq7I4Opv", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Perturbation-based Regret Analysis of Predictive Control in Linear Time Varying Systems", "authorids": ["~Yiheng_Lin1", "~Yang_Hu6", "~Guanya_Shi1", "~Haoyuan_Sun1", "~Guannan_Qu1", "~Adam_Wierman1"], "authors": ["Yiheng Lin", "Yang Hu", "Guanya Shi", "Haoyuan Sun", "Guannan Qu", "Adam Wierman"], "keywords": ["Linear time-varying system", "Online convex optimization", "Predictive control", "Sensitivity analysis"], "abstract": "We study predictive control in a setting where the dynamics are time-varying and linear, and the costs are time-varying and well-conditioned. At each time step, the controller receives the exact predictions of costs, dynamics, and disturbances for the future $k$ time steps. We show that when the prediction window $k$ is sufficiently large, predictive control is input-to-state stable and achieves a dynamic regret of $O(\\lambda^k T)$, where $\\lambda < 1$ is a positive constant. This is the first dynamic regret bound on the predictive control of linear time-varying systems. We also show a variation of predictive control obtains the first competitive bound for the control of linear time-varying systems:  $1 + O(\\lambda^k)$. Our results are derived using a novel proof framework based on a perturbation bound that characterizes how a small change to the system parameters impacts the optimal trajectory.", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "lin|perturbationbased_regret_analysis_of_predictive_control_in_linear_time_varying_systems", "pdf": "/pdf/dfd12c414d7e252cc9bb65c4f821be01a55f0bc7.pdf", "supplementary_material": "/attachment/591dbc69f96ca016296eff55eff73ed5c4e20e85.pdf", "checklist": "", "TL;DR": "We show regret and competitive ratio for predictive control in linear time varying system via a new perturbation analysis.", "thumbnail": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nlin2021perturbationbased,\ntitle={Perturbation-based Regret Analysis of Predictive Control in Linear Time Varying Systems},\nauthor={Yiheng Lin and Yang Hu and Guanya Shi and Haoyuan Sun and Guannan Qu and Adam Wierman},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=xwGeq7I4Opv}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492737418, "odate": 1636492737418, "details": {"replyCount": 11}}, {"id": "U0k2DVAED5", "original": "zIuhdrs6Unc", "number": 3882, "cdate": 1621629884913, "ddate": null, "tcdate": 1621629884913, "tmdate": 1683307603556, "tddate": null, "forum": "U0k2DVAED5", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Width-based Lookaheads with Learnt Base Policies and Heuristics Over the Atari-2600 Benchmark", "authorids": ["~Stefan_O'Toole1", "~Nir_Lipovetzky1", "~Miquel_Ramirez1", "~Adrian_Pearce1"], "authors": ["Stefan O'Toole", "Nir Lipovetzky", "Miquel Ramirez", "Adrian Pearce"], "keywords": ["width based planning", "planning and learning", "online planning", "atari", "planning over simulators"], "abstract": "We propose new width-based planning and learning algorithms inspired from a careful analysis of the design decisions made by previous width-based planners. The algorithms are applied over the Atari-2600 games and our best performing algorithm, Novelty guided Critical Path Learning (N-CPL), outperforms the previously introduced width-based planning and learning algorithms $\\pi$-IW(1), $\\pi$-IW(1)+ and $\\pi$-HIW(n, 1). Furthermore, we present a taxonomy of the Atari-2600 games according to some of their defining characteristics. This analysis of the games provides further insight into the behaviour and performance of the algorithms introduced. Namely, for games with large branching factors, and games with sparse meaningful rewards, N-CPL outperforms $\\pi$-IW, $\\pi$-IW(1)+ and $\\pi$-HIW(n, 1).", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "otoole|widthbased_lookaheads_with_learnt_base_policies_and_heuristics_over_the_atari2600_benchmark", "TL;DR": "We propose new width-based planning and learning algorithms which we apply over the Atari-2600 games.", "pdf": "/pdf/c006a2cf5f8ae9c9c67396a98f6d2881e79e69ed.pdf", "checklist": "", "supplementary_material": "/attachment/3befeb45b376d6b34335fc737cd35e8f1a4362eb.pdf", "code": "https://github.com/stefanotoole/N-CPL", "thumbnail": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\no'toole2021widthbased,\ntitle={Width-based Lookaheads with Learnt Base Policies and Heuristics Over the Atari-2600 Benchmark},\nauthor={Stefan O'Toole and Nir Lipovetzky and Miquel Ramirez and Adrian Pearce},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=U0k2DVAED5}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492743324, "odate": 1636492743324, "details": {"replyCount": 16}}, {"id": "te8iyHjbPQd", "original": "y5-9DnEpb6P", "number": 3878, "cdate": 1621629884665, "ddate": null, "tcdate": 1621629884665, "tmdate": 1683307603151, "tddate": null, "forum": "te8iyHjbPQd", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Understanding the Under-Coverage Bias in Uncertainty Estimation", "authorids": ["~Yu_Bai1", "~Song_Mei1", "~Huan_Wang1", "~Caiming_Xiong1"], "authors": ["Yu Bai", "Song Mei", "Huan Wang", "Caiming Xiong"], "keywords": ["Under-coverage bias", "uncertainty estimation", "quantile regression", "learning theory"], "abstract": "Estimating the data uncertainty in regression tasks is often done by learning a quantile function or a prediction interval of the true label conditioned on the input. It is frequently observed that quantile regression---a vanilla algorithm for learning quantiles with asymptotic guarantees---tends to *under-cover* than the desired coverage level in reality. While various fixes have been proposed, a more fundamental understanding of why this under-coverage bias happens in the first place remains elusive.\nIn this paper, we present a rigorous theoretical study on the coverage of uncertainty estimation algorithms in learning quantiles. We prove that quantile regression suffers from an inherent under-coverage bias, in a vanilla setting where we learn a realizable linear quantile function and there is more data than parameters. More quantitatively, for $\\alpha>0.5$ and small $d/n$, the $\\alpha$-quantile learned by quantile regression roughly achieves coverage $\\alpha - (\\alpha-1/2)\\cdot d/n$ regardless of the noise distribution, where $d$ is the input dimension and $n$ is the number of training data. Our theory reveals that this under-coverage bias stems from a certain high-dimensional parameter estimation error that is not implied by existing theories on quantile regression. Experiments on simulated and real data verify our theory and further illustrate the effect of various factors such as sample size and model capacity on the under-coverage bias in more practical setups.", "submission_history": "", "checklist": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "bai|understanding_the_undercoverage_bias_in_uncertainty_estimation", "TL;DR": "We prove that quantile regression exhibits an inherent under-coverage bias, even in well-specified linear models.", "pdf": "/pdf/7978290c43b77100ce95b4002c9f928d33ada792.pdf", "supplementary_material": "/attachment/e2daa48b6863addf193deef5767bc937b13e5e76.pdf", "code": "/attachment/9efb1f4d5a2347e6a7047ff7f2ab0daf2bbc75d9.zip", "thumbnail": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nbai2021understanding,\ntitle={Understanding the Under-Coverage Bias in Uncertainty Estimation},\nauthor={Yu Bai and Song Mei and Huan Wang and Caiming Xiong},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=te8iyHjbPQd}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492781500, "odate": 1636492781500, "details": {"replyCount": 9}}, {"id": "prVxS4W_ds", "original": "PcDCvZ8rrR4", "number": 3817, "cdate": 1621629880978, "ddate": null, "tcdate": 1621629880978, "tmdate": 1683307601189, "tddate": null, "forum": "prVxS4W_ds", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Near-Optimal Lower Bounds For Convex Optimization For All Orders of Smoothness", "authorids": ["~Ankit_Garg1", "~Robin_Kothari1", "~Praneeth_Netrapalli1", "~Suhail_Sherif1"], "authors": ["Ankit Garg", "Robin Kothari", "Praneeth Netrapalli", "Suhail Sherif"], "keywords": ["Convex optimization", "Oracle complexity", "Lower bounds", "Acceleration"], "TL;DR": "We prove near optimal lower bounds for $p^{\\textrm{th}}$ order smooth convex optimization for any $p \\geq 1$ for both randomized and quantum algorithms.", "abstract": "We study the complexity of optimizing highly smooth convex functions. For a positive integer $p$, we want to find an $\\epsilon$-approximate minimum of a convex function $f$, given oracle access to the function and its first $p$ derivatives, assuming that the $p$th derivative of $f$ is Lipschitz.\n \nRecently, three independent research groups (Jiang et al., PLMR 2019; Gasnikov et al., PLMR 2019; Bubeck et al., PLMR 2019) developed a new algorithm that solves this problem with $\\widetilde{O}\\left(1/\\epsilon^{\\frac{2}{3p+1}}\\right)$ oracle calls for constant $p$. This is known to be optimal (up to log factors) for deterministic algorithms, but known lower bounds for randomized algorithms do not match this bound. We prove a new lower bound that matches this bound (up to log factors), and holds not only for randomized algorithms, but also for quantum algorithms.\n", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "garg|nearoptimal_lower_bounds_for_convex_optimization_for_all_orders_of_smoothness", "pdf": "/pdf/55e9fcf72944bc2d15568c254db468f11b4c397b.pdf", "supplementary_material": "/attachment/d3eba8dda5325264e4f03846d1f29aa8a529bdf7.pdf", "checklist": "", "code": "/attachment/c87e1605d7755d602fd286f540bf13c658652d71.zip", "thumbnail": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\ngarg2021nearoptimal,\ntitle={Near-Optimal Lower Bounds For Convex Optimization For All Orders of Smoothness},\nauthor={Ankit Garg and Robin Kothari and Praneeth Netrapalli and Suhail Sherif},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=prVxS4W_ds}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492750728, "odate": 1636492750728, "details": {"replyCount": 9}}, {"id": "UQsbDkuGM0N", "original": "G5Igy2M0-G", "number": 3754, "cdate": 1621629877154, "ddate": null, "tcdate": 1621629877154, "tmdate": 1683307600213, "tddate": null, "forum": "UQsbDkuGM0N", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "iFlow: Numerically Invertible Flows for Efficient Lossless Compression via a Uniform Coder", "authorids": ["~Shifeng_Zhang5", "~Ning_Kang2", "~Tom_Ryder1", "~Zhenguo_Li1"], "authors": ["Shifeng Zhang", "Ning Kang", "Tom Ryder", "Zhenguo Li"], "keywords": ["lossless compression", "flow model", "entropy coder", "deep generative model"], "abstract": "It was estimated that the world produced $59 ZB$ ($5.9 \\times 10^{13} GB$) of data in 2020, resulting in the enormous costs of both data storage and transmission. Fortunately, recent advances in deep generative models have spearheaded a new class of so-called \"neural compression\" algorithms, which significantly outperform traditional codecs in terms of compression ratio. Unfortunately, the application of neural compression garners little commercial interest due to its limited bandwidth; therefore, developing highly efficient frameworks is of critical practical importance. In this paper, we discuss lossless compression using normalizing flows which have demonstrated a great capacity for achieving high compression ratios. As such, we introduce iFlow, a new method for achieving efficient lossless compression. We first propose Modular Scale Transform (MST) and a novel family of numerically invertible flow transformations based on MST. Then we introduce the Uniform Base Conversion System (UBCS), a fast uniform-distribution codec incorporated into iFlow, enabling efficient compression. iFlow achieves state-of-the-art compression ratios and is $5 \\times$ quicker than other high-performance schemes. Furthermore, the techniques presented in this paper can be used to accelerate coding time for a broad class of flow-based algorithms. ", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "zhang|iflow_numerically_invertible_flows_for_efficient_lossless_compression_via_a_uniform_coder", "pdf": "/pdf/e72b6ba93551974cbefb56ddc5fc60911f5493be.pdf", "checklist": "", "supplementary_material": "/attachment/e6af24e406c13d518a16f249b58adc902d06aa27.pdf", "thumbnail": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nzhang2021iflow,\ntitle={iFlow: Numerically Invertible Flows for Efficient Lossless Compression via a Uniform Coder},\nauthor={Shifeng Zhang and Ning Kang and Tom Ryder and Zhenguo Li},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=UQsbDkuGM0N}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492760630, "odate": 1636492760630, "details": {"replyCount": 19}}, {"id": "cSVl6MtPIEX", "original": "AaHeS16YDLW", "number": 3728, "cdate": 1621629875589, "ddate": null, "tcdate": 1621629875589, "tmdate": 1683307599801, "tddate": null, "forum": "cSVl6MtPIEX", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Uniform Concentration Bounds toward a Unified  Framework for Robust Clustering", "authorids": ["~Debolina_Paul1", "~Saptarshi_Chakraborty1", "~Swagatam_Das2", "~Jason_Xu1"], "authors": ["Debolina Paul", "Saptarshi Chakraborty", "Swagatam Das", "Jason Xu"], "keywords": ["k-means", "median of means", "metric entropy bounds", "Bregman divergences", "Iterative optimization"], "TL;DR": "A robust clustering framework based on median-of-means estimation that unifies and extends several popular approaches and yields new theoretical guarantees", "abstract": "Recent advances in center-based clustering continue to improve upon the drawbacks of Lloyd's celebrated $k$-means algorithm over $60$ years after its introduction. Various methods seek to address poor local minima, sensitivity to outliers, and data that are not well-suited to Euclidean measures of fit, but many are supported largely empirically. Moreover, combining such approaches in a piecemeal manner can result in ad hoc methods, and the limited theoretical results supporting each individual contribution may no longer hold. Toward addressing these issues in a principled way, this paper proposes a cohesive robust framework for center-based clustering under a general class of dissimilarity measures. In particular, we present a rigorous theoretical treatment within a Median-of-Means (MoM) estimation framework, showing that it subsumes several popular $k$-means variants. In addition to unifying existing methods, we derive uniform concentration bounds that complete their analyses, and bridge these results to the MoM framework via Dudley's chaining arguments. Importantly, we neither require any assumptions on the distribution of the outlying observations nor on the relative number of observations $n$ to features $p$. We establish strong consistency and an error rate of $O(n^{-1/2})$ under mild conditions, surpassing the best-known results in the literature. The methods are empirically validated thoroughly on real and synthetic datasets. ", "submission_history": "", "checklist": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "paul|uniform_concentration_bounds_toward_a_unified_framework_for_robust_clustering", "pdf": "/pdf/453f82f5781b7ab06f4b1abdf295f913a9c0492a.pdf", "supplementary_material": "/attachment/ffe16249c1fdd38ef31675ef5202d307a66cce9b.pdf", "thumbnail": "", "code": "/attachment/afbb7eb33f6890c42335e0a8f6af28ce792ec4ed.zip", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\npaul2021uniform,\ntitle={Uniform Concentration Bounds toward a Unified  Framework for Robust Clustering},\nauthor={Debolina Paul and Saptarshi Chakraborty and Swagatam Das and Jason Xu},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=cSVl6MtPIEX}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492727020, "odate": 1636492727020, "details": {"replyCount": 9}}, {"id": "KRODJAa6pzE", "original": "tzbd9-a0rU_", "number": 3700, "cdate": 1621629873880, "ddate": null, "tcdate": 1621629873880, "tmdate": 1697937622172, "tddate": null, "forum": "KRODJAa6pzE", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "A Geometric Analysis of Neural Collapse with Unconstrained Features", "authorids": ["~Zhihui_Zhu1", "~Tianyu_DING2", "~Jinxin_Zhou1", "~Xiao_Li8", "~Chong_You2", "~Jeremias_Sulam1", "~Qing_Qu2"], "authors": ["Zhihui Zhu", "Tianyu DING", "Jinxin Zhou", "Xiao Li", "Chong You", "Jeremias Sulam", "Qing Qu"], "keywords": ["neural collapse", "nonconvex optimization", "low-dimensional model"], "abstract": "We provide the first global optimization landscape analysis of Neural Collapse -- an intriguing empirical phenomenon that arises in the last-layer classifiers and features of neural networks during the terminal phase of training. As recently reported by Papyan et al., this phenomenon implies that (i) the class means and the last-layer classifiers all collapse to the vertices of a Simplex Equiangular Tight Frame (ETF) up to scaling, and (ii) cross-example within-class variability of last-layer activations collapses to zero. We study the problem based on a simplified unconstrained feature model, which isolates the topmost layers from the classifier of the neural network. In this context, we show that the classical cross-entropy loss with weight decay has a benign global landscape, in the sense that the only global minimizers are the Simplex ETFs while all other critical points are strict saddles whose Hessian exhibit negative curvature directions. Our analysis of the simplified model not only explains what kind of features are learned in the last layer, but also shows why they can be efficiently optimized, matching the empirical observations in practical deep network architectures. These findings provide important practical implications. As an example, our experiments demonstrate that one may set the feature dimension equal to the number of classes and fix the last-layer classifier to be a Simplex ETF for network training, which reduces memory cost by over 20% on ResNet18 without sacrificing the generalization performance. The source code is available at https://github.com/tding1/Neural-Collapse.", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "zhu|a_geometric_analysis_of_neural_collapse_with_unconstrained_features", "pdf": "/pdf/6bc0236c128430d08e6d591fd5ac259fdb0a1ffa.pdf", "checklist": "", "supplementary_material": "/attachment/bf5553ae78bb2dbd823cf0eb37b551c9f910fb97.pdf", "code": "https://github.com/tding1/Neural-Collapse", "thumbnail": "", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2105.02375/code)", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nzhu2021a,\ntitle={A Geometric Analysis of Neural Collapse with Unconstrained Features},\nauthor={Zhihui Zhu and Tianyu DING and Jinxin Zhou and Xiao Li and Chong You and Jeremias Sulam and Qing Qu},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=KRODJAa6pzE}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492738882, "odate": 1636492738882, "details": {"replyCount": 16}}, {"id": "dkw9OQMn1t", "original": "VQoOR3Owfat", "number": 3694, "cdate": 1621629873522, "ddate": null, "tcdate": 1621629873522, "tmdate": 1683307598741, "tddate": null, "forum": "dkw9OQMn1t", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Refining Language Models with Compositional Explanations", "authorids": ["~Huihan_Yao1", "~Ying_Chen8", "~Qinyuan_Ye1", "~Xisen_Jin3", "~Xiang_Ren1"], "authors": ["Huihan Yao", "Ying Chen", "Qinyuan Ye", "Xisen Jin", "Xiang Ren"], "keywords": ["Natural language processing", "language model", "explanation-based learning", "spurious patterns", "post-hoc model explanation"], "abstract": "Pre-trained language models have been successful on text classification tasks, but are prone to learning spurious correlations from biased datasets, and are thus vulnerable when making inferences in a new domain. Prior work reveals such spurious patterns via post-hoc explanation algorithms which compute the importance of input features. Further, the model is regularized to align the importance scores with human knowledge, so that the unintended model behaviors are eliminated. However, such a regularization technique lacks flexibility and coverage, since only importance scores towards a pre-defined list of features are adjusted, while more complex human knowledge such as feature interaction and pattern generalization can hardly be incorporated. In this work, we propose to refine a learned language model for a target domain by collecting human-provided compositional explanations regarding observed biases. By parsing these explanations into executable logic rules, the human-specified refinement advice from a small set of explanations can be generalized to more training examples. We additionally introduce a regularization term allowing adjustments for both importance and interaction of features to better rectify model behavior. We demonstrate the effectiveness of the proposed approach on two text classification tasks by showing improved performance in target domain as well as improved model fairness after refinement.", "submission_history": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "yao|refining_language_models_with_compositional_explanations", "pdf": "/pdf/6eab680dabac7696c2baaa8e95c804d1c90f7611.pdf", "checklist": "", "supplementary_material": "/attachment/f2b852287dafac090ed7aa4ad0c57dd8726956a7.pdf", "code": "https://github.com/INK-USC/expl-refinement", "thumbnail": "", "_bibtex": "@inproceedings{\nyao2021refining,\ntitle={Refining Language Models with Compositional Explanations},\nauthor={Huihan Yao and Ying Chen and Qinyuan Ye and Xisen Jin and Xiang Ren},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=dkw9OQMn1t}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492731146, "odate": 1636492731146, "details": {"replyCount": 16}}, {"id": "6tM849_6RF9", "original": "kzVVB5s1_J", "number": 3680, "cdate": 1621629872647, "ddate": null, "tcdate": 1621629872647, "tmdate": 1683307598195, "tddate": null, "forum": "6tM849_6RF9", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Believe What You See: Implicit Constraint Approach for Offline Multi-Agent Reinforcement Learning", "authorids": ["~Yiqin_Yang1", "~Xiaoteng_Ma1", "~Chenghao_Li1", "~Zewu_Zheng2", "~Qiyuan_Zhang1", "~Gao_Huang1", "~Jun_Yang6", "~Qianchuan_Zhao1"], "authors": ["Yiqin Yang", "Xiaoteng Ma", "Chenghao Li", "Zewu Zheng", "Qiyuan Zhang", "Gao Huang", "Jun Yang", "Qianchuan Zhao"], "keywords": ["Extrapolation Error", "Offline Reinforcement Learning", "Multi-Agent Reinforcement Learning"], "TL;DR": "The first study analyzing and addressing the extrapolation error in multi-agent reinforcement learning.", "abstract": "Learning from datasets without interaction with environments (Offline Learning) is an essential step to apply Reinforcement Learning (RL) algorithms in real-world scenarios.\tHowever, compared with the single-agent counterpart, offline multi-agent RL introduces more agents with the larger state and action space, which is more challenging but attracts little attention. We demonstrate current offline RL algorithms are ineffective in multi-agent systems due to the accumulated extrapolation error. In this paper, we propose a novel offline RL algorithm, named Implicit Constraint Q-learning (ICQ), which effectively alleviates the extrapolation error by only trusting the state-action pairs given in the dataset for value estimation.  Moreover, we extend ICQ to multi-agent tasks by decomposing the joint-policy under the implicit constraint.  Experimental results demonstrate that the extrapolation error is successfully controlled within a reasonable range and insensitive to the number of agents. We further show that ICQ achieves the state-of-the-art performance in the challenging multi-agent offline tasks (StarCraft II). Our code is public online at https://github.com/YiqinYang/ICQ.", "submission_history": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "yang|believe_what_you_see_implicit_constraint_approach_for_offline_multiagent_reinforcement_learning", "pdf": "/pdf/1abfb071e9c1450e756c38da0ae48674fd96fc07.pdf", "checklist": "", "supplementary_material": "/attachment/175cd46b1adf549a36e2aa1cdc3daeebbd5a0394.zip", "thumbnail": "", "_bibtex": "@inproceedings{\nyang2021believe,\ntitle={Believe What You See: Implicit Constraint Approach for Offline Multi-Agent Reinforcement Learning},\nauthor={Yiqin Yang and Xiaoteng Ma and Chenghao Li and Zewu Zheng and Qiyuan Zhang and Gao Huang and Jun Yang and Qianchuan Zhao},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=6tM849_6RF9}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492684441, "odate": 1636492684394, "details": {"replyCount": 23}}, {"id": "mPTfR3Upe0o", "original": "EONa53BprCM", "number": 3587, "cdate": 1621629867020, "ddate": null, "tcdate": 1621629867020, "tmdate": 1697937627476, "tddate": null, "forum": "mPTfR3Upe0o", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Generic Neural Architecture Search via Regression", "authorids": ["~Yuhong_Li2", "~Cong_Hao2", "~Pan_Li2", "~Jinjun_Xiong1", "~Deming_Chen1"], "authors": ["Yuhong Li", "Cong Hao", "Pan Li", "Jinjun Xiong", "Deming Chen"], "keywords": ["neural architecture search", "convolutional neural network", "self-supervised learning"], "TL;DR": "We present GenNAS, a generic self-supervised, regression-based, few-shot neural architecture evaluator.", "abstract": "Most existing neural architecture search (NAS) algorithms are dedicated to and evaluated by the downstream tasks, e.g., image classification in computer vision. However, extensive experiments have shown that, prominent neural architectures, such as ResNet in computer vision and LSTM in natural language processing, are generally good at extracting patterns from the input data and perform well on different downstream tasks. In this paper, we attempt to answer two fundamental questions related to NAS. (1) Is it necessary to use the performance of specific downstream tasks to evaluate and search for good neural architectures? (2) Can we perform NAS effectively and efficiently while being agnostic to the downstream tasks? To answer these questions, we propose a novel and generic NAS framework, termed Generic NAS (GenNAS). GenNAS does not use task-specific labels but instead adopts regression on a set of manually designed synthetic signal bases for architecture evaluation. Such a self-supervised regression task can effectively evaluate the intrinsic power of an architecture to capture and transform the input signal patterns, and allow more sufficient usage of training samples. Extensive experiments across 13 CNN search spaces and one NLP space demonstrate the remarkable efficiency of GenNAS using regression, in terms of both evaluating the neural architectures (quantified by the ranking correlation Spearman's rho between the approximated performances and the downstream task performances) and the convergence speed for training (within a few seconds). For example, on NAS-Bench-101, GenNAS achieves 0.85 rho while the existing efficient methods only achieve 0.38. We then propose an automatic task search to optimize the combination of synthetic signals using limited downstream-task-specific labels, further improving the performance of GenNAS. We also thoroughly evaluate GenNAS's generality and end-to-end NAS performance on all search spaces, which outperforms almost all existing works with significant speedup. For example, on NASBench-201, GenNAS can find near-optimal architectures within 0.3 GPU hour.", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "li|generic_neural_architecture_search_via_regression", "pdf": "/pdf/642abc9dc8ff76f9e13ec598b01f87a1a597c461.pdf", "checklist": "", "supplementary_material": "/attachment/84984956f7f2c582121db0d942ea4e7b8c9ad698.pdf", "code": "https://github.com/leeyeehoo/GenNAS", "thumbnail": "", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 6 code implementations](https://www.catalyzex.com/paper/arxiv:2108.01899/code)", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nli2021generic,\ntitle={Generic Neural Architecture Search via Regression},\nauthor={Yuhong Li and Cong Hao and Pan Li and Jinjun Xiong and Deming Chen},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=mPTfR3Upe0o}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492692181, "odate": 1636492692181, "details": {"replyCount": 30}}, {"id": "_vypaVMDs51", "original": "ri2ucEkeLQ", "number": 3556, "cdate": 1621629865142, "ddate": null, "tcdate": 1621629865142, "tmdate": 1683307594610, "tddate": null, "forum": "_vypaVMDs51", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Explaining heterogeneity in medial entorhinal cortex with task-driven neural networks", "authorids": ["~Aran_Nayebi2", "~Alexander_Attinger1", "mgcampb@fas.harvard.edu", "kiahhardcastle@gmail.com", "ilow@stanford.edu", "caitlinmallory@berkeley.edu", "meldefon@stanford.edu", "~Ben_Sorscher1", "~Alex_H_Williams1", "sganguli@fb.com", "~Lisa_Giocomo1", "~Daniel_LK_Yamins1"], "authors": ["Aran Nayebi", "Alexander Attinger", "Malcolm G. Campbell", "Kiah Hardcastle", "Isabel I. C. Low", "Caitlin S. Mallory", "Gabriel Carreira Mel", "Ben Sorscher", "Alex H Williams", "Surya Ganguli", "Lisa Giocomo", "Daniel LK Yamins"], "keywords": ["neural coding", "medial entorhinal cortex", "grid cells", "biologically-inspired navigation", "path integration", "recurrent neural networks"], "abstract": "Medial entorhinal cortex (MEC) supports a wide range of navigational and memory related behaviors.\nWell-known experimental results have revealed specialized cell types in MEC --- e.g. grid, border, and head-direction cells --- whose highly stereotypical response profiles are suggestive of the role they might play in supporting MEC functionality. \nHowever, the majority of MEC neurons do not exhibit stereotypical firing patterns.\nHow should the response profiles of these more \"heterogeneous\" cells be described, and how do they contribute to behavior?\nIn this work, we took a computational approach to addressing these questions.\nWe first performed a statistical analysis that shows that heterogeneous MEC cells are just as reliable in their response patterns as the more stereotypical cell types, suggesting that they have a coherent functional role.\nNext, we evaluated a spectrum of candidate models in terms of their ability to describe the response profiles of both stereotypical and heterogeneous MEC cells.\nWe found that recently developed task-optimized neural network models are substantially better than traditional grid cell-centric models at matching most MEC neuronal response profiles --- including those of grid cells themselves --- despite not being explicitly trained for this purpose.\nSpecific choices of network architecture (such as gated nonlinearities and an explicit intermediate place cell representation) have an important effect on the ability of the model to generalize to novel scenarios, with the best of these models closely approaching the noise ceiling of the data itself.\nWe then performed in silico experiments on this model to address questions involving the relative functional relevance of various cell types, finding that heterogeneous cells are likely to be just as involved in downstream functional outcomes (such as path integration) as grid and border cells.\nFinally, inspired by recent data showing that, going beyond their spatial response selectivity, MEC cells are also responsive to non-spatial rewards, we introduce a new MEC model that performs reward-modulated path integration.\nWe find that this unified model matches neural recordings across all variable-reward conditions.\nTaken together, our results point toward a conceptually principled goal-driven modeling approach for moving future experimental and computational efforts beyond overly-simplistic single-cell stereotypes.", "submission_history": "", "checklist": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "nayebi|explaining_heterogeneity_in_medial_entorhinal_cortex_with_taskdriven_neural_networks", "TL;DR": "Our specific findings suggest that task-driven RNNs with certain architectural motifs effectively explain neural responses in medial entorhinal cortex (MEC), and that heterogeneous cells may play an important role in MEC-mediated animal behaviors.", "pdf": "/pdf/83c988970fb39c6263bc9a1805d7c4581cbdda8b.pdf", "supplementary_material": "/attachment/c4fa437c389f0d2a537ce94c7796c7293b940dbc.pdf", "code": "https://github.com/neuroailab/mec", "thumbnail": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nnayebi2021explaining,\ntitle={Explaining heterogeneity in medial entorhinal cortex with task-driven neural networks},\nauthor={Aran Nayebi and Alexander Attinger and Malcolm G. Campbell and Kiah Hardcastle and Isabel I. C. Low and Caitlin S. Mallory and Gabriel Carreira Mel and Ben Sorscher and Alex H Williams and Surya Ganguli and Lisa Giocomo and Daniel LK Yamins},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=_vypaVMDs51}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492672885, "odate": 1636492672885, "details": {"replyCount": 20}}, {"id": "Q32U7dzWXpc", "original": "f26LY9Cu_uX", "number": 3546, "cdate": 1621629864603, "ddate": null, "tcdate": 1621629864603, "tmdate": 1697937630039, "tddate": null, "forum": "Q32U7dzWXpc", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "A Minimalist Approach to Offline Reinforcement Learning", "authorids": ["~Scott_Fujimoto1", "~Shixiang_Gu1"], "authors": ["Scott Fujimoto", "Shixiang Gu"], "keywords": ["Deep Reinforcement Learning", "Offline Reinforcement Learning"], "TL;DR": "We modify TD3 with a BC term naively and find it can outperform SOTA offline RL algorithms.  ", "abstract": "Offline reinforcement learning (RL) defines the task of learning from a fixed batch of data. Due to errors in value estimation from out-of-distribution actions, most offline RL algorithms take the approach of constraining or regularizing the policy with the actions contained in the dataset. Built on pre-existing RL algorithms, modifications to make an RL algorithm work offline comes at the cost of additional complexity. Offline RL algorithms introduce new hyperparameters and often leverage secondary components such as generative models, while adjusting the underlying RL algorithm. In this paper we aim to make a deep RL algorithm work while making minimal changes. We find that we can match the performance of state-of-the-art offline RL algorithms by simply adding a behavior cloning term to the policy update of an online RL algorithm and normalizing the data. The resulting algorithm is a simple to implement and tune baseline, while more than halving the overall run time by removing the additional computational overheads of previous methods. ", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "fujimoto|a_minimalist_approach_to_offline_reinforcement_learning", "pdf": "/pdf/09e05b0b4d470cc6ffd9ec957e0aa058a4c2d89b.pdf", "checklist": "", "supplementary_material": "/attachment/9db1f96590c9af5416c708e9ec5ddd55d6c60df8.pdf", "code": "https://github.com/sfujim/TD3_BC", "thumbnail": "", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 5 code implementations](https://www.catalyzex.com/paper/arxiv:2106.06860/code)", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nfujimoto2021a,\ntitle={A Minimalist Approach to Offline Reinforcement Learning},\nauthor={Scott Fujimoto and Shixiang Gu},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=Q32U7dzWXpc}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492755987, "odate": 1636492755987, "details": {"replyCount": 11}}, {"id": "16r0qOLv_2i", "original": "ecxtuYj_Vko", "number": 3533, "cdate": 1621629863801, "ddate": null, "tcdate": 1621629863801, "tmdate": 1683307594052, "tddate": null, "forum": "16r0qOLv_2i", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Lower and Upper Bounds on the Pseudo-Dimension of Tensor Network Models", "authorids": ["~Behnoush_Khavari1", "~Guillaume_Rabusseau1"], "authors": ["Behnoush Khavari", "Guillaume Rabusseau"], "keywords": ["Statistical Learning Theory", "Tensor Networks", "Generalization Bound", "VC dimension", "Tensor Decomposition Techniques", "Tensor Train", "Tensor Ring"], "TL;DR": "We derive lower and upper bounds on the VC and pseudo-dimension of tensor network models for classifcation, regression and completion.", "abstract": "Tensor network methods have been a key ingredient of advances in condensed matter physics and have recently sparked interest in the machine learning community for their ability to compactly represent very high-dimensional objects. Tensor network methods can for example be used to efficiently learn linear models in exponentially large feature spaces [Stoudenmire and Schwab, 2016]. In this work, we derive upper and lower bounds on the VC dimension and pseudo-dimension of a large class of tensor network models for classification, regression and completion. Our upper bounds hold for linear models parameterized by arbitrary tensor network structures, and we derive lower bounds for common  tensor decomposition models~(CP, Tensor Train, Tensor Ring and Tucker) showing the tightness of our general upper bound. These results are used to derive a generalization bound which can be applied to classification with low rank matrices as well as linear classifiers based on any of the commonly used tensor decomposition models. As a corollary of our results, we obtain a bound on the VC dimension of the matrix product state classifier introduced in [Stoudenmire and Schwab, 2016] as a function of the so-called bond dimension~(i.e. tensor train rank), which  answers an open problem listed by Cirac, Garre-Rubio and P\u00e9rez-Garc\u00eda in [Cirac et al., 2019].", "submission_history": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "checklist": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "khavari|lower_and_upper_bounds_on_the_pseudodimension_of_tensor_network_models", "pdf": "/pdf/fbde735abdc5705f7798a53dd0257628fbbbdd48.pdf", "supplementary_material": "/attachment/9e5b2c33a4bf9b73628702e6d718c9182d4adf9c.pdf", "code": "/attachment/79b4929ec5b5c86db0430ccaf49cea0a17734612.zip", "thumbnail": "", "_bibtex": "@inproceedings{\nkhavari2021lower,\ntitle={Lower and Upper Bounds on the Pseudo-Dimension of Tensor Network Models},\nauthor={Behnoush Khavari and Guillaume Rabusseau},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=16r0qOLv_2i}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492707934, "odate": 1636492707934, "details": {"replyCount": 7}}, {"id": "WlkzLjxpYe", "original": "hYk8lkX7RF", "number": 3529, "cdate": 1621629863556, "ddate": null, "tcdate": 1621629863556, "tmdate": 1683307593884, "tddate": null, "forum": "WlkzLjxpYe", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Fractal Structure and Generalization Properties of Stochastic Optimization Algorithms", "authorids": ["~Alexander_Camuto1", "~George_Deligiannidis2", "~Murat_A_Erdogdu1", "~Mert_Gurbuzbalaban1", "~Umut_Simsekli1", "~Lingjiong_Zhu1"], "authors": ["Alexander Camuto", "George Deligiannidis", "Murat A Erdogdu", "Mert Gurbuzbalaban", "Umut Simsekli", "Lingjiong Zhu"], "keywords": ["generalization", "stochastic gradient descent", "deep learning", "fractals"], "TL;DR": "We prove that the generalization error of a stochastic optimization algorithm can be linked to the 'complexity' of the fractal structure that underlies its invariant measure.", "abstract": "Understanding generalization in deep learning has been one of the major challenges in statistical learning theory over the last decade. While recent work has illustrated that the dataset and the training algorithm must be taken into account in order to obtain meaningful generalization bounds, it is still theoretically not clear which properties of the data and the algorithm determine the generalization performance. In this study, we approach this problem from a dynamical systems theory perspective and represent stochastic optimization algorithms as \\emph{random iterated function systems} (IFS). Well studied in the dynamical systems literature, under mild assumptions, such IFSs can be shown to be ergodic with an invariant measure that is often supported on sets with a \\emph{fractal structure}. As our main contribution, we prove that the generalization error of a stochastic optimization algorithm can be bounded based on the `complexity' of the fractal structure that underlies its invariant measure. Then, by leveraging results from dynamical systems theory, we show that the generalization error can be explicitly linked to the choice of the algorithm (e.g., stochastic gradient descent -- SGD), algorithm hyperparameters (e.g., step-size, batch-size), and the geometry of the problem (e.g., Hessian of the loss). We further specialize our results to specific problems (e.g., linear/logistic regression, one hidden-layered neural networks) and algorithms (e.g., SGD and preconditioned variants), and obtain analytical estimates for our bound. For modern neural networks, we develop an efficient algorithm to compute the developed bound and support our theory with various experiments on neural networks. ", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "camuto|fractal_structure_and_generalization_properties_of_stochastic_optimization_algorithms", "pdf": "/pdf/dbbd095b7f2b257c961588e2ecc40f1e3a5e01aa.pdf", "checklist": "", "supplementary_material": "/attachment/88fe2ef0d261c14bc942cc3868a6dd108493bd75.pdf", "code": "https://github.com/umutsimsekli/fractal_generalization", "thumbnail": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\ncamuto2021fractal,\ntitle={Fractal Structure and Generalization Properties of Stochastic Optimization Algorithms},\nauthor={Alexander Camuto and George Deligiannidis and Murat A Erdogdu and Mert Gurbuzbalaban and Umut Simsekli and Lingjiong Zhu},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=WlkzLjxpYe}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492712920, "odate": 1636492712920, "details": {"replyCount": 15}}, {"id": "wZrOOO9XBn", "original": "biQZW79NvOk", "number": 3497, "cdate": 1621629861573, "ddate": null, "tcdate": 1621629861573, "tmdate": 1697937632809, "tddate": null, "forum": "wZrOOO9XBn", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Lossy Compression for Lossless Prediction", "authorids": ["~Yann_Dubois1", "~Benjamin_Bloem-Reddy1", "~Karen_Ullrich1", "~Chris_J._Maddison1"], "authors": ["Yann Dubois", "Benjamin Bloem-Reddy", "Karen Ullrich", "Chris J. Maddison"], "keywords": ["Compression", "Invariances", "Information Theory", "Machine Learning", "Self-Supervised Learning"], "TL;DR": "We formalize and experimentally evaluate compression that guarantees high downstream predictive performance under invariances. ", "abstract": "Most data is automatically collected and only ever \"seen\" by algorithms. Yet, data compressors preserve perceptual fidelity rather than just the information needed by algorithms performing downstream tasks. In this paper, we characterize the bit-rate required to ensure high performance on all predictive tasks that are invariant under a set of transformations, such as data augmentations. Based on our theory, we design unsupervised objectives for training neural compressors. Using these objectives, we train a generic image compressor that achieves substantial rate savings (more than 1000x on ImageNet) compared to JPEG on 8 datasets, without decreasing downstream classification performance.", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "dubois|lossy_compression_for_lossless_prediction", "pdf": "/pdf/6305ed7b487161c114bdab21f767edf756912b32.pdf", "checklist": "", "supplementary_material": "/attachment/b454f181212647c05619f9e55406914f1a16ef4c.pdf", "code": "https://github.com/YannDubs/lossyless", "thumbnail": "", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2106.10800/code)", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\ndubois2021lossy,\ntitle={Lossy Compression for Lossless Prediction},\nauthor={Yann Dubois and Benjamin Bloem-Reddy and Karen Ullrich and Chris J. Maddison},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=wZrOOO9XBn}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492677733, "odate": 1636492677733, "details": {"replyCount": 27}}, {"id": "s6MWPKgL5XB", "original": "HnzDbDdy-I5", "number": 3495, "cdate": 1621629861496, "ddate": null, "tcdate": 1621629861496, "tmdate": 1683307592632, "tddate": null, "forum": "s6MWPKgL5XB", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Necessary and sufficient graphical conditions for optimal adjustment sets in causal graphical models with hidden variables", "authorids": ["~Jakob_Runge2"], "authors": ["Jakob Runge"], "keywords": ["causal inference", "information theory", "statistics"], "TL;DR": "The paper presents necessary and sufficient graphical conditions and an algorithm for optimal adjustment sets in causal graphical models with hidden variables.", "abstract": "The problem of selecting optimal backdoor adjustment sets to estimate causal effects in graphical models with hidden and conditioned variables is addressed. Previous work has defined optimality as achieving the smallest asymptotic estimation variance and derived an optimal set for the case without hidden variables. For the case with hidden variables there can be settings where no optimal set exists and currently only a sufficient graphical optimality criterion of limited applicability has been derived. In the present work optimality is characterized as maximizing a certain adjustment information which allows to derive a necessary and sufficient graphical criterion for the existence of an optimal adjustment set and a definition and algorithm to construct it. Further, the optimal set is valid if and only if a valid adjustment set exists and has higher (or equal) adjustment information than the Adjust-set proposed in Perkovi{\\'c} et~al. [Journal of Machine Learning Research, 18: 1--62, 2018] for any graph. The results translate to minimal asymptotic estimation variance for a class of estimators whose asymptotic variance follows a certain information-theoretic relation. Numerical experiments indicate that the asymptotic results also hold for relatively small sample sizes and that the optimal adjustment set or minimized variants thereof often yield better variance also beyond that estimator class. Surprisingly, among the randomly created setups more than 90\\% fulfill the optimality conditions indicating that also in many real-world scenarios graphical optimality may hold.\n", "pdf": "/pdf/8b665604f2587b6697f650765da1d2c1731df0fc.pdf", "supplementary_material": "/attachment/608399baa062d17ee4438f989c09e3bdbb8d6b07.pdf", "submission_history": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "checklist": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "runge|necessary_and_sufficient_graphical_conditions_for_optimal_adjustment_sets_in_causal_graphical_models_with_hidden_variables", "code": "https://github.com/jakobrunge/tigramite", "thumbnail": "", "_bibtex": "@inproceedings{\nrunge2021necessary,\ntitle={Necessary and sufficient graphical conditions for optimal adjustment sets in causal graphical models with hidden variables},\nauthor={Jakob Runge},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=s6MWPKgL5XB}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492746135, "odate": 1636492746135, "details": {"replyCount": 14}}, {"id": "qxKh67NNJ2I", "original": "bJCaRfv37Lh", "number": 3490, "cdate": 1621629861195, "ddate": null, "tcdate": 1621629861195, "tmdate": 1697937632794, "tddate": null, "forum": "qxKh67NNJ2I", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Safe Reinforcement Learning with Natural Language Constraints", "authorids": ["~Tsung-Yen_Yang2", "~Michael_Hu1", "~Yinlam_Chow1", "~Peter_Ramadge1", "~Karthik_R_Narasimhan1"], "authors": ["Tsung-Yen Yang", "Michael Hu", "Yinlam Chow", "Peter Ramadge", "Karthik R Narasimhan"], "keywords": ["Safe reinforcement learning", "Language grounding"], "TL;DR": "We tackle the problem of learning control policies for tasks when provided with constraints in natural language  (e.g., safety or budget constraints). ", "abstract": "While safe reinforcement learning (RL) holds great promise for many practical applications like robotics or autonomous cars, current approaches require specifying constraints in mathematical form. Such specifications demand domain expertise, limiting the adoption of safe RL. In this paper, we propose learning to interpret natural language constraints for safe RL. To this end, we first introduce HAZARDWORLD, a new multi-task benchmark that requires an agent to optimize reward while not violating constraints specified in free-form text. We then develop an agent with a modular architecture that can interpret and adhere to such textual constraints while learning new tasks. Our model consists of (1) a constraint interpreter that encodes textual constraints into spatial and temporal representations of forbidden states, and (2) a policy network that uses these representations to produce a policy achieving minimal constraint violations during training. Across different domains in HAZARDWORLD, we show that our method achieves higher rewards (up to11x) and fewer constraint violations (by 1.8x) compared to existing approaches. However, in terms of absolute performance, HAZARDWORLD still poses significant challenges for agents to learn efficiently, motivating the need for future work.", "submission_history": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "checklist": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "yang|safe_reinforcement_learning_with_natural_language_constraints", "pdf": "/pdf/918b55b88a9e54022c075d2255d6778a527f2b4a.pdf", "supplementary_material": "/attachment/67ec59294d6c4b6edbc6985f871a95d68c53e95d.pdf", "code": "https://github.com/princeton-nlp/SRL-NLC", "thumbnail": "", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2010.05150/code)", "_bibtex": "@inproceedings{\nyang2021safe,\ntitle={Safe Reinforcement Learning with Natural Language Constraints},\nauthor={Tsung-Yen Yang and Michael Hu and Yinlam Chow and Peter Ramadge and Karthik R Narasimhan},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=qxKh67NNJ2I}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492743996, "odate": 1636492743996, "details": {"replyCount": 9}}, {"id": "5Re03X8Iigi", "original": "zABM5L8Id6", "number": 3476, "cdate": 1621629860323, "ddate": null, "tcdate": 1621629860323, "tmdate": 1683307591953, "tddate": null, "forum": "5Re03X8Iigi", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Bayesian decision-making under misspecified priors with applications to meta-learning", "authorids": ["~Max_Simchowitz1", "~Christopher_Tosh1", "~Akshay_Krishnamurthy1", "~Daniel_Hsu1", "~Thodoris_Lykouris1", "~Miroslav_Dud\u00edk1", "~Robert_E._Schapire1"], "authors": ["Max Simchowitz", "Christopher Tosh", "Akshay Krishnamurthy", "Daniel Hsu", "Thodoris Lykouris", "Miroslav Dud\u00edk", "Robert E. Schapire"], "keywords": ["Thompson Sampling", "Bayesian Bandits", "Bayesian Decision Making", "Meta-Learning"], "abstract": "Thompson sampling and other Bayesian sequential decision-making algorithms are among the most popular approaches to tackle explore/exploit trade-offs in (contextual) bandits.  The choice of prior in these algorithms offers flexibility to encode domain knowledge but can also lead to poor performance when misspecified.  In this paper, we demonstrate that performance degrades gracefully with misspecification.  We prove that the expected reward accrued by Thompson sampling (TS) with a misspecified prior differs by at most $\\tilde{O}(H^2 \\epsilon)$ from TS with a well-specified prior, where $\\epsilon$ is the total-variation distance between priors and $H$ is the learning horizon.  \n\nOur bound does not require the prior to have any parametric form.  For priors with bounded support, our bound is independent of the cardinality or structure of the action space, and we show that it is tight up to universal constants in the worst case.\n\nBuilding on our sensitivity analysis, we establish generic PAC guarantees for algorithms in the recently studied Bayesian meta-learning setting and derive corollaries for various families of priors.  Our results generalize along two axes: (1) they apply to a broader family of Bayesian decision-making algorithms, including a Monte-Carlo implementation of the knowledge gradient algorithm (KG), and (2) they apply to Bayesian POMDPs, the most general Bayesian decision-making setting, encompassing contextual bandits as a special case. Through numerical simulations, we illustrate how prior misspecification and the deployment of one-step look-ahead (as in KG) can impact the convergence of meta-learning in multi-armed and contextual bandits with structured and correlated priors.", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "simchowitz|bayesian_decisionmaking_under_misspecified_priors_with_applications_to_metalearning", "TL;DR": "We prove sensitivity bounds for Bayesian decision making under general priors, and investigate their implications in experiments.", "pdf": "/pdf/eb80690d338fca1881fdcbc9e9c27c1489633eac.pdf", "supplementary_material": "/attachment/8d97de9326f59bc3d11721e8c511db09673ccc93.pdf", "checklist": "", "code": "/attachment/16480e4e5f2a5579d3299ac5269a7b52a6dfcf3e.zip", "thumbnail": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nsimchowitz2021bayesian,\ntitle={Bayesian decision-making under misspecified priors with applications to meta-learning},\nauthor={Max Simchowitz and Christopher Tosh and Akshay Krishnamurthy and Daniel Hsu and Thodoris Lykouris and Miroslav Dud{\\'\\i}k and Robert E. Schapire},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=5Re03X8Iigi}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492776042, "odate": 1636492776042, "details": {"replyCount": 12}}, {"id": "T6m9bNI7C__", "original": "wgrcCyWH01B", "number": 3374, "cdate": 1621629854221, "ddate": null, "tcdate": 1621629854221, "tmdate": 1697937638473, "tddate": null, "forum": "T6m9bNI7C__", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Interactive Label Cleaning with Example-based Explanations", "authorids": ["~Stefano_Teso1", "~Andrea_Bontempelli1", "~Fausto_Giunchiglia1", "~Andrea_Passerini2"], "authors": ["Stefano Teso", "Andrea Bontempelli", "Fausto Giunchiglia", "Andrea Passerini"], "keywords": ["learning under noise", "interactive learning", "example-based explanation", "influence functions", "fisher information matrix"], "abstract": "We tackle sequential learning under label noise in applications where a human supervisor can be queried to relabel suspicious examples. Existing approaches are flawed, in that they only relabel incoming examples that look \"suspicious\" to the model. As a consequence, those mislabeled examples that elude (or don't undergo) this cleaning step end up tainting the training data and the model with no further chance of being cleaned. We propose CINCER, a novel approach that cleans both new and past data by identifying \\emph{pairs of mutually incompatible examples}. Whenever it detects a suspicious example, CINCER identifies a counter-example in the training set that - according to the model - is maximally incompatible with the suspicious example, and asks the annotator to relabel either or both examples, resolving this possible inconsistency. The counter-examples are chosen to be maximally incompatible, so to serve as \\emph{explanations} of the model's suspicion, and highly influential, so to convey as much information as possible if relabeled. CINCER achieves this by leveraging an efficient and robust approximation of influence functions based on the Fisher information matrix (FIM). Our extensive empirical evaluation shows that clarifying the reasons behind the model's suspicions by cleaning the counter-examples helps in acquiring substantially better data and models, especially when paired with our FIM approximation.", "submission_history": "", "checklist": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "teso|interactive_label_cleaning_with_examplebased_explanations", "pdf": "/pdf/2ea8e10f20e5bc89692891fb2498aa76df5e0671.pdf", "supplementary_material": "/attachment/baa9725712d4a43d755135505c864dbd47d59467.pdf", "TL;DR": "Approach that enables humans to improve data and models by interacting via example-based explanations selected using influence functions", "thumbnail": "", "code": "https://github.com/abonte/cincer", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2106.03922/code)", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nteso2021interactive,\ntitle={Interactive Label Cleaning with Example-based Explanations},\nauthor={Stefano Teso and Andrea Bontempelli and Fausto Giunchiglia and Andrea Passerini},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=T6m9bNI7C__}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492673934, "odate": 1636492673934, "details": {"replyCount": 11}}, {"id": "W2rRWbI4CTW", "original": "_JDvowqSZP2", "number": 3369, "cdate": 1621629853924, "ddate": null, "tcdate": 1621629853924, "tmdate": 1697937638724, "tddate": null, "forum": "W2rRWbI4CTW", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "A Geometric Perspective towards Neural Calibration via Sensitivity Decomposition", "authorids": ["~Junjiao_Tian1", "~Dylan_Yung1", "~Yen-Chang_Hsu1", "~Zsolt_Kira1"], "authors": ["Junjiao Tian", "Dylan Yung", "Yen-Chang Hsu", "Zsolt Kira"], "keywords": ["uncertainty estimation", "calibration", "sensitivity"], "TL;DR": "We propose a geometric perspective and a simple method for improving deterministic uncertainty estimation and calibration under distribution shift.", "abstract": "It is well known that vision classification models suffer from poor calibration in the face of data distribution shifts. In this paper, we take a geometric approach to this problem. We propose Geometric Sensitivity Decomposition (GSD) which decomposes the norm of a sample feature embedding and the angular similarity to a target classifier into an instance-dependent and an instance-independent com-ponent. The instance-dependent component captures the sensitive information about changes in the input while the instance-independent component represents the insensitive information serving solely to minimize the loss on the training dataset. Inspired by the decomposition, we analytically derive a simple extension to current softmax-linear models, which learns to disentangle the two components during training. On several common vision models, the disentangled model out-performs other calibration methods on standard calibration metrics in the face of out-of-distribution (OOD) data and corruption with significantly less complexity. Specifically, we surpass the current state of the art by 30.8% relative improvement on corrupted CIFAR100 in Expected Calibration Error.\n", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "tian|a_geometric_perspective_towards_neural_calibration_via_sensitivity_decomposition", "pdf": "/pdf/7932cdc582ef30fdfd42a08521e770129cd4fbf2.pdf", "supplementary_material": "/attachment/168601500ebd867554bc94936d96f18129a48f65.pdf", "checklist": "", "code": "https://github.com/GT-RIPL/Geometric-Sensitivity-Decomposition", "thumbnail": "", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 2 code implementations](https://www.catalyzex.com/paper/arxiv:2110.14577/code)", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\ntian2021a,\ntitle={A Geometric Perspective towards Neural Calibration via Sensitivity Decomposition},\nauthor={Junjiao Tian and Dylan Yung and Yen-Chang Hsu and Zsolt Kira},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=W2rRWbI4CTW}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492690908, "odate": 1636492690908, "details": {"replyCount": 12}}, {"id": "uw4mcO8nz3n", "original": "O1DwLeW0UtA", "number": 3344, "cdate": 1621629852383, "ddate": null, "tcdate": 1621629852383, "tmdate": 1683307588429, "tddate": null, "forum": "uw4mcO8nz3n", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "The Semi-Random Satisfaction of Voting Axioms", "authorids": ["~Lirong_Xia2"], "authors": ["Lirong Xia"], "keywords": ["social choice", "voting", "axioms", "smoothed analysis"], "TL;DR": "This paper characterizes the worst average-case satisfaction of two well-studied and important voting axioms, namely Condorcet criterion and participation, in semi-random models", "abstract": "We initiate the work towards a comprehensive picture of the worst average-case satisfaction of  voting axioms in semi-random models, to provide a finer and more realistic foundation for comparing voting rules. We adopt the semi-random model and formulation in [Xia 2020],  where an adversary chooses arbitrarily correlated ``ground truth'' preferences for the agents, on top of which random noises are added. We  focus on characterizing the semi-random satisfaction of two well-studied voting axioms:  Condorcet criterion and participation. We prove that  for any fixed number of alternatives, when the number of voters $n$ is sufficiently large, the semi-random satisfaction of the Condorcet criterion under a wide range of voting rules is $1$, $1-\\exp(-\\Theta(n))$, $\\Theta(n^{-0.5})$, $ \\exp(-\\Theta(n))$, or being $\\Theta(1)$ and $1-\\Theta(1)$ at the same time; and the semi-random satisfaction of participation is  $1-\\Theta(n^{-0.5})$.   Our results  address  open questions by Berg and Lepelley in 1994, and also  confirm the following high-level message: the Condorcet criterion is a bigger concern than participation under realistic models. ", "pdf": "/pdf/bd6bb06466b934deb91bc26e0c6f1d6c608dc8e6.pdf", "supplementary_material": "/attachment/2fafecff5583a5841e148b9a462b17c19ccc0885.pdf", "submission_history": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "checklist": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "xia|the_semirandom_satisfaction_of_voting_axioms", "thumbnail": "", "_bibtex": "@inproceedings{\nxia2021the,\ntitle={The Semi-Random Satisfaction of Voting Axioms},\nauthor={Lirong Xia},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=uw4mcO8nz3n}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492701188, "odate": 1636492701188, "details": {"replyCount": 12}}, {"id": "5CGPY2VeEGb", "original": "7xSlG-oiXh", "number": 3288, "cdate": 1621629849047, "ddate": null, "tcdate": 1621629849047, "tmdate": 1697937641836, "tddate": null, "forum": "5CGPY2VeEGb", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Semi-Supervised Semantic Segmentation via Adaptive Equalization Learning", "authorids": ["~Hanzhe_Hu1", "~Fangyun_Wei1", "~Han_Hu1", "~Qiwei_Ye1", "~Jinshi_Cui1", "~Liwei_Wang1"], "authors": ["Hanzhe Hu", "Fangyun Wei", "Han Hu", "Qiwei Ye", "Jinshi Cui", "Liwei Wang"], "keywords": ["semantic segmentation", "semi-supervised learning", "adaptive equalization learning"], "abstract": "Due to the limited and even imbalanced data, semi-supervised semantic segmentation tends to have poor performance on some certain categories, e.g., tailed categories in Cityscapes dataset which exhibits a long-tailed label distribution. Existing approaches almost all neglect this problem, and treat categories equally. Some popular approaches such as consistency regularization or pseudo-labeling may even harm the learning of under-performing categories, that the predictions or pseudo labels of these categories could be too inaccurate to guide the learning on the unlabeled data. In this paper, we look into this problem, and propose a novel framework for semi-supervised semantic segmentation, named adaptive equalization learning (AEL). AEL adaptively balances the training of well and badly performed categories, with a confidence bank to dynamically track category-wise performance during training. The confidence bank is leveraged as an indicator to tilt training towards under-performing categories, instantiated in three strategies: 1) adaptive Copy-Paste and CutMix data augmentation approaches which give more chance for under-performing categories to be copied or cut; 2) an adaptive data sampling approach to encourage pixels from under-performing category to be sampled; 3) a simple yet effective re-weighting method to alleviate the training noise raised by pseudo-labeling. Experimentally, AEL outperforms the state-of-the-art methods by a large margin on the Cityscapes and Pascal VOC benchmarks under various data partition protocols. Code is available at https://github.com/hzhupku/SemiSeg-AEL.", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "hu|semisupervised_semantic_segmentation_via_adaptive_equalization_learning", "TL;DR": "We introduce a semi-supervised learning framework for semantic segmentation.", "pdf": "/pdf/69969308159f302156dbfb13b5c7489bf03abb7c.pdf", "checklist": "", "supplementary_material": "/attachment/1478867e3174f8095225fd584df1cdda5f91cb1c.pdf", "code": "https://github.com/hzhupku/SemiSeg-AEL", "thumbnail": "", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2110.05474/code)", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nhu2021semisupervised,\ntitle={Semi-Supervised Semantic Segmentation via Adaptive Equalization Learning},\nauthor={Hanzhe Hu and Fangyun Wei and Han Hu and Qiwei Ye and Jinshi Cui and Liwei Wang},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=5CGPY2VeEGb}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492776778, "odate": 1636492776778, "details": {"replyCount": 9}}, {"id": "J-pFhOiGVn7", "original": "NCLMn-3jx3M", "number": 3235, "cdate": 1621629845937, "ddate": null, "tcdate": 1621629845937, "tmdate": 1683307585691, "tddate": null, "forum": "J-pFhOiGVn7", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "An Infinite-Feature Extension for Bayesian ReLU Nets That Fixes Their Asymptotic Overconfidence", "authorids": ["~Agustinus_Kristiadi1", "~Matthias_Hein2", "~Philipp_Hennig1"], "authors": ["Agustinus Kristiadi", "Matthias Hein", "Philipp Hennig"], "keywords": ["bayesian deep learning", "uncertainty quantification", "overconfidence", "gaussian processes"], "abstract": "A Bayesian treatment can mitigate overconfidence in ReLU nets around the training data. But far away from them, ReLU Bayesian neural networks (BNNs) can still underestimate uncertainty and thus be asymptotically overconfident. This issue arises since the output variance of a BNN with finitely many features is quadratic in the distance from the data region. Meanwhile, Bayesian linear models with ReLU features converge, in the infinite-width limit, to a particular Gaussian process (GP) with a variance that grows cubically so that no asymptotic overconfidence can occur. While this may seem of mostly theoretical interest, in this work, we show that it can be used in practice to the benefit of BNNs. We extend finite ReLU BNNs with infinite ReLU features via the GP and show that the resulting model is asymptotically maximally uncertain far away from the data while the BNNs' predictive power is unaffected near the data. Although the resulting model approximates a full GP posterior, thanks to its structure, it can be applied post-hoc to any pre-trained ReLU BNN at a low cost.", "submission_history": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "kristiadi|an_infinitefeature_extension_for_bayesian_relu_nets_that_fixes_their_asymptotic_overconfidence", "TL;DR": "We propose a post-hoc extension, constructed by considering infinitely many ReLU features, for standard ReLU BNNs. This extension effectively fixes ReLU BNNs' overconfidence far away from the training data.", "pdf": "/pdf/59c37faebe54cf2a53b3b465fe8549636d76489c.pdf", "checklist": "", "supplementary_material": "/attachment/4396959396bd2d5f42d3133fe7e4a12c02da9577.pdf", "code": "https://github.com/wiseodd/rgpr", "thumbnail": "", "_bibtex": "@inproceedings{\nkristiadi2021an,\ntitle={An Infinite-Feature Extension for Bayesian Re{LU} Nets That Fixes Their Asymptotic Overconfidence},\nauthor={Agustinus Kristiadi and Matthias Hein and Philipp Hennig},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=J-pFhOiGVn7}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492740969, "odate": 1636492740919, "details": {"replyCount": 20}}, {"id": "HKtsGW-lNbw", "original": "ASA9jRWBs2V", "number": 3173, "cdate": 1621629842456, "ddate": null, "tcdate": 1621629842456, "tmdate": 1683307584015, "tddate": null, "forum": "HKtsGW-lNbw", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Online and Offline Reinforcement Learning by Planning with a Learned Model", "authorids": ["~Julian_Schrittwieser1", "~Thomas_K_Hubert1", "~Amol_Mandhane1", "~Mohammadamin_Barekatain2", "~Ioannis_Antonoglou1", "~David_Silver1"], "authors": ["Julian Schrittwieser", "Thomas K Hubert", "Amol Mandhane", "Mohammadamin Barekatain", "Ioannis Antonoglou", "David Silver"], "keywords": ["Reinforcement Learning", "Deep Learning"], "abstract": "Learning efficiently from small amounts of data has long been the focus of model-based reinforcement learning, both for the online case when interacting with the environment, and the offline case when learning from a fixed dataset. However, to date no single unified algorithm could demonstrate state-of-the-art results for both settings.\nIn this work, we describe the Reanalyse algorithm, which uses model-based policy and value improvement operators to compute improved training targets for existing data points, allowing for efficient learning at data budgets varying by several orders of magnitude. We further show that Reanalyse can also be used to learn completely without environment interactions, as in the case of Offline Reinforcement Learning (Offline RL). Combining Reanalyse with the MuZero algorithm, we introduce MuZero Unplugged, a single unified algorithm for any data budget, including Offline RL. In contrast to previous work, our algorithm requires no special adaptations for the off-policy or Offline RL settings. MuZero Unplugged sets new state-of-the-art results for Atari in the standard 200 million frame online setting as well as in the RL Unplugged Offline RL benchmark.", "submission_history": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "schrittwieser|online_and_offline_reinforcement_learning_by_planning_with_a_learned_model", "pdf": "/pdf/4ded924f378d177a0de11681cf18ab55922ee6f3.pdf", "supplementary_material": "/attachment/6f9302cde7d28ee88c751ab1c76d319bf51bbc70.pdf", "checklist": "", "code": "/attachment/bbf82e1ecddc7a460937d1959b3c899c1b2bf9e1.zip", "thumbnail": "", "_bibtex": "@inproceedings{\nschrittwieser2021online,\ntitle={Online and Offline Reinforcement Learning by Planning with a Learned Model},\nauthor={Julian Schrittwieser and Thomas K Hubert and Amol Mandhane and Mohammadamin Barekatain and Ioannis Antonoglou and David Silver},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=HKtsGW-lNbw}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492766924, "odate": 1636492766924, "details": {"replyCount": 12}}, {"id": "BuoTowxp-9", "original": "zPWxu3BnRFr", "number": 3159, "cdate": 1621629841592, "ddate": null, "tcdate": 1621629841592, "tmdate": 1697937647201, "tddate": null, "forum": "BuoTowxp-9", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Decentralized Learning in Online Queuing Systems", "authorids": ["~Flore_Sentenac1", "~Etienne_Boursier1", "~Vianney_Perchet3"], "authors": ["Flore Sentenac", "Etienne Boursier", "Vianney Perchet"], "keywords": ["Queuing systems", "Decentralized Learning", "Multi-armed Bandits"], "TL;DR": "We propose the first stable algorithm for the problem of online queuing systems, when the ratio between service and arrival rates is only larger than 1.", "abstract": "Motivated by packet routing in computer networks, online queuing systems are composed of queues receiving packets at different rates. Repeatedly, they send packets to servers, each of them treating only at most one packet at a time. In the centralized case, the number of accumulated packets remains bounded (i.e., the system is stable) as long as the ratio between service rates and arrival rates is larger than $1$. In the decentralized case, individual no-regret strategies ensures stability when this ratio is larger than $2$. Yet, myopically minimizing  regret disregards the long term effects due to the carryover of packets to further rounds. On the other hand, minimizing long term costs leads to stable Nash equilibria as soon as the ratio exceeds $\\frac{e}{e-1}$. Stability with decentralized learning strategies  with a ratio below $2$ was a major remaining question. We first argue that for ratios up to $2$, cooperation is required for stability of learning strategies, as  selfish minimization of policy regret, a patient notion of regret, might indeed still be unstable in this case. We therefore consider cooperative queues and propose the first learning decentralized algorithm guaranteeing stability of the system as long as the ratio of rates is larger than $1$, thus reaching performances comparable to centralized strategies.", "submission_history": "", "checklist": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "sentenac|decentralized_learning_in_online_queuing_systems", "pdf": "/pdf/3c02526a74a1ae52cd134fc68685b50e232b62c3.pdf", "supplementary_material": "/attachment/6699cf456679a3ff4183756433f2559b036c2320.pdf", "code": "https://gitlab.com/f_sen/queuing_systems", "thumbnail": "", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2106.04228/code)", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nsentenac2021decentralized,\ntitle={Decentralized Learning in Online Queuing Systems},\nauthor={Flore Sentenac and Etienne Boursier and Vianney Perchet},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=BuoTowxp-9}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492771207, "odate": 1636492771207, "details": {"replyCount": 13}}, {"id": "9uXILaIam0", "original": "NIuC6kUEofB", "number": 3151, "cdate": 1621629841111, "ddate": null, "tcdate": 1621629841111, "tmdate": 1683307583499, "tddate": null, "forum": "9uXILaIam0", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Vector-valued Distance and Gyrocalculus on the Space of Symmetric Positive Definite Matrices", "authorids": ["~Federico_Lopez1", "~Maria_Beatrice_Pozzetti1", "~Steve_J_Trettel1", "~Michael_Strube1", "~Anna_Wienhard1"], "authors": ["Federico Lopez", "Maria Beatrice Pozzetti", "Steve J Trettel", "Michael Strube", "Anna Wienhard"], "keywords": ["symmetric spaces", "spd space", "spd manifold", "symmetric positive definite matrices", "spd", "riemannian manifold", "rotations", "reflections", "translations", "scaling", "gyro vector", "gyro calculus", "gyro groups", "gyrocalculus", "tangent space optimization", "non euclidean optimization", "hyperbolic geometry", "hyperbolic space", "matrix models", "non-euclidean geometry", "finsler metrics", "finsler distance", "finsler geometry", "vector valued distance", "vector valued distance function", "riemannian manifold learning", "manifold learning", "geometric deep learning", "graph embeddings", "knowledge graph embeddings", "item recommendations", "question answering"], "TL;DR": "We propose a framework to compute vector-valued distances and adapt Euclidean operations into the SPD manifold", "abstract": "We propose the use of the vector-valued distance to compute distances and extract geometric information from the manifold of symmetric positive definite matrices (SPD), and develop gyrovector calculus, constructing analogs of vector space operations in this curved space. We implement these operations and showcase their versatility in the tasks of knowledge graph completion, item recommendation, and question answering. In experiments, the SPD models outperform their equivalents in Euclidean and hyperbolic space. The vector-valued distance allows us to visualize embeddings, showing that the models learn to disentangle representations of positive samples from negative ones.", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "lopez|vectorvalued_distance_and_gyrocalculus_on_the_space_of_symmetric_positive_definite_matrices", "pdf": "/pdf/0500339b0ae90cee805d4d7221f9c326d72933e5.pdf", "supplementary_material": "/attachment/cad1cf081336d148eb971e6a44bccbc7e54732a6.pdf", "checklist": "", "code": "https://github.com/fedelopez77/gyrospd", "thumbnail": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nlopez2021vectorvalued,\ntitle={Vector-valued Distance and Gyrocalculus on the Space of Symmetric Positive Definite Matrices},\nauthor={Federico Lopez and Maria Beatrice Pozzetti and Steve J Trettel and Michael Strube and Anna Wienhard},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=9uXILaIam0}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492770800, "odate": 1636492770800, "details": {"replyCount": 14}}, {"id": "R6nFQy2vwQq", "original": "P9ERaaiGfUM", "number": 3004, "cdate": 1621629832500, "ddate": null, "tcdate": 1621629832500, "tmdate": 1683307580917, "tddate": null, "forum": "R6nFQy2vwQq", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Deep Self-Dissimilarities as Powerful Visual Fingerprints", "authorids": ["~Idan_Kligvasser1", "~Tamar_Rott_Shaham1", "~Yuval_Bahat2", "~Tomer_Michaeli1"], "authors": ["Idan Kligvasser", "Tamar Rott Shaham", "Yuval Bahat", "Tomer Michaeli"], "keywords": ["descriptors", "deep-features", "IQA", "image-restoration", "super-resolution", "motion-deblurring"], "abstract": "Features extracted from deep layers of classification networks are widely used as image descriptors. Here, we exploit an unexplored property of these features: their internal dissimilarity. While small image patches are known to have similar statistics across image scales, it turns out that the internal distribution of deep features varies distinctively between scales. We show how this deep self dissimilarity (DSD) property can be used as a powerful visual fingerprint. Particularly, we illustrate that full-reference and no-reference image quality measures derived from DSD are highly correlated with human preference. In addition, incorporating DSD as a loss function in training of image restoration networks, leads to results that are at least as photo-realistic as those obtained by GAN based methods, while not requiring adversarial training.", "submission_history": "", "checklist": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "kligvasser|deep_selfdissimilarities_as_powerful_visual_fingerprints", "TL;DR": "We exploit deep features dissimilarity, and suggest to use it as both image quality measure and as a loss function for image restoration tasks", "pdf": "/pdf/b45f29346b6c092d0d96e0fdc05cd84531018310.pdf", "supplementary_material": "/attachment/b677fd02328d8aaed91b2a4330d8bf44a7ef7d97.pdf", "code": "https://github.com/kligvasser/DSD", "thumbnail": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nkligvasser2021deep,\ntitle={Deep Self-Dissimilarities as Powerful Visual Fingerprints},\nauthor={Idan Kligvasser and Tamar Rott Shaham and Yuval Bahat and Tomer Michaeli},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=R6nFQy2vwQq}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492767801, "odate": 1636492767801, "details": {"replyCount": 11}}, {"id": "q0h6av9Vi8", "original": "xCDnCSMvOw1", "number": 2982, "cdate": 1621629831336, "ddate": null, "tcdate": 1621629831336, "tmdate": 1697937087322, "tddate": null, "forum": "q0h6av9Vi8", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Light Field Networks: Neural Scene Representations with Single-Evaluation Rendering", "authorids": ["~Vincent_Sitzmann1", "~Semon_Rezchikov1", "~William_T._Freeman1", "~Joshua_B._Tenenbaum1", "~Fredo_Durand1"], "authors": ["Vincent Sitzmann", "Semon Rezchikov", "William T. Freeman", "Joshua B. Tenenbaum", "Fredo Durand"], "keywords": ["Neural Fields", "Neural Scene Representations", "Neural Implicit Representations", "Coordinate-based representations", "Neural Rendering", "Light Fields"], "abstract": "Inferring representations of 3D scenes from 2D observations is a fundamental problem of computer graphics, computer vision, and artificial intelligence. Emerging 3D-structured neural scene representations are a promising approach to 3D scene understanding. In this work, we propose a novel neural scene representation, Light Field Networks or LFNs, which represent both geometry and appearance of the underlying 3D scene in a 360-degree, four-dimensional light field parameterized via a neural implicit representation.  Rendering a ray from an LFN requires only a *single* network evaluation, as opposed to hundreds of evaluations per ray for ray-marching or volumetric based renderers in 3D-structured neural scene representations.  In the setting of simple scenes, we leverage meta-learning to learn a prior over LFNs that enables multi-view consistent light field reconstruction from as little as a single image observation. This results in dramatic reductions in time and memory complexity, and enables real-time rendering. The cost of storing a 360-degree light field via an LFN is two orders of magnitude lower than conventional methods such as the Lumigraph.  Utilizing the analytical differentiability of neural implicit representations and a novel parameterization of light space, we further demonstrate the extraction of sparse depth maps from LFNs. ", "submission_history": "", "checklist": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "sitzmann|light_field_networks_neural_scene_representations_with_singleevaluation_rendering", "TL;DR": "We parameterize scenes as 4D light fields instead of 3D implicit representations, enabling real-time rendering with only a single evaluation of the network per ray.", "pdf": "/pdf/8e0ead94c52f89969a45bc0947d7fdcca290a064.pdf", "supplementary_material": "/attachment/e0092829d4a6d1364c227d1ac1444697e9e10bd5.zip", "code": "https://vsitzmann.github.io/lfns/", "thumbnail": "", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 2 code implementations](https://www.catalyzex.com/paper/arxiv:2106.02634/code)", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nsitzmann2021light,\ntitle={Light Field Networks: Neural Scene Representations with Single-Evaluation Rendering},\nauthor={Vincent Sitzmann and Semon Rezchikov and William T. Freeman and Joshua B. Tenenbaum and Fredo Durand},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=q0h6av9Vi8}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492689733, "odate": 1636492689733, "details": {"replyCount": 16}}, {"id": "sf2BxJNXC3K", "original": "YCF_OQ1q_F", "number": 2958, "cdate": 1621629829924, "ddate": null, "tcdate": 1621629829924, "tmdate": 1683307580017, "tddate": null, "forum": "sf2BxJNXC3K", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Ultrahyperbolic Neural Networks", "authorids": ["~Marc_T_Law1"], "authors": ["Marc T Law"], "keywords": ["differential geometry", "pseudo-Riemannian manifolds", "hyperbolic geometry", "elliptic geometry", "ultrahyperbolic geometry", "optimization on manifolds", "pseudo-Riemannian optimization", "quotient manifolds", "graph neural networks"], "TL;DR": "A (graph) neural network mapping representations to a pseudo-Riemannian manifold of constant curvature used to classify hierarchical graphs with cycles", "abstract": "Riemannian space forms, such as the Euclidean space, sphere and hyperbolic space, are popular and powerful representation spaces in machine learning. For instance, hyperbolic geometry is appropriate to represent graphs without cycles and has been used to extend Graph Neural Networks. Recently, some pseudo-Riemannian space forms that generalize both hyperbolic and spherical geometries have been exploited to learn a specific type of nonparametric embedding called ultrahyperbolic. The lack of geodesic between every pair of ultrahyperbolic points makes the task of learning parametric models (e.g., neural networks) difficult. This paper introduces a method to learn parametric models in ultrahyperbolic space. We experimentally show the relevance of our approach in the tasks of graph and node classification. ", "submission_history": "", "checklist": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "law|ultrahyperbolic_neural_networks", "pdf": "/pdf/cdd01cafaeefce33c4bf338f3307b04916f90038.pdf", "supplementary_material": "/attachment/a020a91f904afcd8fe85edf566d6773e00792e55.pdf", "thumbnail": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nlaw2021ultrahyperbolic,\ntitle={Ultrahyperbolic Neural Networks},\nauthor={Marc T Law},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=sf2BxJNXC3K}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492673660, "odate": 1636492673660, "details": {"replyCount": 16}}, {"id": "MgsSQPOYNx1", "original": "YBmqJEi6nEW", "number": 2913, "cdate": 1621629827361, "ddate": null, "tcdate": 1621629827361, "tmdate": 1683307579227, "tddate": null, "forum": "MgsSQPOYNx1", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Improved Learning Rates of a Functional Lasso-type SVM with Sparse Multi-Kernel Representation", "authorids": ["~shaogao_lv1", "~Junhui_Wang3", "~Jiankun_Liu1", "~Yong_Liu7"], "authors": ["shaogao lv", "Junhui Wang", "Jiankun Liu", "Yong Liu"], "keywords": ["Learning theory", "Lasso-type SVM", "Excess risk", "Multi-kernel learning"], "abstract": "In this paper, we  provide  theoretical results of estimation bounds and excess risk upper bounds for  support vector machine (SVM) with sparse multi-kernel representation. These convergence rates for multi-kernel SVM are established by analyzing a Lasso-type regularized learning scheme within composite multi-kernel spaces. It is shown that the oracle rates of convergence of classifiers depend on the complexity of  multi-kernels, the sparsity, a Bernstein condition and the sample size, which significantly improves on previous results even for the additive or linear cases. In summary, this paper not only provides unified theoretical results for multi-kernel SVMs, but also enriches the literature on high-dimensional nonparametric classification.", "submission_history": "", "checklist": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "lv|improved_learning_rates_of_a_functional_lassotype_svm_with_sparse_multikernel_representation", "pdf": "/pdf/e579f9f8479b425a8a1b6d683923d7b8cadaac82.pdf", "supplementary_material": "/attachment/c72e2af813a9c8bd5295bd2cd1f683754c54d2b6.pdf", "thumbnail": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nlv2021improved,\ntitle={Improved Learning Rates of a Functional Lasso-type {SVM} with Sparse Multi-Kernel Representation},\nauthor={shaogao lv and Junhui Wang and Jiankun Liu and Yong Liu},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=MgsSQPOYNx1}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492784908, "odate": 1636492784908, "details": {"replyCount": 15}}, {"id": "NvXnBQQw0Jb", "original": "gH1DoUKMpuG", "number": 2910, "cdate": 1621629827181, "ddate": null, "tcdate": 1621629827181, "tmdate": 1683307578944, "tddate": null, "forum": "NvXnBQQw0Jb", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Fast Bayesian Inference for Gaussian Cox Processes via Path Integral Formulation", "authorids": ["~Hideaki_Kim1"], "authors": ["Hideaki Kim"], "keywords": ["Gaussian Cox processes", "point processes", "time series analysis", "path integral", "Gaussian processes"], "abstract": "Gaussian Cox processes are widely-used point process models that use a Gaussian process to describe the Bayesian a priori uncertainty present in latent intensity functions. In this paper, we propose a novel Bayesian inference scheme for Gaussian Cox processes by exploiting a conceptually-intuitive {\u00a5it path integral} formulation. The proposed scheme does not rely on domain discretization, scales linearly with the number of observed events, has a lower complexity than the state-of-the-art variational Bayesian schemes with respect to the number of inducing points, and is applicable to a wide range of Gaussian Cox processes with various types of link functions. Our scheme is especially beneficial under the multi-dimensional input setting, where the number of inducing points tends to be large. We evaluate our scheme on synthetic and real-world data, and show that it achieves comparable predictive accuracy while being tens of times faster than reference methods.", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "kim|fast_bayesian_inference_for_gaussian_cox_processes_via_path_integral_formulation", "pdf": "/pdf/3bd21016fca74a8c7313a0190a5144e9d18110f8.pdf", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "checklist": "", "supplementary_material": "/attachment/2af69905b85f2b22dd266eff750034b4b696fdf2.pdf", "thumbnail": "", "_bibtex": "@inproceedings{\nkim2021fast,\ntitle={Fast Bayesian Inference for Gaussian Cox Processes via Path Integral Formulation},\nauthor={Hideaki Kim},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=NvXnBQQw0Jb}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492671230, "odate": 1636492671230, "details": {"replyCount": 12}}, {"id": "fzwx-pzQGxe", "original": "oUAEvs0ZgLV", "number": 2883, "cdate": 1621629825604, "ddate": null, "tcdate": 1621629825604, "tmdate": 1697937652580, "tddate": null, "forum": "fzwx-pzQGxe", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Learning to Compose Visual Relations", "authorids": ["~Nan_Liu4", "~Shuang_Li5", "~Yilun_Du1", "~Joshua_B._Tenenbaum1", "~Antonio_Torralba1"], "authors": ["Nan Liu", "Shuang Li", "Yilun Du", "Joshua B. Tenenbaum", "Antonio Torralba"], "keywords": ["Energy-based model", "Image editing", "Image generation", "Compositionality"], "abstract": "The visual world around us can be described as a structured set of objects and their associated relations. An image of a room may be conjured given only the description of the underlying objects and their associated relations. While there has been significant work on designing deep neural networks which may compose individual objects together, less work has been done on composing the individual relations between objects. A principal difficulty is that while the placement of objects is mutually independent, their relations are entangled and dependent on each other. To circumvent this issue, existing works primarily compose relations by utilizing a holistic encoder, in the form of text or graphs. In this work, we instead propose to represent each relation as an unnormalized density (an energy-based model), enabling us to compose separate relations in a factorized manner. We show that such a factorized decomposition allows the model to both generate and edit scenes that have multiple sets of relations more faithfully. We further show that decomposition enables our model to effectively understand the underlying relational scene structure.", "submission_history": "", "checklist": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "liu|learning_to_compose_visual_relations", "TL;DR": "Learning to compose visual relations using energy-based models.", "pdf": "/pdf/d408bdb10a704a667676f992b7afdb623b84bb74.pdf", "supplementary_material": "/attachment/dc1ec168f766ad16a6c598d1e83c4174611f8a7d.pdf", "thumbnail": "", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 2 code implementations](https://www.catalyzex.com/paper/arxiv:2111.09297/code)", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nliu2021learning,\ntitle={Learning to Compose Visual Relations},\nauthor={Nan Liu and Shuang Li and Yilun Du and Joshua B. Tenenbaum and Antonio Torralba},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=fzwx-pzQGxe}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492674917, "odate": 1636492674917, "details": {"replyCount": 16}}, {"id": "43fmQ-db-yJ", "original": "Lo3jgP0sP46", "number": 2817, "cdate": 1621629821922, "ddate": null, "tcdate": 1621629821922, "tmdate": 1683307577094, "tddate": null, "forum": "43fmQ-db-yJ", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Program Synthesis Guided Reinforcement Learning for Partially Observed Environments", "authorids": ["~Yichen_Yang1", "~Jeevana_Priya_Inala1", "~Osbert_Bastani1", "~Yewen_Pu1", "~Armando_Solar-Lezama1", "~Martin_Rinard1"], "authors": ["Yichen Yang", "Jeevana Priya Inala", "Osbert Bastani", "Yewen Pu", "Armando Solar-Lezama", "Martin Rinard"], "keywords": ["program synthesis", "reinforcement learning", "partial observation"], "abstract": "A key challenge for reinforcement learning is solving long-horizon planning problems. Recent work has leveraged programs to guide reinforcement learning in these settings. However, these approaches impose a high manual burden on the user since they must provide a guiding program for every new task. Partially observed environments further complicate the programming task because the program must implement a strategy that correctly, and ideally optimally, handles every possible configuration of the hidden regions of the environment. We propose a new approach, model predictive program synthesis (MPPS), that uses program synthesis to automatically generate the guiding programs. It trains a generative model to predict the unobserved portions of the world, and then synthesizes a program based on samples from this model in a way that is robust to its uncertainty. In our experiments, we show that our approach significantly outperforms non-program-guided approaches on a set of challenging benchmarks, including a 2D Minecraft-inspired environment where the agent must complete a complex sequence of subtasks to achieve its goal, and achieves a similar performance as using handcrafted programs to guide the agent. Our results demonstrate that our approach can obtain the benefits of program-guided reinforcement learning without requiring the user to provide a new guiding program for every new task.", "submission_history": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "yang|program_synthesis_guided_reinforcement_learning_for_partially_observed_environments", "pdf": "/pdf/ceb607c2bb76cb6de648533b9c54cf91a3baa6eb.pdf", "supplementary_material": "/attachment/c76c2a71fb04026bc8e4814404d299ccb9aeba6b.pdf", "checklist": "", "code": "https://github.com/yycdavid/program-synthesis-guided-RL", "thumbnail": "", "_bibtex": "@inproceedings{\nyang2021program,\ntitle={Program Synthesis Guided Reinforcement Learning for Partially Observed Environments},\nauthor={Yichen Yang and Jeevana Priya Inala and Osbert Bastani and Yewen Pu and Armando Solar-Lezama and Martin Rinard},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=43fmQ-db-yJ}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492705775, "odate": 1636492705732, "details": {"replyCount": 15}}, {"id": "Gl3ADZLz9ir", "original": "rvJlZhsPonB", "number": 2789, "cdate": 1621629820452, "ddate": null, "tcdate": 1621629820452, "tmdate": 1683307576265, "tddate": null, "forum": "Gl3ADZLz9ir", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Robust Learning of Optimal Auctions", "authorids": ["~Wenshuo_Guo1", "~Michael_Jordan1", "~Emmanouil_Zampetakis1"], "authors": ["Wenshuo Guo", "Michael Jordan", "Emmanouil Zampetakis"], "keywords": ["optimal auction", "robust learning", "sample complexity"], "TL;DR": "We propose new algorithms for learning multi-bidder revenue-optimal auctions from adversarially corrupted samples, providing robustness theorems and sample complexity bounds for various valuation distributions with optimality guarantees.", "abstract": "We study the problem of learning revenue-optimal multi-bidder auctions from samples when the samples of bidders' valuations can be adversarially corrupted or drawn from distributions that are adversarially perturbed. First, we prove tight upper bounds on the revenue we can obtain with a corrupted distribution under a population model, for both regular valuation distributions and distributions with monotone hazard rate (MHR). We then propose new algorithms that, given only an ``approximate distribution'' for the bidder's valuation, can learn a mechanism whose revenue is nearly optimal simultaneously for all ``true distributions'' that are $\\alpha$-close to the original distribution in Kolmogorov-Smirnov distance. The proposed algorithms operate beyond the setting of bounded distributions that have been studied in prior works, and are guaranteed to obtain a fraction  $1-O(\\alpha)$ of the optimal revenue under the true distribution when the distributions are MHR.  Moreover, they are guaranteed to yield at least a fraction $1-O(\\sqrt{\\alpha})$ of the optimal revenue when the distributions are regular. We prove that these upper bounds cannot be further improved, by providing matching lower bounds. Lastly, we derive sample complexity upper bounds for learning a near-optimal auction for both MHR and regular distributions.", "submission_history": "", "checklist": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "guo|robust_learning_of_optimal_auctions", "pdf": "/pdf/5f52880a6642779c2fa6017331c86ad05c3d8fba.pdf", "supplementary_material": "/attachment/7708e690e23babddfab42dc155453862f7ab4835.pdf", "thumbnail": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nguo2021robust,\ntitle={Robust Learning of Optimal Auctions},\nauthor={Wenshuo Guo and Michael Jordan and Emmanouil Zampetakis},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=Gl3ADZLz9ir}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492697823, "odate": 1636492697823, "details": {"replyCount": 10}}, {"id": "lMgDDWb1ULW", "original": "fI_6WmkGZe1", "number": 2772, "cdate": 1621629819550, "ddate": null, "tcdate": 1621629819550, "tmdate": 1683307575795, "tddate": null, "forum": "lMgDDWb1ULW", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Hash Layers For Large Sparse Models", "authorids": ["~Stephen_Roller1", "~Sainbayar_Sukhbaatar1", "~Arthur_Szlam1", "~Jason_E_Weston1"], "authors": ["Stephen Roller", "Sainbayar Sukhbaatar", "Arthur Szlam", "Jason E Weston"], "keywords": ["large-scale", "sparsity", "Transformers", "hashing", "MoE"], "TL;DR": "Proposes to use hashing to select model parameters per input for effective large, sparse Transformer models.", "abstract": "We investigate the training of sparse layers that use different parameters for different inputs based on hashing in large Transformer models. Specifically, we modify the feedforward layer to hash to different sets of weights depending on the current token, over all tokens in the sequence. We show that this procedure either outperforms or is competitive with learning-to-route mixture-of-expert methods such as Switch Transformers and BASE Layers, while requiring no routing parameters or extra terms in the objective function such as a load balancing loss, and no sophisticated assignment algorithm. We study the performance of different hashing techniques,  hash sizes and input features,  and  show that  balanced and random hashes focused on the most local features work best, compared to either learning clusters or using longer-range context. We show our approach works well both on large language modeling and dialogue tasks, and on downstream fine-tuning tasks.", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "roller|hash_layers_for_large_sparse_models", "pdf": "/pdf/c722df087549e62aa8f20733964d2fe2a2c94c6e.pdf", "supplementary_material": "/attachment/663dcea7fba4d5281c4aade76fad67f85bb61e6f.pdf", "checklist": "", "code": "https://github.com/facebookresearch/ParlAI/tree/main/projects/params_vs_compute", "thumbnail": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nroller2021hash,\ntitle={Hash Layers For Large Sparse Models},\nauthor={Stephen Roller and Sainbayar Sukhbaatar and Arthur Szlam and Jason E Weston},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=lMgDDWb1ULW}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492730116, "odate": 1636492730116, "details": {"replyCount": 10}}, {"id": "sNKpWhzEDWS", "original": "H9z-honh_Q", "number": 2758, "cdate": 1621629818775, "ddate": null, "tcdate": 1621629818775, "tmdate": 1683307575600, "tddate": null, "forum": "sNKpWhzEDWS", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Uncertain Decisions Facilitate Better Preference Learning", "authorids": ["~Cassidy_Laidlaw1", "~Stuart_Russell1"], "authors": ["Cassidy Laidlaw", "Stuart Russell"], "keywords": ["preference learning", "reward learning", "inverse reinforcement learning", "IRL", "statistical learning", "statistical learning theory", "PAC learning", "inverse decision theory", "IDT", "preference elicitation", "decision theory"], "TL;DR": "We give the first statistical analysis of inverse decision theory (IDT), showing that decisions made under uncertainty reveal more information about human preferences than obvious decisions.", "abstract": "Existing observational approaches for learning human preferences, such as inverse reinforcement learning, usually make strong assumptions about the observability of the human's environment. However, in reality, people make many important decisions under uncertainty. To better understand preference learning in these cases, we study the setting of inverse decision theory (IDT), a previously proposed framework where a human is observed making non-sequential binary decisions under uncertainty. In IDT, the human's preferences are conveyed through their loss function, which expresses a tradeoff between different types of mistakes. We give the first statistical analysis of IDT, providing conditions necessary to identify these preferences and characterizing the sample complexity\u2014the number of decisions that must be observed to learn the tradeoff the human is making to a desired precision. Interestingly, we show that it is actually easier to identify preferences when the decision problem is more uncertain. Furthermore, uncertain decision problems allow us to relax the unrealistic assumption that the human is an optimal decision maker but still identify their exact preferences; we give sample complexities in this suboptimal case as well. Our analysis contradicts the intuition that partial observability should make preference learning more difficult. It also provides a first step towards understanding and improving preference learning methods for uncertain and suboptimal humans.", "pdf": "/pdf/519b689c2ad1550e8825acd0b6dd1c8f09efd9e1.pdf", "supplementary_material": "/attachment/b4c73f41cb4ca8fa0d15bc79c81da483bb910b91.pdf", "submission_history": "", "checklist": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "laidlaw|uncertain_decisions_facilitate_better_preference_learning", "thumbnail": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nlaidlaw2021uncertain,\ntitle={Uncertain Decisions Facilitate Better Preference Learning},\nauthor={Cassidy Laidlaw and Stuart Russell},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=sNKpWhzEDWS}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492688439, "odate": 1636492688439, "details": {"replyCount": 10}}, {"id": "HbViCqfbd7", "original": "nXegP5uiT2g", "number": 2667, "cdate": 1621629813525, "ddate": null, "tcdate": 1621629813525, "tmdate": 1683307572638, "tddate": null, "forum": "HbViCqfbd7", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Parametric Complexity Bounds for Approximating PDEs with Neural Networks", "authorids": ["~Tanya_Marwah1", "~Zachary_Chase_Lipton1", "~Andrej_Risteski2"], "authors": ["Tanya Marwah", "Zachary Chase Lipton", "Andrej Risteski"], "keywords": ["PDE", "Partial Differential Equations", "Deep Learning Theory", "Universal Approximation"], "abstract": "Recent experiments have shown that deep networks can approximate solutions to high-dimensional PDEs, seemingly escaping the curse of dimensionality. However, questions regarding the theoretical basis for such approximations, including the required network size remain open. In this paper, we investigate the representational power of neural networks for approximating solutions to linear elliptic PDEs with Dirichlet boundary conditions. We prove that when a PDE's coefficients are representable by small neural networks, the parameters required to approximate its solution scale polynomially with the input dimension $d$ and proportionally to the parameter counts of the coefficient networks. To this end, we develop a proof technique that simulates gradient descent (in an appropriate Hilbert space) by growing a neural network architecture whose iterates each participate as sub-networks in their (slightly larger) successors, and converge to the solution of the PDE.", "submission_history": "", "submission_history_-_venue_and_year": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "marwah|parametric_complexity_bounds_for_approximating_pdes_with_neural_networks", "pdf": "/pdf/45507c8c98121ec502b1f8d6e0c553e78c9f6bd7.pdf", "submission_history_-_improvements_made": "", "checklist": "", "supplementary_material": "/attachment/651adcb01c7f367e5c3cd40336c0695c7f11a75e.pdf", "thumbnail": "", "_bibtex": "@inproceedings{\nmarwah2021parametric,\ntitle={Parametric Complexity Bounds for Approximating {PDE}s with Neural Networks},\nauthor={Tanya Marwah and Zachary Chase Lipton and Andrej Risteski},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=HbViCqfbd7}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492724592, "odate": 1636492724592, "details": {"replyCount": 30}}, {"id": "_MQBBpJzoZd", "original": "OU8tmHB5H9a", "number": 2654, "cdate": 1621629812767, "ddate": null, "tcdate": 1621629812767, "tmdate": 1697937663088, "tddate": null, "forum": "_MQBBpJzoZd", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Bayesian Bellman Operators", "authorids": ["~Matthew_Fellows1", "~Kristian_Hartikainen1", "~Shimon_Whiteson1"], "authors": ["Matthew Fellows", "Kristian Hartikainen", "Shimon Whiteson"], "keywords": ["Bayesian Reinforcement Learning", "Reinforcement Learning"], "abstract": "We introduce a novel perspective on Bayesian reinforcement learning (RL); whereas existing approaches infer a posterior over the transition distribution or Q-function, we characterise the uncertainty in the Bellman operator. Our Bayesian Bellman operator (BBO) framework is motivated by the insight that when bootstrapping is introduced, model-free approaches actually infer a posterior over Bellman operators, not value functions. In this paper, we use BBO to provide a rigorous theoretical analysis of model-free Bayesian RL to better understand its relationship to established frequentist RL methodologies. We prove that Bayesian solutions are consistent with frequentist RL solutions, even when approximate inference is used, and derive conditions for which  convergence properties hold. Empirically, we demonstrate that algorithms derived from the BBO framework have sophisticated deep exploration properties that enable them to solve continuous control tasks at which state-of-the-art regularised actor-critic algorithms fail catastrophically. ", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "fellows|bayesian_bellman_operators", "pdf": "/pdf/3a66fa5ab1aebd692ec2caa76a2a32d9acd89c35.pdf", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "checklist": "", "supplementary_material": "/attachment/7f2d79171a0607783132a0204ff33f0aa2a1f6e1.zip", "code": "", "thumbnail": "", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2106.05012/code)", "_bibtex": "@inproceedings{\nfellows2021bayesian,\ntitle={Bayesian Bellman Operators},\nauthor={Matthew Fellows and Kristian Hartikainen and Shimon Whiteson},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=_MQBBpJzoZd}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492714174, "odate": 1636492714174, "details": {"replyCount": 13}}, {"id": "_tQns0wUl_3", "original": "fNbrXx5puqs", "number": 2649, "cdate": 1621629812475, "ddate": null, "tcdate": 1621629812475, "tmdate": 1683307571744, "tddate": null, "forum": "_tQns0wUl_3", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Refined Learning Bounds for Kernel and Approximate $k$-Means", "authorids": ["~Yong_Liu7"], "authors": ["Yong Liu"], "keywords": ["Kernel $k$-means\uff0cRisk bound", "Kernel methods", "Learning theory"], "TL;DR": "In this paper,  we study the statistical properties of kernel $k$-means and Nystr\\\"{o}m-based kernel $k$-means, and obtain optimal clustering risk bounds, which improves on the existing risk bounds.", "abstract": "Kernel $k$-means is one of the most popular approaches to clustering and its theoretical properties have been investigated for decades. However, the existing state-of-the-art risk bounds are of order $\\mathcal{O}(k/\\sqrt{n})$, which do not match with the stated lower bound $\\Omega(\\sqrt{k/n})$ in terms of $k$, where $k$ is the number of clusters and $n$ is the size of the training set. In this paper, we study the statistical properties of kernel $k$-means and Nystr\\\"{o}m-based kernel $k$-means, and obtain optimal clustering risk bounds, which improve the existing risk bounds. Particularly, based on a refined upper bound of Rademacher complexity [21], we first derive an optimal risk bound of rate $\\mathcal{O}(\\sqrt{k/n})$ for empirical risk minimizer (ERM), and further extend it to general cases beyond ERM. Then, we analyze the statistical effect of computational approximations of Nystr\\\"{o}m kernel $k$-means, and prove that it achieves the same statistical accuracy as the original kernel $k$-means considering only $\\Omega(\\sqrt{nk})$ Nystr\\\"{o}m landmark points. We further relax the restriction of landmark points from $\\Omega(\\sqrt{nk})$ to $\\Omega(\\sqrt{n})$ under a mild condition. Finally, we validate the theoretical findings via numerical experiments.", "submission_history": "", "checklist": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "liu|refined_learning_bounds_for_kernel_and_approximate_kmeans", "pdf": "/pdf/945cb8202be907b423b57d81301402757a7a0123.pdf", "supplementary_material": "/attachment/fc41fd01cae6c408647e31ac0af16015c57e179b.pdf", "code": "http://www.csie.ntu.edu.tw/~cjlin/libsvm", "thumbnail": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nliu2021refined,\ntitle={Refined Learning Bounds for Kernel and Approximate \\$k\\$-Means},\nauthor={Yong Liu},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=_tQns0wUl_3}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492785043, "odate": 1636492785043, "details": {"replyCount": 12}}, {"id": "0vaPiltED1N", "original": "v9NdayjHfHa", "number": 2630, "cdate": 1621629811273, "ddate": null, "tcdate": 1621629811273, "tmdate": 1697937664814, "tddate": null, "forum": "0vaPiltED1N", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Sequence-to-Sequence Learning with Latent Neural Grammars", "authorids": ["~Yoon_Kim1"], "authors": ["Yoon Kim"], "keywords": ["sequence-to-sequence learning", "compositional generalization", "synchronous grammars"], "abstract": "Sequence-to-sequence learning with neural networks has become the de facto standard for sequence modeling. This approach typically models the local distribution over the next element with a powerful neural network that can condition on arbitrary context. While flexible and performant, these models often require large datasets for training and can fail spectacularly on benchmarks designed to test for compositional generalization. This work explores an alternative, hierarchical approach to sequence-to-sequence learning with synchronous grammars, where each node in the target tree is transduced by a subset of nodes in the source tree. The source and target trees are treated as fully latent and marginalized out during training. We develop a neural parameterization of the grammar which enables parameter sharing over combinatorial structures without the need for manual feature engineering. We apply this latent neural grammar to various domains---a diagnostic language navigation task designed to test for compositional generalization (SCAN), style transfer, and small-scale machine translation---and find that it performs respectably compared to standard baselines.", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "kim|sequencetosequence_learning_with_latent_neural_grammars", "pdf": "/pdf/b3dc1d866e1ca0a79b93f0b7f76c61cc8eabba4f.pdf", "supplementary_material": "/attachment/571c3340c4790e8888ddd593163bb71da2c79dbf.pdf", "checklist": "", "code": "https://github.com/yoonkim/neural-qcfg", "thumbnail": "", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 3 code implementations](https://www.catalyzex.com/paper/arxiv:2109.01135/code)", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nkim2021sequencetosequence,\ntitle={Sequence-to-Sequence Learning with Latent Neural Grammars},\nauthor={Yoon Kim},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=0vaPiltED1N}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492682494, "odate": 1636492682448, "details": {"replyCount": 11}}, {"id": "4fLr7H5D_eT", "original": "jdNdE3DB2Rb", "number": 2613, "cdate": 1621629810293, "ddate": null, "tcdate": 1621629810293, "tmdate": 1683307570855, "tddate": null, "forum": "4fLr7H5D_eT", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "FjORD: Fair and Accurate Federated Learning under heterogeneous targets with Ordered Dropout", "authorids": ["~Samuel_Horv\u00e1th1", "~Stefanos_Laskaridis1", "4knahs@gmail.com", "~Ilias_Leontiadis1", "~Stylianos_Venieris1", "~Nicholas_Donald_Lane1"], "authors": ["Samuel Horv\u00e1th", "Stefanos Laskaridis", "Mario Almeida", "Ilias Leontiadis", "Stylianos Venieris", "Nicholas Donald Lane"], "keywords": ["Federated Learning", "Heterogeneity", "Efficient DNNs", "Distributed Systems"], "abstract": "Federated Learning (FL) has been gaining significant traction across different ML tasks, ranging from vision to keyboard predictions. In large-scale deployments, client heterogeneity is a fact and constitutes a primary problem for fairness, training performance and accuracy. Although significant efforts have been made into tackling statistical data heterogeneity, the diversity in the processing capabilities and network bandwidth of clients, termed system heterogeneity, has remained largely unexplored. Current solutions either disregard a large portion of available devices or set a uniform limit on the model's capacity, restricted by the least capable participants.\n\nIn this work, we introduce Ordered Dropout, a mechanism that achieves an ordered, nested representation of knowledge in Neural Networks and enables the extraction of lower footprint submodels without the need for retraining. We further show that for linear maps our Ordered Dropout is equivalent to SVD.  We employ this technique, along with a self-distillation methodology, in the realm of FL in a framework called FjORD. FjORD alleviates the problem of client system heterogeneity by tailoring the model width to the client's capabilities. \nExtensive evaluation on both CNNs and RNNs across diverse modalities shows that FjORD consistently leads to significant performance gains over state-of-the-art baselines while maintaining its nested structure.", "submission_history": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "horv\u00e1th|fjord_fair_and_accurate_federated_learning_under_heterogeneous_targets_with_ordered_dropout", "pdf": "/pdf/46e1880fced843724abe964abebd92266081ec75.pdf", "supplementary_material": "/attachment/5797de4fa8656ad241754465be1db19567e726ec.pdf", "checklist": "", "TL;DR": "FjORD is elastically scaling a networks footprint, via Ordered Dropout, to tackle system heterogeneity in Federated Learning.", "thumbnail": "", "_bibtex": "@inproceedings{\nhorv{\\'a}th2021fjord,\ntitle={Fj{ORD}: Fair and Accurate Federated Learning under heterogeneous targets with Ordered Dropout},\nauthor={Samuel Horv{\\'a}th and Stefanos Laskaridis and Mario Almeida and Ilias Leontiadis and Stylianos Venieris and Nicholas Donald Lane},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=4fLr7H5D_eT}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492747383, "odate": 1636492747383, "details": {"replyCount": 14}}, {"id": "eIdzV1-Jdwv", "original": "84_3H6S-r3L", "number": 2478, "cdate": 1621629802491, "ddate": null, "tcdate": 1621629802491, "tmdate": 1683307567788, "tddate": null, "forum": "eIdzV1-Jdwv", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Beyond Tikhonov: faster learning with self-concordant losses, via iterative regularization", "authorids": ["~Gaspard_Beugnot1", "~Julien_Mairal1", "~Alessandro_Rudi1"], "authors": ["Gaspard Beugnot", "Julien Mairal", "Alessandro Rudi"], "keywords": ["Kernel methods", "learning theory", "self concordance", "iterated tikhonov", "proximal point"], "TL;DR": "The iterative Thikonov regularization scheme achieves optimal sample complexity on self concordant losses. ", "abstract": "The theory of spectral filtering is a remarkable tool to understand the statistical properties of learning with kernels. For least squares, it allows to derive various regularization schemes that yield faster convergence rates of the excess risk than with Tikhonov regularization. This is typically achieved by leveraging classical assumptions called source and capacity conditions, which characterize the difficulty of the learning task. In order to understand estimators derived from other loss functions, Marteau-Ferey et al. have extended the theory of Tikhonov regularization to generalized self concordant loss functions (GSC), which contain, e.g., the logistic loss. In this paper, we go a step further and show that fast and optimal rates can be achieved for GSC by using the iterated Tikhonov regularization scheme, which is intrinsically related to the proximal point method in optimization, and overcomes the limitation of the classical Tikhonov regularization.", "submission_history": "", "checklist": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "beugnot|beyond_tikhonov_faster_learning_with_selfconcordant_losses_via_iterative_regularization", "pdf": "/pdf/f5a1917aebd2bfa6d9a100a36ba84eeb512f7205.pdf", "supplementary_material": "/attachment/d83be0a7f6119ffb0e72261ef03921807a51a5f1.pdf", "code": "/attachment/b1e5281a0f8e8c7ecb9ad40d3cb25936f672b4ef.zip", "thumbnail": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nbeugnot2021beyond,\ntitle={Beyond Tikhonov: faster learning with self-concordant losses, via iterative regularization},\nauthor={Gaspard Beugnot and Julien Mairal and Alessandro Rudi},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=eIdzV1-Jdwv}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492765519, "odate": 1636492765478, "details": {"replyCount": 15}}, {"id": "vrkQ07gp0kq", "original": "_OT1nrKt6o4", "number": 2423, "cdate": 1621629799428, "ddate": null, "tcdate": 1621629799428, "tmdate": 1697937672238, "tddate": null, "forum": "vrkQ07gp0kq", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "TOHAN: A One-step Approach towards Few-shot Hypothesis Adaptation", "authorids": ["~Haoang_Chi1", "~Feng_Liu2", "~Wenjing_Yang1", "~Long_Lan2", "~Tongliang_Liu1", "~Bo_Han1", "~William_Cheung1", "~James_Kwok1"], "authors": ["Haoang Chi", "Feng Liu", "Wenjing Yang", "Long Lan", "Tongliang Liu", "Bo Han", "William Cheung", "James Kwok"], "keywords": ["transfer learning", "domain adaptation", "few-shot learning"], "abstract": "In few-shot domain adaptation (FDA), classifiers for the target domain are trained with \\emph{accessible} labeled data in the source domain (SD) and few labeled data in the target domain (TD). However, data usually contain private information in the current era, e.g., data distributed on personal phones. Thus, the private data will be leaked if we directly access data in SD to train a target-domain classifier (required by FDA methods). In this paper, to prevent privacy leakage in SD, we consider a very challenging problem setting, where the classifier for the TD has to be trained using few labeled target data and a well-trained SD classifier, named few-shot hypothesis adaptation (FHA). In FHA, we cannot access data in SD, as a result, the private information in SD will be protected well. To this end, we propose a target-oriented hypothesis adaptation network (TOHAN) to solve the FHA problem, where we generate highly-compatible unlabeled data (i.e., an intermediate domain) to help train a target-domain classifier. TOHAN maintains two deep networks simultaneously, in which one focuses on learning an intermediate domain and the other takes care of the intermediate-to-target distributional adaptation and the target-risk minimization. Experimental results show that TOHAN outperforms competitive baselines significantly.", "submission_history": "", "checklist": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "chi|tohan_a_onestep_approach_towards_fewshot_hypothesis_adaptation", "pdf": "/pdf/0cb54ceaf3e87a531ea687fc7325a7606f099328.pdf", "supplementary_material": "/attachment/4957ceb663e5a564a88be4d3bca41afda3bf9d11.pdf", "thumbnail": "", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2106.06326/code)", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nchi2021tohan,\ntitle={{TOHAN}: A One-step Approach towards Few-shot Hypothesis Adaptation},\nauthor={Haoang Chi and Feng Liu and Wenjing Yang and Long Lan and Tongliang Liu and Bo Han and William Cheung and James Kwok},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=vrkQ07gp0kq}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492741099, "odate": 1636492741099, "details": {"replyCount": 23}}, {"id": "RQfcckT1M_4", "original": "syLMmZ7uF5M", "number": 2407, "cdate": 1621629798545, "ddate": null, "tcdate": 1621629798545, "tmdate": 1697937672430, "tddate": null, "forum": "RQfcckT1M_4", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Self-Supervised Learning Disentangled Group Representation as Feature", "authorids": ["~Tan_Wang1", "~Zhongqi_Yue1", "~Jianqiang_Huang2", "~Qianru_Sun2", "~Hanwang_Zhang3"], "authors": ["Tan Wang", "Zhongqi Yue", "Jianqiang Huang", "Qianru Sun", "Hanwang Zhang"], "keywords": ["Self-Supervised Learning", "Feature Disentanglement", "Invariant Risk Minimization", "Group Representation"], "TL;DR": "An iterative IRM algorithm for unsupervised feature disentanglement and self-supervised feature learning ", "abstract": "A good visual representation is an inference map from observations (images) to features (vectors) that faithfully reflects the hidden modularized generative factors (semantics). In this paper, we formulate the notion of \"good\" representation from a group-theoretic view using Higgins' definition of disentangled representation, and show that existing Self-Supervised Learning (SSL) only disentangles simple augmentation features such as rotation and colorization, thus unable to modularize the remaining semantics. To break the limitation, we propose an iterative SSL algorithm: Iterative Partition-based Invariant Risk Minimization (IP-IRM), which successfully grounds the abstract semantics and the group acting on them into concrete contrastive learning. At each iteration, IP-IRM first partitions the training samples into two subsets that correspond to an entangled group element. Then, it minimizes a subset-invariant contrastive loss, where the invariance guarantees to disentangle the group element. We prove that IP-IRM converges to a fully disentangled representation and show its effectiveness on various benchmarks. Codes are available at https://github.com/Wangt-CN/IP-IRM.", "pdf": "/pdf/c097c7e762f1df572eff29c172596dd435e72b95.pdf", "supplementary_material": "/attachment/b692ce25297238bb7ec439e76258c7bc507b3ce7.pdf", "submission_history": "", "submission_history_-_venue_and_year": "", "checklist": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "wang|selfsupervised_learning_disentangled_group_representation_as_feature", "code": "https://github.com/Wangt-CN/IP-IRM", "thumbnail": "", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 10 code implementations](https://www.catalyzex.com/paper/arxiv:2110.15255/code)", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nwang2021selfsupervised,\ntitle={Self-Supervised Learning Disentangled Group Representation as Feature},\nauthor={Tan Wang and Zhongqi Yue and Jianqiang Huang and Qianru Sun and Hanwang Zhang},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=RQfcckT1M_4}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492691191, "odate": 1636492691191, "details": {"replyCount": 18}}, {"id": "OJLaKwiXSbx", "original": "XkWUWzR9YA", "number": 2363, "cdate": 1621629796023, "ddate": null, "tcdate": 1621629796023, "tmdate": 1697937674033, "tddate": null, "forum": "OJLaKwiXSbx", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Align before Fuse: Vision and Language Representation Learning with Momentum Distillation", "authorids": ["~Junnan_Li2", "~Ramprasaath_R._Selvaraju1", "~Akhilesh_Deepak_Gotmare1", "~Shafiq_Joty1", "~Caiming_Xiong1", "~Steven_Hoi2"], "authors": ["Junnan Li", "Ramprasaath R. Selvaraju", "Akhilesh Deepak Gotmare", "Shafiq Joty", "Caiming Xiong", "Steven Hoi"], "keywords": ["vision and language pre-training", "representation learning", "image-text retrieval", "visual question answering", "vision-language reasoning"], "abstract": "Large-scale vision and language representation learning has shown promising improvements on various vision-language tasks. Most existing methods employ a transformer-based multimodal encoder to jointly model visual tokens (region-based image features) and word tokens. Because the visual tokens and word tokens are unaligned, it is challenging for the multimodal encoder to learn image-text interactions. In this paper, we introduce a contrastive loss to ALign the image and text representations BEfore Fusing (ALBEF) them through cross-modal attention, which enables more grounded vision and language representation learning. Unlike most existing methods, our method does not require bounding box annotations nor high-resolution images. In order to improve learning from noisy web data, we propose momentum distillation, a self-training method which learns from pseudo-targets produced by a momentum model. We provide a theoretical analysis of ALBEF from a mutual information maximization perspective, showing that different training tasks can be interpreted as different ways to generate views for an image-text pair. ALBEF achieves state-of-the-art performance on multiple downstream vision-language tasks. On image-text retrieval, ALBEF outperforms methods that are pre-trained on orders of magnitude larger datasets. On VQA and NLVR$^2$, ALBEF achieves absolute improvements of 2.37% and 3.84% compared to the state-of-the-art, while enjoying faster inference speed. Code and models are available at https://github.com/salesforce/ALBEF.", "submission_history": "", "checklist": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "li|align_before_fuse_vision_and_language_representation_learning_with_momentum_distillation", "TL;DR": "We propose aligning image and text representations using contrastive learning to enable better image-text interactions with a multimodal transformer encoder, which leads to superior vision-language representations for multiple downstream tasks.", "pdf": "/pdf/3871e256115f20fc403eb8052c4244a4ca63ac0c.pdf", "supplementary_material": "/attachment/963dc9c7f94f27755bc384182d685ffff2b3a495.pdf", "code": "https://github.com/salesforce/ALBEF", "thumbnail": "", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 2 code implementations](https://www.catalyzex.com/paper/arxiv:2107.07651/code)", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nli2021align,\ntitle={Align before Fuse: Vision and Language Representation Learning with Momentum Distillation},\nauthor={Junnan Li and Ramprasaath R. Selvaraju and Akhilesh Deepak Gotmare and Shafiq Joty and Caiming Xiong and Steven Hoi},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=OJLaKwiXSbx}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492788652, "odate": 1636492788652, "details": {"replyCount": 15}}, {"id": "RcbphT7qjTq", "original": "TzwaTIkjfzJ", "number": 2350, "cdate": 1621629795301, "ddate": null, "tcdate": 1621629795301, "tmdate": 1683307565822, "tddate": null, "forum": "RcbphT7qjTq", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Spherical Motion Dynamics: Learning Dynamics of Normalized Neural Network using SGD and Weight Decay", "authorids": ["~Ruosi_Wan4", "~Zhanxing_Zhu1", "~Xiangyu_Zhang1", "~Jian_Sun4"], "authors": ["Ruosi Wan", "Zhanxing Zhu", "Xiangyu Zhang", "Jian Sun"], "keywords": ["normalization", "weight decay", "stochastic gradient descent", "momentum", "neural network"], "TL;DR": "Theoretical and empirical analysis on learning dynamics of neural network with normalization and weight decay.", "abstract": "In this paper, we comprehensively reveal the learning dynamics of normalized neural network using Stochastic Gradient Descent (with momentum) and Weight Decay (WD), named as Spherical Motion Dynamics (SMD). Most related works focus on studying behavior of ``effective learning rate\" in ``equilibrium\" state, i.e. assuming weight norm remains unchanged. However, their discussion on why this equilibrium can be reached is either absent or less convincing. Our work directly explores the cause of equilibrium, as a special state of SMD. Specifically, 1) we introduce the assumptions that can lead to equilibrium state in SMD, and prove equilibrium can be reached in a linear rate regime under given assumptions; 2) we propose ``angular update\" as a substitute for effective learning rate to depict the state of SMD, and derive the theoretical value of angular update in equilibrium state; 3) we verify our assumptions and theoretical results on various large-scale computer vision tasks including ImageNet and MSCOCO with standard settings. Experiment results show our theoretical findings agree well with empirical observations. We also show that the behavior of angular update in SMD can produce interesting effect to the optimization of neural network in practice.", "pdf": "/pdf/b77bb74576d0b8d2400e1003112b402e2141e8fb.pdf", "supplementary_material": "/attachment/3f3585574555c17c0d3828931403d464f85278eb.pdf", "submission_history": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "checklist": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "wan|spherical_motion_dynamics_learning_dynamics_of_normalized_neural_network_using_sgd_and_weight_decay", "thumbnail": "", "_bibtex": "@inproceedings{\nwan2021spherical,\ntitle={Spherical Motion Dynamics: Learning Dynamics of Normalized Neural Network using {SGD} and Weight Decay},\nauthor={Ruosi Wan and Zhanxing Zhu and Xiangyu Zhang and Jian Sun},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=RcbphT7qjTq}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492788702, "odate": 1636492788702, "details": {"replyCount": 20}}, {"id": "8AgtfqiHUhs", "original": "FhZ9lxqve4K", "number": 2343, "cdate": 1621629794898, "ddate": null, "tcdate": 1621629794898, "tmdate": 1683307565486, "tddate": null, "forum": "8AgtfqiHUhs", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Embedding Principle of Loss Landscape of Deep Neural Networks", "authorids": ["~Yaoyu_Zhang1", "~Zhongwang_Zhang1", "~Tao_Luo3", "~Zhiqin_Xu1"], "authors": ["Yaoyu Zhang", "Zhongwang Zhang", "Tao Luo", "Zhiqin Xu"], "keywords": ["deep neural network", "embedding principle", "loss landscape", "critical points", "degree of degeneracy"], "abstract": "Understanding the structure of loss landscape of deep neural networks (DNNs) is obviously important. In this work, we prove an embedding principle that the loss landscape of a DNN \"contains\" all the critical points of all the narrower DNNs. More precisely, we propose a critical embedding such that any critical point, e.g., local or global minima, of a narrower DNN can be embedded to a critical point/affine subspace of the target DNN with higher degeneracy and preserving the DNN output function. Note that, given any training data, differentiable loss function and differentiable activation function, this embedding structure of critical points holds.This general structure of DNNs is starkly different from other nonconvex problems such as protein-folding.Empirically, we find that a wide DNN is often attracted by highly-degenerate critical points that are embedded from narrow DNNs. The embedding principle provides a new perspective to study the general easy optimization of wide DNNs and unravels a potential implicit low-complexity regularization during the training.Overall, our work provides a skeleton for the study of loss landscape of DNNs and its implication, by which a more exact and comprehensive understanding can be anticipated in the near future. ", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "zhang|embedding_principle_of_loss_landscape_of_deep_neural_networks", "TL;DR": "Embedding principle: the loss landscape of any network contains all critical points of all narrower networks.", "pdf": "/pdf/90ff166eaeae4b868cf406b459c8ab9221a80c56.pdf", "supplementary_material": "/attachment/951b263dd1d41c77313a4a2cd92370cc7ce2e0e6.pdf", "checklist": "", "code": "/attachment/101e2cff39bd5161efa0cfc909bf97bfc3d5e361.zip", "thumbnail": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nzhang2021embedding,\ntitle={Embedding Principle of Loss Landscape of Deep Neural Networks},\nauthor={Yaoyu Zhang and Zhongwang Zhang and Tao Luo and Zhiqin Xu},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=8AgtfqiHUhs}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492685057, "odate": 1636492685057, "details": {"replyCount": 17}}, {"id": "-JJy-Hw8TFB", "original": "7w7ydjJLZK", "number": 2319, "cdate": 1621629793471, "ddate": null, "tcdate": 1621629793471, "tmdate": 1683307565009, "tddate": null, "forum": "-JJy-Hw8TFB", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "ViSER: Video-Specific Surface Embeddings for Articulated 3D Shape Reconstruction", "authorids": ["~Gengshan_Yang1", "~Deqing_Sun2", "~Varun_Jampani2", "~Daniel_Vlasic1", "~Forrester_Cole1", "~Ce_Liu1", "~Deva_Ramanan1"], "authors": ["Gengshan Yang", "Deqing Sun", "Varun Jampani", "Daniel Vlasic", "Forrester Cole", "Ce Liu", "Deva Ramanan"], "keywords": ["articulated shape from videos", "nonrigid shape reconstruction", "dense correspondence", "differentiable rendering"], "TL;DR": "A method for jointly recovering an articulated 3D shape and dense correspondences from a monocular video through learned surface embeddings. ", "abstract": "We introduce ViSER, a method for recovering articulated 3D shapes and dense3D trajectories from monocular videos.  Previous work on high-quality reconstruction of dynamic 3D shapes typically relies on multiple camera views, strong category-specific priors, or 2D keypoint supervision. We show that none of these are required if one can reliably estimate long-range correspondences in a video, making use of only 2D object masks and two-frame optical flow as inputs. ViSER infers correspondences by matching 2D pixels to a canonical,  deformable 3D mesh via video-specific surface embeddings that capture the pixel appearance of each surface point.  These embeddings behave as a continuous set of keypoint descriptors defined over the mesh surface, which can be used to establish dense long-range correspondences across pixels.  The surface embeddings are implemented as coordinate-based MLPs that are fit to each video via self-supervised losses.Experimental results show that ViSER compares favorably against prior work on challenging videos of humans with loose clothing and unusual poses as well as animals videos from DAVIS and YTVOS. Project page: viser-shape.github.io.", "submission_history": "", "checklist": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "yang|viser_videospecific_surface_embeddings_for_articulated_3d_shape_reconstruction", "pdf": "/pdf/9720a57b71b2c1f6f7271cb0f2fd467e0425a007.pdf", "supplementary_material": "/attachment/df4e9a7149568f7fe1df6fe596f4d8b7b716d2ec.pdf", "code": "https://viser-shape.github.io/", "thumbnail": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nyang2021viser,\ntitle={Vi{SER}: Video-Specific Surface Embeddings for Articulated 3D Shape Reconstruction},\nauthor={Gengshan Yang and Deqing Sun and Varun Jampani and Daniel Vlasic and Forrester Cole and Ce Liu and Deva Ramanan},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=-JJy-Hw8TFB}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492735715, "odate": 1636492735715, "details": {"replyCount": 10}}, {"id": "mIki_kyHpLb", "original": "ek72RDe63kh", "number": 2258, "cdate": 1621629790004, "ddate": null, "tcdate": 1621629790004, "tmdate": 1683307564161, "tddate": null, "forum": "mIki_kyHpLb", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "A$^2$-Net: Learning Attribute-Aware Hash Codes for Large-Scale Fine-Grained Image Retrieval", "authorids": ["~Xiu-Shen_Wei1", "~Yang_Shen6", "~Xuhao_Sun1", "~Han-Jia_Ye1", "~Jian_Yang1"], "authors": ["Xiu-Shen Wei", "Yang Shen", "Xuhao Sun", "Han-Jia Ye", "Jian Yang"], "keywords": ["Fine-Grained Image Retrieval", "Large-Scale Data", "Attribute-Aware", "Learning to Hash"], "abstract": "Our work focuses on tackling large-scale fine-grained image retrieval as ranking the images depicting the concept of interests (i.e., the same sub-category labels) highest based on the fine-grained details in the query. It is desirable to alleviate the challenges of both fine-grained nature of small inter-class variations with large intra-class variations and explosive growth of fine-grained data for such a practical task. In this paper, we propose an Attribute-Aware hashing Network (A$^2$-Net) for generating attribute-aware hash codes to not only make the retrieval process efficient, but also establish explicit correspondences between hash codes and visual attributes. Specifically, based on the captured visual representations by attention, we develop an encoder-decoder structure network of a reconstruction task to unsupervisedly distill high-level attribute-specific vectors from the appearance-specific visual representations without attribute annotations. A$^2$-Net is also equipped with a feature decorrelation constraint upon these attribute vectors to enhance their representation abilities. Finally, the required hash codes are generated by the attribute vectors driven by preserving original similarities. Qualitative experiments on five benchmark fine-grained datasets show our superiority over competing methods. More importantly, quantitative results demonstrate the obtained hash codes can strongly correspond to certain kinds of crucial properties of fine-grained objects.", "submission_history": "", "checklist": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "wei|a^2net_learning_attributeaware_hash_codes_for_largescale_finegrained_image_retrieval", "TL;DR": "We propose a novel deep hashing model as expected to be efficient, effective and more importantly interpretable for the large-scale fine-grained retrieval task.", "pdf": "/pdf/572f1125b3e9beb31d206398602339afd955769a.pdf", "supplementary_material": "/attachment/ffac9fdc11e079d201fef4183bd8d7672cfcb8b7.pdf", "thumbnail": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nwei2021anet,\ntitle={A\\${\\textasciicircum}2\\$-Net: Learning Attribute-Aware Hash Codes for Large-Scale Fine-Grained Image Retrieval},\nauthor={Xiu-Shen Wei and Yang Shen and Xuhao Sun and Han-Jia Ye and Jian Yang},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=mIki_kyHpLb}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492768976, "odate": 1636492768976, "details": {"replyCount": 9}}, {"id": "OItvP2-i9j", "original": "z_lIx0_CsLV", "number": 2240, "cdate": 1621629788951, "ddate": null, "tcdate": 1621629788951, "tmdate": 1683307563390, "tddate": null, "forum": "OItvP2-i9j", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Closing the Gap: Tighter Analysis of Alternating Stochastic Gradient Methods for Bilevel Problems", "authorids": ["~Tianyi_Chen5", "~Yuejiao_Sun1", "~Wotao_Yin1"], "authors": ["Tianyi Chen", "Yuejiao Sun", "Wotao Yin"], "keywords": ["Stochastic bilevel optimization", "min-max optimization", "compositional optimization", "convergence analysis"], "TL;DR": "Our results explain why simple SGD-type algorithms all work very well in practical bilevel problems without the need for further modifications. ", "abstract": "Stochastic nested optimization, including stochastic compositional, min-max, and bilevel optimization, is gaining popularity in many machine learning applications. \nWhile the three problems share a nested structure, existing works often treat them separately, thus developing problem-specific algorithms and analyses. \nAmong various exciting developments, simple SGD-type updates (potentially on multiple variables) are still prevalent in solving this class of nested problems, but they are believed to have a slower convergence rate than non-nested problems. \nThis paper unifies several SGD-type updates for stochastic nested problems into a single SGD approach that we term ALternating Stochastic gradient dEscenT (ALSET) method. By leveraging the hidden smoothness of the problem, this paper presents a tighter analysis of ALSET for stochastic nested problems. \nUnder the new analysis, to achieve an $\\epsilon$-stationary point of the nested problem, it requires ${\\cal O}(\\epsilon^{-2})$ samples in total. \nUnder certain regularity conditions, applying our results to stochastic compositional, min-max, and reinforcement learning problems either improves or matches the best-known sample complexity in the respective cases. \nOur results explain why simple SGD-type algorithms in stochastic nested problems all work very well in practice without the need for further modifications. ", "pdf": "/pdf/73ab2738d167100d1ec6b33c2f518db5b403da63.pdf", "supplementary_material": "/attachment/3f4b9b2fcba9cd8ae65c2122a52078cbf622aeb1.pdf", "submission_history": "", "checklist": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "chen|closing_the_gap_tighter_analysis_of_alternating_stochastic_gradient_methods_for_bilevel_problems", "thumbnail": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nchen2021closing,\ntitle={Closing the Gap: Tighter Analysis of Alternating Stochastic Gradient Methods for Bilevel Problems},\nauthor={Tianyi Chen and Yuejiao Sun and Wotao Yin},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=OItvP2-i9j}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492670354, "odate": 1636492670308, "details": {"replyCount": 10}}, {"id": "GvU4RvMwlGo", "original": "9f6mEy8JDL5", "number": 2206, "cdate": 1621629786921, "ddate": null, "tcdate": 1621629786921, "tmdate": 1697937679818, "tddate": null, "forum": "GvU4RvMwlGo", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Coresets for Decision Trees of Signals", "authorids": ["~Ibrahim_Jubran1", "~Ernesto_Evgeniy_Sanches_Shayda1", "ilan@cs.haifa.ac.il", "~Dan_Feldman1"], "authors": ["Ibrahim Jubran", "Ernesto Evgeniy Sanches Shayda", "Ilan Newman", "Dan Feldman"], "keywords": ["Coresets", "Machine Learning", "Decision Trees", "Random Forests"], "abstract": "A $k$-decision tree $t$ (or $k$-tree) is a recursive partition of a matrix (2D-signal) into $k\\geq 1$ block matrices (axis-parallel rectangles, leaves) where each rectangle is assigned a real label. Its regression or classification loss to a given matrix $D$ of $N$ entries (labels) is the sum of squared differences over every label in $D$ and its assigned label by $t$.\nGiven an error parameter $\\varepsilon\\in(0,1)$, a $(k,\\varepsilon)$-coreset $C$ of $D$ is a small summarization that provably approximates this loss to \\emph{every} such tree, up to a multiplicative factor of $1\\pm\\varepsilon$. In particular, the optimal $k$-tree of $C$ is a $(1+\\varepsilon)$-approximation to the optimal $k$-tree of $D$.\n\nWe provide the first algorithm that outputs such a $(k,\\varepsilon)$-coreset for \\emph{every} such matrix $D$. The size $|C|$ of the coreset is polynomial in $k\\log(N)/\\varepsilon$, and its construction takes $O(Nk)$ time.\nThis is by forging a link between decision trees from machine learning -- to partition trees in computational geometry. \n\nExperimental results on \\texttt{sklearn} and \\texttt{lightGBM} show that applying our coresets on real-world data-sets boosts the computation time of random forests and their parameter tuning by up to x$10$, while keeping similar accuracy. Full open source code is provided.", "submission_history": "", "checklist": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "jubran|coresets_for_decision_trees_of_signals", "pdf": "/pdf/76d15a9db13a84df21f931a588e24ba4cba2fc4e.pdf", "supplementary_material": "/attachment/06339e0688c9c981eb68c89cb35ca83cfbd53131.pdf", "TL;DR": "Coresets for Decision Trees of Signals", "code": "https://github.com/ernestosanches/Decision-Trees-Coreset", "thumbnail": "", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2110.03195/code)", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\njubran2021coresets,\ntitle={Coresets for Decision Trees of Signals},\nauthor={Ibrahim Jubran and Ernesto Evgeniy Sanches Shayda and Ilan Newman and Dan Feldman},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=GvU4RvMwlGo}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492774873, "odate": 1636492774827, "details": {"replyCount": 7}}, {"id": "-16dlERMZkO", "original": "Yyzki_VBUi7", "number": 2175, "cdate": 1621629785257, "ddate": null, "tcdate": 1621629785257, "tmdate": 1683307561646, "tddate": null, "forum": "-16dlERMZkO", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Private Non-smooth ERM and SCO in Subquadratic Steps", "authorids": ["~Janardhan_Kulkarni2", "~Yin_Tat_Lee1", "~Daogao_Liu1"], "authors": ["Janardhan Kulkarni", "Yin Tat Lee", "Daogao Liu"], "keywords": ["Differential Privacy", "Stochastic convex optimization", "Empirical risk minimization"], "TL;DR": "The first private algorithms for SCO and ERM with  optimal loss and subquadratic gradient queries", "abstract": "We study the differentially private Empirical Risk Minimization (ERM) and Stochastic Convex Optimization (SCO) problems for non-smooth convex functions. \nWe get a (nearly) optimal bound on the excess empirical risk for ERM with $O(\\frac{N^{3/2}}{d^{1/8}}+ \\frac{N^2}{d})$ gradient queries, which is achieved with the help of subsampling and smoothing the function via convolution. \nCombining this result with the iterative localization technique of Feldman et al. \\cite{fkt20}, we achieve the optimal excess population loss for the SCO problem with $O(\\min\\{N^{5/4}d^{1/8},\\frac{ N^{3/2}}{d^{1/8}}\\})$ gradient queries.\nOur work makes progress towards resolving a question raised by Bassily et al. \\cite{bfgt20}, giving first algorithms for private SCO with subquadratic steps. \nIn a concurrent work, Asi et al. \\cite{afkt21} gave other algorithms for private ERM and SCO with subquadratic steps.", "submission_history": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "checklist": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "kulkarni|private_nonsmooth_erm_and_sco_in_subquadratic_steps", "pdf": "/pdf/8c0be840bb3a6f85de9ca1ee93972b81290d971f.pdf", "supplementary_material": "/attachment/28b4c56aac5502668c211f2edc85db3e551495d0.pdf", "thumbnail": "", "_bibtex": "@inproceedings{\nkulkarni2021private,\ntitle={Private Non-smooth {ERM} and {SCO} in Subquadratic Steps},\nauthor={Janardhan Kulkarni and Yin Tat Lee and Daogao Liu},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=-16dlERMZkO}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492753303, "odate": 1636492753303, "details": {"replyCount": 9}}, {"id": "9XAxGtK5cdN", "original": "12VjsTBvXCU", "number": 2122, "cdate": 1621629782178, "ddate": null, "tcdate": 1621629782178, "tmdate": 1683307560315, "tddate": null, "forum": "9XAxGtK5cdN", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Private learning implies quantum stability", "authorids": ["~Yihui_Quek1", "~Srinivasan_A1", "smolin@us.ibm.com"], "authors": ["Yihui Quek", "Srinivasan A", "John Smolin"], "keywords": ["Quantum learning theory", "differential privacy", "online learning"], "TL;DR": "A recent series of surprising implications between models of learning also hold for learning quantum states and real valued functions with noisy labels.", "abstract": "Learning an unknown n-qubit quantum state rho is a fundamental challenge in quantum computing. Information-theoretically, it is known that tomography requires exponential in n many copies of rho to estimate its entries. Motivated by learning theory, Aaronson et al. introduced many (weaker) learning models: the PAC model of learning states (Proceedings of Royal Society A'07), shadow tomography (STOC'18) for learning ``shadows\" of a state, a model that also requires learners to be differentially private (STOC'19) and the online model of learning states (NeurIPS'18). In these models it was shown that an unknown state can be learned ``approximately\" using linear in n many copies of rho. But is there any relationship between these models? In this paper we prove a sequence of (information-theoretic) implications from differentially-private PAC learning to online learning and then to quantum stability.\n\nOur main result generalizes the recent work of Bun, Livni and Moran (Journal of the ACM'21) who showed that finite Littlestone dimension (of Boolean-valued concept classes) implies PAC learnability in the (approximate) differentially private (DP) setting. We first consider their work in the real-valued setting and further extend to their techniques to the setting of learning quantum states. Key to our results is our generic quantum online learner, Robust Standard Optimal Algorithm (RSOA), which is robust to adversarial imprecision. We then show information-theoretic implications between DP learning quantum states in the PAC model, learnability of quantum states in the one-way communication model, online learning of quantum states, quantum stability (which is our conceptual contribution), various combinatorial parameters and give further applications to gentle shadow tomography and noisy quantum state learning.", "submission_history": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "quek|private_learning_implies_quantum_stability", "pdf": "/pdf/fd6e7dcacb76de7a79f76589126ef7110de34f74.pdf", "supplementary_material": "/attachment/de5f503a624cfbec31685e57f4cd55ea5ddde420.pdf", "checklist": "", "thumbnail": "", "_bibtex": "@inproceedings{\nquek2021private,\ntitle={Private learning implies quantum stability},\nauthor={Yihui Quek and Srinivasan A and John Smolin},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=9XAxGtK5cdN}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492787991, "odate": 1636492787991, "details": {"replyCount": 11}}, {"id": "az0BBDjDvwD", "original": "3BY665msSRr", "number": 1994, "cdate": 1621629774946, "ddate": null, "tcdate": 1621629774946, "tmdate": 1683307557541, "tddate": null, "forum": "az0BBDjDvwD", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Finding Discriminative Filters for Specific Degradations in Blind Super-Resolution", "authorids": ["~Liangbin_Xie1", "~Xintao_Wang1", "~Chao_Dong4", "~Zhongang_Qi1", "~Ying_Shan2"], "authors": ["Liangbin Xie", "Xintao Wang", "Chao Dong", "Zhongang Qi", "Ying Shan"], "keywords": ["blind super-resolution", "network interpretation", "degradation prediction"], "TL;DR": "We make the first attempt to interpret blind SR networks and have discovered discriminative filters for specific degradations in blind super-resolution.", "abstract": "Recent blind super-resolution (SR) methods typically consist of two branches, one for degradation prediction and the other for conditional restoration. However, our experiments show that a one-branch network can achieve comparable performance to the two-branch scheme. Then we wonder: how can one-branch networks automatically learn to distinguish degradations? To find the answer, we propose a new diagnostic tool -- Filter Attribution method based on Integral Gradient (FAIG). Unlike previous integral gradient methods, our FAIG aims at finding the most discriminative filters instead of input pixels/features for degradation removal in blind SR networks. With the discovered filters, we further develop a simple yet effective method to predict the degradation of an input image. Based on FAIG, we show that, in one-branch blind SR networks, 1) we could find a very small number of (1%) discriminative filters for each specific degradation; 2) The weights, locations and connections of the discovered filters are all important to determine the specific network function. 3) The task of degradation prediction can be implicitly realized by these discriminative filters without explicit supervised learning. Our findings can not only help us better understand network behaviors inside one-branch blind SR networks, but also provide guidance on designing more efficient architectures and diagnosing networks for blind SR.", "submission_history": "", "submission_history_-_venue_and_year": "", "checklist": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "xie|finding_discriminative_filters_for_specific_degradations_in_blind_superresolution", "pdf": "/pdf/f49fa287ee8b7b3f824d5dd177938bfb2d3de7ab.pdf", "supplementary_material": "/attachment/b177072ac3ffad583332c6192db3733da04e3cb6.pdf", "thumbnail": "", "code": "https://github.com/TencentARC/FAIG", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nxie2021finding,\ntitle={Finding Discriminative Filters for Specific Degradations in Blind Super-Resolution},\nauthor={Liangbin Xie and Xintao Wang and Chao Dong and Zhongang Qi and Ying Shan},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=az0BBDjDvwD}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492678831, "odate": 1636492678831, "details": {"replyCount": 12}}, {"id": "iX0TSH45eOd", "original": "WFJ_8mzfJHM", "number": 1928, "cdate": 1621629771383, "ddate": null, "tcdate": 1621629771383, "tmdate": 1697937688976, "tddate": null, "forum": "iX0TSH45eOd", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Continuous vs. Discrete Optimization of Deep Neural Networks", "authorids": ["~Omer_Elkabetz1", "~Nadav_Cohen1"], "authors": ["Omer Elkabetz", "Nadav Cohen"], "keywords": ["Deep Learning", "Non-Convex Optimization", "Gradient Flow", "Gradient Descent"], "TL;DR": "We present a theory quantifying the discrepancy between gradient flow and gradient descent over deep neural networks, and use it to translate an analysis of gradient flow into a new convergence guarantee for gradient descent.", "abstract": "Existing analyses of optimization in deep learning are either continuous, focusing on (variants of) gradient flow, or discrete, directly treating (variants of) gradient descent.  Gradient flow is amenable to theoretical analysis, but is stylized and disregards computational efficiency.  The extent to which it represents gradient descent is an open question in the theory of deep learning.  The current paper studies this question.  Viewing gradient descent as an approximate numerical solution to the initial value problem of gradient flow, we find that the degree of approximation depends on the curvature around the gradient flow trajectory.  We then show that over deep neural networks with homogeneous activations, gradient flow trajectories enjoy favorable curvature, suggesting they are well approximated by gradient descent.  This finding allows us to translate an analysis of gradient flow over deep linear neural networks into a guarantee that gradient descent efficiently converges to global minimum almost surely under random initialization.  Experiments suggest that over simple deep neural networks, gradient descent with conventional step size is indeed close to gradient flow.  We hypothesize that the theory of gradient flows will unravel mysteries behind deep learning.", "pdf": "/pdf/7a7346bdd1e5412513909a45e624886c4d81a82c.pdf", "submission_history": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "checklist": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "elkabetz|continuous_vs_discrete_optimization_of_deep_neural_networks", "supplementary_material": "/attachment/e0a002db2f0b2c38bcf3b457f04f2019254befc1.pdf", "code": "https://github.com/elkabzo/cont_disc_opt_dnn", "thumbnail": "", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2107.06608/code)", "_bibtex": "@inproceedings{\nelkabetz2021continuous,\ntitle={Continuous vs. Discrete Optimization of Deep Neural Networks},\nauthor={Omer Elkabetz and Nadav Cohen},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=iX0TSH45eOd}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492668121, "odate": 1636492668070, "details": {"replyCount": 19}}, {"id": "AAWuCvzaVt", "original": "GvWVaxotcNl", "number": 1854, "cdate": 1621629767342, "ddate": null, "tcdate": 1621629767342, "tmdate": 1697937692209, "tddate": null, "forum": "AAWuCvzaVt", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Diffusion Models Beat GANs on Image Synthesis", "authorids": ["~Prafulla_Dhariwal1", "~Alexander_Quinn_Nichol1"], "authors": ["Prafulla Dhariwal", "Alexander Quinn Nichol"], "keywords": ["generative models", "diffusion models", "score-based models", "denoising diffusion probabilistic models", "image generation", "neural networks", "attention"], "TL;DR": "We achieve state-of-the-art image generation on ImageNet and several LSUN classes with diffusion models.", "abstract": "We show that diffusion models can achieve image sample quality superior to the current state-of-the-art generative models. We achieve this on unconditional image synthesis by finding a better architecture through a series of ablations. For conditional image synthesis, we further improve sample quality with classifier guidance: a simple, compute-efficient method for trading off diversity for fidelity using gradients from a classifier. We achieve an FID of 2.97 on ImageNet 128$\\times$128, 4.59 on ImageNet 256$\\times$256, and 7.72 on ImageNet 512$\\times$512, and we match BigGAN-deep even with as few as 25 forward passes per sample, all while maintaining better coverage of the distribution. Finally, we find that classifier guidance combines well with upsampling diffusion models, further improving FID to 3.94 on ImageNet 256$\\times$256 and 3.85 on ImageNet 512$\\times$512.", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "dhariwal|diffusion_models_beat_gans_on_image_synthesis", "pdf": "/pdf/fac47484c51c0a9ca609c04dfef93927c49cea18.pdf", "supplementary_material": "/attachment/c47d3fa2b246d4d640583c0ee3166c25b0eaef15.pdf", "checklist": "", "code": "https://github.com/openai/guided-diffusion", "thumbnail": "", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2105.05233/code)", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\ndhariwal2021diffusion,\ntitle={Diffusion Models Beat {GAN}s on Image Synthesis},\nauthor={Prafulla Dhariwal and Alexander Quinn Nichol},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=AAWuCvzaVt}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492779528, "odate": 1636492779487, "details": {"replyCount": 13}}, {"id": "Re_VXFOyyO", "original": "9a86S64tIU", "number": 1752, "cdate": 1621629762312, "ddate": null, "tcdate": 1621629762312, "tmdate": 1683307552124, "tddate": null, "forum": "Re_VXFOyyO", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "On the Convergence and Sample Efficiency of Variance-Reduced Policy Gradient Method", "authorids": ["~Junyu_Zhang1", "~Chengzhuo_Ni1", "~Zheng_Yu1", "~Csaba_Szepesvari1", "~Mengdi_Wang1"], "authors": ["Junyu Zhang", "Chengzhuo Ni", "Zheng Yu", "Csaba Szepesvari", "Mengdi Wang"], "keywords": ["Reinforcement Learning", "Policy Gradient Method", "Variance Reduction", "Gradient Truncation"], "TL;DR": "We derive a novel form of variance reduced policy gradient method for solving RL beyond cumulative reward.", "abstract": "Policy gradient (PG) gives rise to a rich class of reinforcement learning (RL) methods. Recently, there has been an emerging trend to augment the existing PG methods such as REINFORCE by the \\emph{variance reduction} techniques.  However, all existing variance-reduced PG methods heavily rely on an uncheckable importance weight assumption made for every single iteration of the algorithms. In this paper, a simple gradient truncation mechanism is proposed to address this issue. Moreover, we design a Truncated Stochastic Incremental Variance-Reduced Policy Gradient (TSIVR-PG) method, which is able to maximize not only a cumulative sum of rewards but also a general utility function over a policy's long-term visiting distribution.  We show an $\\tilde{\\mathcal{O}}(\\epsilon^{-3})$ sample complexity for TSIVR-PG to find an $\\epsilon$-stationary policy. By assuming the \\emph{overparameterization} of policy and exploiting the \\emph{hidden convexity} of the problem, we further show that TSIVR-PG converges to global $\\epsilon$-optimal policy with $\\tilde{\\mathcal{O}}(\\epsilon^{-2})$ samples. ", "submission_history": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "zhang|on_the_convergence_and_sample_efficiency_of_variancereduced_policy_gradient_method", "pdf": "/pdf/1d5725b21bcd7833e82783f6ffa9b8dc1e9b4e0c.pdf", "supplementary_material": "/attachment/9b1a573f1919efb764f37f3795f9cce2816d00ac.pdf", "checklist": "", "thumbnail": "", "code": "/attachment/b2ae3034e0faef2cd6b44f0edd78f55adc82046c.zip", "_bibtex": "@inproceedings{\nzhang2021on,\ntitle={On the Convergence and Sample Efficiency of Variance-Reduced Policy Gradient Method},\nauthor={Junyu Zhang and Chengzhuo Ni and Zheng Yu and Csaba Szepesvari and Mengdi Wang},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=Re_VXFOyyO}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492783666, "odate": 1636492783666, "details": {"replyCount": 10}}, {"id": "FHQBDiMwvK", "original": "me-4orcMPKj", "number": 1678, "cdate": 1621629758167, "ddate": null, "tcdate": 1621629758167, "tmdate": 1697937698513, "tddate": null, "forum": "FHQBDiMwvK", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "DOCTOR: A Simple Method for Detecting Misclassification Errors", "authorids": ["~Federica_Granese1", "~Marco_Romanelli1", "~Daniele_Gorla1", "~Catuscia_Palamidessi1", "~Pablo_Piantanida2"], "authors": ["Federica Granese", "Marco Romanelli", "Daniele Gorla", "Catuscia Palamidessi", "Pablo Piantanida"], "keywords": ["AI Safety", "Algorithms Evaluation", "Deep Learning", "misclassification detection", "out-of-distribution"], "TL;DR": "We propose DOCTOR a simple method (without training) that aims to identify whether the prediction of a DNN classifier should (or should not) be trusted so that, consequently, it would be possible to accept or to reject it.", "abstract": "Deep neural networks (DNNs) have shown to perform very well on large scale object recognition problems and lead to widespread use for real-world applications, including situations where DNN are implemented as \u201cblack boxes\u201d.  A promising approach to secure their use is to accept decisions that are likely to be correct while discarding the others.  In this work, we propose DOCTOR, a simple method that aims to identify whether the prediction of a DNN classifier should (or should not) be trusted so that, consequently, it would be possible to accept it or to reject it. Two scenarios are investigated: Totally Black Box (TBB) where only the soft-predictions are available and Partially Black Box (PBB) where gradient-propagation to perform input pre-processing is allowed. Empirically, we show that DOCTOR outperforms all state-of-the-art methods on various well-known images and sentiment analysis datasets. In particular, we observe a reduction of up to 4% of the false rejection rate (FRR) in the PBB scenario. DOCTOR can be applied to any pre-trained model, it does not require prior information about the underlying dataset and is as simple as the simplest available methods in the literature.", "submission_history": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "checklist": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "granese|doctor_a_simple_method_for_detecting_misclassification_errors", "pdf": "/pdf/875cabfbeb1c48d6b9db1c4e3d73710e1ccfa5ca.pdf", "supplementary_material": "/attachment/8ca4f06d63ed2a8a21125bf9aeb4cc43755c4ea9.pdf", "code": "https://github.com/doctor-public-submission/DOCTOR", "thumbnail": "", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2106.02395/code)", "_bibtex": "@inproceedings{\ngranese2021doctor,\ntitle={{DOCTOR}: A Simple Method for Detecting Misclassification Errors},\nauthor={Federica Granese and Marco Romanelli and Daniele Gorla and Catuscia Palamidessi and Pablo Piantanida},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=FHQBDiMwvK}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492701645, "odate": 1636492701645, "details": {"replyCount": 10}}, {"id": "wtLW-Amuds", "original": "_fALqg22AVN", "number": 1651, "cdate": 1621629756606, "ddate": null, "tcdate": 1621629756606, "tmdate": 1697937700121, "tddate": null, "forum": "wtLW-Amuds", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "The Sensory Neuron as a Transformer: Permutation-Invariant Neural Networks for Reinforcement Learning", "authorids": ["~Yujin_Tang1", "~David_Ha1"], "authors": ["Yujin Tang", "David Ha"], "keywords": ["self-organization", "attention", "reinforcement learning", "evolution strategies", "zero-shot generalization", "meta-learning", "permutation invariance", "multi-agent reinforcement learning"], "abstract": "In complex systems, we often observe complex global behavior emerge from a collection of agents interacting with each other in their environment, with each individual agent acting only on locally available information, without knowing the full picture. Such systems have inspired development of artificial intelligence algorithms in areas such as swarm optimization and cellular automata. Motivated by the emergence of collective behavior from complex cellular systems, we build systems that feed each sensory input from the environment into distinct, but identical neural networks, each with no fixed relationship with one another. We show that these sensory networks can be trained to integrate information received locally, and through communication via an attention mechanism, can collectively produce a globally coherent policy. Moreover, the system can still perform its task even if the ordering of its inputs is randomly permuted several times during an episode. These permutation invariant systems also display useful robustness and generalization properties that are broadly applicable. Interactive demo and videos of our results: https://attentionneuron.github.io", "submission_history": "", "checklist": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "tang|the_sensory_neuron_as_a_transformer_permutationinvariant_neural_networks_for_reinforcement_learning", "TL;DR": "We investigate permutation invariant RL agents achieved through modular processing of localized sensory information and attention-based communication, and demonstrate several useful properties of these agents through a series of experimental studies.", "pdf": "/pdf/d4f2a0f27d27c2713549a5a3685a5a92214997db.pdf", "supplementary_material": "/attachment/2e427b8c4ab53b6d14a8390347026e830dbac942.pdf", "code": "https://attentionneuron.github.io", "thumbnail": "", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 2 code implementations](https://www.catalyzex.com/paper/arxiv:2109.02869/code)", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\ntang2021the,\ntitle={The Sensory Neuron as a Transformer: Permutation-Invariant Neural Networks for Reinforcement Learning},\nauthor={Yujin Tang and David Ha},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=wtLW-Amuds}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492788459, "odate": 1636492788459, "details": {"replyCount": 18}}, {"id": "9rphbXqgmqM", "original": "pLm5uk4-wCA", "number": 1506, "cdate": 1621629748402, "ddate": null, "tcdate": 1621629748402, "tmdate": 1683307547104, "tddate": null, "forum": "9rphbXqgmqM", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Iterative Teaching by Label Synthesis", "authorids": ["~Weiyang_Liu1", "~Zhen_Liu6", "~Hanchen_Wang1", "~Liam_Paull1", "~Bernhard_Sch\u00f6lkopf1", "~Adrian_Weller1"], "authors": ["Weiyang Liu", "Zhen Liu", "Hanchen Wang", "Liam Paull", "Bernhard Sch\u00f6lkopf", "Adrian Weller"], "keywords": ["Iterative Machine Teaching", "Reinforcement Learning", "Unrolling", "Label"], "abstract": "In this paper, we consider the problem of iterative machine teaching, where a teacher provides examples sequentially based on the current iterative learner. In contrast to previous methods that have to scan over the entire pool and select teaching examples from it in each iteration, we propose a label synthesis teaching framework where the teacher randomly selects input teaching examples (e.g., images) and then synthesizes suitable outputs (e.g., labels) for them. We show that this framework can avoid costly example selection while still provably achieving exponential teachability. We propose multiple novel teaching algorithms in this framework. Finally, we empirically demonstrate the value of our framework.", "submission_history": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "checklist": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "liu|iterative_teaching_by_label_synthesis", "pdf": "/pdf/91a0aa5980f38fa43c605acf39c818767b53aa65.pdf", "supplementary_material": "/attachment/3228abe2c78c2c4b4d8701c8820c70488b5a707f.pdf", "TL;DR": "An iterative teaching framework via label synthesis.", "thumbnail": "", "_bibtex": "@inproceedings{\nliu2021iterative,\ntitle={Iterative Teaching by Label Synthesis},\nauthor={Weiyang Liu and Zhen Liu and Hanchen Wang and Liam Paull and Bernhard Sch{\\\"o}lkopf and Adrian Weller},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=9rphbXqgmqM}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492668679, "odate": 1636492668679, "details": {"replyCount": 19}}, {"id": "MxE7xFzv0N8", "original": "v25CHgkQwz5", "number": 1489, "cdate": 1621629747353, "ddate": null, "tcdate": 1621629747353, "tmdate": 1683307545418, "tddate": null, "forum": "MxE7xFzv0N8", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Exact marginal prior distributions of finite Bayesian neural networks", "authorids": ["~Jacob_A_Zavatone-Veth1", "~Cengiz_Pehlevan2"], "authors": ["Jacob A Zavatone-Veth", "Cengiz Pehlevan"], "keywords": ["Bayesian neural networks", "inductive bias", "infinite-width limits"], "abstract": "Bayesian neural networks are theoretically well-understood only in the infinite-width limit, where Gaussian priors over network weights yield Gaussian priors over network outputs. Recent work has suggested that finite Bayesian networks may outperform their infinite counterparts, but their non-Gaussian output priors have been characterized only though perturbative approaches. Here, we derive exact solutions for the function space priors for individual input examples of a class of finite fully-connected feedforward Bayesian neural networks. For deep linear networks, the prior has a simple expression in terms of the Meijer $G$-function. The prior of a finite ReLU network is a mixture of the priors of linear networks of smaller widths, corresponding to different numbers of active units in each layer. Our results unify previous descriptions of finite network priors in terms of their tail decay and large-width behavior. ", "pdf": "/pdf/7e930ae80fc2aade278c8e99dc700106e47208d1.pdf", "supplementary_material": "/attachment/471dbfaa4a4d2dfea3c878a57871989a7fe9c82e.pdf", "submission_history": "", "checklist": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "zavatoneveth|exact_marginal_prior_distributions_of_finite_bayesian_neural_networks", "TL;DR": "We compute the exact marginal function-space priors of a class of finite Bayesian neural networks. ", "code": "https://github.com/Pehlevan-Group/ExactBayesianNetworkPriors", "thumbnail": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nzavatone-veth2021exact,\ntitle={Exact marginal prior distributions of finite Bayesian neural networks},\nauthor={Jacob A Zavatone-Veth and Cengiz Pehlevan},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=MxE7xFzv0N8}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492784676, "odate": 1636492784676, "details": {"replyCount": 13}}, {"id": "pZHGKM9mAp", "original": "fsAk1KcmSnr", "number": 1436, "cdate": 1621629744284, "ddate": null, "tcdate": 1621629744284, "tmdate": 1683307543925, "tddate": null, "forum": "pZHGKM9mAp", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Learning Interpretable Decision Rule Sets: A Submodular Optimization Approach", "authorids": ["~Fan_Yang14", "~Kai_He3", "~Linxiao_Yang1", "~Hongxia_Du1", "~Jingbang_Yang1", "~Bo_Yang12", "~Liang_Sun2"], "authors": ["Fan Yang", "Kai He", "Linxiao Yang", "Hongxia Du", "Jingbang Yang", "Bo Yang", "Liang Sun"], "keywords": ["interpretable", "rule set", "submodular", "rule-based model"], "TL;DR": "A submodular optimization perspective on interpretable rule set learning", "abstract": "Rule sets are highly interpretable logical models in which the predicates for decision are expressed in disjunctive normal form (DNF, OR-of-ANDs), or, equivalently, the overall model comprises an unordered collection of if-then decision rules. In this paper, we consider a submodular optimization based approach for learning rule sets. The learning problem is framed as a subset selection task in which a subset of all possible rules needs to be selected to form an accurate and interpretable rule set. We employ an objective function that exhibits submodularity and thus is amenable to submodular optimization techniques. To overcome the difficulty arose from dealing with the exponential-sized ground set of rules, the subproblem of searching a rule is casted as another subset selection task that asks for a subset of features. We show it is possible to write the induced objective function for the subproblem as a difference of two submodular (DS) functions to make it approximately solvable by DS optimization algorithms. Overall, the proposed approach is simple, scalable, and likely to be benefited from further research on submodular optimization. Experiments on real datasets demonstrate the effectiveness of our method.", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "yang|learning_interpretable_decision_rule_sets_a_submodular_optimization_approach", "pdf": "/pdf/aa9762f3eed6a2fbda3829a37c3510d13c914459.pdf", "checklist": "", "supplementary_material": "/attachment/532b34d9bed263d7a8d5088e2f188ba7f2d4a33e.pdf", "thumbnail": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nyang2021learning,\ntitle={Learning Interpretable Decision Rule Sets: A Submodular Optimization Approach},\nauthor={Fan Yang and Kai He and Linxiao Yang and Hongxia Du and Jingbang Yang and Bo Yang and Liang Sun},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=pZHGKM9mAp}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492747986, "odate": 1636492747986, "details": {"replyCount": 10}}, {"id": "f2Llmm_z5Sm", "original": "TOpZw1CduI", "number": 1376, "cdate": 1621629741049, "ddate": null, "tcdate": 1621629741049, "tmdate": 1697937713396, "tddate": null, "forum": "f2Llmm_z5Sm", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Training Feedback Spiking Neural Networks by Implicit Differentiation on the Equilibrium State", "authorids": ["~Mingqing_Xiao1", "~Qingyan_Meng1", "~Zongpeng_Zhang1", "~Yisen_Wang1", "~Zhouchen_Lin1"], "authors": ["Mingqing Xiao", "Qingyan Meng", "Zongpeng Zhang", "Yisen Wang", "Zhouchen Lin"], "keywords": ["spiking neural networks", "feedback connections", "equilibrium state", "training method"], "abstract": "Spiking neural networks (SNNs) are brain-inspired models that enable energy-efficient implementation on neuromorphic hardware. However, the supervised training of SNNs remains a hard problem due to the discontinuity of the spiking neuron model. Most existing methods imitate the backpropagation framework and feedforward architectures for artificial neural networks, and use surrogate derivatives or compute gradients with respect to the spiking time to deal with the problem. These approaches either accumulate approximation errors or only propagate information limitedly through existing spikes, and usually require information propagation along time steps with large memory costs and biological implausibility. In this work, we consider feedback spiking neural networks, which are more brain-like, and propose a novel training method that does not rely on the exact reverse of the forward computation. First, we show that the average firing rates of SNNs with feedback connections would gradually evolve to an equilibrium state along time, which follows a fixed-point equation. Then by viewing the forward computation of feedback SNNs as a black-box solver for this equation, and leveraging the implicit differentiation on the equation, we can compute the gradient for parameters without considering the exact forward procedure. In this way, the forward and backward procedures are decoupled and therefore the problem of non-differentiable spiking functions is avoided. We also briefly discuss the biological plausibility of implicit differentiation, which only requires computing another equilibrium. Extensive experiments on MNIST, Fashion-MNIST, N-MNIST, CIFAR-10, and CIFAR-100 demonstrate the superior performance of our method for feedback models with fewer neurons and parameters in a small number of time steps. Our code is available at https://github.com/pkuxmq/IDE-FSNN.", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "xiao|training_feedback_spiking_neural_networks_by_implicit_differentiation_on_the_equilibrium_state", "TL;DR": "We derive the equilibrium states for the average firing rates of feedback spiking neural networks and propose a novel supervised training method based on implicit differentiation, which achieves superior results with low latency.", "pdf": "/pdf/cde23ffbff1a41d05dd3fa6c59d6270a128a4af9.pdf", "supplementary_material": "/attachment/d39cf6f74dd587d73283e2921c1eba1ebbac923a.pdf", "checklist": "", "code": "https://github.com/pkuxmq/IDE-FSNN", "thumbnail": "", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2109.14247/code)", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nxiao2021training,\ntitle={Training Feedback Spiking Neural Networks by Implicit Differentiation on the Equilibrium State},\nauthor={Mingqing Xiao and Qingyan Meng and Zongpeng Zhang and Yisen Wang and Zhouchen Lin},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=f2Llmm_z5Sm}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492775196, "odate": 1636492775196, "details": {"replyCount": 10}}, {"id": "l7-DBWawSZH", "original": "qKqLFjuszKT", "number": 1357, "cdate": 1621629740093, "ddate": null, "tcdate": 1621629740093, "tmdate": 1683307542136, "tddate": null, "forum": "l7-DBWawSZH", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Optimal Policies Tend To Seek Power", "authorids": ["~Alexander_Matt_Turner1", "~Logan_Riggs_Smith1", "~Rohin_Shah1", "~Andrew_Critch1", "~Prasad_Tadepalli1"], "authors": ["Alexander Matt Turner", "Logan Riggs Smith", "Rohin Shah", "Andrew Critch", "Prasad Tadepalli"], "keywords": ["ai alignment", "mdp theory", "reinforcement learning", "optimal policies"], "TL;DR": "Power-seeking incentives arise from certain symmetries in the agent's environment.", "abstract": "Some researchers speculate that intelligent reinforcement learning (RL) agents would be incentivized to seek resources and power in pursuit of the objectives we specify for them. Other researchers point out that RL agents need not have human-like power-seeking instincts. To clarify this discussion, we develop the first formal theory of the statistical tendencies of optimal policies. In the context of Markov decision processes, we prove that certain environmental symmetries are sufficient for optimal policies to tend to seek power over the environment. These symmetries exist in many environments in which the agent can be shut down or destroyed. We prove that in these environments, most reward functions make it optimal to seek power by keeping a range of options available and, when maximizing average reward, by navigating towards larger sets of potential terminal states.", "submission_history": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "checklist": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "turner|optimal_policies_tend_to_seek_power", "pdf": "/pdf/398c9f127c5380ff3ada16b8bdbd9abb6ecd7483.pdf", "supplementary_material": "/attachment/5a4f3146cc75969e90ba4bd91437fef5673f47c7.pdf", "thumbnail": "", "_bibtex": "@inproceedings{\nturner2021optimal,\ntitle={Optimal Policies Tend To Seek Power},\nauthor={Alexander Matt Turner and Logan Riggs Smith and Rohin Shah and Andrew Critch and Prasad Tadepalli},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=l7-DBWawSZH}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492787759, "odate": 1636492787759, "details": {"replyCount": 27}}, {"id": "_8vCV7AxPZ", "original": "ew3EX_6q4pH", "number": 1309, "cdate": 1621629737568, "ddate": null, "tcdate": 1621629737568, "tmdate": 1683307540860, "tddate": null, "forum": "_8vCV7AxPZ", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Subgaussian and Differentiable Importance Sampling for Off-Policy Evaluation and Learning", "authorids": ["~Alberto_Maria_Metelli2", "~Alessio_Russo2", "~Marcello_Restelli1"], "authors": ["Alberto Maria Metelli", "Alessio Russo", "Marcello Restelli"], "keywords": ["Importance Sampling", "Off-Policy Evaluation", "Off-Policy Learning", "Subgaussian"], "abstract": "Importance Sampling (IS) is a widely used building block for a large variety of off-policy estimation and learning algorithms. However, empirical and theoretical studies have progressively shown that vanilla IS leads to poor estimations whenever the behavioral and target policies are too dissimilar. In this paper, we analyze the theoretical properties of the IS estimator by deriving a novel anticoncentration bound that formalizes the intuition behind its undesired behavior. Then, we propose a new class of IS transformations, based on the notion of power mean. To the best of our knowledge, the resulting estimator is the first to achieve, under certain conditions, two key properties: (i) it displays a subgaussian concentration rate; (ii) it preserves the differentiability in the target distribution. Finally, we provide numerical simulations on both synthetic examples and contextual bandits, in comparison with off-policy evaluation and learning baselines.", "submission_history": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "metelli|subgaussian_and_differentiable_importance_sampling_for_offpolicy_evaluation_and_learning", "pdf": "/pdf/bf1b114f001fd4a42fbc587bb1dc93b4fd231846.pdf", "checklist": "", "supplementary_material": "/attachment/120092e7ec3c2cf3285adaa3813827c648cfdee5.pdf", "code": "https://github.com/albertometelli/subgaussian-is", "thumbnail": "", "_bibtex": "@inproceedings{\nmetelli2021subgaussian,\ntitle={Subgaussian and Differentiable Importance Sampling for Off-Policy Evaluation and Learning},\nauthor={Alberto Maria Metelli and Alessio Russo and Marcello Restelli},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=_8vCV7AxPZ}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492691674, "odate": 1636492691674, "details": {"replyCount": 17}}, {"id": "oE5lMpPRm0", "original": "Q_e1S-qofT", "number": 1256, "cdate": 1621629734470, "ddate": null, "tcdate": 1621629734470, "tmdate": 1683307539527, "tddate": null, "forum": "oE5lMpPRm0", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Hardware-adaptive Efficient Latency Prediction for NAS via Meta-Learning", "authorids": ["~Hayeon_Lee1", "~Sewoong_Lee1", "~Song_Chong1", "~Sung_Ju_Hwang1"], "authors": ["Hayeon Lee", "Sewoong Lee", "Song Chong", "Sung Ju Hwang"], "keywords": ["neural architecture search", "meta-learning"], "abstract": "For deployment, neural architecture search should be hardware-aware, in order to satisfy the device-specific constraints (e.g., memory usage, latency and energy consumption) and enhance the model efficiency. Existing methods on hardware-aware NAS collect a large number of samples (e.g., accuracy and latency) from a target device, either builds a lookup table or a latency estimator. However, such approach is impractical in real-world scenarios as there exist numerous devices with different hardware specifications, and collecting samples from such a large number of devices will require prohibitive computational and monetary cost. To overcome such limitations, we propose Hardware-adaptive Efficient Latency Predictor (HELP), which formulates the device-specific latency estimation problem as a meta-learning problem, such that we can estimate the latency of a model's performance for a given task on an unseen device with a few samples. To this end, we introduce novel hardware embeddings to embed any devices considering them as black-box functions that output latencies, and meta-learn the hardware-adaptive latency predictor in a device-dependent manner, using the hardware embeddings. We validate the proposed HELP for its latency estimation performance on unseen platforms, on which it achieves high estimation performance with as few as 10 measurement samples, outperforming all relevant baselines. We also validate end-to-end NAS frameworks using HELP against ones without it, and show that it largely reduces the total time cost of the base NAS method, in latency-constrained settings.", "pdf": "/pdf/fba240ba5c3c293d197980203caa11482ca87b49.pdf", "submission_history": "", "checklist": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "lee|hardwareadaptive_efficient_latency_prediction_for_nas_via_metalearning", "TL;DR": "We proposed a novel meta-learned latency predictor, that can estimate the latency of an architecture on a novel (unseen) device, using only a few measurements from it.", "supplementary_material": "/attachment/80f0a3c40237c68eb6d00998618486ead6e55bb7.pdf", "code": "https://github.com/HayeonLee/HELP", "thumbnail": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nlee2021hardwareadaptive,\ntitle={Hardware-adaptive Efficient Latency Prediction for {NAS} via Meta-Learning},\nauthor={Hayeon Lee and Sewoong Lee and Song Chong and Sung Ju Hwang},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=oE5lMpPRm0}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492768048, "odate": 1636492768048, "details": {"replyCount": 19}}, {"id": "ekKaTdleJVq", "original": "CFm8CuwzWSR", "number": 1237, "cdate": 1621629733327, "ddate": null, "tcdate": 1621629733327, "tmdate": 1697937719903, "tddate": null, "forum": "ekKaTdleJVq", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Node Dependent Local Smoothing for Scalable Graph Learning", "authorids": ["~Wentao_Zhang1", "~Mingyu_Yang2", "~Zeang_Sheng1", "~Yang_Li36", "~Wen_Ouyang1", "~Yangyu_Tao2", "~Zhi_Yang4", "~Bin_CUI2"], "authors": ["Wentao Zhang", "Mingyu Yang", "Zeang Sheng", "Yang Li", "Wen Ouyang", "Yangyu Tao", "Zhi Yang", "Bin CUI"], "keywords": ["Graph Neural Network", "Scalability", "Smoothness"], "TL;DR": "A simple, scalable, flexible and efficient method for graph learning.", "abstract": "Recent works reveal that feature or label smoothing lies at the core of Graph Neural Networks (GNNs). Concretely, they show feature smoothing combined with simple linear regression achieves comparable performance with the carefully designed GNNs, and a simple MLP model with label smoothing of its prediction can outperform the vanilla GCN. Though an interesting finding, smoothing has not been well understood, especially regarding how to control the extent of smoothness. Intuitively, too small or too large smoothing iterations may cause under-smoothing or over-smoothing and can lead to sub-optimal performance. Moreover, the extent of smoothness is node-specific, depending on its degree and local structure. To this end, we propose a novel algorithm called node-dependent local smoothing (NDLS), which aims to control the smoothness of every node by setting a node-specific smoothing iteration. Specifically, NDLS computes influence scores based on the adjacency matrix and selects the iteration number by setting a threshold on the scores. Once selected, the iteration number can be applied to both feature smoothing and label smoothing. Experimental results demonstrate that NDLS enjoys high accuracy -- state-of-the-art performance on node classifications tasks, flexibility -- can be incorporated with any models, scalability and efficiency -- can support large scale graphs with fast training.", "submission_history": "", "checklist": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "zhang|node_dependent_local_smoothing_for_scalable_graph_learning", "pdf": "/pdf/15214667741e7beedd00b4f2d9ba20feda6204c5.pdf", "supplementary_material": "/attachment/1cb519df5ce34299c89b58ca62572c526a757a10.pdf", "code": "/attachment/8167e7b406f62a637d92face7e06f46c95d16c8c.zip", "thumbnail": "", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 14 code implementations](https://www.catalyzex.com/paper/arxiv:2110.14377/code)", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nzhang2021node,\ntitle={Node Dependent Local Smoothing for Scalable Graph Learning},\nauthor={Wentao Zhang and Mingyu Yang and Zeang Sheng and Yang Li and Wen Ouyang and Yangyu Tao and Zhi Yang and Bin CUI},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=ekKaTdleJVq}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492743452, "odate": 1636492743452, "details": {"replyCount": 17}}, {"id": "P84bifNCpFQ", "original": "w25LJVWgpe-", "number": 1229, "cdate": 1621629732904, "ddate": null, "tcdate": 1621629732904, "tmdate": 1683307538658, "tddate": null, "forum": "P84bifNCpFQ", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "A Theory-Driven Self-Labeling Refinement Method for Contrastive Representation Learning", "authorids": ["~Pan_Zhou3", "~Caiming_Xiong1", "~Xiaotong_Yuan1", "~Steven_Hoi2"], "authors": ["Pan Zhou", "Caiming Xiong", "Xiaotong Yuan", "Steven Hoi"], "keywords": ["self-supervised learning", "contrastive learning"], "TL;DR": "We first prove inaccurate label assignment heavily  impairs the generalization of contrastive learning, and then propose a self-labeling refinement method to improve label accuracy. ", "abstract": "For an image  query, unsupervised contrastive learning  labels crops of  the same image as positives,  and other image crops as  negatives. Although intuitive, such a native label assignment strategy cannot reveal the underlying semantic similarity between a  query and  its positives and negatives, and impairs performance,  since some negatives are  semantically similar to  the query or even share the same semantic class as the query.  In this work, we first  prove that for  contrastive learning,  inaccurate label assignment heavily  impairs its generalization for semantic instance discrimination, while accurate labels  benefit its generalization.  Inspired by this theory, we  propose   a novel self-labeling refinement approach for contrastive learning. It improves the label quality via two complementary  modules:  (i)  self-labeling refinery (SLR) to  generate accurate labels and (ii)  momentum mixup (MM)  to enhance similarity between query and its positive. SLR uses a positive of a query to estimate  semantic similarity between  a query and its positive and negatives, and  combines estimated similarity with  vanilla label assignment in contrastive learning to  iteratively generate  more accurate and informative soft labels. We theoretically show that our SLR can exactly recover the true semantic  labels of  label-corrupted  data, and  supervises   networks to achieve zero prediction  error on classification tasks.  MM randomly  combines   queries and  positives to increase  semantic similarity between the generated virtual queries and their positives so as to improves label accuracy.  Experimental results on CIFAR10,  ImageNet, VOC and COCO show the effectiveness of our method.  ", "submission_history": "", "checklist": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "zhou|a_theorydriven_selflabeling_refinement_method_for_contrastive_representation_learning", "pdf": "/pdf/2c6fe7e9c9addd2d8261322a04e7dfa67483bd74.pdf", "supplementary_material": "/attachment/daf25cc4055c15a04066f6fa8d57961e62382de3.pdf", "code": "/attachment/66a48569227aa2302349cf2f64c4be6837907185.zip", "thumbnail": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nzhou2021a,\ntitle={A Theory-Driven Self-Labeling Refinement Method for Contrastive Representation Learning},\nauthor={Pan Zhou and Caiming Xiong and Xiaotong Yuan and Steven Hoi},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=P84bifNCpFQ}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492775362, "odate": 1636492775362, "details": {"replyCount": 11}}, {"id": "CEkbBN_-Ja8", "original": "fufeX_TVdFt", "number": 1228, "cdate": 1621629732844, "ddate": null, "tcdate": 1621629732844, "tmdate": 1697937720607, "tddate": null, "forum": "CEkbBN_-Ja8", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "RIM: Reliable Influence-based Active Learning on Graphs", "authorids": ["~Wentao_Zhang1", "~Yexin_Wang2", "~Zhenbang_You1", "~Meng_Cao2", "~Ping_Huang1", "~Jiulong_Shan2", "~Zhi_Yang4", "~Bin_CUI2"], "authors": ["Wentao Zhang", "Yexin Wang", "Zhenbang You", "Meng Cao", "Ping Huang", "Jiulong Shan", "Zhi Yang", "Bin CUI"], "keywords": ["Active Learning", "Graph", "Label Noise", "Social Influence Maximization"], "TL;DR": "An attempt to consider both influence quality and quantity in graph-based active learning.", "abstract": "Message passing is the core of most graph models such as Graph Convolutional Network (GCN) and Label Propagation (LP), which usually require a large number of clean labeled data to smooth out the neighborhood over the graph. However, the labeling process can be tedious, costly, and error-prone in practice. In this paper, we propose to unify active learning (AL) and message passing towards minimizing labeling costs, e.g., making use of few and unreliable labels that can be obtained cheaply. We make two contributions towards that end. First, we open up a perspective by drawing a connection between AL enforcing message passing and social influence maximization, ensuring that the selected samples effectively improve the model performance. Second, we propose an extension to the influence model that incorporates an explicit quality factor to model label noise. In this way, we derive a fundamentally new AL selection criterion for GCN and LP--reliable influence maximization (RIM)--by considering quantity and quality of influence simultaneously. Empirical studies on public datasets show that RIM significantly outperforms current AL methods in terms of accuracy and efficiency. ", "submission_history": "", "checklist": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "zhang|rim_reliable_influencebased_active_learning_on_graphs", "pdf": "/pdf/3693bf0a54fffed4766aaa1337a7d1e4647bd7fc.pdf", "supplementary_material": "/attachment/ea33c7605c6c870d1e0760228717b0bf46873eee.pdf", "code": "/attachment/8d435a4ba3c227ca97d33812a8761dfd48ca9e2d.zip", "thumbnail": "", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 4 code implementations](https://www.catalyzex.com/paper/arxiv:2110.14854/code)", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nzhang2021rim,\ntitle={{RIM}: Reliable Influence-based Active Learning on Graphs},\nauthor={Wentao Zhang and Yexin Wang and Zhenbang You and Meng Cao and Ping Huang and Jiulong Shan and Zhi Yang and Bin CUI},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=CEkbBN_-Ja8}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492743496, "odate": 1636492743496, "details": {"replyCount": 13}}, {"id": "U68DvXABbJ3", "original": "X5JEpI6uR2Y", "number": 1191, "cdate": 1621629730899, "ddate": null, "tcdate": 1621629730899, "tmdate": 1683307537363, "tddate": null, "forum": "U68DvXABbJ3", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Task-Adaptive Neural Network Search with Meta-Contrastive Learning", "authorids": ["~Wonyong_Jeong1", "~Hayeon_Lee1", "~Geon_Park1", "~Eunyoung_Hyung2", "~Jinheon_Baek1", "~Sung_Ju_Hwang1"], "authors": ["Wonyong Jeong", "Hayeon Lee", "Geon Park", "Eunyoung Hyung", "Jinheon Baek", "Sung Ju Hwang"], "keywords": ["AutoML", "Meta-Learning", "Transfer Learning"], "TL;DR": "We introduce a novel problem of Neural Network Search (NNS) and propose an amortized meta-learning framework with contrastive loss, namely Task-Adaptive Neural Network Search (TANS). ", "abstract": "Most conventional Neural Architecture Search (NAS) approaches are limited in that they only generate architectures without searching for the optimal parameters. While some NAS methods handle this issue by utilizing a supernet trained on a large-scale dataset such as ImageNet, they may be suboptimal if the target tasks are highly dissimilar from the dataset the supernet is trained on. To address such limitations, we introduce a novel problem of Neural Network Search (NNS), whose goal is to search for the optimal pretrained network for a novel dataset and constraints (e.g. number of parameters), from a model zoo. Then, we propose a novel framework to tackle the problem, namely Task-Adaptive Neural Network Search (TANS). Given a model-zoo that consists of network pretrained on diverse datasets, we use a novel amortized meta-learning framework to learn a cross-modal latent space with contrastive loss, to maximize the similarity between a dataset and a high-performing network on it, and minimize the similarity between irrelevant dataset-network pairs. We validate the effectiveness and efficiency of our method on ten real-world datasets, against existing NAS/AutoML baselines. The results show that our method instantly retrieves networks that outperform models obtained with the baselines with significantly fewer training steps to reach the target performance, thus minimizing the total cost of obtaining a task-optimal network. Our code and the model-zoo are available at https://anonymous.4open.science/r/TANS-33D6", "pdf": "/pdf/512008b33b35bd3eb08b2d70791e2a4c7d064194.pdf", "supplementary_material": "/attachment/dd93ef7982c00055478624cd82bb9c55287d4c48.pdf", "submission_history": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "checklist": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "jeong|taskadaptive_neural_network_search_with_metacontrastive_learning", "code": "https://github.com/wyjeong/TANS", "thumbnail": "", "_bibtex": "@inproceedings{\njeong2021taskadaptive,\ntitle={Task-Adaptive Neural Network Search with Meta-Contrastive Learning},\nauthor={Wonyong Jeong and Hayeon Lee and Geon Park and Eunyoung Hyung and Jinheon Baek and Sung Ju Hwang},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=U68DvXABbJ3}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492716931, "odate": 1636492716931, "details": {"replyCount": 18}}, {"id": "Ghk0AJ8XtVx", "original": "Afj5SU1k2gn", "number": 1154, "cdate": 1621629728974, "ddate": null, "tcdate": 1621629728974, "tmdate": 1697937724557, "tddate": null, "forum": "Ghk0AJ8XtVx", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Baleen: Robust Multi-Hop Reasoning at Scale via Condensed Retrieval", "authorids": ["~Omar_Khattab1", "~Christopher_Potts1", "~Matei_Zaharia1"], "authors": ["Omar Khattab", "Christopher Potts", "Matei Zaharia"], "keywords": ["neural retrieval", "multi-hop question answering", "claim verification", "reasoning", "ColBERT"], "TL;DR": "We propose a system for multi-hop retrieval, with innovations in the system architecture, the retrieval modeling, and supervision.", "abstract": "Multi-hop reasoning (i.e., reasoning across two or more documents) is a key ingredient for NLP models that leverage large corpora to exhibit broad knowledge. To retrieve evidence passages, multi-hop models must contend with a fast-growing search space across the hops, represent complex queries that combine multiple information needs, and resolve ambiguity about the best order in which to hop between training passages. We tackle these problems via Baleen, a system that improves the accuracy of multi-hop retrieval while learning robustly from weak training signals in the many-hop setting. To tame the search space, we propose condensed retrieval, a pipeline that summarizes the retrieved passages after each hop into a single compact context. To model complex queries, we introduce a focused late interaction retriever that allows different parts of the same query representation to match disparate relevant passages. Lastly, to infer the hopping dependencies among unordered training passages, we devise latent hop ordering, a weak-supervision strategy in which the trained retriever itself selects the sequence of hops. We evaluate Baleen on retrieval for two-hop question answering and many-hop claim verification, establishing state-of-the-art performance.", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "khattab|baleen_robust_multihop_reasoning_at_scale_via_condensed_retrieval", "pdf": "/pdf/85f954af983429fc88c6a453696e001499cb4a27.pdf", "checklist": "", "supplementary_material": "/attachment/d20ea30a4c8de1f9f6e5b423ea9060a72e377bf3.pdf", "thumbnail": "", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 5 code implementations](https://www.catalyzex.com/paper/arxiv:2101.00436/code)", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nkhattab2021baleen,\ntitle={Baleen: Robust Multi-Hop Reasoning at Scale via Condensed Retrieval},\nauthor={Omar Khattab and Christopher Potts and Matei Zaharia},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=Ghk0AJ8XtVx}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492714489, "odate": 1636492714489, "details": {"replyCount": 11}}, {"id": "ClwfZc4ooKM", "original": "sfVtOmIXvR", "number": 1148, "cdate": 1621629728614, "ddate": null, "tcdate": 1621629728614, "tmdate": 1697937725343, "tddate": null, "forum": "ClwfZc4ooKM", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Pragmatic Image Compression for Human-in-the-Loop Decision-Making", "authorids": ["~Siddharth_Reddy1", "~Anca_Dragan1", "~Sergey_Levine1"], "authors": ["Siddharth Reddy", "Anca Dragan", "Sergey Levine"], "keywords": ["image compression", "human-in-the-loop learning", "generative adversarial networks", "sequential decision-making", "pragmatics", "generative models"], "TL;DR": "We explore a new approach to lossy image compression that adapts compression to user behavior, optimizing reconstructions to be useful for downstream tasks instead of preserving visual appearance.", "abstract": "Standard lossy image compression algorithms aim to preserve an image's appearance, while minimizing the number of bits needed to transmit it. However, the amount of information actually needed by the user for downstream tasks -- e.g., deciding which product to click on in a shopping website -- is likely much lower. To achieve this lower bitrate, we would ideally only transmit the visual features that drive user behavior, while discarding details irrelevant to the user's decisions. We approach this problem by training a compression model through human-in-the-loop learning as the user performs tasks with the compressed images. The key insight is to train the model to produce a compressed image that induces the user to take the same action that they would have taken had they seen the original image. To approximate the loss function for this model, we train a discriminator that tries to distinguish whether a user's action was taken in response to the compressed image or the original. We evaluate our method through experiments with human participants on four tasks: reading handwritten digits, verifying photos of faces, browsing an online shopping catalogue, and playing a car racing video game. The results show that our method learns to match the user's actions with and without compression at lower bitrates than baseline methods, and adapts the compression model to the user's behavior: it preserves the digit number and randomizes handwriting style in the digit reading task, preserves hats and eyeglasses while randomizing faces in the photo verification task, preserves the perceived price of an item while randomizing its color and background in the online shopping task, and preserves upcoming bends in the road in the car racing game.", "pdf": "/pdf/79cb99290810594db351158f8044c117bed32c30.pdf", "supplementary_material": "/attachment/3ee250906d3c81c73b24efa004f46f40f5bb22d4.zip", "submission_history": "", "checklist": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "reddy|pragmatic_image_compression_for_humanintheloop_decisionmaking", "code": "https://github.com/rddy/pico", "thumbnail": "", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 2 code implementations](https://www.catalyzex.com/paper/arxiv:2108.04219/code)", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nreddy2021pragmatic,\ntitle={Pragmatic Image Compression for Human-in-the-Loop Decision-Making},\nauthor={Siddharth Reddy and Anca Dragan and Sergey Levine},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=ClwfZc4ooKM}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492788317, "odate": 1636492788317, "details": {"replyCount": 17}}, {"id": "B83B16bWvuI", "original": "MTONuKktNFN", "number": 1136, "cdate": 1621629727941, "ddate": null, "tcdate": 1621629727941, "tmdate": 1683307535794, "tddate": null, "forum": "B83B16bWvuI", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Near-optimal Offline and Streaming Algorithms for Learning Non-Linear Dynamical Systems", "authorids": ["~Suhas_S_Kowshik1", "~Dheeraj_Mysore_Nagaraj1", "~Prateek_Jain1", "~Praneeth_Netrapalli1"], "authors": ["Suhas S Kowshik", "Dheeraj Mysore Nagaraj", "Prateek Jain", "Praneeth Netrapalli"], "keywords": ["Non-Linear Dynamical Systems", "Learning with Dependent Data", "Streaming Algorithms", "Experience Replay"], "abstract": "We consider the setting of vector valued non-linear dynamical systems $X_{t+1} = \\phi(A^{*} X_t) + \\eta_t$, where $\\eta_t$ is unbiased noise and $\\phi : \\mathbb{R} \\to \\mathbb{R}$ is a known link function that satisfies certain {\\em expansivity property}. The goal is to learn $A^{*}$ from a single trajectory $X_1,\\cdots , X_T$ of {\\em dependent or correlated} samples.\n\tWhile the problem is well-studied in the linear case, where $\\phi$ is identity, with optimal error rates even for non-mixing systems, existing results in the non-linear case hold only for mixing systems. In this work, we improve existing results for learning nonlinear systems in a number of ways: a) we provide the first offline algorithm that can learn non-linear dynamical systems without the mixing assumption, b) we significantly improve upon the sample complexity of existing results for mixing systems, c) in the much harder one-pass, streaming setting we study a SGD with Reverse Experience Replay (SGD-RER) method, and demonstrate that for mixing systems, it achieves the same sample complexity as our offline algorithm, d) we justify the expansivity assumption by showing that for the popular ReLU  link function --- a non-expansive but easy to learn link function with i.i.d. samples --- any method would require exponentially many samples (with respect to dimension of $X_t$) from the dynamical system. We validate our results via. simulations and  demonstrate that a naive application of SGD can be highly sub-optimal. Indeed, our work demonstrates that for correlated data, specialized  methods designed for the dependency structure in data can  significantly outperform  standard SGD based methods. ", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "kowshik|nearoptimal_offline_and_streaming_algorithms_for_learning_nonlinear_dynamical_systems", "pdf": "/pdf/e59eceb0a8be8b2d1d7ccf8b2067b85ac25ac455.pdf", "supplementary_material": "/attachment/9bd1c561c4339c1f03fec6f4a1a6016f77151e8d.pdf", "checklist": "", "TL;DR": "We provide offline and streaming algorithms for learning non-linear dynamical systems from a single trajectory with i.i.d. data like performance.", "code": "/attachment/aef5be25660442c0900e5195e8640852ec989e4e.zip", "thumbnail": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nkowshik2021nearoptimal,\ntitle={Near-optimal Offline and Streaming Algorithms for Learning Non-Linear Dynamical Systems},\nauthor={Suhas S Kowshik and Dheeraj Mysore Nagaraj and Prateek Jain and Praneeth Netrapalli},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=B83B16bWvuI}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492755270, "odate": 1636492755270, "details": {"replyCount": 14}}, {"id": "gKyyBfMM4Y", "original": "e7sRWEoAsEd", "number": 1065, "cdate": 1621629723885, "ddate": null, "tcdate": 1621629723885, "tmdate": 1683307533499, "tddate": null, "forum": "gKyyBfMM4Y", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Adversarial Teacher-Student Representation Learning for Domain Generalization", "authorids": ["~Fu-En_Yang1", "~Yuan-Chia_Cheng1", "~Zu-Yun_Shiau1", "~Yu-Chiang_Frank_Wang2"], "authors": ["Fu-En Yang", "Yuan-Chia Cheng", "Zu-Yun Shiau", "Yu-Chiang Frank Wang"], "keywords": ["Domain Generalization", "Representation Learning", "Adversarial Learning"], "abstract": "Domain generalization (DG) aims to transfer the learning task from a single or multiple source domains to unseen target domains. To extract and leverage the information which exhibits sufficient generalization ability, we propose a simple yet effective approach of Adversarial Teacher-Student Representation Learning, with the goal of deriving the domain generalizable representations via generating and exploring out-of-source data distributions. Our proposed framework advances Teacher-Student learning in an adversarial learning manner, which alternates between knowledge-distillation based representation learning and novel-domain data augmentation. The former progressively updates the teacher network for deriving domain-generalizable representations, while the latter synthesizes data out-of-source yet plausible distributions. Extensive image classification experiments on benchmark datasets in multiple and single source DG settings confirm that, our model exhibits sufficient generalization ability and performs favorably against state-of-the-art DG methods.", "submission_history": "", "checklist": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "yang|adversarial_teacherstudent_representation_learning_for_domain_generalization", "pdf": "/pdf/1cdf585bb3ebc18cb4b30fdf1b83afe847e86b89.pdf", "supplementary_material": "/attachment/f1ede4aa3c2e356725a2afb0bce64816f72c1c04.pdf", "thumbnail": "", "TL;DR": "For DG problems, our proposed adversarial learning framework learns the domain generalizable representations via generating and exploring out-of-source data distributions.", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nyang2021adversarial,\ntitle={Adversarial Teacher-Student Representation Learning for Domain Generalization},\nauthor={Fu-En Yang and Yuan-Chia Cheng and Zu-Yun Shiau and Yu-Chiang Frank Wang},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=gKyyBfMM4Y}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492770672, "odate": 1636492770672, "details": {"replyCount": 16}}, {"id": "DPHsCQ8OpA", "original": "BzgpvZIXZAC", "number": 1024, "cdate": 1621629721642, "ddate": null, "tcdate": 1621629721642, "tmdate": 1697937731240, "tddate": null, "forum": "DPHsCQ8OpA", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Habitat 2.0: Training Home Assistants to Rearrange their Habitat", "authorids": ["~Andrew_Szot1", "~Alexander_Clegg1", "~Eric_Undersander2", "~Erik_Wijmans1", "~Yili_Zhao2", "~John_M_Turner1", "~Noah_D_Maestre1", "~Mustafa_Mukadam1", "~Devendra_Singh_Chaplot2", "~Oleksandr_Maksymets1", "~Aaron_Gokaslan1", "~Vladim\u00edr_Vondru\u01611", "~Sameer_Dharur1", "~Franziska_Meier2", "~Wojciech_Galuba1", "~Angel_X_Chang1", "~Zsolt_Kira1", "~Vladlen_Koltun1", "~Jitendra_Malik2", "~Manolis_Savva1", "~Dhruv_Batra1"], "authors": ["Andrew Szot", "Alexander Clegg", "Eric Undersander", "Erik Wijmans", "Yili Zhao", "John M Turner", "Noah D Maestre", "Mustafa Mukadam", "Devendra Singh Chaplot", "Oleksandr Maksymets", "Aaron Gokaslan", "Vladim\u00edr Vondru\u0161", "Sameer Dharur", "Franziska Meier", "Wojciech Galuba", "Angel X Chang", "Zsolt Kira", "Vladlen Koltun", "Jitendra Malik", "Manolis Savva", "Dhruv Batra"], "keywords": ["Benchmark", "Simulator", "Reinforcement Learning", "Embodied AI"], "abstract": "We introduce Habitat 2.0 (H2.0), a simulation platform for training virtual robots in interactive 3D environments and complex physics-enabled scenarios. We make comprehensive contributions to all levels of the embodied AI stack \u2013 data, simulation, and benchmark tasks. Specifically, we present: (i) ReplicaCAD: an artist-authored, annotated, reconfigurable 3D dataset of apartments (matching real spaces) with articulated objects (e.g. cabinets and drawers that can open/close); (ii) H2.0: a high-performance physics-enabled 3D simulator with speeds exceeding 25,000 simulation steps per second (850x real-time) on an 8-GPU node, representing 100x speed-ups over prior work; and, (iii) Home Assistant Benchmark (HAB): a suite of common tasks for assistive robots (tidy the house, stock groceries, set the table) that test a range of mobile manipulation capabilities. These large-scale engineering contributions allow us to systematically compare deep reinforcement learning (RL) at scale and classical sense-plan-act (SPA) pipelines in long-horizon structured tasks, with an emphasis on generalization to new objects, receptacles, and layouts. We find that (1) flat RL policies struggle on HAB compared to hierarchical ones; (2) a hierarchy with independent skills suffers from \u2018hand-off problems\u2019, and (3) SPA pipelines are more brittle than RL policies.", "pdf": "/pdf/856d8e0f743acc722768bb5dec11c439163ef5d6.pdf", "supplementary_material": "/attachment/45410866c7e54d2e120a638d2850be0885a737eb.pdf", "submission_history": "", "checklist": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "szot|habitat_20_training_home_assistants_to_rearrange_their_habitat", "code": "https://github.com/facebookresearch/habitat-lab", "thumbnail": "", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2106.14405/code)", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nszot2021habitat,\ntitle={Habitat 2.0: Training Home Assistants to Rearrange their Habitat},\nauthor={Andrew Szot and Alexander Clegg and Eric Undersander and Erik Wijmans and Yili Zhao and John M Turner and Noah D Maestre and Mustafa Mukadam and Devendra Singh Chaplot and Oleksandr Maksymets and Aaron Gokaslan and Vladim{\\'\\i}r Vondru{\\v{s}} and Sameer Dharur and Franziska Meier and Wojciech Galuba and Angel X Chang and Zsolt Kira and Vladlen Koltun and Jitendra Malik and Manolis Savva and Dhruv Batra},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=DPHsCQ8OpA}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492671763, "odate": 1636492671763, "details": {"replyCount": 20}}, {"id": "EvhsTX6GMyM", "original": "HAo0RKElsKr", "number": 1009, "cdate": 1621629720727, "ddate": null, "tcdate": 1621629720727, "tmdate": 1683307532384, "tddate": null, "forum": "EvhsTX6GMyM", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Conformal Prediction using Conditional Histograms", "authorids": ["~Matteo_Sesia1", "~Yaniv_Romano1"], "authors": ["Matteo Sesia", "Yaniv Romano"], "keywords": ["Conformal prediction", "quantile regression", "histograms", "skewed data."], "TL;DR": "This paper develops and studies a novel conformal method to compute prediction intervals that automatically adapt to skewed data.", "abstract": "This paper develops a conformal method to compute prediction intervals for non-parametric regression that can automatically adapt to skewed data. Leveraging black-box machine learning algorithms to estimate the conditional distribution of the outcome using histograms, it translates their output into the shortest prediction intervals with approximate conditional coverage. The resulting prediction intervals provably have marginal coverage in finite samples, while asymptotically achieving conditional coverage and optimal length if the black-box model is consistent. Numerical experiments with simulated and real data demonstrate improved performance compared to state-of-the-art alternatives, including conformalized quantile regression and other distributional conformal prediction approaches.", "pdf": "/pdf/2513bc1d2391f18d9afb8e5145067cf7a022d8a7.pdf", "supplementary_material": "/attachment/19a6121dc448cba80f40bf7e8041bb7b2337f1b7.pdf", "submission_history": "", "checklist": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "sesia|conformal_prediction_using_conditional_histograms", "code": "https://github.com/msesia/chr", "thumbnail": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nsesia2021conformal,\ntitle={Conformal Prediction using Conditional Histograms},\nauthor={Matteo Sesia and Yaniv Romano},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=EvhsTX6GMyM}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492768632, "odate": 1636492768632, "details": {"replyCount": 18}}, {"id": "xB4lGVLvXDz", "original": "H4IeCSqOd-d", "number": 985, "cdate": 1621629719576, "ddate": null, "tcdate": 1621629719576, "tmdate": 1683307531392, "tddate": null, "forum": "xB4lGVLvXDz", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Reliable Estimation of KL Divergence using a Discriminator in Reproducing Kernel Hilbert Space", "authorids": ["~Sandesh_Ghimire2", "~Aria_Masoomi1", "~Jennifer_Dy1"], "authors": ["Sandesh Ghimire", "Aria Masoomi", "Jennifer Dy"], "keywords": ["RKHS", "KL Divergence", "Sample Complexity", "Statistical Learning Theory", "Kernel Methods", "Bayesian inference", "Mutual Information", "Reliable estimation"], "abstract": "Estimating Kullback\u2013Leibler (KL) divergence from samples of two distributions is essential in many machine learning problems. Variational methods using neural network discriminator have been proposed to achieve this task in a scalable manner. However, we noticed that most of these methods using neural network discriminators suffer from high fluctuations (variance) in estimates and instability in training. In this paper, we look at this issue from statistical learning theory and function space complexity perspective to understand why this happens and how to solve it. We argue that the cause of these pathologies is lack of control over the complexity of the neural network discriminator function and could be mitigated by controlling it. To achieve this objective, we 1) present a novel construction of the discriminator in the Reproducing Kernel Hilbert Space (RKHS), 2) theoretically relate the error probability bound of the KL estimates to the complexity of the discriminator in the RKHS space, 3) present a scalable way to control the complexity (RKHS norm) of the discriminator for a reliable estimation of KL divergence, and 4) prove the consistency of the proposed estimator. In three different applications of KL divergence -- estimation of KL, estimation of mutual information and Variational Bayes -- we show that by controlling the complexity as developed in the theory, we are able to reduce the variance of KL estimates and stabilize the training.", "submission_history": "", "checklist": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "ghimire|reliable_estimation_of_kl_divergence_using_a_discriminator_in_reproducing_kernel_hilbert_space", "TL;DR": "We propose a new way to construct neural function such that it lies on RKHS; and use this function as discriminator to compute KL divergence from samples. We provide theoretical insights and consistency guarantee of the KL estimator.", "pdf": "/pdf/f17b3f0337df3f4db9d3dd071521d36ee989968f.pdf", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "supplementary_material": "/attachment/cc5339273b9baa39aef044a87b259d176d4cb3af.pdf", "code": "https://github.com/sandeshgh/Reliable-KL-estimation", "thumbnail": "", "_bibtex": "@inproceedings{\nghimire2021reliable,\ntitle={Reliable Estimation of {KL} Divergence using a Discriminator in Reproducing Kernel Hilbert Space},\nauthor={Sandesh Ghimire and Aria Masoomi and Jennifer Dy},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=xB4lGVLvXDz}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492723483, "odate": 1636492723483, "details": {"replyCount": 12}}, {"id": "Aeo-xqtb5p", "original": "WDZAwB5toTU", "number": 883, "cdate": 1621629713742, "ddate": null, "tcdate": 1621629713742, "tmdate": 1697937738433, "tddate": null, "forum": "Aeo-xqtb5p", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "IQ-Learn: Inverse soft-Q Learning for Imitation", "authorids": ["~Divyansh_Garg1", "~Shuvam_Chakraborty1", "~Chris_Cundy1", "~Jiaming_Song1", "~Stefano_Ermon1"], "authors": ["Divyansh Garg", "Shuvam Chakraborty", "Chris Cundy", "Jiaming Song", "Stefano Ermon"], "keywords": ["reinforcement learning", "imitation learning", "inverse reinforcement learning", "statistical learning", "energy-based models"], "abstract": "In many sequential decision-making problems (e.g., robotics control, game playing, sequential prediction), human or expert data is available containing useful information about the task. However, imitation learning (IL) from a small amount of expert data can be challenging in high-dimensional environments with complex dynamics. Behavioral cloning is a simple method that is widely used due to its simplicity of implementation and stable convergence but doesn't utilize any information involving the environment\u2019s dynamics. Many existing methods that exploit dynamics information are difficult to train in practice due to an adversarial optimization process over reward and policy approximators or biased, high variance gradient estimators. We introduce a method for dynamics-aware IL which avoids adversarial training by learning a single Q-function, implicitly representing both reward and policy. On standard benchmarks, the implicitly learned rewards show a high positive correlation with the ground-truth rewards, illustrating our method can also be used for inverse reinforcement learning (IRL). Our method, Inverse soft-Q learning (IQ-Learn) obtains state-of-the-art results in offline and online imitation learning settings, significantly outperforming existing methods both in the number of required environment interactions and scalability in high-dimensional spaces, often by more than 3x.", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "garg|iqlearn_inverse_softq_learning_for_imitation", "TL;DR": "Introduce a novel framework for learning soft-Q functions for IL; build a method that is performant even with very sparse expert data, and scales to complex image-based environments", "pdf": "/pdf/825fb10d27e212f8cbc68d8ba820a870490eb97e.pdf", "checklist": "", "supplementary_material": "/attachment/f23d2529ba42b3353afd33576160b27d467746f5.pdf", "code": "https://github.com/Div99/IQ-Learn", "thumbnail": "", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 2 code implementations](https://www.catalyzex.com/paper/arxiv:2106.12142/code)", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\ngarg2021iqlearn,\ntitle={{IQ}-Learn: Inverse soft-Q Learning for Imitation},\nauthor={Divyansh Garg and Shuvam Chakraborty and Chris Cundy and Jiaming Song and Stefano Ermon},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=Aeo-xqtb5p}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492691541, "odate": 1636492691541, "details": {"replyCount": 18}}, {"id": "XwetFe0U63c", "original": "1lYkck_foD", "number": 728, "cdate": 1621629704853, "ddate": null, "tcdate": 1621629704853, "tmdate": 1697937745289, "tddate": null, "forum": "XwetFe0U63c", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Second-Order Neural ODE Optimizer", "authorids": ["~Guan-Horng_Liu1", "~Tianrong_Chen1", "~Evangelos_Theodorou1"], "authors": ["Guan-Horng Liu", "Tianrong Chen", "Evangelos Theodorou"], "keywords": ["Neural ODEs", "second-order optimization", "continuous-time optimal control"], "TL;DR": " An efficient second-order optimizer for training Neural ODEs that achieves superior convergence against first-order methods in wall-clock time on various applications. ", "abstract": "We propose a novel second-order optimization framework for training the emerging deep continuous-time models, specifically the Neural Ordinary Differential Equations (Neural ODEs). Since their training already involves expensive gradient computation by solving a backward ODE, deriving efficient second-order methods becomes highly nontrivial. Nevertheless, inspired by the recent Optimal Control (OC) interpretation of training deep networks, we show that a specific continuous-time OC methodology, called Differential Programming, can be adopted to derive backward ODEs for higher-order derivatives at the same O(1) memory cost. We further explore a low-rank representation of the second-order derivatives and show that it leads to efficient preconditioned updates with the aid of Kronecker-based factorization. The resulting method \u2013 named SNOpt \u2013 converges much faster than first-order baselines in wall-clock time, and the improvement remains consistent across various applications, e.g. image classification, generative flow, and time-series prediction. Our framework also enables direct architecture optimization, such as the integration time of Neural ODEs, with second-order feedback policies, strengthening the OC perspective as a principled tool of analyzing optimization in deep learning. Our code is available at https://github.com/ghliu/snopt.", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "liu|secondorder_neural_ode_optimizer", "pdf": "/pdf/f268d42fb7acd37f444025c07de930195f84d09c.pdf", "supplementary_material": "/attachment/fa2ea85da92eafc52e0903f25f20c02b0d6c1b70.pdf", "checklist": "", "thumbnail": "", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 3 code implementations](https://www.catalyzex.com/paper/arxiv:2109.14158/code)", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nliu2021secondorder,\ntitle={Second-Order Neural {ODE} Optimizer},\nauthor={Guan-Horng Liu and Tianrong Chen and Evangelos Theodorou},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=XwetFe0U63c}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492676127, "odate": 1636492676127, "details": {"replyCount": 16}}, {"id": "aohkNJxjYJX", "original": "Cp6mtZsyjbw", "number": 590, "cdate": 1621629697460, "ddate": null, "tcdate": 1621629697460, "tmdate": 1697937748516, "tddate": null, "forum": "aohkNJxjYJX", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Long Short-Term Transformer for Online Action Detection", "authorids": ["~Mingze_Xu2", "~Yuanjun_Xiong3", "~Hao_Chen16", "~Xinyu_Li4", "~Wei_Xia6", "~Zhuowen_Tu1", "~Stefano_Soatto1"], "authors": ["Mingze Xu", "Yuanjun Xiong", "Hao Chen", "Xinyu Li", "Wei Xia", "Zhuowen Tu", "Stefano Soatto"], "keywords": ["Online Action Detection", "Action and Behavior Recognition", "Video Analysis", "Transformers", "Recurrent Neural Networks"], "abstract": "We present Long Short-term TRansformer (LSTR), a temporal modeling algorithm for online action detection, which employs a long- and short-term memory mechanism to model prolonged sequence data. It consists of an LSTR encoder that dynamically leverages coarse-scale historical information from an extended temporal window (e.g., 2048 frames spanning of up to 8 minutes), together with an LSTR decoder that focuses on a short time window (e.g., 32 frames spanning 8 seconds) to model the fine-scale characteristics of the data. Compared to prior work, LSTR provides an effective and efficient method to model long videos with fewer heuristics, which is validated by extensive empirical analysis. LSTR achieves state-of-the-art performance on three standard online action detection benchmarks, THUMOS'14, TVSeries, and HACS Segment. Code has been made available at: https://xumingze0308.github.io/projects/lstr.", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "xu|long_shortterm_transformer_for_online_action_detection", "TL;DR": "We propose a new Transformer based architecture for online action detection by employing a long- and short-term memory mechanism that models prolonged sequence data.", "pdf": "/pdf/acce77e3ced15a3f99ea164d38198a40c03e9d3b.pdf", "checklist": "", "supplementary_material": "/attachment/d8b4e7a0a6c33e4f065dd576864edd13b1d91206.pdf", "thumbnail": "", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2107.03377/code)", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nxu2021long,\ntitle={Long Short-Term Transformer for Online Action Detection},\nauthor={Mingze Xu and Yuanjun Xiong and Hao Chen and Xinyu Li and Wei Xia and Zhuowen Tu and Stefano Soatto},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=aohkNJxjYJX}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492692368, "odate": 1636492692368, "details": {"replyCount": 14}}, {"id": "bc-f0ZBNker", "original": "jIpYCg5oxmb", "number": 579, "cdate": 1621629696842, "ddate": null, "tcdate": 1621629696842, "tmdate": 1683307522804, "tddate": null, "forum": "bc-f0ZBNker", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Representation Learning Beyond Linear Prediction Functions", "authorids": ["~Ziping_Xu1", "~Ambuj_Tewari1"], "authors": ["Ziping Xu", "Ambuj Tewari"], "keywords": ["Representation Learning", "Few Shot Learning", "Multitask Learning"], "TL;DR": "We show that it requires exponentially many source tasks to learn a representation that can generalize when the prediction function class is nonlinear.", "abstract": "Recent papers on the theory of representation learning has shown the importance of a quantity called diversity when generalizing from a set of source tasks to a target task. Most of these papers assume that the function mapping shared representations to predictions is linear, for both source and target tasks. In practice, researchers in deep learning use different numbers of extra layers following the pretrained model based on the difficulty of the new task. This motivates us to ask whether diversity can be achieved when source tasks and the target task use different prediction function spaces beyond linear functions. We show that diversity holds even if the target task uses a neural network with multiple layers, as long as source tasks use linear functions. If source tasks use nonlinear prediction functions, we provide a negative result by showing that depth-1 neural networks with ReLu activation function need exponentially many source tasks to achieve diversity. For a general function class, we find that eluder dimension gives a lower bound on the number of tasks required for diversity. Our theoretical results imply that simpler tasks generalize better. Though our theoretical results are shown for the global minimizer of empirical risks, their qualitative predictions still hold true for gradient-based optimization algorithms as verified by our simulations on deep neural networks.", "pdf": "/pdf/526705ff61f5b88191baebc7f9f5f1e0b035dbd4.pdf", "supplementary_material": "/attachment/8d618b40db93f5c439d1524ff83b662ae0266888.pdf", "submission_history": "", "checklist": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "xu|representation_learning_beyond_linear_prediction_functions", "code": "/attachment/2efa853c264c14c5901257bec0103073fc9b83cc.zip", "thumbnail": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nxu2021representation,\ntitle={Representation Learning Beyond Linear Prediction Functions},\nauthor={Ziping Xu and Ambuj Tewari},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=bc-f0ZBNker}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492787849, "odate": 1636492787849, "details": {"replyCount": 11}}, {"id": "zAuDbrHC6fq", "original": "5MIG13WXliN", "number": 555, "cdate": 1621629695416, "ddate": null, "tcdate": 1621629695416, "tmdate": 1683307522035, "tddate": null, "forum": "zAuDbrHC6fq", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Aligned Structured Sparsity Learning for Efficient Image Super-Resolution", "authorids": ["~Yulun_Zhang1", "~Huan_Wang3", "~Can_Qin1", "~Yun_Fu1"], "authors": ["Yulun Zhang", "Huan Wang", "Can Qin", "Yun Fu"], "keywords": ["Neural Network Pruning", "Lightweight Image Super-Resolution", "Aligned Structured Sparsity Learning"], "abstract": "Lightweight image super-resolution (SR) networks have obtained promising results with moderate model size. Many SR methods have focused on designing lightweight architectures, which neglect to further reduce the redundancy of network parameters. On the other hand, model compression techniques, like neural architecture search and knowledge distillation, typically consume considerable memory and computation resources. In contrast, network pruning is a cheap and effective model compression technique. However, it is hard to be applied to SR networks directly, because filter pruning for residual blocks is well-known tricky. To address the above issues, we propose aligned structured sparsity learning (ASSL), which introduces a weight normalization layer and applies $L_2$ regularization to the scale parameters for sparsity. To align the pruned locations across different layers, we propose a \\emph{sparsity structure alignment} penalty term, which minimizes the norm of soft mask gram matrix. We apply aligned structured sparsity learning strategy to train efficient image SR network, named as ASSLN, with smaller model size and lower computation than state-of-the-art methods. We conduct extensive comparisons with lightweight SR networks. Our ASSLN achieves superior performance gains over recent methods quantitatively and visually.", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "zhang|aligned_structured_sparsity_learning_for_efficient_image_superresolution", "TL;DR": "Optimize image SR networks with network pruning simultaneously and achieve SOTA results", "pdf": "/pdf/e913bbc7caee9b11a9a70c1d1094df9563ffaa17.pdf", "checklist": "", "supplementary_material": "/attachment/5c4711c1c6e821b0ea607dcad2fdd7da6717080d.pdf", "code": "https://github.com/MingSun-Tse/ASSL", "thumbnail": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nzhang2021aligned,\ntitle={Aligned Structured Sparsity Learning for Efficient Image Super-Resolution},\nauthor={Yulun Zhang and Huan Wang and Can Qin and Yun Fu},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=zAuDbrHC6fq}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492706077, "odate": 1636492706022, "details": {"replyCount": 8}}, {"id": "877bJocr-w", "original": "XRrVEKSOcym", "number": 552, "cdate": 1621629695236, "ddate": null, "tcdate": 1621629695236, "tmdate": 1683307522031, "tddate": null, "forum": "877bJocr-w", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Image Generation using Continuous Filter Atoms", "authorids": ["~Ze_Wang3", "~Seunghyun_Hwang1", "~Zichen_Miao1", "~Qiang_Qiu1"], "authors": ["Ze Wang", "Seunghyun Hwang", "Zichen Miao", "Qiang Qiu"], "keywords": ["Conditional image generation", "neural ordinary differential equations", "convolutional filter decomposition", "continuous image generation"], "abstract": "In this paper, we model the subspace of convolutional filters with a neural ordinary differential equation (ODE) to enable gradual changes in generated images. Decomposing convolutional filters over a set of filter atoms allows efficiently modeling and sampling from a subspace of high-dimensional filters. By further modeling filters atoms with a neural ODE, we show both empirically and theoretically that such introduced continuity can be propagated to the generated images, and thus achieves gradually evolved image generation. We support the proposed framework of image generation with continuous filter atoms using various experiments, including image-to-image translation and image generation conditioned on continuous labels. Without auxiliary network components and heavy supervision, the proposed continuous filter atoms allow us to easily manipulate the gradual change of generated images by controlling integration intervals of neural ordinary differential equation. This research sheds the light on using the subspace of network parameters to navigate the diverse appearance of image generation.", "submission_history": "", "checklist": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "wang|image_generation_using_continuous_filter_atoms", "pdf": "/pdf/30fabfcfacaf63c64e7d5654f39192efe2786f76.pdf", "supplementary_material": "/attachment/f03677a17755dffde6599b1daa850ade54feb0ce.pdf", "thumbnail": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nwang2021image,\ntitle={Image Generation using Continuous Filter Atoms},\nauthor={Ze Wang and Seunghyun Hwang and Zichen Miao and Qiang Qiu},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=877bJocr-w}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492700185, "odate": 1636492700185, "details": {"replyCount": 13}}, {"id": "PIcuKeiWvj-", "original": "K9DLzcPiljF", "number": 536, "cdate": 1621629694432, "ddate": null, "tcdate": 1621629694432, "tmdate": 1697937751087, "tddate": null, "forum": "PIcuKeiWvj-", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Explaining Latent Representations with a Corpus of Examples", "authorids": ["~Jonathan_Crabb\u00e91", "~Zhaozhi_Qian1", "~Fergus_Imrie1", "~Mihaela_van_der_Schaar2"], "authors": ["Jonathan Crabb\u00e9", "Zhaozhi Qian", "Fergus Imrie", "Mihaela van der Schaar"], "keywords": ["explainability", "interpretability", "latent", "representation", "decomposition", "exampled-based", "explanation", "feature-based", "feature", "importance"], "TL;DR": "We introduce SimplEx, a method that decomposes latent representations of test examples in terms of the representations of a corpus of examples.", "abstract": "Modern machine learning models are complicated. Most of them rely on convoluted latent representations of their input to issue a prediction. To achieve greater transparency than a black-box that connects inputs to predictions, it is necessary to gain a deeper understanding of these latent representations. To that aim, we propose SimplEx: a user-centred method that provides example-based explanations with reference to a freely selected set of examples, called the corpus. SimplEx uses the corpus to improve the user\u2019s understanding of the latent space with post-hoc explanations answering two questions: (1) Which corpus examples explain the prediction issued for a given test example? (2) What features of these corpus examples are relevant for the model to relate them to the test example? SimplEx provides an answer by reconstructing the test latent representation as a mixture of corpus latent representations. Further, we propose a novel approach, the integrated Jacobian, that allows SimplEx to make explicit the contribution of each corpus feature in the mixture. Through experiments on tasks ranging from mortality prediction to image classification, we demonstrate that these decompositions are robust and accurate. With illustrative use cases in medicine, we show that SimplEx empowers the user by highlighting relevant patterns in the corpus that explain model representations. Moreover, we demonstrate how the freedom in choosing the corpus allows the user to have personalized explanations in terms of examples that are meaningful for them.\n\n", "pdf": "/pdf/d1970978fa5228a8887d9250c4a50098f2b0686a.pdf", "submission_history": "", "checklist": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "crabb\u00e9|explaining_latent_representations_with_a_corpus_of_examples", "supplementary_material": "/attachment/38e6387d4077a9a769e8c0937b9a1452036c0a8a.pdf", "code": "https://github.com/JonathanCrabbe/Simplex", "thumbnail": "", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2110.15355/code)", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\ncrabb{\\'e}2021explaining,\ntitle={Explaining Latent Representations with a Corpus of Examples},\nauthor={Jonathan Crabb{\\'e} and Zhaozhi Qian and Fergus Imrie and Mihaela van der Schaar},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=PIcuKeiWvj-}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492766670, "odate": 1636492766670, "details": {"replyCount": 16}}, {"id": "OkFPq7ZtsQ", "original": "a8AvaqOlnCz", "number": 327, "cdate": 1621629683304, "ddate": null, "tcdate": 1621629683304, "tmdate": 1683307519040, "tddate": null, "forum": "OkFPq7ZtsQ", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Prototypical Cross-Attention Networks for Multiple Object Tracking and Segmentation", "authorids": ["~Lei_Ke1", "~Xia_Li3", "~Martin_Danelljan4", "~Yu-Wing_Tai2", "~Chi-Keung_Tang1", "~Fisher_Yu2"], "authors": ["Lei Ke", "Xia Li", "Martin Danelljan", "Yu-Wing Tai", "Chi-Keung Tang", "Fisher Yu"], "keywords": ["multiple object tracking and segmentation", "video instance segmentation", "efficient cross-attention networks", "space-time memory"], "abstract": "Multiple object tracking and segmentation requires detecting, tracking, and segmenting objects belonging to a set of given classes. Most approaches only exploit the temporal dimension to address the association problem, while relying on single frame predictions for the segmentation mask itself. We propose Prototypical Cross-Attention Network (PCAN), capable of leveraging rich spatio-temporal information for online multiple object tracking and segmentation. PCAN first distills a space-time memory into a set of prototypes and then employs cross-attention to retrieve rich information from the past frames. To segment each object, PCAN adopts a prototypical appearance module to learn a set of contrastive foreground and background prototypes, which are then propagated over time. Extensive experiments demonstrate that PCAN outperforms current video instance tracking and segmentation competition winners on both Youtube-VIS and BDD100K datasets, and shows efficacy to both one-stage and two-stage segmentation frameworks. Code and video resources are available at http://vis.xyz/pub/pcan.", "submission_history": "", "checklist": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "ke|prototypical_crossattention_networks_for_multiple_object_tracking_and_segmentation", "pdf": "/pdf/c5cb01ad4f3f209cee2fb4bfccc8e3cb1d1ec7b4.pdf", "supplementary_material": "/attachment/acdf5ecd0d24df872985030342ded6ed80e660fe.pdf", "TL;DR": "We design efficient cross-attention networks (PCAN) for multiple object tracking and segmentation.", "code": "https://github.com/SysCV/pcan", "thumbnail": "", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nke2021prototypical,\ntitle={Prototypical Cross-Attention Networks for Multiple Object Tracking and Segmentation},\nauthor={Lei Ke and Xia Li and Martin Danelljan and Yu-Wing Tai and Chi-Keung Tang and Fisher Yu},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=OkFPq7ZtsQ}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492672837, "odate": 1636492672792, "details": {"replyCount": 13}}, {"id": "0lz69oI5iZP", "original": "aI8oaBOJRn", "number": 312, "cdate": 1621629682573, "ddate": null, "tcdate": 1621629682573, "tmdate": 1697937756244, "tddate": null, "forum": "0lz69oI5iZP", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "Per-Pixel Classification is Not All You Need for Semantic Segmentation", "authorids": ["~Bowen_Cheng1", "~Alex_Schwing1", "~Alexander_Kirillov1"], "authors": ["Bowen Cheng", "Alex Schwing", "Alexander Kirillov"], "keywords": ["semantic segmentation", "panoptic segmentation", "mask classification"], "TL;DR": "Mask classification permits use of the exact same model, loss, and training for both semantic- and instance-level segmentation while achieving state-of-the-art results on semantic segmentation.", "abstract": "Modern approaches typically formulate semantic segmentation as a per-pixel classification task, while instance-level segmentation is handled with an alternative mask classification. Our key insight: mask classification is sufficiently general to solve both semantic- and instance-level segmentation tasks in a unified manner using the exact same model, loss, and training procedure. Following this observation, we propose MaskFormer, a simple mask classification model which predicts a set of binary masks, each associated with a single global class label prediction. Overall, the proposed mask classification-based method simplifies the landscape of effective approaches to semantic and panoptic segmentation tasks and shows excellent empirical results. In particular, we observe that MaskFormer outperforms per-pixel classification baselines when the number of classes is large. Our mask classification-based method outperforms both current state-of-the-art semantic (55.6 mIoU on ADE20K) and panoptic segmentation (52.7 PQ on COCO) models.", "submission_history": "", "checklist": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "cheng|perpixel_classification_is_not_all_you_need_for_semantic_segmentation", "pdf": "/pdf/dc21d6ec8f22b0d143843cb699099e05dc424472.pdf", "supplementary_material": "/attachment/b7f0f2eb78b86e0560dc6a1778056eb2cc25071b.pdf", "code": "https://github.com/facebookresearch/MaskFormer", "thumbnail": "", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 1 code implementation](https://www.catalyzex.com/paper/arxiv:2107.06278/code)", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\ncheng2021perpixel,\ntitle={Per-Pixel Classification is Not All You Need for Semantic Segmentation},\nauthor={Bowen Cheng and Alex Schwing and Alexander Kirillov},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=0lz69oI5iZP}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492766753, "odate": 1636492766753, "details": {"replyCount": 13}}, {"id": "rndqBJsGoKh", "original": "GSYN69nEEyD", "number": 209, "cdate": 1621629676749, "ddate": null, "tcdate": 1621629676749, "tmdate": 1697937759850, "tddate": null, "forum": "rndqBJsGoKh", "replyto": null, "invitation": "NeurIPS.cc/2021/Conference/-/Blind_Submission", "content": {"title": "SOFT: Softmax-free Transformer with Linear Complexity", "authorids": ["~Jiachen_Lu1", "~Jinghan_Yao1", "~Junge_Zhang2", "~Xiatian_Zhu3", "~Hang_Xu1", "~Weiguo_Gao1", "~Chunjing_Xu1", "~Tao_Xiang1", "~Li_Zhang5"], "authors": ["Jiachen Lu", "Jinghan Yao", "Junge Zhang", "Xiatian Zhu", "Hang Xu", "Weiguo Gao", "Chunjing Xu", "Tao Xiang", "Li Zhang"], "keywords": ["Transformer"], "abstract": "Vision transformers (ViTs) have pushed the state-of-the-art for various visual recognition tasks by patch-wise image tokenization followed by self-attention. However, the employment of self-attention modules results in a quadratic complexity in both computation and memory usage. Various attempts on approximating the self-attention computation with linear complexity have been made in Natural Language Processing. However, an in-depth analysis in this work shows that they are either theoretically flawed or empirically ineffective for visual recognition. We further identify that their limitations are rooted in keeping the softmax self-attention during approximations.  Specifically, conventional self-attention is computed by normalizing the scaled dot-product between token feature vectors. Keeping this softmax operation challenges any subsequent linearization efforts. Based on this insight, for the first time, a softmax-free transformer or  SOFT is proposed. To remove softmax in self-attention,  Gaussian kernel function is used to replace the dot-product similarity without further normalization. This enables a full self-attention matrix to be approximated via a low-rank  matrix decomposition. The robustness of the approximation is achieved by calculating its Moore-Penrose inverse using  a  Newton-Raphson method. Extensive experiments on ImageNet show that our SOFT significantly improves the computational efficiency of existing ViT variants. Crucially, with a linear complexity, much longer token sequences are permitted in SOFT, resulting in superior trade-off between accuracy and complexity.", "submission_history": "", "code_of_conduct": "I certify that all co-authors of this work have read and commit to adhering to the NeurIPS Statement on Ethics, Fairness, Inclusivity, and Code of Conduct.", "paperhash": "lu|soft_softmaxfree_transformer_with_linear_complexity", "pdf": "/pdf/82d037021c14fd9ad0eaeebebd048f59a1696e5a.pdf", "checklist": "", "supplementary_material": "/attachment/d82238a59b82dec9675d8318a36ab8b565d82502.pdf", "thumbnail": "", "community_implementations": "[![CatalyzeX](/images/catalyzex_icon.svg) 2 code implementations](https://www.catalyzex.com/paper/arxiv:2110.11945/code)", "submission_history_-_venue_and_year": "", "submission_history_-_improvements_made": "", "_bibtex": "@inproceedings{\nlu2021soft,\ntitle={{SOFT}: Softmax-free Transformer with Linear Complexity},\nauthor={Jiachen Lu and Jinghan Yao and Junge Zhang and Xiatian Zhu and Hang Xu and Weiguo Gao and Chunjing Xu and Tao Xiang and Li Zhang},\nbooktitle={Advances in Neural Information Processing Systems},\neditor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},\nyear={2021},\nurl={https://openreview.net/forum?id=rndqBJsGoKh}\n}", "venue": "NeurIPS 2021 Spotlight", "venueid": "NeurIPS.cc/2021/Conference"}, "signatures": ["NeurIPS.cc/2021/Conference"], "readers": ["everyone"], "nonreaders": [], "writers": ["NeurIPS.cc/2021/Conference"], "mdate": null, "pdate": 1636492670797, "odate": 1636492670797, "details": {"replyCount": 12}}], "count": 284}